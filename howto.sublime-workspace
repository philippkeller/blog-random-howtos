{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"dest",
				"dest_filename"
			],
			[
				"des",
				"dest_bucketname"
			],
			[
				"S",
				"S3_FILE"
			],
			[
				"if",
				"ifmain\tif __name__ == '__main__'"
			],
			[
				"max",
				"max_1plus_cows"
			],
			[
				"start",
				"start_time"
			],
			[
				"star",
				"start_time"
			],
			[
				"ma",
				"max_0_cows"
			],
			[
				"sta",
				"start_time"
			],
			[
				"global",
				"globalMaxVal"
			],
			[
				"time",
				"timedelta"
			],
			[
				"num",
				"number_of_lines"
			],
			[
				"re",
				"replace_album"
			],
			[
				"ex",
				"external_port"
			],
			[
				"exte",
				"external_hostname"
			],
			[
				"se",
				"search_terms"
			],
			[
				"in",
				"internal_ip"
			],
			[
				"get",
				"get_sonos_device"
			],
			[
				"acc",
				"access_token"
			],
			[
				"cre",
				"credential_path"
			],
			[
				"from",
				"from_number"
			],
			[
				"SC",
				"SCRIPT_DIR"
			],
			[
				"retur",
				"return_list"
			],
			[
				"tim",
				"timer_return"
			],
			[
				"shar",
				"shared_dict"
			],
			[
				"pri",
				"price_container"
			],
			[
				"par",
				"parts_sorted"
			],
			[
				"po",
				"possible_list"
			],
			[
				"user",
				"user_agent"
			],
			[
				"clien",
				"client_secret"
			],
			[
				"line",
				"line_formatted"
			],
			[
				"mat",
				"matchingSet2Record"
			],
			[
				"s",
				"set1Record"
			],
			[
				"i",
				"ifmain\tif __name__ == '__main__'"
			]
		]
	},
	"buffers":
	[
		{
			"file": "source/_posts/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF.md",
			"settings":
			{
				"buffer_size": 12966,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"contents": "Searching 10383 files for \"gutter\" (regex)\n\n/home/philipp/blogs/howto/db.json:\n    1: {\"meta\":{\"version\":1,\"warehouse\":\"2.2.0\"},\"models\":{\"Asset\":[{\"_id\":\"source/CNAME\",\"path\":\"CNAME\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/favicon.png\",\"path\":\"favicon.png\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/images/automate.jpg\",\"path\":\"images/automate.jpg\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/images/scan_flow.png\",\"path\":\"images/scan_flow.png\",\"modified\":1,\"renderable\":0},{\"_id\":\"source/images/asha-302.jpg\",\"path\":\"images/asha-302.jpg\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/images/etcher.png\",\"path\":\"images/etcher.png\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/images/tape.jpg\",\"path\":\"images/tape.jpg\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/images/pi.jpg\",\"path\":\"images/pi.jpg\",\"modified\":0,\"renderable\":0},{\"_id\":\"source/images/screenshot.png\",\"path\":\"images/screenshot.png\",\"modified\":0,\"renderable\":0},{\"_id\":\"themes/ewal/source/fancybox/blank.gif\",\"path\":\"fancybox/blank.gif\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fancybox/fancybox_loading.gif\",\"path\":\"fancybox/fancybox_loading.gif\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fancybox/fancybox_overlay.png\",\"path\":\"fancybox/fancybox_overlay.png\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fancybox/fancybox_sprite.png\",\"path\":\"fancybox/fancybox_sprite.png\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fancybox/jquery.fancybox.css\",\"path\":\"fancybox/jquery.fancybox.css\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fancybox/jquery.fancybox.pack.js\",\"path\":\"fancybox/jquery.fancybox.pack.js\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.eot\",\"path\":\"fonts/glyphicons-halflings-regular.eot\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.ttf\",\"path\":\"fonts/glyphicons-halflings-regular.ttf\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.woff\",\"path\":\"fonts/glyphicons-halflings-regular.woff\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.svg\",\"path\":\"fonts/glyphicons-halflings-regular.svg\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/css/captionjs.min.css\",\"path\":\"css/captionjs.min.css\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/css/site.less\",\"path\":\"css/site.less\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/js/ewal.js\",\"path\":\"js/ewal.js\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/js/jquery.caption.min.js\",\"path\":\"js/jquery.caption.min.js\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/js/jquery.min.js\",\"path\":\"js/jquery.min.js\",\"modified\":0,\"renderable\":1},{\"_id\":\"themes/ewal/source/css/highlightjs/solarized_dark.css\",\"path\":\"css/highlightjs/solarized_dark.css\",\"modified\":0,\"renderable\":1}],\"Cache\":[{\"_id\":\"source/CNAME\",\"hash\":\"578d77e8c53c31ce7fb1aaea595e0520828fb209\",\"modified\":1510396275576},{\"_id\":\"source/favicon.png\",\"hash\":\"48142d78d1ba2d449f6b0a9c695a018e5798e3fc\",\"modified\":1355176732000},{\"_id\":\"themes/ewal/.gitignore\",\"hash\":\"28b5c12b152cdf48f02e36afd6527d5a1bd3f0d6\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/LICENSE\",\"hash\":\"d187c7f941659f6f32e49be66f063cfd43130957\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/README.md\",\"hash\":\"f3d93e0245b9a6773f7e3548b474d3698f49c4b0\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/_config.yml\",\"hash\":\"14d9f6c442c8411ff989239bfca3071200bece53\",\"modified\":1510385699213},{\"_id\":\"source/_posts/Django-Serve-big-files-via-fcgid.md\",\"hash\":\"9daf2eb440824da90fa386eb54799de9047fbf4f\",\"modified\":1510434757408},{\"_id\":\"source/_posts/Automated-tag-clustering.md\",\"hash\":\"4c34532c5b401a167d4b3cf22df29ec36fcfb53b\",\"modified\":1510435121798},{\"_id\":\"source/_posts/Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet.md\",\"hash\":\"54e0a084f1ee087ba95612fe4af4d34e67053764\",\"modified\":1511968730173},{\"_id\":\"source/_posts/How-to-mass-convert-mp3-files-to-aac-m3a.md\",\"hash\":\"35839572484a7d77114a9370a6eeeddb7a061724\",\"modified\":1512136127198},{\"_id\":\"source/_posts/How-to-attach-a-file-to-google-spreadsheet.md\",\"hash\":\"006f3de651dcd5e0838924284789cc4b50468c78\",\"modified\":1510434954261},{\"_id\":\"source/_posts/How-to-reset-Jambox-when-bluetooth-completely-stopped-working.md\",\"hash\":\"4e1c36441a32b3af2d403584c55e9344f6321fa7\",\"modified\":1510470753757},{\"_id\":\"source/_posts/How-to-streamline-cd-ripping-without-tagging-track-data.md\",\"hash\":\"8e7a96d3da40c4ab1cc78fb1da589c63116ec7fd\",\"modified\":1512819157501},{\"_id\":\"source/_posts/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi.md\",\"hash\":\"882ac99169d04d537ed99268a911da734c6d2f49\",\"modified\":1516446776388},{\"_id\":\"source/_posts/Python-Find-out-cpu-time-of-a-certain-process.md\",\"hash\":\"85ea82f58d9df655193f14abeadc85ee1408df6d\",\"modified\":1510434741440},{\"_id\":\"source/_posts/Python-Print-list-of-dicts-as-ascii-table.md\",\"hash\":\"db937b02261d71807c32e806aa24d06cffc68e88\",\"modified\":1510384545012},{\"_id\":\"source/_posts/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF.md\",\"hash\":\"2270373a811bd5722f85ecd9d4f22afdc3059a48\",\"modified\":1516654556210},{\"_id\":\"source/_posts/Send-javascript-errors-by-mail.md\",\"hash\":\"4e16a3be92cff47d2719473e406af10807bafc96\",\"modified\":1510434774445},{\"_id\":\"source/_posts/Tag-history-and-gartners-hype-cycles.md\",\"hash\":\"9c7a149f2c6bed5ce83df687131c66e916b5acf9\",\"modified\":1510435142432},{\"_id\":\"source/_posts/Tags-with-MySQL-fulltext.md\",\"hash\":\"6098b8c8c1ca2eb274797f12eeefce22b31c7987\",\"modified\":1510435061579},{\"_id\":\"source/_posts/Turn-demoscene-modules-into-mp3s.md\",\"hash\":\"68ded155f417ce2f0c77b4b058b14799a402800f\",\"modified\":1510434536692},{\"_id\":\"source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5.md\",\"hash\":\"47713922c8cb9b28e1f628219dad8ce507313e0f\",\"modified\":1510470709371},{\"_id\":\"source/_posts/Tags-Database-schemas.md\",\"hash\":\"1b2bd24e4a1856fdc5cc808dc2312278b265029a\",\"modified\":1510514112638},{\"_id\":\"source/_posts/how-to-fix-jambox-static-noise.md\",\"hash\":\"d03d7b1dc4f15a6a467ee90e745a2873a3a55c61\",\"modified\":1510470793634},{\"_id\":\"source/_posts/set-timeout-for-a-shell-command-in-python.md\",\"hash\":\"811359a45efcb261bde0474880cd5fb633bcddc6\",\"modified\":1510434680003},{\"_id\":\"source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL.md\",\"hash\":\"86d3474858499184a2d7d35cff592efd5dc418d7\",\"modified\":1510470564902},{\"_id\":\"source/_posts/Tagsystems-performance-tests.md\",\"hash\":\"d33546ea9e06f52d70cf562387600a18a18c0964\",\"modified\":1510435074698},{\"_id\":\"source/_posts/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments.md\",\"hash\":\"0c4ee35cbb58a09e1648f45751bc63648421e660\",\"modified\":1510434844026},{\"_id\":\"source/images/automate.jpg\",\"hash\":\"47ca84b0d7035021fcbaf84555473eb9eb7eea48\",\"modified\":1512819141933},{\"_id\":\"source/images/scan_flow.png\",\"hash\":\"8913cc5c25f85b39e8771b914faf64dd4d75c4f0\",\"modified\":1516654111867},{\"_id\":\"source/images/asha-302.jpg\",\"hash\":\"5bd531eddd52007987ed53513a4c642734bcd9e9\",\"modified\":1330338742000},{\"_id\":\"source/images/etcher.png\",\"hash\":\"adcbf2f3e3d3ba119afd06cb19b53431dea6731b\",\"modified\":1516437769818},{\"_id\":\"themes/ewal/.git/HEAD\",\"hash\":\"acbaef275e46a7f14c1ef456fff2c8bbe8c84724\",\"modified\":1510384995474},{\"_id\":\"source/images/tape.jpg\",\"hash\":\"20f50b97c3b9d955dc5ee4a09ecd87026463dc88\",\"modified\":1512057466556},{\"_id\":\"source/images/pi.jpg\",\"hash\":\"5e36f5c79e1edbe68804fff1d89e7c36265321cb\",\"modified\":1442675945000},{\"_id\":\"themes/ewal/.git/config\",\"hash\":\"941e52f295ec3366e7dc21df9335fee2a85a6276\",\"modified\":1510384995474},{\"_id\":\"themes/ewal/.git/description\",\"hash\":\"9635f1b7e12c045212819dd934d809ef07efa2f4\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/packed-refs\",\"hash\":\"204a950ddc0523391f8e53c4d8bba57ebdf9bc06\",\"modified\":1510384995470},{\"_id\":\"themes/ewal/languages/de.yml\",\"hash\":\"8000e3f7e3c94e08b7045a29551b6adf8c73f4b6\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/languages/default.yml\",\"hash\":\"f7bd84543ce79c448217f418394abc68b57378cf\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/languages/en.yml\",\"hash\":\"4924d8f7a01daf31f71a04aa4c605e932a667cb2\",\"modified\":1516438120714},{\"_id\":\"themes/ewal/languages/ru.yml\",\"hash\":\"648e58f47931ae71915e39cd17d97896e4bbbe1b\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/languages/zh-CN.yml\",\"hash\":\"6b82ae9f292bf5109d164c882e67156138b88769\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/languages/zh-TW.yml\",\"hash\":\"a2206da63bc6171ed7a129228e00f2a81e45b348\",\"modified\":1510384995478},{\"_id\":\"themes/ewal/layout/archive.ejs\",\"hash\":\"f0c9365f86161db75a6871aa7003113d56770441\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/category.ejs\",\"hash\":\"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/index.ejs\",\"hash\":\"358b71c25fcd996cd8752a0292be96c146d9e32f\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/layout.ejs\",\"hash\":\"032471de4382c9b37aa025d16767aab178fe4750\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/page.ejs\",\"hash\":\"87293910dcf9839f8478a720b95ef5945104abb3\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/post.ejs\",\"hash\":\"47011d02d48b04abe2adb73c3b2022c74be65c72\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/tag.ejs\",\"hash\":\"45150a2365768b6b67880193c9264ad2bb4814db\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/.git/index\",\"hash\":\"06a3661bd006bd1e2cdbf8147af75d6ad9a1eedc\",\"modified\":1510385343739},{\"_id\":\"source/images/screenshot.png\",\"hash\":\"0466c79bc1d0b6569f10fa0e59c8f5e8bcd32f59\",\"modified\":1516437721202},{\"_id\":\"themes/ewal/.git/hooks/applypatch-msg.sample\",\"hash\":\"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/commit-msg.sample\",\"hash\":\"ee1ed5aad98a435f2020b6de35c173b75d9affac\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/post-update.sample\",\"hash\":\"b614c2f63da7dca9f1db2e7ade61ef30448fc96c\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/pre-push.sample\",\"hash\":\"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/pre-commit.sample\",\"hash\":\"36aed8976dcc08b5076844f0ec645b18bc37758f\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/pre-applypatch.sample\",\"hash\":\"f208287c1a92525de9f5462e905a9d31de1e2d75\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/update.sample\",\"hash\":\"e729cd61b27c128951d139de8e7c63d1a3758dde\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/prepare-commit-msg.sample\",\"hash\":\"2b6275eda365cad50d167fe3a387c9bc9fedd54f\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/hooks/pre-rebase.sample\",\"hash\":\"18be3eb275c1decd3614e139f5a311b75f1b0ab8\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/.git/logs/HEAD\",\"hash\":\"a4e865344a516d3d934e57ae806e97675dfc92d9\",\"modified\":1510384995474},{\"_id\":\"themes/ewal/layout/_partial/after_footer.ejs\",\"hash\":\"c8e109b31f42660628975d71f6affcac88a875f4\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/archive.ejs\",\"hash\":\"d2fd869113f2e1de564c16bb493e905b27fb3bd3\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/article.ejs\",\"hash\":\"3415d2899b71b3cf513c40683c0a33f1452b13bb\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/comment.ejs\",\"hash\":\"8cd4cd5fb3d1ede96505c203ae38a261f8e36a3a\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/footer.ejs\",\"hash\":\"d3e4389a8c303c92029628071c8afb13d825ca40\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/google_analytics.ejs\",\"hash\":\"bc193effd64907a7291804d7af514cda2eeb018a\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/head.ejs\",\"hash\":\"f72f634e057053c102223aeb816d0af37d293ac1\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/pagination.ejs\",\"hash\":\"3062a56ac9c4bb7f1a0157c002d6269b02dd7a2a\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/header.ejs\",\"hash\":\"1a4d6fe7893810e2d5c61189344197cd33eb6cdb\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/.git/info/exclude\",\"hash\":\"c879df015d97615050afa7b9641e3352a1e701ac\",\"modified\":1510384992794},{\"_id\":\"themes/ewal/layout/_partial/sidebar.ejs\",\"hash\":\"8b06b25abf0e56580248404063a4561207cc67eb\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/twitter.ejs\",\"hash\":\"668fb8fe7b2c8426de25e99276907aaf4d30bef6\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_widget/about.ejs\",\"hash\":\"91bd47a7e76e691a36c17e6fa750d3bd27969ddd\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/noteworthy.ejs\",\"hash\":\"db7c7bb72f3a74dc36d9c19758dac0c03c7280ed\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/recent_posts.ejs\",\"hash\":\"367aa4f70dbc5e36c2baefd0c0e092140ad0bc53\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/category.ejs\",\"hash\":\"aa8e59f5219e6aa153df27499006fed727251205\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/recommended_links.ejs\",\"hash\":\"1914134b88073464f85a473ec65d784b5c056750\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/search.ejs\",\"hash\":\"dd69a22b3f020261dbd78dae86c6e02874797aaf\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/subscribe_mailchimp.ejs\",\"hash\":\"6154e0271b98c097caa559e8f8a683ab8fb93e7f\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/tag.ejs\",\"hash\":\"2da20a4e0d21e078d437b8d65e656756b383ddfd\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/layout/_widget/tagcloud.ejs\",\"hash\":\"1606b4c718902d69141f20d658290204d1c3516e\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/source/fancybox/blank.gif\",\"hash\":\"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/fancybox/fancybox_loading.gif\",\"hash\":\"48673ea547f521de42a1a2057df6939cafda7ae5\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/fancybox/fancybox_overlay.png\",\"hash\":\"b3a4ee645ba494f52840ef8412015ba0f465dbe0\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/fancybox/fancybox_sprite.png\",\"hash\":\"17df19f97628e77be09c352bf27425faea248251\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/fancybox/jquery.fancybox.css\",\"hash\":\"98644f55b533a25495961ac6fd411ca27807d54d\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/fancybox/jquery.fancybox.pack.js\",\"hash\":\"2629dcc9d237f1244c02de196733830a5723cb90\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.eot\",\"hash\":\"f3a9a3b609133c3d21d6b42abbf7f43bd111df72\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/css/_abstract.less\",\"hash\":\"5798494e74b8d67342640277230ab0e5990e155f\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.ttf\",\"hash\":\"aafafdc09404c4aa4447d7e898a2183def9cc1b1\",\"modified\":1510384995506},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.woff\",\"hash\":\"22037a3455914e5662fa51a596677bdb329e2c5c\",\"modified\":1510384995506},{\"_id\":\"themes/ewal/source/fonts/glyphicons-halflings-regular.svg\",\"hash\":\"3ef91859cbec165ac97df6957b176f69e8d6a04d\",\"modified\":1510384995506},{\"_id\":\"themes/ewal/source/css/_core.less\",\"hash\":\"b32f00bc65e196c2eff352b3a0d6e29ef37250c3\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_index.less\",\"hash\":\"88007bdf90ee386ad81e0537d2bde64409c06887\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_post.less\",\"hash\":\"e84c31a1af569addc28cfea1e9a7b000a45bfca2\",\"modified\":1510385388608},{\"_id\":\"themes/ewal/source/css/_projects.less\",\"hash\":\"66f9b53fef2ee3254e3477af22f33f15b77088ef\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/captionjs.min.css\",\"hash\":\"7e09dc8e5e448b96d7918ea8ae2d1673665417b2\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/css/site.less\",\"hash\":\"a6bdeeb1e7b94124f775cc1872c4cefbda27ae6f\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/js/ewal.js\",\"hash\":\"b919c5abd99402e3c027d5e33773a79f69cd4a4f\",\"modified\":1510384995506},{\"_id\":\"themes/ewal/source/css/_variables.less\",\"hash\":\"6a3ce9c30ffb9eda63517dc74647bf7b19cce734\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/js/jquery.caption.min.js\",\"hash\":\"ee2fcf27e192461d904251cd83008f36fddc16ea\",\"modified\":1510384995506},{\"_id\":\"themes/ewal/.git/refs/heads/master\",\"hash\":\"5f4172c37dc73a87979af1a71eb87431e415c9af\",\"modified\":1510384995474},{\"_id\":\"themes/ewal/source/js/jquery.min.js\",\"hash\":\"b66ed708717bf0b4a005a4d0113af8843ef3b8ff\",\"modified\":1510384995510},{\"_id\":\"themes/ewal/layout/_partial/post/addthis.ejs\",\"hash\":\"b41609e3094aca63dd30ac277a9d80ddd32b6273\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/post/category.ejs\",\"hash\":\"08e0cdbb0dded4fb5efe59fd4b1796d21fb59be9\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/post/tag.ejs\",\"hash\":\"095418df66a27a28cbab16d7cb0d16001b0e23f1\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/layout/_partial/post/title.ejs\",\"hash\":\"d7fbc575d35ae68f9045a382c651450e4131f335\",\"modified\":1510384995482},{\"_id\":\"themes/ewal/source/css/_bootstrap/badges.less\",\"hash\":\"41e154ac20861ecf3ff51654e5343348bf8eb8cb\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/source/css/_bootstrap/alerts.less\",\"hash\":\"ca95e6063933dec32153e0d73aff192a62db0d53\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/source/css/_bootstrap/breadcrumbs.less\",\"hash\":\"4cd71e392faecf7fba402f385a06e6bf83260e62\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/bootstrap.less\",\"hash\":\"55be2cc2059e7650a206264c368ebcc85e626923\",\"modified\":1510384995486},{\"_id\":\"themes/ewal/source/css/_bootstrap/buttons.less\",\"hash\":\"642da05648f9bb6298765356ecef9c8871672f22\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/button-groups.less\",\"hash\":\"caacdee8d9dbe8d48ac3274304c482b9ab884453\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/carousel.less\",\"hash\":\"ddb8ffc852a32a984ecf9b78704092586c92e547\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/close.less\",\"hash\":\"fd7150f39cd8e361dcf6a83367bd34ea96940fc6\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/code.less\",\"hash\":\"e5b8f0aa42139d8c8779fa43ad3cc3dd546808a9\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/component-animations.less\",\"hash\":\"d17330603cbfcb0753c925f8ca77d9b7e1a6b07b\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/dropdowns.less\",\"hash\":\"06844f57485fbddd09b6aced9ab68149359bccf2\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/.git/objects/pack/pack-d2d0350d37e7b9953c8de63c37779695da32f21f.idx\",\"hash\":\"45c67a7b8014ae815ba3edb990dadc64ba4fa0d6\",\"modified\":1510384995270},{\"_id\":\"themes/ewal/source/css/_bootstrap/forms.less\",\"hash\":\"693801c987a62f067b4c3e304897113bcff89e68\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/input-groups.less\",\"hash\":\"feaf08a4aaaf4c5e7492487d51259502e95a9d32\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/jumbotron.less\",\"hash\":\"c9f052ad6611536cb7f25143b875bf93d36db5c6\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/glyphicons.less\",\"hash\":\"8c304d1c10b56090f6820b9bf87db991fe333c2e\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/labels.less\",\"hash\":\"fb73fae7d7b7398c512b5ecd3a765287570e54ae\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/list-group.less\",\"hash\":\"27c25b1019e8284db0b94c5e85539b9bc9e0bf74\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/media.less\",\"hash\":\"7417e1ecf63f79c25411ef45543cce2a56d8d097\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/modals.less\",\"hash\":\"48d92dbf64b53f6ba67509644093b483aebdb488\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/grid.less\",\"hash\":\"bf66e6afb36c9d8983dcca09246d9a9318c137dd\",\"modified\":1510384995490},{\"_id\":\"themes/ewal/source/css/_bootstrap/navbar.less\",\"hash\":\"74391386a900f0efeeeb8712d5bc832c90d72825\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/pager.less\",\"hash\":\"062e4887a57a290a066d0916265e5b3cef9ab498\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/pagination.less\",\"hash\":\"9fdad6b8cce7fa7f556e7a89f7bdbea59461dcfc\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/normalize.less\",\"hash\":\"e0ce2fa6ff6a33732c3bea77656ef080388a4ad0\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/panels.less\",\"hash\":\"afd1a78943ebafc3079d1498f93d01f12a00abf9\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/popovers.less\",\"hash\":\"a54a591bea3828e274792b891a0d441244c148fc\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/print.less\",\"hash\":\"a8423b6930a9ef18712a22686276aaf8811699c3\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/progress-bars.less\",\"hash\":\"e97f065f5d12440598a396f91b4135bbaa46e355\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/scaffolding.less\",\"hash\":\"acba3e6322b7322467556f745a6eecf474aaa3d6\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/responsive-utilities.less\",\"hash\":\"5f0cad3b63ae532084a02f94fc8c4fdf421cca9d\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/tables.less\",\"hash\":\"48d3f9473de403cf23e0d4c69dad49af120cf269\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/thumbnails.less\",\"hash\":\"b5700cccb491e5c7f00a9be9ddca7ab17e352ec2\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/theme.less\",\"hash\":\"c4bfe5da1b8d8c8f7468e3b6d2ad3f82e692cf0e\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/tooltip.less\",\"hash\":\"1a316c19e50f703e6f5509d8808da3ab8ccb5467\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/utilities.less\",\"hash\":\"e9f0414df6719f4afadc473ea3704981ce5ed1dd\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/type.less\",\"hash\":\"f4f1b2919f6ea25a2957915895e529e72044379c\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/mixins.less\",\"hash\":\"6323a7412fc49c3cc288cae100412fed6833fa0e\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/source/css/_bootstrap/wells.less\",\"hash\":\"e6a4a294aef45c9e9f592485628cf28886849a20\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/_bootstrap/variables.less\",\"hash\":\"6b5bd35095d2a44f5a92ea28193e3f6178989a0f\",\"modified\":1510384995498},{\"_id\":\"themes/ewal/source/css/highlightjs/solarized_dark.css\",\"hash\":\"bb7b30788f1d79f8d1b9f1d5216e28e25f9463d2\",\"modified\":1510384995502},{\"_id\":\"themes/ewal/source/css/_bootstrap/navs.less\",\"hash\":\"3a902fbf91c6e112736a79ec69d4f0890a8ad98a\",\"modified\":1510384995494},{\"_id\":\"themes/ewal/.git/logs/refs/heads/master\",\"hash\":\"a4e865344a516d3d934e57ae806e97675dfc92d9\",\"modified\":1510384995474},{\"_id\":\"themes/ewal/.git/refs/remotes/origin/HEAD\",\"hash\":\"d9427cda09aba1cdde5c69c2b13c905bddb0bc51\",\"modified\":1510384995470},{\"_id\":\"themes/ewal/.git/logs/refs/remotes/origin/HEAD\",\"hash\":\"a4e865344a516d3d934e57ae806e97675dfc92d9\",\"modified\":1510384995474},{\"_id\":\"themes/ewal/.git/objects/pack/pack-d2d0350d37e7b9953c8de63c37779695da32f21f.pack\",\"hash\":\"f526c6543632e48a4727190b883ff4893a39c3da\",\"modified\":1510384995270}],\"Category\":[],\"Data\":[],\"Page\":[],\"Post\":[{\"title\":\"Django: Serve big files via fcgid\",\"date\":\"2007-10-03T08:14:00.000Z\",\"alias\":\"/post/37471157406/django-serve-big-files-via-fcgid\",\"_content\":\"\\nI&rsquo;ve got a [django project](http://extranet.icoc.ch) running which requires you to login to access files.\\n\\nThat means that I have to serve the files via python, like this:\\n<pre>\\n  @login_required\\n  def download(request, filename):\\n    # ... some code specific to my site ...\\n    response = HttpResponse(mimetype=postUpload.mimetype)\\n    response['Content-Disposition'] = \\\"attachment; filename=\\\" + original_filename\\n    response['Content-Length'] = os.path.getsize(filename_path)\\n    response.write(open(filename_path).read())\\n    return response\\n</pre>\\n<!-- more -->\\n\\nThe problem: If the download of a file exceeded 5 minutes (big files and/or low\\nbandwidth) the download was canceled on the server side by a timeout. This Apache\\nconfiguration for mod_fcgid solved the problem (see [mod_fcgid documentation for BusyTimeout](http://fastcgi.coremail.cn/doc.htm))\\n\\n<pre>\\n&lt;IfModule mod_fcgid.c&gt;\\n BusyTimeout 1200\\n&lt;/IfModule&gt;\\n</pre>\\n\\nThe problem was that the apache module scanned every minute for processes that run for\\nmore than BusyTimeout seconds. These processes are potentially in bad health (infinite\\nloop et al.) and have to be killed. Not so with my processes (since I know what I&rsquo;m\\ndoing..). The setting of the busy timeout to 1200 seconds now lets my processes run for\\na maximum of one hour.\\n\\nAs this setting can&rsquo;t by overwritten in a htaccess file by default I needed to bug\\n[my web hosting provider](http://www.citrin.ch/) with the request, which was\\nhandled in 24 hours, so thanks for that one!\\n\\nPS: If you know of another way how to serve protected static files via a single sign on\\n(no HTTP basic auth), please let me know.\",\"source\":\"_posts/Django-Serve-big-files-via-fcgid.md\",\"raw\":\"---\\ntitle: 'Django: Serve big files via fcgid'\\ntags:\\n  - python\\n  - django\\ndate: 2007-10-03 10:14:00\\nalias: /post/37471157406/django-serve-big-files-via-fcgid\\n---\\n\\nI&rsquo;ve got a [django project](http://extranet.icoc.ch) running which requires you to login to access files.\\n\\nThat means that I have to serve the files via python, like this:\\n<pre>\\n  @login_required\\n  def download(request, filename):\\n    # ... some code specific to my site ...\\n    response = HttpResponse(mimetype=postUpload.mimetype)\\n    response['Content-Disposition'] = \\\"attachment; filename=\\\" + original_filename\\n    response['Content-Length'] = os.path.getsize(filename_path)\\n    response.write(open(filename_path).read())\\n    return response\\n</pre>\\n<!-- more -->\\n\\nThe problem: If the download of a file exceeded 5 minutes (big files and/or low\\nbandwidth) the download was canceled on the server side by a timeout. This Apache\\nconfiguration for mod_fcgid solved the problem (see [mod_fcgid documentation for BusyTimeout](http://fastcgi.coremail.cn/doc.htm))\\n\\n<pre>\\n&lt;IfModule mod_fcgid.c&gt;\\n BusyTimeout 1200\\n&lt;/IfModule&gt;\\n</pre>\\n\\nThe problem was that the apache module scanned every minute for processes that run for\\nmore than BusyTimeout seconds. These processes are potentially in bad health (infinite\\nloop et al.) and have to be killed. Not so with my processes (since I know what I&rsquo;m\\ndoing..). The setting of the busy timeout to 1200 seconds now lets my processes run for\\na maximum of one hour.\\n\\nAs this setting can&rsquo;t by overwritten in a htaccess file by default I needed to bug\\n[my web hosting provider](http://www.citrin.ch/) with the request, which was\\nhandled in 24 hours, so thanks for that one!\\n\\nPS: If you know of another way how to serve protected static files via a single sign on\\n(no HTTP basic auth), please let me know.\",\"slug\":\"Django-Serve-big-files-via-fcgid\",\"published\":1,\"updated\":\"2017-11-11T21:12:37.408Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6010000i85pj87vf4yy\",\"content\":\"<p>I&rsquo;ve got a <a href=\\\"http://extranet.icoc.ch\\\" target=\\\"_blank\\\" rel=\\\"external\\\">django project</a> running which requires you to login to access files.</p>\\n<p>That means that I have to serve the files via python, like this:</p>\\n<pre>\\n  @login_required\\n  def download(request, filename):\\n    # ... some code specific to my site ...\\n    response = HttpResponse(mimetype=postUpload.mimetype)\\n    response['Content-Disposition'] = \\\"attachment; filename=\\\" + original_filename\\n    response['Content-Length'] = os.path.getsize(filename_path)\\n    response.write(open(filename_path).read())\\n    return response\\n</pre>\\n<a id=\\\"more\\\"></a>\\n\\nThe problem: If the download of a file exceeded 5 minutes (big files and/or low\\nbandwidth) the download was canceled on the server side by a timeout. This Apache\\nconfiguration for mod_fcgid solved the problem (see [mod_fcgid documentation for BusyTimeout](http://fastcgi.coremail.cn/doc.htm))\\n\\n<pre>\\n&lt;IfModule mod_fcgid.c&gt;\\n BusyTimeout 1200\\n&lt;/IfModule&gt;\\n</pre>\\n\\n<p>The problem was that the apache module scanned every minute for processes that run for<br>more than BusyTimeout seconds. These processes are potentially in bad health (infinite<br>loop et al.) and have to be killed. Not so with my processes (since I know what I&rsquo;m<br>doing..). The setting of the busy timeout to 1200 seconds now lets my processes run for<br>a maximum of one hour.</p>\\n<p>As this setting can&rsquo;t by overwritten in a htaccess file by default I needed to bug<br><a href=\\\"http://www.citrin.ch/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">my web hosting provider</a> with the request, which was<br>handled in 24 hours, so thanks for that one!</p>\\n<p>PS: If you know of another way how to serve protected static files via a single sign on<br>(no HTTP basic auth), please let me know.</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>I&rsquo;ve got a <a href=\\\"http://extranet.icoc.ch\\\" target=\\\"_blank\\\" rel=\\\"external\\\">django project</a> running which requires you to login to access files.</p>\\n<p>That means that I have to serve the files via python, like this:</p>\\n<pre>\\n  @login_required\\n  def download(request, filename):\\n    # ... some code specific to my site ...\\n    response = HttpResponse(mimetype=postUpload.mimetype)\\n    response['Content-Disposition'] = \\\"attachment; filename=\\\" + original_filename\\n    response['Content-Length'] = os.path.getsize(filename_path)\\n    response.write(open(filename_path).read())\\n    return response\\n</pre>\",\"more\":\"The problem: If the download of a file exceeded 5 minutes (big files and/or low\\nbandwidth) the download was canceled on the server side by a timeout. This Apache\\nconfiguration for mod_fcgid solved the problem (see [mod_fcgid documentation for BusyTimeout](http://fastcgi.coremail.cn/doc.htm))\\n\\n<pre>\\n&lt;IfModule mod_fcgid.c&gt;\\n BusyTimeout 1200\\n&lt;/IfModule&gt;\\n</pre>\\n\\n<p>The problem was that the apache module scanned every minute for processes that run for<br>more than BusyTimeout seconds. These processes are potentially in bad health (infinite<br>loop et al.) and have to be killed. Not so with my processes (since I know what I&rsquo;m<br>doing..). The setting of the busy timeout to 1200 seconds now lets my processes run for<br>a maximum of one hour.</p>\\n<p>As this setting can&rsquo;t by overwritten in a htaccess file by default I needed to bug<br><a href=\\\"http://www.citrin.ch/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">my web hosting provider</a> with the request, which was<br>handled in 24 hours, so thanks for that one!</p>\\n<p>PS: If you know of another way how to serve protected static files via a single sign on<br>(no HTTP basic auth), please let me know.</p>\"},{\"title\":\"Feature phone with tethering (Nokia Asha 302) - tune out of Internet\",\"date\":\"2016-05-15T18:25:41.000Z\",\"alias\":\"/post/144409514866/feature-phone-with-tethering-nokia-asha-302\",\"_content\":\"\\n<img src=\\\"/images/asha-302.jpg\\\" />\\n\\nSince the days of the iPhone finding the right way to handle the mobile phone is challenging to me. Working in web programming and being a father and husband at the same time is means that I need to be able to connect to my colleagues at work when not at my desk while being able to &ldquo;tune out&rdquo; while being with my family.\\n\\nMy latest try at the problem was to buy a &ldquo;feature phone&rdquo; which was good enough to support the bare minimum (apart phone calls and SMS this is WhatsApp and internet tethering for my tablet/laptop) but was dumb enough that it would not tempt me away to check any news/mails while being with my family. I came across the &ldquo;Nokia Asha 302&rdquo; which is no longer produced but IMO was selling bad enough that there are some in stock in the most countries (at least that was in case here in Switzerland).\\n\\nI&rsquo;m on this &ldquo;feature phone&rdquo; now since a few days and must say that I&rsquo;m quite happy with it. When I am at work I just take my android tablet (nvidia shield k1) with me, if I want to tune out I can leave the house with my mobile only. As it is an outdated phone there are some tweaks you need to do which I documented below:\\n\\n<!-- more -->\\n\\n# Tips and Tricks\\n\\n## Install WhatsApp\\n\\nWhen trying to access the nokia store the first time I got\\n\\n> certificate not valid according to phone&rsquo;s date\\n\\nWhat solved the issue for me was to set the date a few years back (I think I tried 2013). After the store was updated I needed to set the date back to the current date in order to download WhatsApp (otherwise it triggers another certificate exception)\\n\\n## Install Google Maps\\n\\nGo to [getjar.com](http://www.getjar.com) with your mobile and search for &ldquo;map&rdquo; -&gt; lets you install google maps on your s40 based phone even though google maps is no longer officially supported for this series.\\n\\n## Tethering\\n\\nJust enable bluetooth on your mobile, pair device and connect to network.\\n\\n## Phone doesn&rsquo;t turn on\\n\\nI had this when trying to charge with a wrong adapter. Asha 302 said it was charging but in fact it was not, just change to a different adapter\\n\\n## Headphones\\n\\nAll headphones with three rings do not work (e.g. iphone headphones), but the &ldquo;normal&rdquo; headphones without mic with just two rings do work.\\n\\n\",\"source\":\"_posts/Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet.md\",\"raw\":\"---\\ntitle: Feature phone with tethering (Nokia Asha 302) - tune out of Internet\\ntags:\\n  - nokia asha 302\\n  - nvidia shield\\n  - tethering\\ndate: 2016-05-15 20:25:41\\nalias: /post/144409514866/feature-phone-with-tethering-nokia-asha-302\\n---\\n\\n<img src=\\\"/images/asha-302.jpg\\\" />\\n\\nSince the days of the iPhone finding the right way to handle the mobile phone is challenging to me. Working in web programming and being a father and husband at the same time is means that I need to be able to connect to my colleagues at work when not at my desk while being able to &ldquo;tune out&rdquo; while being with my family.\\n\\nMy latest try at the problem was to buy a &ldquo;feature phone&rdquo; which was good enough to support the bare minimum (apart phone calls and SMS this is WhatsApp and internet tethering for my tablet/laptop) but was dumb enough that it would not tempt me away to check any news/mails while being with my family. I came across the &ldquo;Nokia Asha 302&rdquo; which is no longer produced but IMO was selling bad enough that there are some in stock in the most countries (at least that was in case here in Switzerland).\\n\\nI&rsquo;m on this &ldquo;feature phone&rdquo; now since a few days and must say that I&rsquo;m quite happy with it. When I am at work I just take my android tablet (nvidia shield k1) with me, if I want to tune out I can leave the house with my mobile only. As it is an outdated phone there are some tweaks you need to do which I documented below:\\n\\n<!-- more -->\\n\\n# Tips and Tricks\\n\\n## Install WhatsApp\\n\\nWhen trying to access the nokia store the first time I got\\n\\n> certificate not valid according to phone&rsquo;s date\\n\\nWhat solved the issue for me was to set the date a few years back (I think I tried 2013). After the store was updated I needed to set the date back to the current date in order to download WhatsApp (otherwise it triggers another certificate exception)\\n\\n## Install Google Maps\\n\\nGo to [getjar.com](http://www.getjar.com) with your mobile and search for &ldquo;map&rdquo; -&gt; lets you install google maps on your s40 based phone even though google maps is no longer officially supported for this series.\\n\\n## Tethering\\n\\nJust enable bluetooth on your mobile, pair device and connect to network.\\n\\n## Phone doesn&rsquo;t turn on\\n\\nI had this when trying to charge with a wrong adapter. Asha 302 said it was charging but in fact it was not, just change to a different adapter\\n\\n## Headphones\\n\\nAll headphones with three rings do not work (e.g. iphone headphones), but the &ldquo;normal&rdquo; headphones without mic with just two rings do work.\\n\\n\",\"slug\":\"Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet\",\"published\":1,\"updated\":\"2017-11-29T15:18:50.173Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6050001i85p377a2aml\",\"content\":\"<p><img src=\\\"/images/asha-302.jpg\\\"></p>\\n<p>Since the days of the iPhone finding the right way to handle the mobile phone is challenging to me. Working in web programming and being a father and husband at the same time is means that I need to be able to connect to my colleagues at work when not at my desk while being able to &ldquo;tune out&rdquo; while being with my family.</p>\\n<p>My latest try at the problem was to buy a &ldquo;feature phone&rdquo; which was good enough to support the bare minimum (apart phone calls and SMS this is WhatsApp and internet tethering for my tablet/laptop) but was dumb enough that it would not tempt me away to check any news/mails while being with my family. I came across the &ldquo;Nokia Asha 302&rdquo; which is no longer produced but IMO was selling bad enough that there are some in stock in the most countries (at least that was in case here in Switzerland).</p>\\n<p>I&rsquo;m on this &ldquo;feature phone&rdquo; now since a few days and must say that I&rsquo;m quite happy with it. When I am at work I just take my android tablet (nvidia shield k1) with me, if I want to tune out I can leave the house with my mobile only. As it is an outdated phone there are some tweaks you need to do which I documented below:</p>\\n<a id=\\\"more\\\"></a>\\n<h1 id=\\\"Tips-and-Tricks\\\"><a href=\\\"#Tips-and-Tricks\\\" class=\\\"headerlink\\\" title=\\\"Tips and Tricks\\\"></a>Tips and Tricks</h1><h2 id=\\\"Install-WhatsApp\\\"><a href=\\\"#Install-WhatsApp\\\" class=\\\"headerlink\\\" title=\\\"Install WhatsApp\\\"></a>Install WhatsApp</h2><p>When trying to access the nokia store the first time I got</p>\\n<blockquote>\\n<p>certificate not valid according to phone&rsquo;s date</p>\\n</blockquote>\\n<p>What solved the issue for me was to set the date a few years back (I think I tried 2013). After the store was updated I needed to set the date back to the current date in order to download WhatsApp (otherwise it triggers another certificate exception)</p>\\n<h2 id=\\\"Install-Google-Maps\\\"><a href=\\\"#Install-Google-Maps\\\" class=\\\"headerlink\\\" title=\\\"Install Google Maps\\\"></a>Install Google Maps</h2><p>Go to <a href=\\\"http://www.getjar.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">getjar.com</a> with your mobile and search for &ldquo;map&rdquo; -&gt; lets you install google maps on your s40 based phone even though google maps is no longer officially supported for this series.</p>\\n<h2 id=\\\"Tethering\\\"><a href=\\\"#Tethering\\\" class=\\\"headerlink\\\" title=\\\"Tethering\\\"></a>Tethering</h2><p>Just enable bluetooth on your mobile, pair device and connect to network.</p>\\n<h2 id=\\\"Phone-doesn-rsquo-t-turn-on\\\"><a href=\\\"#Phone-doesn-rsquo-t-turn-on\\\" class=\\\"headerlink\\\" title=\\\"Phone doesn&rsquo;t turn on\\\"></a>Phone doesn&rsquo;t turn on</h2><p>I had this when trying to charge with a wrong adapter. Asha 302 said it was charging but in fact it was not, just change to a different adapter</p>\\n<h2 id=\\\"Headphones\\\"><a href=\\\"#Headphones\\\" class=\\\"headerlink\\\" title=\\\"Headphones\\\"></a>Headphones</h2><p>All headphones with three rings do not work (e.g. iphone headphones), but the &ldquo;normal&rdquo; headphones without mic with just two rings do work.</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"/images/asha-302.jpg\\\"></p>\\n<p>Since the days of the iPhone finding the right way to handle the mobile phone is challenging to me. Working in web programming and being a father and husband at the same time is means that I need to be able to connect to my colleagues at work when not at my desk while being able to &ldquo;tune out&rdquo; while being with my family.</p>\\n<p>My latest try at the problem was to buy a &ldquo;feature phone&rdquo; which was good enough to support the bare minimum (apart phone calls and SMS this is WhatsApp and internet tethering for my tablet/laptop) but was dumb enough that it would not tempt me away to check any news/mails while being with my family. I came across the &ldquo;Nokia Asha 302&rdquo; which is no longer produced but IMO was selling bad enough that there are some in stock in the most countries (at least that was in case here in Switzerland).</p>\\n<p>I&rsquo;m on this &ldquo;feature phone&rdquo; now since a few days and must say that I&rsquo;m quite happy with it. When I am at work I just take my android tablet (nvidia shield k1) with me, if I want to tune out I can leave the house with my mobile only. As it is an outdated phone there are some tweaks you need to do which I documented below:</p>\",\"more\":\"<h1 id=\\\"Tips-and-Tricks\\\"><a href=\\\"#Tips-and-Tricks\\\" class=\\\"headerlink\\\" title=\\\"Tips and Tricks\\\"></a>Tips and Tricks</h1><h2 id=\\\"Install-WhatsApp\\\"><a href=\\\"#Install-WhatsApp\\\" class=\\\"headerlink\\\" title=\\\"Install WhatsApp\\\"></a>Install WhatsApp</h2><p>When trying to access the nokia store the first time I got</p>\\n<blockquote>\\n<p>certificate not valid according to phone&rsquo;s date</p>\\n</blockquote>\\n<p>What solved the issue for me was to set the date a few years back (I think I tried 2013). After the store was updated I needed to set the date back to the current date in order to download WhatsApp (otherwise it triggers another certificate exception)</p>\\n<h2 id=\\\"Install-Google-Maps\\\"><a href=\\\"#Install-Google-Maps\\\" class=\\\"headerlink\\\" title=\\\"Install Google Maps\\\"></a>Install Google Maps</h2><p>Go to <a href=\\\"http://www.getjar.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">getjar.com</a> with your mobile and search for &ldquo;map&rdquo; -&gt; lets you install google maps on your s40 based phone even though google maps is no longer officially supported for this series.</p>\\n<h2 id=\\\"Tethering\\\"><a href=\\\"#Tethering\\\" class=\\\"headerlink\\\" title=\\\"Tethering\\\"></a>Tethering</h2><p>Just enable bluetooth on your mobile, pair device and connect to network.</p>\\n<h2 id=\\\"Phone-doesn-rsquo-t-turn-on\\\"><a href=\\\"#Phone-doesn-rsquo-t-turn-on\\\" class=\\\"headerlink\\\" title=\\\"Phone doesn&rsquo;t turn on\\\"></a>Phone doesn&rsquo;t turn on</h2><p>I had this when trying to charge with a wrong adapter. Asha 302 said it was charging but in fact it was not, just change to a different adapter</p>\\n<h2 id=\\\"Headphones\\\"><a href=\\\"#Headphones\\\" class=\\\"headerlink\\\" title=\\\"Headphones\\\"></a>Headphones</h2><p>All headphones with three rings do not work (e.g. iphone headphones), but the &ldquo;normal&rdquo; headphones without mic with just two rings do work.</p>\"},{\"title\":\"Automated tag clustering\",\"date\":\"2006-07-11T07:03:00.000Z\",\"alias\":\"/post/37027750128/automated-tag-clustering\",\"_content\":\"\\n[Grigory Begelman](http://www.cs.technion.ac.il/%7Egbeg/) ([Technion - Israel Institute of Technology Computer Science Dpt)](http://www.cs.technion.ac.il/), [Frank Smadja](http://smadja.us/) ([RawSugar](http://www.rawsugar.com/)) and I did a paper for [www2006](http://www2006.org) called &ldquo;automated tag clustering&rdquo;. It deals with why clustering the tag space makes sense and how this could be done.\\n\\nAfter the presentation at the [tagging workshop](http://blog.rawsugar.com/wikka/wikka.php?wakka=HomePage) at www2006 we felt the need to give our paper a more www-friendly, I-don&rsquo;t-want-to-read-through-those-theoretical-equation-flooded-papers face.\\n\\n[![clustering the tag space](http://i.imgur.com/40BW8.png \\\"clustering the tag space\\\")](http://tagging.pui.ch/automated_tag_clustering/#cluster)\\n\\nSo, here you go: [Automated Tag Clustering: Improving search and exploration in the tag space](http://tagging.pui.ch/automated_tag_clustering/).<!-- more -->\\n\\nTo read this document you should have a clue what tags are about, you should also know some tag services as [delicious](http://del.icio.us) or [flickr](http://www.flickr.com) so you can understand the limitations these services currently have. If you don&rsquo;t want to read through the whole papers, the numerous figures give you a good summary. Finally, to wet your appetite, here a few excerpts of the document:\\n\\n> Currently tagging services still provide a relatively marginal value for information discovery and we claim that with the use of clustering techniques this can be greatly improved [from [introduction](http://tagging.pui.ch/automated_tag_clustering/#p_motivation)]\\n> The whole promise of collaborative tagging is that by exploring the tag space you can discover a lot of useful information you would not find with traditional search engines. When your information need is not well defined, the idea that you can explore and see what other people tagged with certain tags is very attractive. We believe that tagging will be able to reach a very wide audience only when exploration techniques will be effective. [from [limited exploration](http://tagging.pui.ch/automated_tag_clustering/#p_exploration)]\\n> Although a great visualization paradigm, we believe that with today&rsquo;s tagclouds it is hard to find more than one or two tags to click on. Tags are not grouped, there is too much information, so that you find lot of related tags scattered on the tag cloud. One or two popular topics and all their related tags tend to dominate the whole cloud. For example, looking at the del.icio.us tagcloud, one would mostly see tags related to web design and technologies. This is because these topics are overwhelmingly more frequent than anything else. [from [limited exploration](http://tagging.pui.ch/automated_tag_clustering/#p_exploration)]\\n> Tag _web2.0_ nowadays is so popular and is combined wildly with anything. In fact this tag is so overused that if you look at [tag _bookmarks_ in the del.icio.us dataset](http://del.icio.us/tag/bookmarks), the most used cotag is _web2.0_[&hellip;]. Basing tag similarity on these numbers often doesn&rsquo;t make sense at all. The similarity measure should be chosen so the popularity of a tag doesn&rsquo;t affect the set of a tags related tags. Don&rsquo;t cut the [long tail](http://en.wikipedia.org/wiki/Long_tail). The success of blogs is driven by the importance of the long tail. We all know that it is crucial to support the niches. Tagging applications should empower the long tail too. If you just sort by popularity, you&rsquo;d loose all those niches. [from [choosing a similarity measure](http://tagging.pui.ch/automated_tag_clustering/#p_similarity)]\\n\\nWe&rsquo;d be happy to get any kind of feedback on the article. Just post a comment to this blog post.\\n\\n**Edit (4 years later!)**: A few guys asked me about the source code: [Source code with syntax highlighting](http://pastie.org/1098455).\\nYou need [kmetis](http://people.sc.fsu.edu/~jburkardt/c_src/kmetis/kmetis.html) to make this run, see `usage()` to see how it should be used.\\n\\n**Edit**: Robin sent me [this fixed source code](http://pastie.org/3549928), didn&rsquo;t test it though:\\n\\n<div class=\\\"blogger-post-footer\\\">![](https://blogger.googleusercontent.com/tracker/2748783673844839576-786221472892263493?l=theneachwenttohisownhome.blogspot.com)</div>\",\"source\":\"_posts/Automated-tag-clustering.md\",\"raw\":\"---\\ntitle: Automated tag clustering\\ntags:\\n  - RawSugar\\n  - Research\\n  - Tags\\n  - Clustering\\n  - Del.icio.us\\ndate: 2006-07-11 09:03:00\\nalias: /post/37027750128/automated-tag-clustering\\n---\\n\\n[Grigory Begelman](http://www.cs.technion.ac.il/%7Egbeg/) ([Technion - Israel Institute of Technology Computer Science Dpt)](http://www.cs.technion.ac.il/), [Frank Smadja](http://smadja.us/) ([RawSugar](http://www.rawsugar.com/)) and I did a paper for [www2006](http://www2006.org) called &ldquo;automated tag clustering&rdquo;. It deals with why clustering the tag space makes sense and how this could be done.\\n\\nAfter the presentation at the [tagging workshop](http://blog.rawsugar.com/wikka/wikka.php?wakka=HomePage) at www2006 we felt the need to give our paper a more www-friendly, I-don&rsquo;t-want-to-read-through-those-theoretical-equation-flooded-papers face.\\n\\n[![clustering the tag space](http://i.imgur.com/40BW8.png \\\"clustering the tag space\\\")](http://tagging.pui.ch/automated_tag_clustering/#cluster)\\n\\nSo, here you go: [Automated Tag Clustering: Improving search and exploration in the tag space](http://tagging.pui.ch/automated_tag_clustering/).<!-- more -->\\n\\nTo read this document you should have a clue what tags are about, you should also know some tag services as [delicious](http://del.icio.us) or [flickr](http://www.flickr.com) so you can understand the limitations these services currently have. If you don&rsquo;t want to read through the whole papers, the numerous figures give you a good summary. Finally, to wet your appetite, here a few excerpts of the document:\\n\\n> Currently tagging services still provide a relatively marginal value for information discovery and we claim that with the use of clustering techniques this can be greatly improved [from [introduction](http://tagging.pui.ch/automated_tag_clustering/#p_motivation)]\\n> The whole promise of collaborative tagging is that by exploring the tag space you can discover a lot of useful information you would not find with traditional search engines. When your information need is not well defined, the idea that you can explore and see what other people tagged with certain tags is very attractive. We believe that tagging will be able to reach a very wide audience only when exploration techniques will be effective. [from [limited exploration](http://tagging.pui.ch/automated_tag_clustering/#p_exploration)]\\n> Although a great visualization paradigm, we believe that with today&rsquo;s tagclouds it is hard to find more than one or two tags to click on. Tags are not grouped, there is too much information, so that you find lot of related tags scattered on the tag cloud. One or two popular topics and all their related tags tend to dominate the whole cloud. For example, looking at the del.icio.us tagcloud, one would mostly see tags related to web design and technologies. This is because these topics are overwhelmingly more frequent than anything else. [from [limited exploration](http://tagging.pui.ch/automated_tag_clustering/#p_exploration)]\\n> Tag _web2.0_ nowadays is so popular and is combined wildly with anything. In fact this tag is so overused that if you look at [tag _bookmarks_ in the del.icio.us dataset](http://del.icio.us/tag/bookmarks), the most used cotag is _web2.0_[&hellip;]. Basing tag similarity on these numbers often doesn&rsquo;t make sense at all. The similarity measure should be chosen so the popularity of a tag doesn&rsquo;t affect the set of a tags related tags. Don&rsquo;t cut the [long tail](http://en.wikipedia.org/wiki/Long_tail). The success of blogs is driven by the importance of the long tail. We all know that it is crucial to support the niches. Tagging applications should empower the long tail too. If you just sort by popularity, you&rsquo;d loose all those niches. [from [choosing a similarity measure](http://tagging.pui.ch/automated_tag_clustering/#p_similarity)]\\n\\nWe&rsquo;d be happy to get any kind of feedback on the article. Just post a comment to this blog post.\\n\\n**Edit (4 years later!)**: A few guys asked me about the source code: [Source code with syntax highlighting](http://pastie.org/1098455).\\nYou need [kmetis](http://people.sc.fsu.edu/~jburkardt/c_src/kmetis/kmetis.html) to make this run, see `usage()` to see how it should be used.\\n\\n**Edit**: Robin sent me [this fixed source code](http://pastie.org/3549928), didn&rsquo;t test it though:\\n\\n<div class=\\\"blogger-post-footer\\\">![](https://blogger.googleusercontent.com/tracker/2748783673844839576-786221472892263493?l=theneachwenttohisownhome.blogspot.com)</div>\",\"slug\":\"Automated-tag-clustering\",\"published\":1,\"updated\":\"2017-11-11T21:18:41.798Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6080003i85posj73dhw\",\"content\":\"<p><a href=\\\"http://www.cs.technion.ac.il/%7Egbeg/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Grigory Begelman</a> (<a href=\\\"http://www.cs.technion.ac.il/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Technion - Israel Institute of Technology Computer Science Dpt)</a>, <a href=\\\"http://smadja.us/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Frank Smadja</a> (<a href=\\\"http://www.rawsugar.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">RawSugar</a>) and I did a paper for <a href=\\\"http://www2006.org\\\" target=\\\"_blank\\\" rel=\\\"external\\\">www2006</a> called &ldquo;automated tag clustering&rdquo;. It deals with why clustering the tag space makes sense and how this could be done.</p>\\n<p>After the presentation at the <a href=\\\"http://blog.rawsugar.com/wikka/wikka.php?wakka=HomePage\\\" target=\\\"_blank\\\" rel=\\\"external\\\">tagging workshop</a> at www2006 we felt the need to give our paper a more www-friendly, I-don&rsquo;t-want-to-read-through-those-theoretical-equation-flooded-papers face.</p>\\n<p><a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#cluster\\\" target=\\\"_blank\\\" rel=\\\"external\\\"><img src=\\\"http://i.imgur.com/40BW8.png\\\" alt=\\\"clustering the tag space\\\" title=\\\"clustering the tag space\\\"></a></p>\\n<p>So, here you go: <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Automated Tag Clustering: Improving search and exploration in the tag space</a>.<a id=\\\"more\\\"></a></p>\\n<p>To read this document you should have a clue what tags are about, you should also know some tag services as <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">delicious</a> or <a href=\\\"http://www.flickr.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">flickr</a> so you can understand the limitations these services currently have. If you don&rsquo;t want to read through the whole papers, the numerous figures give you a good summary. Finally, to wet your appetite, here a few excerpts of the document:</p>\\n<blockquote>\\n<p>Currently tagging services still provide a relatively marginal value for information discovery and we claim that with the use of clustering techniques this can be greatly improved [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_motivation\\\" target=\\\"_blank\\\" rel=\\\"external\\\">introduction</a>]<br>The whole promise of collaborative tagging is that by exploring the tag space you can discover a lot of useful information you would not find with traditional search engines. When your information need is not well defined, the idea that you can explore and see what other people tagged with certain tags is very attractive. We believe that tagging will be able to reach a very wide audience only when exploration techniques will be effective. [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_exploration\\\" target=\\\"_blank\\\" rel=\\\"external\\\">limited exploration</a>]<br>Although a great visualization paradigm, we believe that with today&rsquo;s tagclouds it is hard to find more than one or two tags to click on. Tags are not grouped, there is too much information, so that you find lot of related tags scattered on the tag cloud. One or two popular topics and all their related tags tend to dominate the whole cloud. For example, looking at the del.icio.us tagcloud, one would mostly see tags related to web design and technologies. This is because these topics are overwhelmingly more frequent than anything else. [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_exploration\\\" target=\\\"_blank\\\" rel=\\\"external\\\">limited exploration</a>]<br>Tag <em>web2.0</em> nowadays is so popular and is combined wildly with anything. In fact this tag is so overused that if you look at <a href=\\\"http://del.icio.us/tag/bookmarks\\\" target=\\\"_blank\\\" rel=\\\"external\\\">tag <em>bookmarks</em> in the del.icio.us dataset</a>, the most used cotag is <em>web2.0</em>[&hellip;]. Basing tag similarity on these numbers often doesn&rsquo;t make sense at all. The similarity measure should be chosen so the popularity of a tag doesn&rsquo;t affect the set of a tags related tags. Don&rsquo;t cut the <a href=\\\"http://en.wikipedia.org/wiki/Long_tail\\\" target=\\\"_blank\\\" rel=\\\"external\\\">long tail</a>. The success of blogs is driven by the importance of the long tail. We all know that it is crucial to support the niches. Tagging applications should empower the long tail too. If you just sort by popularity, you&rsquo;d loose all those niches. [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_similarity\\\" target=\\\"_blank\\\" rel=\\\"external\\\">choosing a similarity measure</a>]</p>\\n</blockquote>\\n<p>We&rsquo;d be happy to get any kind of feedback on the article. Just post a comment to this blog post.</p>\\n<p><strong>Edit (4 years later!)</strong>: A few guys asked me about the source code: <a href=\\\"http://pastie.org/1098455\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Source code with syntax highlighting</a>.<br>You need <a href=\\\"http://people.sc.fsu.edu/~jburkardt/c_src/kmetis/kmetis.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">kmetis</a> to make this run, see <code>usage()</code> to see how it should be used.</p>\\n<p><strong>Edit</strong>: Robin sent me <a href=\\\"http://pastie.org/3549928\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this fixed source code</a>, didn&rsquo;t test it though:</p>\\n<div class=\\\"blogger-post-footer\\\"><img src=\\\"https://blogger.googleusercontent.com/tracker/2748783673844839576-786221472892263493?l=theneachwenttohisownhome.blogspot.com\\\" alt=\\\"\\\"></div>\",\"site\":{\"data\":{}},\"excerpt\":\"<p><a href=\\\"http://www.cs.technion.ac.il/%7Egbeg/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Grigory Begelman</a> (<a href=\\\"http://www.cs.technion.ac.il/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Technion - Israel Institute of Technology Computer Science Dpt)</a>, <a href=\\\"http://smadja.us/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Frank Smadja</a> (<a href=\\\"http://www.rawsugar.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">RawSugar</a>) and I did a paper for <a href=\\\"http://www2006.org\\\" target=\\\"_blank\\\" rel=\\\"external\\\">www2006</a> called &ldquo;automated tag clustering&rdquo;. It deals with why clustering the tag space makes sense and how this could be done.</p>\\n<p>After the presentation at the <a href=\\\"http://blog.rawsugar.com/wikka/wikka.php?wakka=HomePage\\\" target=\\\"_blank\\\" rel=\\\"external\\\">tagging workshop</a> at www2006 we felt the need to give our paper a more www-friendly, I-don&rsquo;t-want-to-read-through-those-theoretical-equation-flooded-papers face.</p>\\n<p><a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#cluster\\\" target=\\\"_blank\\\" rel=\\\"external\\\"><img src=\\\"http://i.imgur.com/40BW8.png\\\" alt=\\\"clustering the tag space\\\" title=\\\"clustering the tag space\\\"></a></p>\\n<p>So, here you go: <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Automated Tag Clustering: Improving search and exploration in the tag space</a>.\",\"more\":\"</p>\\n<p>To read this document you should have a clue what tags are about, you should also know some tag services as <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">delicious</a> or <a href=\\\"http://www.flickr.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">flickr</a> so you can understand the limitations these services currently have. If you don&rsquo;t want to read through the whole papers, the numerous figures give you a good summary. Finally, to wet your appetite, here a few excerpts of the document:</p>\\n<blockquote>\\n<p>Currently tagging services still provide a relatively marginal value for information discovery and we claim that with the use of clustering techniques this can be greatly improved [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_motivation\\\" target=\\\"_blank\\\" rel=\\\"external\\\">introduction</a>]<br>The whole promise of collaborative tagging is that by exploring the tag space you can discover a lot of useful information you would not find with traditional search engines. When your information need is not well defined, the idea that you can explore and see what other people tagged with certain tags is very attractive. We believe that tagging will be able to reach a very wide audience only when exploration techniques will be effective. [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_exploration\\\" target=\\\"_blank\\\" rel=\\\"external\\\">limited exploration</a>]<br>Although a great visualization paradigm, we believe that with today&rsquo;s tagclouds it is hard to find more than one or two tags to click on. Tags are not grouped, there is too much information, so that you find lot of related tags scattered on the tag cloud. One or two popular topics and all their related tags tend to dominate the whole cloud. For example, looking at the del.icio.us tagcloud, one would mostly see tags related to web design and technologies. This is because these topics are overwhelmingly more frequent than anything else. [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_exploration\\\" target=\\\"_blank\\\" rel=\\\"external\\\">limited exploration</a>]<br>Tag <em>web2.0</em> nowadays is so popular and is combined wildly with anything. In fact this tag is so overused that if you look at <a href=\\\"http://del.icio.us/tag/bookmarks\\\" target=\\\"_blank\\\" rel=\\\"external\\\">tag <em>bookmarks</em> in the del.icio.us dataset</a>, the most used cotag is <em>web2.0</em>[&hellip;]. Basing tag similarity on these numbers often doesn&rsquo;t make sense at all. The similarity measure should be chosen so the popularity of a tag doesn&rsquo;t affect the set of a tags related tags. Don&rsquo;t cut the <a href=\\\"http://en.wikipedia.org/wiki/Long_tail\\\" target=\\\"_blank\\\" rel=\\\"external\\\">long tail</a>. The success of blogs is driven by the importance of the long tail. We all know that it is crucial to support the niches. Tagging applications should empower the long tail too. If you just sort by popularity, you&rsquo;d loose all those niches. [from <a href=\\\"http://tagging.pui.ch/automated_tag_clustering/#p_similarity\\\" target=\\\"_blank\\\" rel=\\\"external\\\">choosing a similarity measure</a>]</p>\\n</blockquote>\\n<p>We&rsquo;d be happy to get any kind of feedback on the article. Just post a comment to this blog post.</p>\\n<p><strong>Edit (4 years later!)</strong>: A few guys asked me about the source code: <a href=\\\"http://pastie.org/1098455\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Source code with syntax highlighting</a>.<br>You need <a href=\\\"http://people.sc.fsu.edu/~jburkardt/c_src/kmetis/kmetis.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">kmetis</a> to make this run, see <code>usage()</code> to see how it should be used.</p>\\n<p><strong>Edit</strong>: Robin sent me <a href=\\\"http://pastie.org/3549928\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this fixed source code</a>, didn&rsquo;t test it though:</p>\\n<div class=\\\"blogger-post-footer\\\"><img src=\\\"https://blogger.googleusercontent.com/tracker/2748783673844839576-786221472892263493?l=theneachwenttohisownhome.blogspot.com\\\" alt=\\\"\\\"></div>\"},{\"title\":\"How to attach a file to google spreadsheet\",\"date\":\"2014-01-20T15:06:00.000Z\",\"alias\":\"/post/73949358752/how-to-attach-a-file-to-google-spreadsheet\",\"_content\":\"\\n![asdf](http://i.imgur.com/UnohuzJ.png)\\n\\nThe following setup lets you\\n\\n*   choose a file from your computer to upload\\n*   upload it to a defined folder on google drive\\n*   inserts the link to the current cell\\n\\n<!-- more -->\\n\\nTo get it working:\\n\\n1.  find out the id of the google drive folder you want your attachments be saved (in the example below this is `0B0uw1JCogWHuc29FWFJMWmc3Z1k`)\\n2.  in the spreadsheet where you want to upload the file: do Tools→Script Editor.. and paste the script below. Be sure to replace the id with your folders id\\n\\n**Update 2014**: Made it working with [the new sheets](http://googleblog.blogspot.ch/2013/12/new-google-sheets-faster-more-powerful.html)\\n**Update 2016-05** Fixed the script thanks to the comments by Fede and Dov (DocsList.getFolderId was not working any more)\\n\\n        // upload document into google spreadsheet\\n        // and put link to it into current cell\\n\\n        function onOpen(e) {\\n          var ss = SpreadsheetApp.getActiveSpreadsheet()\\n          var menuEntries = [];\\n          menuEntries.push({name: \\\"File...\\\", functionName: \\\"doGet\\\"});\\n          ss.addMenu(\\\"Attach ...\\\", menuEntries);\\n        }\\n\\n        function doGet(e) {\\n          var app = UiApp.createApplication().setTitle(\\\"upload attachment into Google Drive\\\");\\n          SpreadsheetApp.getActiveSpreadsheet().show(app);\\n          var form = app.createFormPanel().setId('frm').setEncoding('multipart/form-data');\\n          var formContent = app.createVerticalPanel();\\n          form.add(formContent);  \\n          formContent.add(app.createFileUpload().setName('thefile'));\\n\\n          // these parameters need to be passed by form\\n          // in doPost() these cannot be found out anymore\\n          formContent.add(app.createHidden(\\\"activeCell\\\", SpreadsheetApp.getActiveRange().getA1Notation()));\\n          formContent.add(app.createHidden(\\\"activeSheet\\\", SpreadsheetApp.getActiveSheet().getName()));\\n          formContent.add(app.createHidden(\\\"activeSpreadsheet\\\", SpreadsheetApp.getActiveSpreadsheet().getId()));\\n          formContent.add(app.createSubmitButton('Submit'));\\n          app.add(form);\\n          SpreadsheetApp.getActiveSpreadsheet().show(app);\\n          return app;\\n        }\\n\\n        function doPost(e) {\\n          var app = UiApp.getActiveApplication();\\n          app.createLabel('saving...');\\n          var fileBlob = e.parameter.thefile;\\n      var doc = DriveApp.getFolderById('0B0uw1JCogWHuc29FWFJMWmc3Z1k').createFile(fileBlob);\\n          var label = app.createLabel('file uploaded successfully');\\n\\n          // write value into current cell\\n          var value = 'hyperlink(\\\"' + doc.getUrl() + '\\\";\\\"' + doc.getName() + '\\\")'\\n          var activeSpreadsheet = e.parameter.activeSpreadsheet;\\n          var activeSheet = e.parameter.activeSheet;\\n          var activeCell = e.parameter.activeCell;\\n          var label = app.createLabel('file uploaded successfully');\\n          app.add(label);\\n          SpreadsheetApp.openById(activeSpreadsheet).getSheetByName(activeSheet).getRange(activeCell).setFormula(value);\\n          app.close();\\n          return app;\\n        }\\n    \",\"source\":\"_posts/How-to-attach-a-file-to-google-spreadsheet.md\",\"raw\":\"---\\ntitle: How to attach a file to google spreadsheet\\ntags:\\n  - google-spreadsheet\\n  - google-apps-scripts\\n  - attachments\\ndate: 2014-01-20 16:06:00\\nalias: /post/73949358752/how-to-attach-a-file-to-google-spreadsheet\\n---\\n\\n![asdf](http://i.imgur.com/UnohuzJ.png)\\n\\nThe following setup lets you\\n\\n*   choose a file from your computer to upload\\n*   upload it to a defined folder on google drive\\n*   inserts the link to the current cell\\n\\n<!-- more -->\\n\\nTo get it working:\\n\\n1.  find out the id of the google drive folder you want your attachments be saved (in the example below this is `0B0uw1JCogWHuc29FWFJMWmc3Z1k`)\\n2.  in the spreadsheet where you want to upload the file: do Tools→Script Editor.. and paste the script below. Be sure to replace the id with your folders id\\n\\n**Update 2014**: Made it working with [the new sheets](http://googleblog.blogspot.ch/2013/12/new-google-sheets-faster-more-powerful.html)\\n**Update 2016-05** Fixed the script thanks to the comments by Fede and Dov (DocsList.getFolderId was not working any more)\\n\\n        // upload document into google spreadsheet\\n        // and put link to it into current cell\\n\\n        function onOpen(e) {\\n          var ss = SpreadsheetApp.getActiveSpreadsheet()\\n          var menuEntries = [];\\n          menuEntries.push({name: \\\"File...\\\", functionName: \\\"doGet\\\"});\\n          ss.addMenu(\\\"Attach ...\\\", menuEntries);\\n        }\\n\\n        function doGet(e) {\\n          var app = UiApp.createApplication().setTitle(\\\"upload attachment into Google Drive\\\");\\n          SpreadsheetApp.getActiveSpreadsheet().show(app);\\n          var form = app.createFormPanel().setId('frm').setEncoding('multipart/form-data');\\n          var formContent = app.createVerticalPanel();\\n          form.add(formContent);  \\n          formContent.add(app.createFileUpload().setName('thefile'));\\n\\n          // these parameters need to be passed by form\\n          // in doPost() these cannot be found out anymore\\n          formContent.add(app.createHidden(\\\"activeCell\\\", SpreadsheetApp.getActiveRange().getA1Notation()));\\n          formContent.add(app.createHidden(\\\"activeSheet\\\", SpreadsheetApp.getActiveSheet().getName()));\\n          formContent.add(app.createHidden(\\\"activeSpreadsheet\\\", SpreadsheetApp.getActiveSpreadsheet().getId()));\\n          formContent.add(app.createSubmitButton('Submit'));\\n          app.add(form);\\n          SpreadsheetApp.getActiveSpreadsheet().show(app);\\n          return app;\\n        }\\n\\n        function doPost(e) {\\n          var app = UiApp.getActiveApplication();\\n          app.createLabel('saving...');\\n          var fileBlob = e.parameter.thefile;\\n      var doc = DriveApp.getFolderById('0B0uw1JCogWHuc29FWFJMWmc3Z1k').createFile(fileBlob);\\n          var label = app.createLabel('file uploaded successfully');\\n\\n          // write value into current cell\\n          var value = 'hyperlink(\\\"' + doc.getUrl() + '\\\";\\\"' + doc.getName() + '\\\")'\\n          var activeSpreadsheet = e.parameter.activeSpreadsheet;\\n          var activeSheet = e.parameter.activeSheet;\\n          var activeCell = e.parameter.activeCell;\\n          var label = app.createLabel('file uploaded successfully');\\n          app.add(label);\\n          SpreadsheetApp.openById(activeSpreadsheet).getSheetByName(activeSheet).getRange(activeCell).setFormula(value);\\n          app.close();\\n          return app;\\n        }\\n    \",\"slug\":\"How-to-attach-a-file-to-google-spreadsheet\",\"published\":1,\"updated\":\"2017-11-11T21:15:54.261Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6090004i85p0e6xutyk\",\"content\":\"<p><img src=\\\"http://i.imgur.com/UnohuzJ.png\\\" alt=\\\"asdf\\\"></p>\\n<p>The following setup lets you</p>\\n<ul>\\n<li>choose a file from your computer to upload</li>\\n<li>upload it to a defined folder on google drive</li>\\n<li>inserts the link to the current cell</li>\\n</ul>\\n<a id=\\\"more\\\"></a>\\n<p>To get it working:</p>\\n<ol>\\n<li>find out the id of the google drive folder you want your attachments be saved (in the example below this is <code>0B0uw1JCogWHuc29FWFJMWmc3Z1k</code>)</li>\\n<li>in the spreadsheet where you want to upload the file: do Tools→Script Editor.. and paste the script below. Be sure to replace the id with your folders id</li>\\n</ol>\\n<p><strong>Update 2014</strong>: Made it working with <a href=\\\"http://googleblog.blogspot.ch/2013/12/new-google-sheets-faster-more-powerful.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">the new sheets</a><br><strong>Update 2016-05</strong> Fixed the script thanks to the comments by Fede and Dov (DocsList.getFolderId was not working any more)</p>\\n<pre><code>  // upload document into google spreadsheet\\n  // and put link to it into current cell\\n\\n  function onOpen(e) {\\n    var ss = SpreadsheetApp.getActiveSpreadsheet()\\n    var menuEntries = [];\\n    menuEntries.push({name: &quot;File...&quot;, functionName: &quot;doGet&quot;});\\n    ss.addMenu(&quot;Attach ...&quot;, menuEntries);\\n  }\\n\\n  function doGet(e) {\\n    var app = UiApp.createApplication().setTitle(&quot;upload attachment into Google Drive&quot;);\\n    SpreadsheetApp.getActiveSpreadsheet().show(app);\\n    var form = app.createFormPanel().setId(&apos;frm&apos;).setEncoding(&apos;multipart/form-data&apos;);\\n    var formContent = app.createVerticalPanel();\\n    form.add(formContent);  \\n    formContent.add(app.createFileUpload().setName(&apos;thefile&apos;));\\n\\n    // these parameters need to be passed by form\\n    // in doPost() these cannot be found out anymore\\n    formContent.add(app.createHidden(&quot;activeCell&quot;, SpreadsheetApp.getActiveRange().getA1Notation()));\\n    formContent.add(app.createHidden(&quot;activeSheet&quot;, SpreadsheetApp.getActiveSheet().getName()));\\n    formContent.add(app.createHidden(&quot;activeSpreadsheet&quot;, SpreadsheetApp.getActiveSpreadsheet().getId()));\\n    formContent.add(app.createSubmitButton(&apos;Submit&apos;));\\n    app.add(form);\\n    SpreadsheetApp.getActiveSpreadsheet().show(app);\\n    return app;\\n  }\\n\\n  function doPost(e) {\\n    var app = UiApp.getActiveApplication();\\n    app.createLabel(&apos;saving...&apos;);\\n    var fileBlob = e.parameter.thefile;\\nvar doc = DriveApp.getFolderById(&apos;0B0uw1JCogWHuc29FWFJMWmc3Z1k&apos;).createFile(fileBlob);\\n    var label = app.createLabel(&apos;file uploaded successfully&apos;);\\n\\n    // write value into current cell\\n    var value = &apos;hyperlink(&quot;&apos; + doc.getUrl() + &apos;&quot;;&quot;&apos; + doc.getName() + &apos;&quot;)&apos;\\n    var activeSpreadsheet = e.parameter.activeSpreadsheet;\\n    var activeSheet = e.parameter.activeSheet;\\n    var activeCell = e.parameter.activeCell;\\n    var label = app.createLabel(&apos;file uploaded successfully&apos;);\\n    app.add(label);\\n    SpreadsheetApp.openById(activeSpreadsheet).getSheetByName(activeSheet).getRange(activeCell).setFormula(value);\\n    app.close();\\n    return app;\\n  }\\n</code></pre>\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"http://i.imgur.com/UnohuzJ.png\\\" alt=\\\"asdf\\\"></p>\\n<p>The following setup lets you</p>\\n<ul>\\n<li>choose a file from your computer to upload</li>\\n<li>upload it to a defined folder on google drive</li>\\n<li>inserts the link to the current cell</li>\\n</ul>\",\"more\":\"<p>To get it working:</p>\\n<ol>\\n<li>find out the id of the google drive folder you want your attachments be saved (in the example below this is <code>0B0uw1JCogWHuc29FWFJMWmc3Z1k</code>)</li>\\n<li>in the spreadsheet where you want to upload the file: do Tools→Script Editor.. and paste the script below. Be sure to replace the id with your folders id</li>\\n</ol>\\n<p><strong>Update 2014</strong>: Made it working with <a href=\\\"http://googleblog.blogspot.ch/2013/12/new-google-sheets-faster-more-powerful.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">the new sheets</a><br><strong>Update 2016-05</strong> Fixed the script thanks to the comments by Fede and Dov (DocsList.getFolderId was not working any more)</p>\\n<pre><code>  // upload document into google spreadsheet\\n  // and put link to it into current cell\\n\\n  function onOpen(e) {\\n    var ss = SpreadsheetApp.getActiveSpreadsheet()\\n    var menuEntries = [];\\n    menuEntries.push({name: &quot;File...&quot;, functionName: &quot;doGet&quot;});\\n    ss.addMenu(&quot;Attach ...&quot;, menuEntries);\\n  }\\n\\n  function doGet(e) {\\n    var app = UiApp.createApplication().setTitle(&quot;upload attachment into Google Drive&quot;);\\n    SpreadsheetApp.getActiveSpreadsheet().show(app);\\n    var form = app.createFormPanel().setId(&apos;frm&apos;).setEncoding(&apos;multipart/form-data&apos;);\\n    var formContent = app.createVerticalPanel();\\n    form.add(formContent);  \\n    formContent.add(app.createFileUpload().setName(&apos;thefile&apos;));\\n\\n    // these parameters need to be passed by form\\n    // in doPost() these cannot be found out anymore\\n    formContent.add(app.createHidden(&quot;activeCell&quot;, SpreadsheetApp.getActiveRange().getA1Notation()));\\n    formContent.add(app.createHidden(&quot;activeSheet&quot;, SpreadsheetApp.getActiveSheet().getName()));\\n    formContent.add(app.createHidden(&quot;activeSpreadsheet&quot;, SpreadsheetApp.getActiveSpreadsheet().getId()));\\n    formContent.add(app.createSubmitButton(&apos;Submit&apos;));\\n    app.add(form);\\n    SpreadsheetApp.getActiveSpreadsheet().show(app);\\n    return app;\\n  }\\n\\n  function doPost(e) {\\n    var app = UiApp.getActiveApplication();\\n    app.createLabel(&apos;saving...&apos;);\\n    var fileBlob = e.parameter.thefile;\\nvar doc = DriveApp.getFolderById(&apos;0B0uw1JCogWHuc29FWFJMWmc3Z1k&apos;).createFile(fileBlob);\\n    var label = app.createLabel(&apos;file uploaded successfully&apos;);\\n\\n    // write value into current cell\\n    var value = &apos;hyperlink(&quot;&apos; + doc.getUrl() + &apos;&quot;;&quot;&apos; + doc.getName() + &apos;&quot;)&apos;\\n    var activeSpreadsheet = e.parameter.activeSpreadsheet;\\n    var activeSheet = e.parameter.activeSheet;\\n    var activeCell = e.parameter.activeCell;\\n    var label = app.createLabel(&apos;file uploaded successfully&apos;);\\n    app.add(label);\\n    SpreadsheetApp.openById(activeSpreadsheet).getSheetByName(activeSheet).getRange(activeCell).setFormula(value);\\n    app.close();\\n    return app;\\n  }\\n</code></pre>\"},{\"title\":\"How to mass convert mp3 files to aac (m3a)\",\"date\":\"2017-11-29T15:22:14.000Z\",\"_content\":\"\\n<img src=\\\"/images/tape.jpg\\\" />\\n\\nSince aac has a slightly better compression rate than mp3 (and, geez, mp3 was standardized 1992, there must be better standards nowaday), I decided to mass convert my music library from mp3 to aac\\n\\n# Won't the quality be just awful?\\n\\nOf course, re-encoding sounds like a terrible idea. You're converting from one lossfull format to another, similar when mass-converting gifs to jpegs. But on the other hand, for my setting it was just good enough. The library I converted we listen to at home over Sonos or in the car. So in both settings there are only half-decent speakers. Also, many of the tracks I converted from audio cassettes, so they were in a bad quality already. You can certainly play with the bitrate, but if you have invested into an expensive stereo you'd be better off converting from a lossless source.\\n\\n# Declutter\\n\\nFirst things first: Almost everything in life is easier if you first reduce it to the absolute necessity. I recently spoke with a colleague who told me she has converted her whole CD stack into mp3 without first trashing the CDs she never listens to. That's insane.\\n\\nFirst, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don't need to carry.\\n\\n# No words! I just want to copy-paste\\n\\nHere you go: Once, you haved `cd`ed into the directory with the mp3 files you want to convert, do this:\\n\\n```\\ndetox *.mp3\\nfmpeg -i *.mp3([1]) artwork.jpg\\nfor i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 ${i/mp3/m4a}; done\\nfor i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done\\nrm artwork.jpg && rm *.mp3\\n```\\n\\n<!-- more -->\\n\\n# Line 1: Asciify your filenames with detox\\n\\nEverything is easier on the shell if instead of having `my süpér s'öñg.mp3` having a file called `my_super_song.mp3`. Detox converts all characters which you need to somehow escape on the shell to ascii characters.\\n\\n# Line 2: Extract artwork\\n\\nWe'll use ffmpeg to convert from mp3 to aac. Sadly the convert command does not transport your artworks, so you need to first extract the artwork. Use the correct ending (otherwise you'll have a problem in line 4). This command takes the first mp3 and extracts the artwork into artwork.jpg.\\n\\n# Line 3: Convert\\n\\nNow, in my version of Ubuntu (Xenial, 16.04) ffmpeg does not come with the compiled in converter from mp3 to aac, so I needed to first [compile ffmpeg from source](http://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu). This was quite straightforward for me except that it kept saying I had x265 not installed even after doing `sudo apt install libx265-dev`. I needed to follow [these steps](https://bitbucket.org/multicoreware/x265/issues/125/x265-not-found-using-pkg-config#comment-17635086) to have this resolved. \\n\\nIf you don't want to compile from source then [here](https://superuser.com/a/370637) is a good overview on all the options you have for doing this step. Just be sure to use the right path, `~/bin/ffmpeg` is referring to my compiled ffmpeg binary.\\n\\n## Playing with the options\\n\\n- `-b:a 128k`: this sets a fixed bitrate. If you'd wish a variable bitrate (having more details for more \\\"dynamic\\\" sections of the track) then you can use `-vbr 4` instead, or lower it for lower quality/higher compression.\\n- the `-vf scale=1280:-2` bit is needed to circumvent the `height not divisible by 2` error. Taken from [here](https://stackoverflow.com/a/20848224/119861)\\n\\n# Line 4: Set artwork\\n\\nThis just sets back the artwork you extracted in line 2. This was taken from [here](https://superuser.com/a/524120).\\n\\n# Line 5: Cleanup\\n\\nYeah, finally delete all the old file and enjoy the smaller filesize :)\\n\",\"source\":\"_posts/How-to-mass-convert-mp3-files-to-aac-m3a.md\",\"raw\":\"---\\ntitle: How to mass convert mp3 files to aac (m3a)\\ndate: 2017-11-29 16:22:14\\ntags:\\n- ffmpeg\\n- mp3\\n- aac\\n---\\n\\n<img src=\\\"/images/tape.jpg\\\" />\\n\\nSince aac has a slightly better compression rate than mp3 (and, geez, mp3 was standardized 1992, there must be better standards nowaday), I decided to mass convert my music library from mp3 to aac\\n\\n# Won't the quality be just awful?\\n\\nOf course, re-encoding sounds like a terrible idea. You're converting from one lossfull format to another, similar when mass-converting gifs to jpegs. But on the other hand, for my setting it was just good enough. The library I converted we listen to at home over Sonos or in the car. So in both settings there are only half-decent speakers. Also, many of the tracks I converted from audio cassettes, so they were in a bad quality already. You can certainly play with the bitrate, but if you have invested into an expensive stereo you'd be better off converting from a lossless source.\\n\\n# Declutter\\n\\nFirst things first: Almost everything in life is easier if you first reduce it to the absolute necessity. I recently spoke with a colleague who told me she has converted her whole CD stack into mp3 without first trashing the CDs she never listens to. That's insane.\\n\\nFirst, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don't need to carry.\\n\\n# No words! I just want to copy-paste\\n\\nHere you go: Once, you haved `cd`ed into the directory with the mp3 files you want to convert, do this:\\n\\n```\\ndetox *.mp3\\nfmpeg -i *.mp3([1]) artwork.jpg\\nfor i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 ${i/mp3/m4a}; done\\nfor i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done\\nrm artwork.jpg && rm *.mp3\\n```\\n\\n<!-- more -->\\n\\n# Line 1: Asciify your filenames with detox\\n\\nEverything is easier on the shell if instead of having `my süpér s'öñg.mp3` having a file called `my_super_song.mp3`. Detox converts all characters which you need to somehow escape on the shell to ascii characters.\\n\\n# Line 2: Extract artwork\\n\\nWe'll use ffmpeg to convert from mp3 to aac. Sadly the convert command does not transport your artworks, so you need to first extract the artwork. Use the correct ending (otherwise you'll have a problem in line 4). This command takes the first mp3 and extracts the artwork into artwork.jpg.\\n\\n# Line 3: Convert\\n\\nNow, in my version of Ubuntu (Xenial, 16.04) ffmpeg does not come with the compiled in converter from mp3 to aac, so I needed to first [compile ffmpeg from source](http://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu). This was quite straightforward for me except that it kept saying I had x265 not installed even after doing `sudo apt install libx265-dev`. I needed to follow [these steps](https://bitbucket.org/multicoreware/x265/issues/125/x265-not-found-using-pkg-config#comment-17635086) to have this resolved. \\n\\nIf you don't want to compile from source then [here](https://superuser.com/a/370637) is a good overview on all the options you have for doing this step. Just be sure to use the right path, `~/bin/ffmpeg` is referring to my compiled ffmpeg binary.\\n\\n## Playing with the options\\n\\n- `-b:a 128k`: this sets a fixed bitrate. If you'd wish a variable bitrate (having more details for more \\\"dynamic\\\" sections of the track) then you can use `-vbr 4` instead, or lower it for lower quality/higher compression.\\n- the `-vf scale=1280:-2` bit is needed to circumvent the `height not divisible by 2` error. Taken from [here](https://stackoverflow.com/a/20848224/119861)\\n\\n# Line 4: Set artwork\\n\\nThis just sets back the artwork you extracted in line 2. This was taken from [here](https://superuser.com/a/524120).\\n\\n# Line 5: Cleanup\\n\\nYeah, finally delete all the old file and enjoy the smaller filesize :)\\n\",\"slug\":\"How-to-mass-convert-mp3-files-to-aac-m3a\",\"published\":1,\"updated\":\"2017-12-01T13:48:47.198Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60a0005i85prebk9zdp\",\"content\":\"<p><img src=\\\"/images/tape.jpg\\\"></p>\\n<p>Since aac has a slightly better compression rate than mp3 (and, geez, mp3 was standardized 1992, there must be better standards nowaday), I decided to mass convert my music library from mp3 to aac</p>\\n<h1 id=\\\"Won’t-the-quality-be-just-awful\\\"><a href=\\\"#Won’t-the-quality-be-just-awful\\\" class=\\\"headerlink\\\" title=\\\"Won’t the quality be just awful?\\\"></a>Won’t the quality be just awful?</h1><p>Of course, re-encoding sounds like a terrible idea. You’re converting from one lossfull format to another, similar when mass-converting gifs to jpegs. But on the other hand, for my setting it was just good enough. The library I converted we listen to at home over Sonos or in the car. So in both settings there are only half-decent speakers. Also, many of the tracks I converted from audio cassettes, so they were in a bad quality already. You can certainly play with the bitrate, but if you have invested into an expensive stereo you’d be better off converting from a lossless source.</p>\\n<h1 id=\\\"Declutter\\\"><a href=\\\"#Declutter\\\" class=\\\"headerlink\\\" title=\\\"Declutter\\\"></a>Declutter</h1><p>First things first: Almost everything in life is easier if you first reduce it to the absolute necessity. I recently spoke with a colleague who told me she has converted her whole CD stack into mp3 without first trashing the CDs she never listens to. That’s insane.</p>\\n<p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p>\\n<h1 id=\\\"No-words-I-just-want-to-copy-paste\\\"><a href=\\\"#No-words-I-just-want-to-copy-paste\\\" class=\\\"headerlink\\\" title=\\\"No words! I just want to copy-paste\\\"></a>No words! I just want to copy-paste</h1><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">detox *.mp3</span><br><span class=\\\"line\\\">fmpeg -i *.mp3([1]) artwork.jpg</span><br><span class=\\\"line\\\">for i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 $&#123;i/mp3/m4a&#125;; done</span><br><span class=\\\"line\\\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done</span><br><span class=\\\"line\\\">rm artwork.jpg &amp;&amp; rm *.mp3</span><br></pre></td></tr></table></figure>\\n<a id=\\\"more\\\"></a>\\n<h1 id=\\\"Line-1-Asciify-your-filenames-with-detox\\\"><a href=\\\"#Line-1-Asciify-your-filenames-with-detox\\\" class=\\\"headerlink\\\" title=\\\"Line 1: Asciify your filenames with detox\\\"></a>Line 1: Asciify your filenames with detox</h1><p>Everything is easier on the shell if instead of having <code>my süpér s&#39;öñg.mp3</code> having a file called <code>my_super_song.mp3</code>. Detox converts all characters which you need to somehow escape on the shell to ascii characters.</p>\\n<h1 id=\\\"Line-2-Extract-artwork\\\"><a href=\\\"#Line-2-Extract-artwork\\\" class=\\\"headerlink\\\" title=\\\"Line 2: Extract artwork\\\"></a>Line 2: Extract artwork</h1><p>We’ll use ffmpeg to convert from mp3 to aac. Sadly the convert command does not transport your artworks, so you need to first extract the artwork. Use the correct ending (otherwise you’ll have a problem in line 4). This command takes the first mp3 and extracts the artwork into artwork.jpg.</p>\\n<h1 id=\\\"Line-3-Convert\\\"><a href=\\\"#Line-3-Convert\\\" class=\\\"headerlink\\\" title=\\\"Line 3: Convert\\\"></a>Line 3: Convert</h1><p>Now, in my version of Ubuntu (Xenial, 16.04) ffmpeg does not come with the compiled in converter from mp3 to aac, so I needed to first <a href=\\\"http://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu\\\" target=\\\"_blank\\\" rel=\\\"external\\\">compile ffmpeg from source</a>. This was quite straightforward for me except that it kept saying I had x265 not installed even after doing <code>sudo apt install libx265-dev</code>. I needed to follow <a href=\\\"https://bitbucket.org/multicoreware/x265/issues/125/x265-not-found-using-pkg-config#comment-17635086\\\" target=\\\"_blank\\\" rel=\\\"external\\\">these steps</a> to have this resolved. </p>\\n<p>If you don’t want to compile from source then <a href=\\\"https://superuser.com/a/370637\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a> is a good overview on all the options you have for doing this step. Just be sure to use the right path, <code>~/bin/ffmpeg</code> is referring to my compiled ffmpeg binary.</p>\\n<h2 id=\\\"Playing-with-the-options\\\"><a href=\\\"#Playing-with-the-options\\\" class=\\\"headerlink\\\" title=\\\"Playing with the options\\\"></a>Playing with the options</h2><ul>\\n<li><code>-b:a 128k</code>: this sets a fixed bitrate. If you’d wish a variable bitrate (having more details for more “dynamic” sections of the track) then you can use <code>-vbr 4</code> instead, or lower it for lower quality/higher compression.</li>\\n<li>the <code>-vf scale=1280:-2</code> bit is needed to circumvent the <code>height not divisible by 2</code> error. Taken from <a href=\\\"https://stackoverflow.com/a/20848224/119861\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a></li>\\n</ul>\\n<h1 id=\\\"Line-4-Set-artwork\\\"><a href=\\\"#Line-4-Set-artwork\\\" class=\\\"headerlink\\\" title=\\\"Line 4: Set artwork\\\"></a>Line 4: Set artwork</h1><p>This just sets back the artwork you extracted in line 2. This was taken from <a href=\\\"https://superuser.com/a/524120\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>.</p>\\n<h1 id=\\\"Line-5-Cleanup\\\"><a href=\\\"#Line-5-Cleanup\\\" class=\\\"headerlink\\\" title=\\\"Line 5: Cleanup\\\"></a>Line 5: Cleanup</h1><p>Yeah, finally delete all the old file and enjoy the smaller filesize :)</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"/images/tape.jpg\\\"></p>\\n<p>Since aac has a slightly better compression rate than mp3 (and, geez, mp3 was standardized 1992, there must be better standards nowaday), I decided to mass convert my music library from mp3 to aac</p>\\n<h1 id=\\\"Won’t-the-quality-be-just-awful\\\"><a href=\\\"#Won’t-the-quality-be-just-awful\\\" class=\\\"headerlink\\\" title=\\\"Won’t the quality be just awful?\\\"></a>Won’t the quality be just awful?</h1><p>Of course, re-encoding sounds like a terrible idea. You’re converting from one lossfull format to another, similar when mass-converting gifs to jpegs. But on the other hand, for my setting it was just good enough. The library I converted we listen to at home over Sonos or in the car. So in both settings there are only half-decent speakers. Also, many of the tracks I converted from audio cassettes, so they were in a bad quality already. You can certainly play with the bitrate, but if you have invested into an expensive stereo you’d be better off converting from a lossless source.</p>\\n<h1 id=\\\"Declutter\\\"><a href=\\\"#Declutter\\\" class=\\\"headerlink\\\" title=\\\"Declutter\\\"></a>Declutter</h1><p>First things first: Almost everything in life is easier if you first reduce it to the absolute necessity. I recently spoke with a colleague who told me she has converted her whole CD stack into mp3 without first trashing the CDs she never listens to. That’s insane.</p>\\n<p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p>\\n<h1 id=\\\"No-words-I-just-want-to-copy-paste\\\"><a href=\\\"#No-words-I-just-want-to-copy-paste\\\" class=\\\"headerlink\\\" title=\\\"No words! I just want to copy-paste\\\"></a>No words! I just want to copy-paste</h1><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">detox *.mp3</span><br><span class=\\\"line\\\">fmpeg -i *.mp3([1]) artwork.jpg</span><br><span class=\\\"line\\\">for i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 $&#123;i/mp3/m4a&#125;; done</span><br><span class=\\\"line\\\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done</span><br><span class=\\\"line\\\">rm artwork.jpg &amp;&amp; rm *.mp3</span><br></pre></td></tr></table></figure>\",\"more\":\"<h1 id=\\\"Line-1-Asciify-your-filenames-with-detox\\\"><a href=\\\"#Line-1-Asciify-your-filenames-with-detox\\\" class=\\\"headerlink\\\" title=\\\"Line 1: Asciify your filenames with detox\\\"></a>Line 1: Asciify your filenames with detox</h1><p>Everything is easier on the shell if instead of having <code>my süpér s&#39;öñg.mp3</code> having a file called <code>my_super_song.mp3</code>. Detox converts all characters which you need to somehow escape on the shell to ascii characters.</p>\\n<h1 id=\\\"Line-2-Extract-artwork\\\"><a href=\\\"#Line-2-Extract-artwork\\\" class=\\\"headerlink\\\" title=\\\"Line 2: Extract artwork\\\"></a>Line 2: Extract artwork</h1><p>We’ll use ffmpeg to convert from mp3 to aac. Sadly the convert command does not transport your artworks, so you need to first extract the artwork. Use the correct ending (otherwise you’ll have a problem in line 4). This command takes the first mp3 and extracts the artwork into artwork.jpg.</p>\\n<h1 id=\\\"Line-3-Convert\\\"><a href=\\\"#Line-3-Convert\\\" class=\\\"headerlink\\\" title=\\\"Line 3: Convert\\\"></a>Line 3: Convert</h1><p>Now, in my version of Ubuntu (Xenial, 16.04) ffmpeg does not come with the compiled in converter from mp3 to aac, so I needed to first <a href=\\\"http://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu\\\" target=\\\"_blank\\\" rel=\\\"external\\\">compile ffmpeg from source</a>. This was quite straightforward for me except that it kept saying I had x265 not installed even after doing <code>sudo apt install libx265-dev</code>. I needed to follow <a href=\\\"https://bitbucket.org/multicoreware/x265/issues/125/x265-not-found-using-pkg-config#comment-17635086\\\" target=\\\"_blank\\\" rel=\\\"external\\\">these steps</a> to have this resolved. </p>\\n<p>If you don’t want to compile from source then <a href=\\\"https://superuser.com/a/370637\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a> is a good overview on all the options you have for doing this step. Just be sure to use the right path, <code>~/bin/ffmpeg</code> is referring to my compiled ffmpeg binary.</p>\\n<h2 id=\\\"Playing-with-the-options\\\"><a href=\\\"#Playing-with-the-options\\\" class=\\\"headerlink\\\" title=\\\"Playing with the options\\\"></a>Playing with the options</h2><ul>\\n<li><code>-b:a 128k</code>: this sets a fixed bitrate. If you’d wish a variable bitrate (having more details for more “dynamic” sections of the track) then you can use <code>-vbr 4</code> instead, or lower it for lower quality/higher compression.</li>\\n<li>the <code>-vf scale=1280:-2</code> bit is needed to circumvent the <code>height not divisible by 2</code> error. Taken from <a href=\\\"https://stackoverflow.com/a/20848224/119861\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a></li>\\n</ul>\\n<h1 id=\\\"Line-4-Set-artwork\\\"><a href=\\\"#Line-4-Set-artwork\\\" class=\\\"headerlink\\\" title=\\\"Line 4: Set artwork\\\"></a>Line 4: Set artwork</h1><p>This just sets back the artwork you extracted in line 2. This was taken from <a href=\\\"https://superuser.com/a/524120\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>.</p>\\n<h1 id=\\\"Line-5-Cleanup\\\"><a href=\\\"#Line-5-Cleanup\\\" class=\\\"headerlink\\\" title=\\\"Line 5: Cleanup\\\"></a>Line 5: Cleanup</h1><p>Yeah, finally delete all the old file and enjoy the smaller filesize :)</p>\"},{\"title\":\"How to reset Jambox when bluetooth completely stopped working\",\"date\":\"2012-07-14T17:26:00.000Z\",\"alias\":\"/post/37471160886/how-to-reset-jambox-when-bluetooth-completely\",\"_content\":\"\\n  I bought a Jambox about half a year ago. Sound wise it is great, but apparently it is not very stable, especially after recharging it falls into some state where it only utters static noise. In this state it still plays music over the aux cable, but not any more over bluetooth.<!-- more -->\\n\\nApparently the issue is the aux port which has two contacts that should touch each other when there is no aux cable inserted. But, because of manufacture problems these two contacts don&rsquo;t touch on some device, even though there is no aux cable inserted. So: The jambox thinks there is an aux cable, but there is none. That&rsquo;s why it utters static noise\\n\\n  So, because I have a device with such problems I needed to hard reset my jambox half a dozen. That&rsquo;s why I thought I finally write it down.\\n\\n*   **Soft reset**: Holding down the circle button (talk button) and plugging it into the charger and then releasing. You will see the red flash\\n*   Unpair / Pair again; being deleting it from every device, restarting all of them and pairing once more\\n*   **Hard reset**: Turn off bluetooth on all devices in reach, then turn on the jambox and press the circle button six times, when you see the light flash red, press the circle once more and hold it and it will go into pairing mode\\n*   Update the software to &gt;=2.1 using [mytalk.jawbone.com](http://mytalk.jawbone.com)\\n*   Insert an **aux cable** and removing it again (worked a few times for me)\\n*   Insert a small **screw driver** (this is scary, more detailed instructions [here](http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/m-p/14882/highlight/true#M748)). This connects the two metal contacts which should touch each other to make the Jambox believe there is no AUX cable inserted\\n*   If the screw driver thing is working for you, you might consider putting a screw into the aux port: [![](http://i.imgur.com/udCI5.jpg)](http://i.imgur.com/udCI5.jpg)\\n*   If nothing of the above works, you can [solder a bypass of the aux port](http://howto.philippkeller.com/2012/07/21/how-to-fix-jambox-static-noise/) (which is what I finally did)\\n\\n  I don&rsquo;t recommend buying a Jambox to anyone, I completely agree with [this review on Amazon](http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU)\",\"source\":\"_posts/How-to-reset-Jambox-when-bluetooth-completely-stopped-working.md\",\"raw\":\"---\\ntitle: How to reset Jambox when bluetooth completely stopped working\\ntags:\\n  - gadgets\\ndate: 2012-07-14 19:26:00\\nalias: /post/37471160886/how-to-reset-jambox-when-bluetooth-completely\\n---\\n\\n  I bought a Jambox about half a year ago. Sound wise it is great, but apparently it is not very stable, especially after recharging it falls into some state where it only utters static noise. In this state it still plays music over the aux cable, but not any more over bluetooth.<!-- more -->\\n\\nApparently the issue is the aux port which has two contacts that should touch each other when there is no aux cable inserted. But, because of manufacture problems these two contacts don&rsquo;t touch on some device, even though there is no aux cable inserted. So: The jambox thinks there is an aux cable, but there is none. That&rsquo;s why it utters static noise\\n\\n  So, because I have a device with such problems I needed to hard reset my jambox half a dozen. That&rsquo;s why I thought I finally write it down.\\n\\n*   **Soft reset**: Holding down the circle button (talk button) and plugging it into the charger and then releasing. You will see the red flash\\n*   Unpair / Pair again; being deleting it from every device, restarting all of them and pairing once more\\n*   **Hard reset**: Turn off bluetooth on all devices in reach, then turn on the jambox and press the circle button six times, when you see the light flash red, press the circle once more and hold it and it will go into pairing mode\\n*   Update the software to &gt;=2.1 using [mytalk.jawbone.com](http://mytalk.jawbone.com)\\n*   Insert an **aux cable** and removing it again (worked a few times for me)\\n*   Insert a small **screw driver** (this is scary, more detailed instructions [here](http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/m-p/14882/highlight/true#M748)). This connects the two metal contacts which should touch each other to make the Jambox believe there is no AUX cable inserted\\n*   If the screw driver thing is working for you, you might consider putting a screw into the aux port: [![](http://i.imgur.com/udCI5.jpg)](http://i.imgur.com/udCI5.jpg)\\n*   If nothing of the above works, you can [solder a bypass of the aux port](http://howto.philippkeller.com/2012/07/21/how-to-fix-jambox-static-noise/) (which is what I finally did)\\n\\n  I don&rsquo;t recommend buying a Jambox to anyone, I completely agree with [this review on Amazon](http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU)\",\"slug\":\"How-to-reset-Jambox-when-bluetooth-completely-stopped-working\",\"published\":1,\"updated\":\"2017-11-12T07:12:33.757Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60b0007i85pb083htuz\",\"content\":\"<p>  I bought a Jambox about half a year ago. Sound wise it is great, but apparently it is not very stable, especially after recharging it falls into some state where it only utters static noise. In this state it still plays music over the aux cable, but not any more over bluetooth.<a id=\\\"more\\\"></a></p>\\n<p>Apparently the issue is the aux port which has two contacts that should touch each other when there is no aux cable inserted. But, because of manufacture problems these two contacts don&rsquo;t touch on some device, even though there is no aux cable inserted. So: The jambox thinks there is an aux cable, but there is none. That&rsquo;s why it utters static noise</p>\\n<p>  So, because I have a device with such problems I needed to hard reset my jambox half a dozen. That&rsquo;s why I thought I finally write it down.</p>\\n<ul>\\n<li><strong>Soft reset</strong>: Holding down the circle button (talk button) and plugging it into the charger and then releasing. You will see the red flash</li>\\n<li>Unpair / Pair again; being deleting it from every device, restarting all of them and pairing once more</li>\\n<li><strong>Hard reset</strong>: Turn off bluetooth on all devices in reach, then turn on the jambox and press the circle button six times, when you see the light flash red, press the circle once more and hold it and it will go into pairing mode</li>\\n<li>Update the software to &gt;=2.1 using <a href=\\\"http://mytalk.jawbone.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mytalk.jawbone.com</a></li>\\n<li>Insert an <strong>aux cable</strong> and removing it again (worked a few times for me)</li>\\n<li>Insert a small <strong>screw driver</strong> (this is scary, more detailed instructions <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/m-p/14882/highlight/true#M748\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>). This connects the two metal contacts which should touch each other to make the Jambox believe there is no AUX cable inserted</li>\\n<li>If the screw driver thing is working for you, you might consider putting a screw into the aux port: <a href=\\\"http://i.imgur.com/udCI5.jpg\\\" target=\\\"_blank\\\" rel=\\\"external\\\"><img src=\\\"http://i.imgur.com/udCI5.jpg\\\" alt=\\\"\\\"></a></li>\\n<li><p>If nothing of the above works, you can <a href=\\\"http://howto.philippkeller.com/2012/07/21/how-to-fix-jambox-static-noise/\\\">solder a bypass of the aux port</a> (which is what I finally did)</p>\\n<p>I don&rsquo;t recommend buying a Jambox to anyone, I completely agree with <a href=\\\"http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this review on Amazon</a></p>\\n</li>\\n</ul>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>  I bought a Jambox about half a year ago. Sound wise it is great, but apparently it is not very stable, especially after recharging it falls into some state where it only utters static noise. In this state it still plays music over the aux cable, but not any more over bluetooth.\",\"more\":\"</p>\\n<p>Apparently the issue is the aux port which has two contacts that should touch each other when there is no aux cable inserted. But, because of manufacture problems these two contacts don&rsquo;t touch on some device, even though there is no aux cable inserted. So: The jambox thinks there is an aux cable, but there is none. That&rsquo;s why it utters static noise</p>\\n<p>  So, because I have a device with such problems I needed to hard reset my jambox half a dozen. That&rsquo;s why I thought I finally write it down.</p>\\n<ul>\\n<li><strong>Soft reset</strong>: Holding down the circle button (talk button) and plugging it into the charger and then releasing. You will see the red flash</li>\\n<li>Unpair / Pair again; being deleting it from every device, restarting all of them and pairing once more</li>\\n<li><strong>Hard reset</strong>: Turn off bluetooth on all devices in reach, then turn on the jambox and press the circle button six times, when you see the light flash red, press the circle once more and hold it and it will go into pairing mode</li>\\n<li>Update the software to &gt;=2.1 using <a href=\\\"http://mytalk.jawbone.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mytalk.jawbone.com</a></li>\\n<li>Insert an <strong>aux cable</strong> and removing it again (worked a few times for me)</li>\\n<li>Insert a small <strong>screw driver</strong> (this is scary, more detailed instructions <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/m-p/14882/highlight/true#M748\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>). This connects the two metal contacts which should touch each other to make the Jambox believe there is no AUX cable inserted</li>\\n<li>If the screw driver thing is working for you, you might consider putting a screw into the aux port: <a href=\\\"http://i.imgur.com/udCI5.jpg\\\" target=\\\"_blank\\\" rel=\\\"external\\\"><img src=\\\"http://i.imgur.com/udCI5.jpg\\\" alt=\\\"\\\"></a></li>\\n<li><p>If nothing of the above works, you can <a href=\\\"http://howto.philippkeller.com/2012/07/21/how-to-fix-jambox-static-noise/\\\">solder a bypass of the aux port</a> (which is what I finally did)</p>\\n<p>I don&rsquo;t recommend buying a Jambox to anyone, I completely agree with <a href=\\\"http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this review on Amazon</a></p>\\n</li>\\n</ul>\"},{\"title\":\"How to streamline cd ripping without tagging track data\",\"date\":\"2017-12-02T15:23:53.000Z\",\"_content\":\"\\n![CD tower to rip](/images/automate.jpg)\\n\\nSince we recently stopped using Spotify (mainly because I think having everything at your fingertips influences brain in a negative way) we switched to borrowing CDs from the local library (which, in our case is only 200m away from our house).\\n\\nNow, because the kids get CDs at least once a week, I needed a way to quickly import those CDs into our Sonos system without too much hassle. Since the kids only borrow children stories (spoken audio) which often are not on MusicBrainz, I needed an easy way to tag them myself. Because I don't care about tagging every single track (because you usually listen to a story start to end anyway), I wanted to have a streamlined process. The following script does:\\n\\n- Rip the CD and convert it to m4a (AAC encoding, slightly better compression than mp3)\\n- Eject the CD\\n- Ask me for the album and artist name\\n- Opens chrome so I can choose an artwork\\n- Convert the artwork to JPG in a reasonable size\\n- Copies the music to the directory on my NAS\\n- Triggers Sonos to update the music library\\n\\n<!-- more -->\\n\\nYou may take it as a starting point, you'd want to adapt:\\n\\n- the paranoia level. `-Y` is only basic checking which is enough for me. You can remove the `-Y` to increase the error handle\\n- the bitrate (line 7). 96k is enough for me\\n- the genre (line 8)\\n- the handling of special characters for the album directory name (line 15)\\n- the hostname/directory of your NAS\\n- the updating of the music library (line 23. For Sonos there's [soco](https://github.com/SoCo/SoCo), an awesome python library. If you want to use that you'd need to `pip install soco` first)\\n\\nBtw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.\\n\\n```\\n#!/bin/bash\\nset -e\\ntmp_dir=$(mktemp -d)\\ncd $tmp_dir\\ncdparanoia -BY\\neject\\nfor i in *.wav; do ffmpeg -i $i -c:a libfdk_aac -b:a 96k ${i/cdda.wav/m4a}; done\\ntotal=$(ls *.m4a | wc -l); for i in *.m4a; do number=$(echo $i | sed 's/^track\\\\([0-9]\\\\+\\\\).*/\\\\1/'); AtomicParsley $i --tracknum \\\"$number/$total\\\" --title \\\"Track $number\\\" --genre \\\"Kinder Geschichten\\\" --overWrite; done\\necho -n \\\"Album name>\\\" && read album\\necho -n \\\"Artist name>\\\" && read artist\\nsearch_term=\\\"$(perl -MURI::Escape -e 'print uri_escape($ARGV[0]);' \\\"$album $artist cd\\\")\\\"\\nchrome \\\"https://www.google.ch/search?&q=$search_term&tbm=isch\\\" >/dev/null 2>/dev/null &\\necho -n \\\"Artwork url>\\\" && read artwork_url\\nwget -q \\\"$artwork_url\\\" -O artwork.orig\\nconvert artwork.orig -resize \\\"250x\\\" artwork.jpg\\nfor i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --artist \\\"$artist\\\" --album \\\"$album\\\" --overWrite; done\\ndir_name=$(echo \\\"${artist// /_}_${album// /_}\\\" | sed 's/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g' | tr '[:upper:]' '[:lower:]')\\nmkdir $dir_name\\nmv *.m4a $dir_name\\nscp -rp $dir_name root@wdmycloud:/DataVolume/shares/Public/Shared\\\\\\\\\\\\ Music/kinder\\npython3 -c \\\"import soco; soco.music_library.MusicLibrary().start_library_update()\\\"\\ncd -\\nrm -rf $tmp_dir\\n```\\n\",\"source\":\"_posts/How-to-streamline-cd-ripping-without-tagging-track-data.md\",\"raw\":\"---\\ntitle: How to streamline cd ripping without tagging track data\\ndate: 2017-12-02 16:23:53\\ntags:\\n- ripping\\n- music\\n---\\n\\n![CD tower to rip](/images/automate.jpg)\\n\\nSince we recently stopped using Spotify (mainly because I think having everything at your fingertips influences brain in a negative way) we switched to borrowing CDs from the local library (which, in our case is only 200m away from our house).\\n\\nNow, because the kids get CDs at least once a week, I needed a way to quickly import those CDs into our Sonos system without too much hassle. Since the kids only borrow children stories (spoken audio) which often are not on MusicBrainz, I needed an easy way to tag them myself. Because I don't care about tagging every single track (because you usually listen to a story start to end anyway), I wanted to have a streamlined process. The following script does:\\n\\n- Rip the CD and convert it to m4a (AAC encoding, slightly better compression than mp3)\\n- Eject the CD\\n- Ask me for the album and artist name\\n- Opens chrome so I can choose an artwork\\n- Convert the artwork to JPG in a reasonable size\\n- Copies the music to the directory on my NAS\\n- Triggers Sonos to update the music library\\n\\n<!-- more -->\\n\\nYou may take it as a starting point, you'd want to adapt:\\n\\n- the paranoia level. `-Y` is only basic checking which is enough for me. You can remove the `-Y` to increase the error handle\\n- the bitrate (line 7). 96k is enough for me\\n- the genre (line 8)\\n- the handling of special characters for the album directory name (line 15)\\n- the hostname/directory of your NAS\\n- the updating of the music library (line 23. For Sonos there's [soco](https://github.com/SoCo/SoCo), an awesome python library. If you want to use that you'd need to `pip install soco` first)\\n\\nBtw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.\\n\\n```\\n#!/bin/bash\\nset -e\\ntmp_dir=$(mktemp -d)\\ncd $tmp_dir\\ncdparanoia -BY\\neject\\nfor i in *.wav; do ffmpeg -i $i -c:a libfdk_aac -b:a 96k ${i/cdda.wav/m4a}; done\\ntotal=$(ls *.m4a | wc -l); for i in *.m4a; do number=$(echo $i | sed 's/^track\\\\([0-9]\\\\+\\\\).*/\\\\1/'); AtomicParsley $i --tracknum \\\"$number/$total\\\" --title \\\"Track $number\\\" --genre \\\"Kinder Geschichten\\\" --overWrite; done\\necho -n \\\"Album name>\\\" && read album\\necho -n \\\"Artist name>\\\" && read artist\\nsearch_term=\\\"$(perl -MURI::Escape -e 'print uri_escape($ARGV[0]);' \\\"$album $artist cd\\\")\\\"\\nchrome \\\"https://www.google.ch/search?&q=$search_term&tbm=isch\\\" >/dev/null 2>/dev/null &\\necho -n \\\"Artwork url>\\\" && read artwork_url\\nwget -q \\\"$artwork_url\\\" -O artwork.orig\\nconvert artwork.orig -resize \\\"250x\\\" artwork.jpg\\nfor i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --artist \\\"$artist\\\" --album \\\"$album\\\" --overWrite; done\\ndir_name=$(echo \\\"${artist// /_}_${album// /_}\\\" | sed 's/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g' | tr '[:upper:]' '[:lower:]')\\nmkdir $dir_name\\nmv *.m4a $dir_name\\nscp -rp $dir_name root@wdmycloud:/DataVolume/shares/Public/Shared\\\\\\\\\\\\ Music/kinder\\npython3 -c \\\"import soco; soco.music_library.MusicLibrary().start_library_update()\\\"\\ncd -\\nrm -rf $tmp_dir\\n```\\n\",\"slug\":\"How-to-streamline-cd-ripping-without-tagging-track-data\",\"published\":1,\"updated\":\"2017-12-09T11:32:37.501Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60c0008i85p866f4juy\",\"content\":\"<p><img src=\\\"/images/automate.jpg\\\" alt=\\\"CD tower to rip\\\"></p>\\n<p>Since we recently stopped using Spotify (mainly because I think having everything at your fingertips influences brain in a negative way) we switched to borrowing CDs from the local library (which, in our case is only 200m away from our house).</p>\\n<p>Now, because the kids get CDs at least once a week, I needed a way to quickly import those CDs into our Sonos system without too much hassle. Since the kids only borrow children stories (spoken audio) which often are not on MusicBrainz, I needed an easy way to tag them myself. Because I don’t care about tagging every single track (because you usually listen to a story start to end anyway), I wanted to have a streamlined process. The following script does:</p>\\n<ul>\\n<li>Rip the CD and convert it to m4a (AAC encoding, slightly better compression than mp3)</li>\\n<li>Eject the CD</li>\\n<li>Ask me for the album and artist name</li>\\n<li>Opens chrome so I can choose an artwork</li>\\n<li>Convert the artwork to JPG in a reasonable size</li>\\n<li>Copies the music to the directory on my NAS</li>\\n<li>Triggers Sonos to update the music library</li>\\n</ul>\\n<a id=\\\"more\\\"></a>\\n<p>You may take it as a starting point, you’d want to adapt:</p>\\n<ul>\\n<li>the paranoia level. <code>-Y</code> is only basic checking which is enough for me. You can remove the <code>-Y</code> to increase the error handle</li>\\n<li>the bitrate (line 7). 96k is enough for me</li>\\n<li>the genre (line 8)</li>\\n<li>the handling of special characters for the album directory name (line 15)</li>\\n<li>the hostname/directory of your NAS</li>\\n<li>the updating of the music library (line 23. For Sonos there’s <a href=\\\"https://github.com/SoCo/SoCo\\\" target=\\\"_blank\\\" rel=\\\"external\\\">soco</a>, an awesome python library. If you want to use that you’d need to <code>pip install soco</code> first)</li>\\n</ul>\\n<p>Btw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br><span class=\\\"line\\\">17</span><br><span class=\\\"line\\\">18</span><br><span class=\\\"line\\\">19</span><br><span class=\\\"line\\\">20</span><br><span class=\\\"line\\\">21</span><br><span class=\\\"line\\\">22</span><br><span class=\\\"line\\\">23</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/bash</span><br><span class=\\\"line\\\">set -e</span><br><span class=\\\"line\\\">tmp_dir=$(mktemp -d)</span><br><span class=\\\"line\\\">cd $tmp_dir</span><br><span class=\\\"line\\\">cdparanoia -BY</span><br><span class=\\\"line\\\">eject</span><br><span class=\\\"line\\\">for i in *.wav; do ffmpeg -i $i -c:a libfdk_aac -b:a 96k $&#123;i/cdda.wav/m4a&#125;; done</span><br><span class=\\\"line\\\">total=$(ls *.m4a | wc -l); for i in *.m4a; do number=$(echo $i | sed &apos;s/^track\\\\([0-9]\\\\+\\\\).*/\\\\1/&apos;); AtomicParsley $i --tracknum &quot;$number/$total&quot; --title &quot;Track $number&quot; --genre &quot;Kinder Geschichten&quot; --overWrite; done</span><br><span class=\\\"line\\\">echo -n &quot;Album name&gt;&quot; &amp;&amp; read album</span><br><span class=\\\"line\\\">echo -n &quot;Artist name&gt;&quot; &amp;&amp; read artist</span><br><span class=\\\"line\\\">search_term=&quot;$(perl -MURI::Escape -e &apos;print uri_escape($ARGV[0]);&apos; &quot;$album $artist cd&quot;)&quot;</span><br><span class=\\\"line\\\">chrome &quot;https://www.google.ch/search?&amp;q=$search_term&amp;tbm=isch&quot; &gt;/dev/null 2&gt;/dev/null &amp;</span><br><span class=\\\"line\\\">echo -n &quot;Artwork url&gt;&quot; &amp;&amp; read artwork_url</span><br><span class=\\\"line\\\">wget -q &quot;$artwork_url&quot; -O artwork.orig</span><br><span class=\\\"line\\\">convert artwork.orig -resize &quot;250x&quot; artwork.jpg</span><br><span class=\\\"line\\\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --artist &quot;$artist&quot; --album &quot;$album&quot; --overWrite; done</span><br><span class=\\\"line\\\">dir_name=$(echo &quot;$&#123;artist// /_&#125;_$&#123;album// /_&#125;&quot; | sed &apos;s/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g&apos; | tr &apos;[:upper:]&apos; &apos;[:lower:]&apos;)</span><br><span class=\\\"line\\\">mkdir $dir_name</span><br><span class=\\\"line\\\">mv *.m4a $dir_name</span><br><span class=\\\"line\\\">scp -rp $dir_name root@wdmycloud:/DataVolume/shares/Public/Shared\\\\\\\\\\\\ Music/kinder</span><br><span class=\\\"line\\\">python3 -c &quot;import soco; soco.music_library.MusicLibrary().start_library_update()&quot;</span><br><span class=\\\"line\\\">cd -</span><br><span class=\\\"line\\\">rm -rf $tmp_dir</span><br></pre></td></tr></table></figure>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"/images/automate.jpg\\\" alt=\\\"CD tower to rip\\\"></p>\\n<p>Since we recently stopped using Spotify (mainly because I think having everything at your fingertips influences brain in a negative way) we switched to borrowing CDs from the local library (which, in our case is only 200m away from our house).</p>\\n<p>Now, because the kids get CDs at least once a week, I needed a way to quickly import those CDs into our Sonos system without too much hassle. Since the kids only borrow children stories (spoken audio) which often are not on MusicBrainz, I needed an easy way to tag them myself. Because I don’t care about tagging every single track (because you usually listen to a story start to end anyway), I wanted to have a streamlined process. The following script does:</p>\\n<ul>\\n<li>Rip the CD and convert it to m4a (AAC encoding, slightly better compression than mp3)</li>\\n<li>Eject the CD</li>\\n<li>Ask me for the album and artist name</li>\\n<li>Opens chrome so I can choose an artwork</li>\\n<li>Convert the artwork to JPG in a reasonable size</li>\\n<li>Copies the music to the directory on my NAS</li>\\n<li>Triggers Sonos to update the music library</li>\\n</ul>\",\"more\":\"<p>You may take it as a starting point, you’d want to adapt:</p>\\n<ul>\\n<li>the paranoia level. <code>-Y</code> is only basic checking which is enough for me. You can remove the <code>-Y</code> to increase the error handle</li>\\n<li>the bitrate (line 7). 96k is enough for me</li>\\n<li>the genre (line 8)</li>\\n<li>the handling of special characters for the album directory name (line 15)</li>\\n<li>the hostname/directory of your NAS</li>\\n<li>the updating of the music library (line 23. For Sonos there’s <a href=\\\"https://github.com/SoCo/SoCo\\\" target=\\\"_blank\\\" rel=\\\"external\\\">soco</a>, an awesome python library. If you want to use that you’d need to <code>pip install soco</code> first)</li>\\n</ul>\\n<p>Btw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br><span class=\\\"line\\\">17</span><br><span class=\\\"line\\\">18</span><br><span class=\\\"line\\\">19</span><br><span class=\\\"line\\\">20</span><br><span class=\\\"line\\\">21</span><br><span class=\\\"line\\\">22</span><br><span class=\\\"line\\\">23</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/bash</span><br><span class=\\\"line\\\">set -e</span><br><span class=\\\"line\\\">tmp_dir=$(mktemp -d)</span><br><span class=\\\"line\\\">cd $tmp_dir</span><br><span class=\\\"line\\\">cdparanoia -BY</span><br><span class=\\\"line\\\">eject</span><br><span class=\\\"line\\\">for i in *.wav; do ffmpeg -i $i -c:a libfdk_aac -b:a 96k $&#123;i/cdda.wav/m4a&#125;; done</span><br><span class=\\\"line\\\">total=$(ls *.m4a | wc -l); for i in *.m4a; do number=$(echo $i | sed &apos;s/^track\\\\([0-9]\\\\+\\\\).*/\\\\1/&apos;); AtomicParsley $i --tracknum &quot;$number/$total&quot; --title &quot;Track $number&quot; --genre &quot;Kinder Geschichten&quot; --overWrite; done</span><br><span class=\\\"line\\\">echo -n &quot;Album name&gt;&quot; &amp;&amp; read album</span><br><span class=\\\"line\\\">echo -n &quot;Artist name&gt;&quot; &amp;&amp; read artist</span><br><span class=\\\"line\\\">search_term=&quot;$(perl -MURI::Escape -e &apos;print uri_escape($ARGV[0]);&apos; &quot;$album $artist cd&quot;)&quot;</span><br><span class=\\\"line\\\">chrome &quot;https://www.google.ch/search?&amp;q=$search_term&amp;tbm=isch&quot; &gt;/dev/null 2&gt;/dev/null &amp;</span><br><span class=\\\"line\\\">echo -n &quot;Artwork url&gt;&quot; &amp;&amp; read artwork_url</span><br><span class=\\\"line\\\">wget -q &quot;$artwork_url&quot; -O artwork.orig</span><br><span class=\\\"line\\\">convert artwork.orig -resize &quot;250x&quot; artwork.jpg</span><br><span class=\\\"line\\\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --artist &quot;$artist&quot; --album &quot;$album&quot; --overWrite; done</span><br><span class=\\\"line\\\">dir_name=$(echo &quot;$&#123;artist// /_&#125;_$&#123;album// /_&#125;&quot; | sed &apos;s/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g&apos; | tr &apos;[:upper:]&apos; &apos;[:lower:]&apos;)</span><br><span class=\\\"line\\\">mkdir $dir_name</span><br><span class=\\\"line\\\">mv *.m4a $dir_name</span><br><span class=\\\"line\\\">scp -rp $dir_name root@wdmycloud:/DataVolume/shares/Public/Shared\\\\\\\\\\\\ Music/kinder</span><br><span class=\\\"line\\\">python3 -c &quot;import soco; soco.music_library.MusicLibrary().start_library_update()&quot;</span><br><span class=\\\"line\\\">cd -</span><br><span class=\\\"line\\\">rm -rf $tmp_dir</span><br></pre></td></tr></table></figure>\"},{\"title\":\"How to set up raspberry pi headless with ssh and wifi\",\"date\":\"2018-01-20T08:32:44.000Z\",\"_content\":\"\\n![raspberry pi 3](/images/pi.jpg)\\n\\nSetting up raspberry pi is a bit tedious when doing it over attached monitor, keyboard and mouse (I usually don't have those around anyway, being laptop only at the moment), so here's a good and easy way to get an installation directly from your laptop, making the pi automatically join your wifi and enable ssh:\\n\\n# Flash\\n\\n![etcher](/images/etcher.png)\\n\\nI found that etcher.io is a very easy way to flash, in order to do so:\\n\\n- **Install [etcher](https://etcher.io/)** (available for linux/osx/windows)\\n- **Download image:** I chose the raspbian lite version from [official](https://www.raspberrypi.org/downloads/raspbian/)\\n- **Open etcher** etcher (on linux just unzip the etcher.zip and open the executable therein)\\n- **Insert sd card** (don't mount it yet!), watch that etcher now detects that new card in the middle\\n- **Select image** e.g. `~/Downloads/2017-11-29-raspbian-stretch-lite.zip` and **flash** <small>(for linux i3 users: you'll get a polkit error. You'll need to start a polkit agent, e.g. `/usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1` before flashing)</small>\\n\\n<!-- more -->\\n\\n# Enable ssh and wlan on the image\\n\\nEtcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using `sudo fdisk -l`. In my case I found:\\n\\n```\\nDisk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectors\\nUnits: sectors of 1 * 512 = 512 bytes\\nSector size (logical/physical): 512 bytes / 512 bytes\\nI/O size (minimum/optimal): 512 bytes / 512 bytes\\nDisklabel type: dos\\nDisk identifier: 0x37665771\\nDevice         Boot Start     End Sectors  Size Id Type\\n/dev/mmcblk0p1       8192   93236   85045 41.5M  c W95 FAT32 (LBA)\\n/dev/mmcblk0p2      94208 3629055 3534848  1.7G 83 Linux\\n```\\n\\nThe relevant lines are 8 (boot partition) and 9 (data partition).\\n\\n## Enable ssh\\n\\n- create the mount point e.g. `mkdir /var/tmp/sdcard`\\n- mount the boot partition with `sudo mount -t vfat /dev/mmcblk0p1 /var/tmp/sdcard` whereas you specify the file system using `-t vfar` (corresponds to W95 FAT32) and the device `/dev/mmcblk0p1` is what you take from above (be sure to take the first one, that with the lower start number)\\n- `sudo touch /var/tmp/sdcard/ssh` to enable ssh on the first boot\\n- `sudo umount /var/tmp/sdcard`\\n\\n## Enable wireless\\n\\n- mount the data partition with `sudo mount -t ext4 /dev/mmcblk0p2 /var/tmp/sdcard`, be sure to take the correct `/dev/`, `-t ext4` corresponds to the `Linux` fs type\\n- run `wpa_passphrase <ssid> <password>` to create the wireless config config\\n- edit `/var/tmp/sdcard/etc/wpa_supplicant/wpa_supplicant.conf` and add the config you just got from `wpa_passphrase`. Be sure to delete the plain text psk line\\n- `sudo umount /var/tmp/sdcard`\\n\\n# Profit!\\n\\nThat's it, boot your pi, check your router for the ip address it just got and ssh in with `ssh pi@192.168.x.x` using `raspberry` as password.\\n\\nA good first step is to start `sudo raspi-config` in order to:\\n\\n- change password\\n- generate the locale (get rid of the `warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)`)\\n- set the correct timezone\\n\\nAnd, of course add your public key to authorized_keys:\\n\\n```\\ncat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x \\\"mkdir -p ~/.ssh && chmod 700 ~/.ssh && cat >>  ~/.ssh/authorized_keys\\\"\\n```\",\"source\":\"_posts/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi.md\",\"raw\":\"---\\ntitle: How to set up raspberry pi headless with ssh and wifi\\ndate: 2018-01-20 09:32:44\\ntags:\\n---\\n\\n![raspberry pi 3](/images/pi.jpg)\\n\\nSetting up raspberry pi is a bit tedious when doing it over attached monitor, keyboard and mouse (I usually don't have those around anyway, being laptop only at the moment), so here's a good and easy way to get an installation directly from your laptop, making the pi automatically join your wifi and enable ssh:\\n\\n# Flash\\n\\n![etcher](/images/etcher.png)\\n\\nI found that etcher.io is a very easy way to flash, in order to do so:\\n\\n- **Install [etcher](https://etcher.io/)** (available for linux/osx/windows)\\n- **Download image:** I chose the raspbian lite version from [official](https://www.raspberrypi.org/downloads/raspbian/)\\n- **Open etcher** etcher (on linux just unzip the etcher.zip and open the executable therein)\\n- **Insert sd card** (don't mount it yet!), watch that etcher now detects that new card in the middle\\n- **Select image** e.g. `~/Downloads/2017-11-29-raspbian-stretch-lite.zip` and **flash** <small>(for linux i3 users: you'll get a polkit error. You'll need to start a polkit agent, e.g. `/usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1` before flashing)</small>\\n\\n<!-- more -->\\n\\n# Enable ssh and wlan on the image\\n\\nEtcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using `sudo fdisk -l`. In my case I found:\\n\\n```\\nDisk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectors\\nUnits: sectors of 1 * 512 = 512 bytes\\nSector size (logical/physical): 512 bytes / 512 bytes\\nI/O size (minimum/optimal): 512 bytes / 512 bytes\\nDisklabel type: dos\\nDisk identifier: 0x37665771\\nDevice         Boot Start     End Sectors  Size Id Type\\n/dev/mmcblk0p1       8192   93236   85045 41.5M  c W95 FAT32 (LBA)\\n/dev/mmcblk0p2      94208 3629055 3534848  1.7G 83 Linux\\n```\\n\\nThe relevant lines are 8 (boot partition) and 9 (data partition).\\n\\n## Enable ssh\\n\\n- create the mount point e.g. `mkdir /var/tmp/sdcard`\\n- mount the boot partition with `sudo mount -t vfat /dev/mmcblk0p1 /var/tmp/sdcard` whereas you specify the file system using `-t vfar` (corresponds to W95 FAT32) and the device `/dev/mmcblk0p1` is what you take from above (be sure to take the first one, that with the lower start number)\\n- `sudo touch /var/tmp/sdcard/ssh` to enable ssh on the first boot\\n- `sudo umount /var/tmp/sdcard`\\n\\n## Enable wireless\\n\\n- mount the data partition with `sudo mount -t ext4 /dev/mmcblk0p2 /var/tmp/sdcard`, be sure to take the correct `/dev/`, `-t ext4` corresponds to the `Linux` fs type\\n- run `wpa_passphrase <ssid> <password>` to create the wireless config config\\n- edit `/var/tmp/sdcard/etc/wpa_supplicant/wpa_supplicant.conf` and add the config you just got from `wpa_passphrase`. Be sure to delete the plain text psk line\\n- `sudo umount /var/tmp/sdcard`\\n\\n# Profit!\\n\\nThat's it, boot your pi, check your router for the ip address it just got and ssh in with `ssh pi@192.168.x.x` using `raspberry` as password.\\n\\nA good first step is to start `sudo raspi-config` in order to:\\n\\n- change password\\n- generate the locale (get rid of the `warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)`)\\n- set the correct timezone\\n\\nAnd, of course add your public key to authorized_keys:\\n\\n```\\ncat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x \\\"mkdir -p ~/.ssh && chmod 700 ~/.ssh && cat >>  ~/.ssh/authorized_keys\\\"\\n```\",\"slug\":\"How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi\",\"published\":1,\"updated\":\"2018-01-20T11:12:56.388Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60e000ai85pinegb42q\",\"content\":\"<p><img src=\\\"/images/pi.jpg\\\" alt=\\\"raspberry pi 3\\\"></p>\\n<p>Setting up raspberry pi is a bit tedious when doing it over attached monitor, keyboard and mouse (I usually don’t have those around anyway, being laptop only at the moment), so here’s a good and easy way to get an installation directly from your laptop, making the pi automatically join your wifi and enable ssh:</p>\\n<h1 id=\\\"Flash\\\"><a href=\\\"#Flash\\\" class=\\\"headerlink\\\" title=\\\"Flash\\\"></a>Flash</h1><p><img src=\\\"/images/etcher.png\\\" alt=\\\"etcher\\\"></p>\\n<p>I found that etcher.io is a very easy way to flash, in order to do so:</p>\\n<ul>\\n<li><strong>Install <a href=\\\"https://etcher.io/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">etcher</a></strong> (available for linux/osx/windows)</li>\\n<li><strong>Download image:</strong> I chose the raspbian lite version from <a href=\\\"https://www.raspberrypi.org/downloads/raspbian/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">official</a></li>\\n<li><strong>Open etcher</strong> etcher (on linux just unzip the etcher.zip and open the executable therein)</li>\\n<li><strong>Insert sd card</strong> (don’t mount it yet!), watch that etcher now detects that new card in the middle</li>\\n<li><strong>Select image</strong> e.g. <code>~/Downloads/2017-11-29-raspbian-stretch-lite.zip</code> and <strong>flash</strong> <small>(for linux i3 users: you’ll get a polkit error. You’ll need to start a polkit agent, e.g. <code>/usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1</code> before flashing)</small></li>\\n</ul>\\n<a id=\\\"more\\\"></a>\\n<h1 id=\\\"Enable-ssh-and-wlan-on-the-image\\\"><a href=\\\"#Enable-ssh-and-wlan-on-the-image\\\" class=\\\"headerlink\\\" title=\\\"Enable ssh and wlan on the image\\\"></a>Enable ssh and wlan on the image</h1><p>Etcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using <code>sudo fdisk -l</code>. In my case I found:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">Disk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectors</span><br><span class=\\\"line\\\">Units: sectors of 1 * 512 = 512 bytes</span><br><span class=\\\"line\\\">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class=\\\"line\\\">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class=\\\"line\\\">Disklabel type: dos</span><br><span class=\\\"line\\\">Disk identifier: 0x37665771</span><br><span class=\\\"line\\\">Device         Boot Start     End Sectors  Size Id Type</span><br><span class=\\\"line\\\">/dev/mmcblk0p1       8192   93236   85045 41.5M  c W95 FAT32 (LBA)</span><br><span class=\\\"line\\\">/dev/mmcblk0p2      94208 3629055 3534848  1.7G 83 Linux</span><br></pre></td></tr></table></figure>\\n<p>The relevant lines are 8 (boot partition) and 9 (data partition).</p>\\n<h2 id=\\\"Enable-ssh\\\"><a href=\\\"#Enable-ssh\\\" class=\\\"headerlink\\\" title=\\\"Enable ssh\\\"></a>Enable ssh</h2><ul>\\n<li>create the mount point e.g. <code>mkdir /var/tmp/sdcard</code></li>\\n<li>mount the boot partition with <code>sudo mount -t vfat /dev/mmcblk0p1 /var/tmp/sdcard</code> whereas you specify the file system using <code>-t vfar</code> (corresponds to W95 FAT32) and the device <code>/dev/mmcblk0p1</code> is what you take from above (be sure to take the first one, that with the lower start number)</li>\\n<li><code>sudo touch /var/tmp/sdcard/ssh</code> to enable ssh on the first boot</li>\\n<li><code>sudo umount /var/tmp/sdcard</code></li>\\n</ul>\\n<h2 id=\\\"Enable-wireless\\\"><a href=\\\"#Enable-wireless\\\" class=\\\"headerlink\\\" title=\\\"Enable wireless\\\"></a>Enable wireless</h2><ul>\\n<li>mount the data partition with <code>sudo mount -t ext4 /dev/mmcblk0p2 /var/tmp/sdcard</code>, be sure to take the correct <code>/dev/</code>, <code>-t ext4</code> corresponds to the <code>Linux</code> fs type</li>\\n<li>run <code>wpa_passphrase &lt;ssid&gt; &lt;password&gt;</code> to create the wireless config config</li>\\n<li>edit <code>/var/tmp/sdcard/etc/wpa_supplicant/wpa_supplicant.conf</code> and add the config you just got from <code>wpa_passphrase</code>. Be sure to delete the plain text psk line</li>\\n<li><code>sudo umount /var/tmp/sdcard</code></li>\\n</ul>\\n<h1 id=\\\"Profit\\\"><a href=\\\"#Profit\\\" class=\\\"headerlink\\\" title=\\\"Profit!\\\"></a>Profit!</h1><p>That’s it, boot your pi, check your router for the ip address it just got and ssh in with <code>ssh pi@192.168.x.x</code> using <code>raspberry</code> as password.</p>\\n<p>A good first step is to start <code>sudo raspi-config</code> in order to:</p>\\n<ul>\\n<li>change password</li>\\n<li>generate the locale (get rid of the <code>warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)</code>)</li>\\n<li>set the correct timezone</li>\\n</ul>\\n<p>And, of course add your public key to authorized_keys:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat &gt;&gt;  ~/.ssh/authorized_keys&quot;</span><br></pre></td></tr></table></figure>\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"/images/pi.jpg\\\" alt=\\\"raspberry pi 3\\\"></p>\\n<p>Setting up raspberry pi is a bit tedious when doing it over attached monitor, keyboard and mouse (I usually don’t have those around anyway, being laptop only at the moment), so here’s a good and easy way to get an installation directly from your laptop, making the pi automatically join your wifi and enable ssh:</p>\\n<h1 id=\\\"Flash\\\"><a href=\\\"#Flash\\\" class=\\\"headerlink\\\" title=\\\"Flash\\\"></a>Flash</h1><p><img src=\\\"/images/etcher.png\\\" alt=\\\"etcher\\\"></p>\\n<p>I found that etcher.io is a very easy way to flash, in order to do so:</p>\\n<ul>\\n<li><strong>Install <a href=\\\"https://etcher.io/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">etcher</a></strong> (available for linux/osx/windows)</li>\\n<li><strong>Download image:</strong> I chose the raspbian lite version from <a href=\\\"https://www.raspberrypi.org/downloads/raspbian/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">official</a></li>\\n<li><strong>Open etcher</strong> etcher (on linux just unzip the etcher.zip and open the executable therein)</li>\\n<li><strong>Insert sd card</strong> (don’t mount it yet!), watch that etcher now detects that new card in the middle</li>\\n<li><strong>Select image</strong> e.g. <code>~/Downloads/2017-11-29-raspbian-stretch-lite.zip</code> and <strong>flash</strong> <small>(for linux i3 users: you’ll get a polkit error. You’ll need to start a polkit agent, e.g. <code>/usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1</code> before flashing)</small></li>\\n</ul>\",\"more\":\"<h1 id=\\\"Enable-ssh-and-wlan-on-the-image\\\"><a href=\\\"#Enable-ssh-and-wlan-on-the-image\\\" class=\\\"headerlink\\\" title=\\\"Enable ssh and wlan on the image\\\"></a>Enable ssh and wlan on the image</h1><p>Etcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using <code>sudo fdisk -l</code>. In my case I found:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">Disk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectors</span><br><span class=\\\"line\\\">Units: sectors of 1 * 512 = 512 bytes</span><br><span class=\\\"line\\\">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class=\\\"line\\\">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class=\\\"line\\\">Disklabel type: dos</span><br><span class=\\\"line\\\">Disk identifier: 0x37665771</span><br><span class=\\\"line\\\">Device         Boot Start     End Sectors  Size Id Type</span><br><span class=\\\"line\\\">/dev/mmcblk0p1       8192   93236   85045 41.5M  c W95 FAT32 (LBA)</span><br><span class=\\\"line\\\">/dev/mmcblk0p2      94208 3629055 3534848  1.7G 83 Linux</span><br></pre></td></tr></table></figure>\\n<p>The relevant lines are 8 (boot partition) and 9 (data partition).</p>\\n<h2 id=\\\"Enable-ssh\\\"><a href=\\\"#Enable-ssh\\\" class=\\\"headerlink\\\" title=\\\"Enable ssh\\\"></a>Enable ssh</h2><ul>\\n<li>create the mount point e.g. <code>mkdir /var/tmp/sdcard</code></li>\\n<li>mount the boot partition with <code>sudo mount -t vfat /dev/mmcblk0p1 /var/tmp/sdcard</code> whereas you specify the file system using <code>-t vfar</code> (corresponds to W95 FAT32) and the device <code>/dev/mmcblk0p1</code> is what you take from above (be sure to take the first one, that with the lower start number)</li>\\n<li><code>sudo touch /var/tmp/sdcard/ssh</code> to enable ssh on the first boot</li>\\n<li><code>sudo umount /var/tmp/sdcard</code></li>\\n</ul>\\n<h2 id=\\\"Enable-wireless\\\"><a href=\\\"#Enable-wireless\\\" class=\\\"headerlink\\\" title=\\\"Enable wireless\\\"></a>Enable wireless</h2><ul>\\n<li>mount the data partition with <code>sudo mount -t ext4 /dev/mmcblk0p2 /var/tmp/sdcard</code>, be sure to take the correct <code>/dev/</code>, <code>-t ext4</code> corresponds to the <code>Linux</code> fs type</li>\\n<li>run <code>wpa_passphrase &lt;ssid&gt; &lt;password&gt;</code> to create the wireless config config</li>\\n<li>edit <code>/var/tmp/sdcard/etc/wpa_supplicant/wpa_supplicant.conf</code> and add the config you just got from <code>wpa_passphrase</code>. Be sure to delete the plain text psk line</li>\\n<li><code>sudo umount /var/tmp/sdcard</code></li>\\n</ul>\\n<h1 id=\\\"Profit\\\"><a href=\\\"#Profit\\\" class=\\\"headerlink\\\" title=\\\"Profit!\\\"></a>Profit!</h1><p>That’s it, boot your pi, check your router for the ip address it just got and ssh in with <code>ssh pi@192.168.x.x</code> using <code>raspberry</code> as password.</p>\\n<p>A good first step is to start <code>sudo raspi-config</code> in order to:</p>\\n<ul>\\n<li>change password</li>\\n<li>generate the locale (get rid of the <code>warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)</code>)</li>\\n<li>set the correct timezone</li>\\n</ul>\\n<p>And, of course add your public key to authorized_keys:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat &gt;&gt;  ~/.ssh/authorized_keys&quot;</span><br></pre></td></tr></table></figure>\"},{\"title\":\"Python: Find out cpu time of a certain process\",\"date\":\"2007-06-08T04:52:00.000Z\",\"alias\":\"/post/37471156554/python-find-out-cpu-time-of-a-certain-process\",\"_content\":\"\\n<p>\\n  To find out how many percentage a certain process uses the cpu:\\n</p>\\n<!-- more -->\\n<pre>\\n  import os, time\\n\\n  # find out the pid by username.\\n  # \\\"-o pid h\\\" omits the header and just prints the pid\\n  pid = os.popen('ps -U my_user_name -o pid h').read().strip()\\n\\n  # 14th column is utime, 15th column is stime:\\n  # The time the process has been scheduled in user/kernel mode\\n  # The time value is in jiffies. One jiffie is appox 1/100 second\\n  # see man proc for more info\\n  stat = os.popen('cat /proc/%s/stat' % pid).read().strip()\\n  cpu_time1=int(stat.split()[14]) + int(stat.split()[15])\\n  time1=time.time()\\n\\n  time.sleep(1)\\n  stat = os.popen('cat /proc/%s/stat' % pid).read().strip()\\n  cpu_time2=int(stat.split()[14]) + int(stat.split()[15])\\n  time2=time.time()\\n\\n  print str(float(cpu_time2 - cpu_time1) / (time2 - time1)) + \\\"%\\\"\\n</pre>\\n<p>\\n  I don't know though if the number is accurate.<br>\\n  What is \\\"cpu time\\\" anyway? It's the time the process is running (using the cpu for 100%) divided by the time the process is laid asleep by the scheduler.<br>\\n  Then, <a href=\\\"http://www.ecos.sourceware.org/ml/systemtap/2005-q4/msg00185.html\\\">jiffies seem to be not a safe number</a> for time measurements.<br>\\n  But for relative measurements it should do the trick.\\n</p>\",\"source\":\"_posts/Python-Find-out-cpu-time-of-a-certain-process.md\",\"raw\":\"---\\ntitle: \\\"Python: Find out cpu time of a certain process\\\"\\ntags:\\n  - python\\ndate: 2007-06-08 06:52:00 \\nalias: /post/37471156554/python-find-out-cpu-time-of-a-certain-process\\n---\\n\\n<p>\\n  To find out how many percentage a certain process uses the cpu:\\n</p>\\n<!-- more -->\\n<pre>\\n  import os, time\\n\\n  # find out the pid by username.\\n  # \\\"-o pid h\\\" omits the header and just prints the pid\\n  pid = os.popen('ps -U my_user_name -o pid h').read().strip()\\n\\n  # 14th column is utime, 15th column is stime:\\n  # The time the process has been scheduled in user/kernel mode\\n  # The time value is in jiffies. One jiffie is appox 1/100 second\\n  # see man proc for more info\\n  stat = os.popen('cat /proc/%s/stat' % pid).read().strip()\\n  cpu_time1=int(stat.split()[14]) + int(stat.split()[15])\\n  time1=time.time()\\n\\n  time.sleep(1)\\n  stat = os.popen('cat /proc/%s/stat' % pid).read().strip()\\n  cpu_time2=int(stat.split()[14]) + int(stat.split()[15])\\n  time2=time.time()\\n\\n  print str(float(cpu_time2 - cpu_time1) / (time2 - time1)) + \\\"%\\\"\\n</pre>\\n<p>\\n  I don't know though if the number is accurate.<br>\\n  What is \\\"cpu time\\\" anyway? It's the time the process is running (using the cpu for 100%) divided by the time the process is laid asleep by the scheduler.<br>\\n  Then, <a href=\\\"http://www.ecos.sourceware.org/ml/systemtap/2005-q4/msg00185.html\\\">jiffies seem to be not a safe number</a> for time measurements.<br>\\n  But for relative measurements it should do the trick.\\n</p>\",\"slug\":\"Python-Find-out-cpu-time-of-a-certain-process\",\"published\":1,\"updated\":\"2017-11-11T21:12:21.440Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60f000ci85p0k3hdc7d\",\"content\":\"<p><br>  To find out how many percentage a certain process uses the cpu:<br></p><br><a id=\\\"more\\\"></a><br><pre><br>  import os, time<br><br>  # find out the pid by username.<br>  # “-o pid h” omits the header and just prints the pid<br>  pid = os.popen(‘ps -U my_user_name -o pid h’).read().strip()<br><br>  # 14th column is utime, 15th column is stime:<br>  # The time the process has been scheduled in user/kernel mode<br>  # The time value is in jiffies. One jiffie is appox 1/100 second<br>  # see man proc for more info<br>  stat = os.popen(‘cat /proc/%s/stat’ % pid).read().strip()<br>  cpu_time1=int(stat.split()[14]) + int(stat.split()[15])<br>  time1=time.time()<br><br>  time.sleep(1)<br>  stat = os.popen(‘cat /proc/%s/stat’ % pid).read().strip()<br>  cpu_time2=int(stat.split()[14]) + int(stat.split()[15])<br>  time2=time.time()<br><br>  print str(float(cpu_time2 - cpu_time1) / (time2 - time1)) + “%”<br></pre><br><p><br>  I don’t know though if the number is accurate.<br><br>  What is “cpu time” anyway? It’s the time the process is running (using the cpu for 100%) divided by the time the process is laid asleep by the scheduler.<br><br>  Then, <a href=\\\"http://www.ecos.sourceware.org/ml/systemtap/2005-q4/msg00185.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">jiffies seem to be not a safe number</a> for time measurements.<br><br>  But for relative measurements it should do the trick.<br></p>\",\"site\":{\"data\":{}},\"excerpt\":\"<p><br>  To find out how many percentage a certain process uses the cpu:<br></p><br>\",\"more\":\"<br><pre><br>  import os, time<br><br>  # find out the pid by username.<br>  # “-o pid h” omits the header and just prints the pid<br>  pid = os.popen(‘ps -U my_user_name -o pid h’).read().strip()<br><br>  # 14th column is utime, 15th column is stime:<br>  # The time the process has been scheduled in user/kernel mode<br>  # The time value is in jiffies. One jiffie is appox 1/100 second<br>  # see man proc for more info<br>  stat = os.popen(‘cat /proc/%s/stat’ % pid).read().strip()<br>  cpu_time1=int(stat.split()[14]) + int(stat.split()[15])<br>  time1=time.time()<br><br>  time.sleep(1)<br>  stat = os.popen(‘cat /proc/%s/stat’ % pid).read().strip()<br>  cpu_time2=int(stat.split()[14]) + int(stat.split()[15])<br>  time2=time.time()<br><br>  print str(float(cpu_time2 - cpu_time1) / (time2 - time1)) + “%”<br></pre><br><p><br>  I don’t know though if the number is accurate.<br><br>  What is “cpu time” anyway? It’s the time the process is running (using the cpu for 100%) divided by the time the process is laid asleep by the scheduler.<br><br>  Then, <a href=\\\"http://www.ecos.sourceware.org/ml/systemtap/2005-q4/msg00185.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">jiffies seem to be not a safe number</a> for time measurements.<br><br>  But for relative measurements it should do the trick.<br></p>\"},{\"title\":\"Python: Print list of dicts as ascii table\",\"date\":\"2010-02-27T11:55:00.000Z\",\"_content\":\"\\nSometimes I want to print list of dicts as an ascii table, like this:\\n\\n<pre>  | Programming Language | Language Type | Years of Experience |\\n  +----------------------+---------------+---------------------+\\n  | python               | script        |                    4 |\\n  | php                  | script        |                    5 |\\n  | java                 | compiled      |                   11 |\\n  | assember             | compiled      |                   15 |\\n</pre>\\n\\nI searched on Google - but without luck.<!-- more -->\\n\\n That&rsquo;s what I came up with - it&rsquo;s not particularly nice but it does the job:\\n\\n<pre>  def table_print(data, title_row):\\n    \\\"\\\"\\\"\\n    data: list of dicts,\\n    title_row: e.g. [('name', 'Programming Language'), ('type', 'Language Type')]\\n    \\\"\\\"\\\"\\n    max_widths = {}\\n    data_copy = [dict(title_row)] + list(data)\\n    for col in data_copy[0].keys():\\n      max_widths[col] = max([len(str(row[col])) for row in data_copy])\\n    cols_order = [tup[0] for tup in title_row]\\n\\n    def custom_just(col, value):\\n      if type(value) == int:\\n        return str(value).rjust(max_widths[col])\\n      else:\\n        return value.ljust(max_widths[col])\\n\\n    for row in data_copy:\\n      row_str = \\\" | \\\".join([custom_just(col, row[col]) for col in cols_order])\\n      print \\\"| %s |\\\" % row_str\\n      if data_copy.index(row) == 0:\\n        underline = \\\"-+-\\\".join(['-' * max_widths[col] for col in cols_order])\\n        print '+-%s-+' % underline\\n\\n  </pre>\\n\\nUse it like that:\\n\\n<pre>  data = [dict(name='python', type='script', years_experience=4),\\n    dict(name='php', type='script', years_experience=5),\\n    dict(name='java', type='compiled', years_experience=11),\\n    dict(name='assember', type='compiled', years_experience=15)\\n    ]\\n  titles = [('name', 'Programming Language'),\\n    ('type', 'Language Type'),\\n    ('years_experience', 'Years of Experience')]\\n  table_print(data, titles)\\n  </pre>\\n\\nIt will produce the table printed above. It&rsquo;s not fancy - the only &lsquo;smart&rsquo; thing it does is **right-adjusting integers, strings are left-adjusted**.\\n\\n P.S. no, I don&rsquo;t have 15 years of experience of Assembler - I just know it since 15 years - it&rsquo;s one of the first programming languages I learned - and I even wrote a text editor with it - then I learned that&rsquo;s probably not the best language to write an editor :-)\",\"source\":\"_posts/Python-Print-list-of-dicts-as-ascii-table.md\",\"raw\":\"---\\ntitle: 'Python: Print list of dicts as ascii table'\\ntags:\\n  - python\\ndate: 2010-02-27 12:55:00\\n---\\n\\nSometimes I want to print list of dicts as an ascii table, like this:\\n\\n<pre>  | Programming Language | Language Type | Years of Experience |\\n  +----------------------+---------------+---------------------+\\n  | python               | script        |                    4 |\\n  | php                  | script        |                    5 |\\n  | java                 | compiled      |                   11 |\\n  | assember             | compiled      |                   15 |\\n</pre>\\n\\nI searched on Google - but without luck.<!-- more -->\\n\\n That&rsquo;s what I came up with - it&rsquo;s not particularly nice but it does the job:\\n\\n<pre>  def table_print(data, title_row):\\n    \\\"\\\"\\\"\\n    data: list of dicts,\\n    title_row: e.g. [('name', 'Programming Language'), ('type', 'Language Type')]\\n    \\\"\\\"\\\"\\n    max_widths = {}\\n    data_copy = [dict(title_row)] + list(data)\\n    for col in data_copy[0].keys():\\n      max_widths[col] = max([len(str(row[col])) for row in data_copy])\\n    cols_order = [tup[0] for tup in title_row]\\n\\n    def custom_just(col, value):\\n      if type(value) == int:\\n        return str(value).rjust(max_widths[col])\\n      else:\\n        return value.ljust(max_widths[col])\\n\\n    for row in data_copy:\\n      row_str = \\\" | \\\".join([custom_just(col, row[col]) for col in cols_order])\\n      print \\\"| %s |\\\" % row_str\\n      if data_copy.index(row) == 0:\\n        underline = \\\"-+-\\\".join(['-' * max_widths[col] for col in cols_order])\\n        print '+-%s-+' % underline\\n\\n  </pre>\\n\\nUse it like that:\\n\\n<pre>  data = [dict(name='python', type='script', years_experience=4),\\n    dict(name='php', type='script', years_experience=5),\\n    dict(name='java', type='compiled', years_experience=11),\\n    dict(name='assember', type='compiled', years_experience=15)\\n    ]\\n  titles = [('name', 'Programming Language'),\\n    ('type', 'Language Type'),\\n    ('years_experience', 'Years of Experience')]\\n  table_print(data, titles)\\n  </pre>\\n\\nIt will produce the table printed above. It&rsquo;s not fancy - the only &lsquo;smart&rsquo; thing it does is **right-adjusting integers, strings are left-adjusted**.\\n\\n P.S. no, I don&rsquo;t have 15 years of experience of Assembler - I just know it since 15 years - it&rsquo;s one of the first programming languages I learned - and I even wrote a text editor with it - then I learned that&rsquo;s probably not the best language to write an editor :-)\",\"slug\":\"Python-Print-list-of-dicts-as-ascii-table\",\"published\":1,\"updated\":\"2017-11-11T07:15:45.012Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60g000fi85p5naditwi\",\"content\":\"<p>Sometimes I want to print list of dicts as an ascii table, like this:</p>\\n<pre>  | Programming Language | Language Type | Years of Experience |\\n  +----------------------+---------------+---------------------+\\n  | python               | script        |                    4 |\\n  | php                  | script        |                    5 |\\n  | java                 | compiled      |                   11 |\\n  | assember             | compiled      |                   15 |\\n</pre>\\n\\n<p>I searched on Google - but without luck.<a id=\\\"more\\\"></a></p>\\n<p> That&rsquo;s what I came up with - it&rsquo;s not particularly nice but it does the job:</p>\\n<pre>  def table_print(data, title_row):\\n    \\\"\\\"\\\"\\n    data: list of dicts,\\n    title_row: e.g. [('name', 'Programming Language'), ('type', 'Language Type')]\\n    \\\"\\\"\\\"\\n    max_widths = {}\\n    data_copy = [dict(title_row)] + list(data)\\n    for col in data_copy[0].keys():\\n      max_widths[col] = max([len(str(row[col])) for row in data_copy])\\n    cols_order = [tup[0] for tup in title_row]\\n\\n    def custom_just(col, value):\\n      if type(value) == int:\\n        return str(value).rjust(max_widths[col])\\n      else:\\n        return value.ljust(max_widths[col])\\n\\n    for row in data_copy:\\n      row_str = \\\" | \\\".join([custom_just(col, row[col]) for col in cols_order])\\n      print \\\"| %s |\\\" % row_str\\n      if data_copy.index(row) == 0:\\n        underline = \\\"-+-\\\".join(['-' * max_widths[col] for col in cols_order])\\n        print '+-%s-+' % underline\\n\\n  </pre>\\n\\n<p>Use it like that:</p>\\n<pre>  data = [dict(name='python', type='script', years_experience=4),\\n    dict(name='php', type='script', years_experience=5),\\n    dict(name='java', type='compiled', years_experience=11),\\n    dict(name='assember', type='compiled', years_experience=15)\\n    ]\\n  titles = [('name', 'Programming Language'),\\n    ('type', 'Language Type'),\\n    ('years_experience', 'Years of Experience')]\\n  table_print(data, titles)\\n  </pre>\\n\\n<p>It will produce the table printed above. It&rsquo;s not fancy - the only &lsquo;smart&rsquo; thing it does is <strong>right-adjusting integers, strings are left-adjusted</strong>.</p>\\n<p> P.S. no, I don&rsquo;t have 15 years of experience of Assembler - I just know it since 15 years - it&rsquo;s one of the first programming languages I learned - and I even wrote a text editor with it - then I learned that&rsquo;s probably not the best language to write an editor :-)</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>Sometimes I want to print list of dicts as an ascii table, like this:</p>\\n<pre>  | Programming Language | Language Type | Years of Experience |\\n  +----------------------+---------------+---------------------+\\n  | python               | script        |                    4 |\\n  | php                  | script        |                    5 |\\n  | java                 | compiled      |                   11 |\\n  | assember             | compiled      |                   15 |\\n</pre>\\n\\n<p>I searched on Google - but without luck.\",\"more\":\"</p>\\n<p> That&rsquo;s what I came up with - it&rsquo;s not particularly nice but it does the job:</p>\\n<pre>  def table_print(data, title_row):\\n    \\\"\\\"\\\"\\n    data: list of dicts,\\n    title_row: e.g. [('name', 'Programming Language'), ('type', 'Language Type')]\\n    \\\"\\\"\\\"\\n    max_widths = {}\\n    data_copy = [dict(title_row)] + list(data)\\n    for col in data_copy[0].keys():\\n      max_widths[col] = max([len(str(row[col])) for row in data_copy])\\n    cols_order = [tup[0] for tup in title_row]\\n\\n    def custom_just(col, value):\\n      if type(value) == int:\\n        return str(value).rjust(max_widths[col])\\n      else:\\n        return value.ljust(max_widths[col])\\n\\n    for row in data_copy:\\n      row_str = \\\" | \\\".join([custom_just(col, row[col]) for col in cols_order])\\n      print \\\"| %s |\\\" % row_str\\n      if data_copy.index(row) == 0:\\n        underline = \\\"-+-\\\".join(['-' * max_widths[col] for col in cols_order])\\n        print '+-%s-+' % underline\\n\\n  </pre>\\n\\n<p>Use it like that:</p>\\n<pre>  data = [dict(name='python', type='script', years_experience=4),\\n    dict(name='php', type='script', years_experience=5),\\n    dict(name='java', type='compiled', years_experience=11),\\n    dict(name='assember', type='compiled', years_experience=15)\\n    ]\\n  titles = [('name', 'Programming Language'),\\n    ('type', 'Language Type'),\\n    ('years_experience', 'Years of Experience')]\\n  table_print(data, titles)\\n  </pre>\\n\\n<p>It will produce the table printed above. It&rsquo;s not fancy - the only &lsquo;smart&rsquo; thing it does is <strong>right-adjusting integers, strings are left-adjusted</strong>.</p>\\n<p> P.S. no, I don&rsquo;t have 15 years of experience of Assembler - I just know it since 15 years - it&rsquo;s one of the first programming languages I learned - and I even wrote a text editor with it - then I learned that&rsquo;s probably not the best language to write an editor :-)</p>\"},{\"title\":\"Send javascript errors by mail\",\"date\":\"2007-10-06T13:33:00.000Z\",\"alias\":\"/post/37471157855/send-javascript-errors-by-mail\",\"_content\":\"\\n  I&rsquo;m running [a Django-powered site for a closed user group](http://extranet.icoc.ch) and added a bit of JavaScript magic here and there (mainly [Prototype](http://www.prototypejs.org/) and [Tooltip](http://codylindley.com/Javascript/219/finding-a-javascript-tool-tip-script)).\\n\\n<!-- more -->\\n  Now Django sends me a mail whenever a 404 or 500 error occurs. But when one of my users encounters a JavaScript-Error, I&rsquo;m not informed. I thought anyone in the web has solved this problem but didn&rsquo;t find anything, so here&rsquo;s my take: Just send any error using Ajax (here: using [Prototypes Ajax abstraction](http://www.prototypejs.org/learn/introduction-to-ajax)) to the server\\n\\n<pre>\\nonerror = Extranet.mailError;\\nfunction mailError(msg, url, line) {\\n var postBody = 'url=' + url + '&amp;line=' + line + '&amp;message=' + escape(msg) + '&amp;useragent=' + escape(navigator.userAgent) + '&amp;user=' + escape(user_name);\\n var myAjax = new Ajax.Request('/api/jserror/', {method: 'post', postBody: postBody});\\n}\\n</pre>\\n\\n  `user_name` is a JavaScript variable holding the Django username (so I know whom I can inform when the error is fixed).\\n\\n  On the server side, I just send me mails containing the JavaScript error message, the username and the user agent:\\n\\n<pre>\\ndef jserror(request):\\n from django.core.mail import mail_admins\\n omit_messages = ['pointerobj is not defined', 'tipobj is not defined', 'ns6 is not defined', 'enabletip is not defined']\\n if request.POST.get('message', '') not in omit_messages:\\n  message = \\\"\\\"\\\"url: %s (%s)\\n%s\\nuser-agent: %s\\nusername: %s\\n\\\"\\\"\\\" % (request.POST.get('url', ''), request.POST.get('line', ''), request.POST.get('message', ''), request.POST.get('useragent', ''), request.POST.get('user', ''))\\n  mail_admins(\\\"javascript error\\\", urldecode(message))\\n return HttpResponse()\\n</pre>\\n\\n  Yeah, that&rsquo;s all very trivial but I wonder what other solutions exist for this problem&hellip;\",\"source\":\"_posts/Send-javascript-errors-by-mail.md\",\"raw\":\"---\\ntitle: Send javascript errors by mail\\ntags:\\n  - python\\n  - django\\n  - javascript\\ndate: 2007-10-06 15:33:00\\nalias: /post/37471157855/send-javascript-errors-by-mail\\n---\\n\\n  I&rsquo;m running [a Django-powered site for a closed user group](http://extranet.icoc.ch) and added a bit of JavaScript magic here and there (mainly [Prototype](http://www.prototypejs.org/) and [Tooltip](http://codylindley.com/Javascript/219/finding-a-javascript-tool-tip-script)).\\n\\n<!-- more -->\\n  Now Django sends me a mail whenever a 404 or 500 error occurs. But when one of my users encounters a JavaScript-Error, I&rsquo;m not informed. I thought anyone in the web has solved this problem but didn&rsquo;t find anything, so here&rsquo;s my take: Just send any error using Ajax (here: using [Prototypes Ajax abstraction](http://www.prototypejs.org/learn/introduction-to-ajax)) to the server\\n\\n<pre>\\nonerror = Extranet.mailError;\\nfunction mailError(msg, url, line) {\\n var postBody = 'url=' + url + '&amp;line=' + line + '&amp;message=' + escape(msg) + '&amp;useragent=' + escape(navigator.userAgent) + '&amp;user=' + escape(user_name);\\n var myAjax = new Ajax.Request('/api/jserror/', {method: 'post', postBody: postBody});\\n}\\n</pre>\\n\\n  `user_name` is a JavaScript variable holding the Django username (so I know whom I can inform when the error is fixed).\\n\\n  On the server side, I just send me mails containing the JavaScript error message, the username and the user agent:\\n\\n<pre>\\ndef jserror(request):\\n from django.core.mail import mail_admins\\n omit_messages = ['pointerobj is not defined', 'tipobj is not defined', 'ns6 is not defined', 'enabletip is not defined']\\n if request.POST.get('message', '') not in omit_messages:\\n  message = \\\"\\\"\\\"url: %s (%s)\\n%s\\nuser-agent: %s\\nusername: %s\\n\\\"\\\"\\\" % (request.POST.get('url', ''), request.POST.get('line', ''), request.POST.get('message', ''), request.POST.get('useragent', ''), request.POST.get('user', ''))\\n  mail_admins(\\\"javascript error\\\", urldecode(message))\\n return HttpResponse()\\n</pre>\\n\\n  Yeah, that&rsquo;s all very trivial but I wonder what other solutions exist for this problem&hellip;\",\"slug\":\"Send-javascript-errors-by-mail\",\"published\":1,\"updated\":\"2017-11-11T21:12:54.445Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60h000hi85pejrwvch3\",\"content\":\"<p>  I&rsquo;m running <a href=\\\"http://extranet.icoc.ch\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a Django-powered site for a closed user group</a> and added a bit of JavaScript magic here and there (mainly <a href=\\\"http://www.prototypejs.org/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Prototype</a> and <a href=\\\"http://codylindley.com/Javascript/219/finding-a-javascript-tool-tip-script\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Tooltip</a>).</p>\\n<a id=\\\"more\\\"></a>\\n<p>  Now Django sends me a mail whenever a 404 or 500 error occurs. But when one of my users encounters a JavaScript-Error, I&rsquo;m not informed. I thought anyone in the web has solved this problem but didn&rsquo;t find anything, so here&rsquo;s my take: Just send any error using Ajax (here: using <a href=\\\"http://www.prototypejs.org/learn/introduction-to-ajax\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Prototypes Ajax abstraction</a>) to the server</p>\\n<pre>\\nonerror = Extranet.mailError;\\nfunction mailError(msg, url, line) {\\n var postBody = 'url=' + url + '&amp;line=' + line + '&amp;message=' + escape(msg) + '&amp;useragent=' + escape(navigator.userAgent) + '&amp;user=' + escape(user_name);\\n var myAjax = new Ajax.Request('/api/jserror/', {method: 'post', postBody: postBody});\\n}\\n</pre>\\n\\n<p>  <code>user_name</code> is a JavaScript variable holding the Django username (so I know whom I can inform when the error is fixed).</p>\\n<p>  On the server side, I just send me mails containing the JavaScript error message, the username and the user agent:</p>\\n<pre>\\ndef jserror(request):\\n from django.core.mail import mail_admins\\n omit_messages = ['pointerobj is not defined', 'tipobj is not defined', 'ns6 is not defined', 'enabletip is not defined']\\n if request.POST.get('message', '') not in omit_messages:\\n  message = \\\"\\\"\\\"url: %s (%s)\\n%s\\nuser-agent: %s\\nusername: %s\\n\\\"\\\"\\\" % (request.POST.get('url', ''), request.POST.get('line', ''), request.POST.get('message', ''), request.POST.get('useragent', ''), request.POST.get('user', ''))\\n  mail_admins(\\\"javascript error\\\", urldecode(message))\\n return HttpResponse()\\n</pre>\\n\\n<p>  Yeah, that&rsquo;s all very trivial but I wonder what other solutions exist for this problem&hellip;</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>  I&rsquo;m running <a href=\\\"http://extranet.icoc.ch\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a Django-powered site for a closed user group</a> and added a bit of JavaScript magic here and there (mainly <a href=\\\"http://www.prototypejs.org/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Prototype</a> and <a href=\\\"http://codylindley.com/Javascript/219/finding-a-javascript-tool-tip-script\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Tooltip</a>).</p>\",\"more\":\"<p>  Now Django sends me a mail whenever a 404 or 500 error occurs. But when one of my users encounters a JavaScript-Error, I&rsquo;m not informed. I thought anyone in the web has solved this problem but didn&rsquo;t find anything, so here&rsquo;s my take: Just send any error using Ajax (here: using <a href=\\\"http://www.prototypejs.org/learn/introduction-to-ajax\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Prototypes Ajax abstraction</a>) to the server</p>\\n<pre>\\nonerror = Extranet.mailError;\\nfunction mailError(msg, url, line) {\\n var postBody = 'url=' + url + '&amp;line=' + line + '&amp;message=' + escape(msg) + '&amp;useragent=' + escape(navigator.userAgent) + '&amp;user=' + escape(user_name);\\n var myAjax = new Ajax.Request('/api/jserror/', {method: 'post', postBody: postBody});\\n}\\n</pre>\\n\\n<p>  <code>user_name</code> is a JavaScript variable holding the Django username (so I know whom I can inform when the error is fixed).</p>\\n<p>  On the server side, I just send me mails containing the JavaScript error message, the username and the user agent:</p>\\n<pre>\\ndef jserror(request):\\n from django.core.mail import mail_admins\\n omit_messages = ['pointerobj is not defined', 'tipobj is not defined', 'ns6 is not defined', 'enabletip is not defined']\\n if request.POST.get('message', '') not in omit_messages:\\n  message = \\\"\\\"\\\"url: %s (%s)\\n%s\\nuser-agent: %s\\nusername: %s\\n\\\"\\\"\\\" % (request.POST.get('url', ''), request.POST.get('line', ''), request.POST.get('message', ''), request.POST.get('useragent', ''), request.POST.get('user', ''))\\n  mail_admins(\\\"javascript error\\\", urldecode(message))\\n return HttpResponse()\\n</pre>\\n\\n<p>  Yeah, that&rsquo;s all very trivial but I wonder what other solutions exist for this problem&hellip;</p>\"},{\"title\":\"Scan with raspberry pi, convert with aws to searchable PDF\",\"date\":\"2018-01-22T20:16:13.000Z\",\"_content\":\"\\n![scan flow scanner to raspberry to s3 to lambda to s3](/images/scan_flow.png)\\n\\nI have long dreamed for a setup which lets me just press the scan button on my scanner and without any further input it uploads it as a searchable PDF onto some cloud store. Thanks to the good support of scanners by SANE and the ease of use of AWS lambda it's actually *quite* easy (judging to the length of this post it looks like quite a task, but in the end it is straightforwards and is - surprisingly - quite free of hacks).\\n\\nIn this solution you:\\n\\n- set up SANE on your raspberry pi 3 so it scans your document\\n- set up scanbd to detect the scan button\\n- set up a S3 bucket for uploading\\n- set up a lambda function which uses tesseract to create a searchable PDF\\n\\nWhat you need:\\n\\n- Raspberry Pi 3 (I guess the other models serve equally well)\\n- Paper scanner with a \\\"scan\\\" button.\\n- an AWS account\\n\\nPersonally I'm using Raspbian Stretch Lite as OS on my Raspberry and a Fujitsu S1300i.\\n\\n# Set up SANE\\n\\n\\n# sane\\n\\ncheck that your scanner is supported [here](http://www.sane-project.org/sane-mfgs.html)\\n\\n```\\nsudo apt install sane-utils -y\\nsane-find-scanner -q # shows scanner\\nusermod -a -G scanner pi # makes it available for pi\\ngrep 1300 /etc/sane.d/*.conf\\nsudo mkdir /usr/share/sane/epjitsu/\\nsudo wget https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -O /usr/share/sane/epjitsu/1300i_0D12.nal\\nscanimage >/tmp/out.pnm\\n```\\n\\n# scanbd\\n\\n```\\nsudo apt install scanbd -y\\nsudo vim /etc/scandb/scandb.conf # set debug-level=7, user=pi\\nsudo scanbd -f\\n```\\n\\n```\\nsudo vim /etc/scandb/scandb.conf # set script_dir=/etc/scanbd/scripts, in action 'scan': desc=\\\"Scan to a file and upload to s3\\\", script=\\\"scan.sh\\\"\\nsudo mkdir /etc/scanbd/scripts/\\nsudo vim /etc/scanbd/scripts/scan.sh\\nsudo chmod a+x /etc/scanbd/scripts/scan.sh\\n```\\n\\nreplug scanner, test with `sudo scanbd -f`\\nclose lid, open lid -> segementation fault\\n\\n```\\nsudo vim /lib/systemd/system/scanbd.service # add Restart=on-failure\\nsudo systemctl daemon-reload\\nsudo service scanbd start\\nsudo update-rc.d scanbd enable\\n```\\n\\n# s3 script\\n\\n```\\nsudo apt install python-pip -y\\nsudo pip install awscli\\naws configure\\naws s3 ls s3://scanner-upload/\\n```\\n\\n```\\n#!/bin/sh\\n\\nset -e\\nexport TMP_DIR=`mktemp -d`\\n\\necho 'scanning..'\\nscanimage --resolution 300 --batch=\\\"$TMP_DIR/scan_%03d.pnm\\\" --format=pnm --mode Gray --source \\\"ADF Duplex\\\"\\n\\necho 'packaging and uploading in subshell'\\n(tarname=scan_$(date \\\"+%Y-%m-%d_%H%M%S\\\").tar.gz\\ncd $TMP_DIR\\ntar -czf $tarname *.pnm\\necho 'uploading..'\\naws s3 cp $TMP_DIR/$tarname s3://scanner-upload/\\nrm -rf $TMP_DIR\\necho 'done') &\\n```\\n\\n\\n\\n# 1. Make sane work with fujitsu 1300i\\n\\nThere are plenty of howtos out there how to get Fujitsu 1300i running with raspberry pi (my favourite one was [this one](https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup)), but for completeness sake here it is again (and the bottom doc bases on this exact setup)\\n\\n## Install driver/sane/...\\n\\n\\n```\\nsudo apt install git-core libusb-dev -y\\ncd /var/tmp/\\ngit clone git://git.debian.org/sane/sane-backends.git\\ncd sane-backends/\\nBACKENDS=epjitsu ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var\\nmake\\nsudo make install\\ncd /usr/share/sane/epjitsu/\\nsudo curl https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -L -O\\n```\\n\\n\\n\\n```\\nsudo vim \\n```\\n\\n\\n## Test with root\\n\\nNow, `sudo sane-find-scanner -q` should show something like:\\n\\n```\\nfound USB scanner (vendor=0x04c6 [FUJITSU], product=0x128d [ScanSnap S1300i]) at libusb:001:011\\nfound USB scanner (vendor=0x0424, product=0xec00) at libusb:001:003\\n```\\n\\nDo a test scan: `sudo scanimage >/tmp/out.pnm`\\n\\nNow you could try to get it to run with user `pi` but after some messing around I gave it up. The setup [mentioned in this doc](https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup#sane_permissions) did not work for me\\n\\n# 2. Detect scanner button pressed\\n\\n## Install scanbd\\n\\nInstall scanbd via `apt`. Be sure to hit `N` when being asked about overwriting `dll.conf` and `epjitsu.conf`:\\n\\n```\\nsudo apt install scanbd\\n```\\n\\nScanbd is a daemon which polls the scanner button and starts a custom scripts when the button is pressed. In the script you'll use the sane setup you just did.\\n\\nFirst, we'll do a quick test just to see that scanbd does its job: Edit `/etc/scanbd/scanbd.conf` ((if the config file is missing, as it was in my case when I initially installed with `apt` you can take [this initial scanbd.conf](https://gist.github.com/philippkeller/f2dafcd8c9e22e691b2a21ca9746303c) as a start) and:\\n\\n- set `debug-level=7`, that's just for the beginning until we're sure that everything works\\n- set `user=root`, as we just made saned run in the root user\\n\\nStart scanbd with `sudo scanbd -f` and you'll the the polling. When you hit the scan button then you'll see that it tries running `/etc/scanbd/scripts/test.script` which doesn't exist yet. So far, so good!\\n\\n<!--\\n\\nUnfortunately the scanbd version which - at the time of this blog post - is in the repo has [an annoying bug which causes scanbd to crash (segfault) when you close/unplug the scanner and replug it again](https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095).\\n\\nIf `apt search scanbd` gives you a version > 1.5.1-1 then you can just install it with `sudo apt install scan scanbuttond` and skip to the next section.\\n\\nTo compile from source, do the following:\\n\\n```\\nsudo apt install libconfuse-dev libdbus-1-dev libsane-dev -y\\ncd /var/tmp/\\nwget https://sourceforge.net/projects/scanbd/files/latest/download?source=files -O scanbd.tar.gz\\ntar -xzvf scanbd.tar.gz\\ncd 1.5.1\\n./configure\\nmake\\nsudo make install\\n```\\n\\n\\n\\n## Configure scanbd\\n\\nContrary to some howtos on the net you don't need to copy files, etc. Scanbd just uses the just sane client to regularly poll the button and then starts a custom script.\\n\\nFirst, you need to check where the scanbd config file is. Do `man scanbd` and check the `-c` option. For older versions (ie.g. installed via apt) this is in `/etc/scanbd/scanbd.conf`, for newer (i.e. compiled from source) this is in `/usr/local/etc/scanbd/scanbd.conf`.\\n\\nNow, adapt your config file like this (if the config file is missing, as it was in my case when I initially installed with `apt` you can take [this initial scanbd.conf](https://gist.github.com/philippkeller/9d6a6ccea6c448bedd67338e8eb98870) as a start):\\n-->\\n\\n\\n## Configure scanbd\\n\\nIn `/etc/scanbd/scanbd.conf`:\\n\\n- set `scriptdir = /etc/scanbd/scripts`\\n- in action `scan` set `desc=\\\"Scan to file and upload to s3\\\"` and `script=scan.sh`\\n\\nThen, after `mkdir /etc/scanbd/scripts` put that into `/etc/scanbd/scripts/scan.sh` just to test (don't forget to `chmod a+x` the file):\\n\\n```\\n#!/bin/sh\\nscanimage > /tmp/foo.pnm\\n```\\n\\nStart scanbd with `sudo scanbd -f` and you should see the polling and your script being called. `cat /var/tmp/foo.txt` should show a bunch of \\\"scan button pressed\\\" lines. Wohoo!\\n\\n## Test via service\\n\\nNow, also test if it works when you start it with `sudo service scanbd start`. If you have any problems then you might need to correct `ExecStart` and `SANE_CONFIG_DIR` with the correct directories and reload it with `sudo systemctl daemon-reload`.\\n\\nTo see the logs, do `tail -f /var/log/syslog`\\n\\nNow, scanbd [has a bug so when you close/open your printer or reconnect the usb it segfaults](https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095). The versions > 1.5.1.1 have fixed this bug. I tried to use those but then it just didn't carry on after replugging so I went back to the version provided by `apt`.\\n\\nTo work around the segfault it is actually easier to\\n\\n- add `Restart=on-failure` to `/lib/systemd/system/scanbd.service`\\n- reload `sudo systemctl daemon-reload`\\n\\nNow you should be able to close the lid of the scanner, see the usb disconnect message in `/var/log/syslog`, then open the lid and the scanner button should still work.\\n\\n# 3. Make the scanner upload to s3\\n\\n## Preparing S3\\n\\n- create an s3 bucket, e.g. `scanner-upload` (be sure to choose a region close to you. Upload speed is a lot faster for closer regions). Note the ARN of the bucket.\\n- in IAM create a policy `scanner-upload`, swith into JSON editor and paste this (replace the arn):\\n\\n```\\n{\\n  \\\"Version\\\": \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\\"s3:ListBucket\\\"],\\n      \\\"Resource\\\": [\\\"arn:aws:s3:::scanner-upload\\\"]\\n    },\\n    {\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\n        \\\"s3:PutObject\\\",\\n        \\\"s3:GetObject\\\",\\n        \\\"s3:DeleteObject\\\"\\n      ],\\n      \\\"Resource\\\": [\\\"arn:aws:s3:::scanner-upload/*\\\"]\\n    }\\n  ]\\n}\\n```\\n\\n- in IAM create a user and attach the `scanner-upload` policy. Note the key/secret or download the csv\\n- install `aws cli` on raspberry pi: `sudo pip install awscli --upgrade --user` (be sure to use `sudo`, otherwise it'll be installed into `~/.local/bin/` which might not be in your `$PATH`)\\n- start `aws configure` to put the key/secret and aws region into your config\\n- test that s3 access works with `aws s3 ls s3://scanner-upload/` and uploading a file using `aws s3 cp some_file.txt s3://scanner-upload/`\\n\\n## Put `scan.sh` into place\\n\\nPut this into `/etc/scanbd/scan.sh` (replace `scanner-upload` with your bucket name):\\n\\n```\\n#!/bin/sh\\n\\nset -e\\nTMP_DIR=`mktemp -d`\\n\\necho 'scanning..'\\nscanimage --resolution 300 --batch=\\\"$TMP_DIR/scan_%03d.pnm\\\" --format=pnm --mode Gray --source \\\"ADF Duplex\\\"\\n\\necho 'packaging..'\\ntarname=scan_$(date \\\"+%Y-%m-%d_%H%M%S\\\").tar.gz\\ncd $TMP_DIR\\ntar -czf $tarname *.pnm\\n\\necho 'uploading..'\\naws s3 cp $TMP_DIR/$tarname s3://scanner-upload/\\nrm -rf $TMP_DIR\\n```\\n\\nYou might want to play around with the `scanimage` command. In the above script it\\n\\n- scans in batch mode: creates multiple files until the feeder is empty\\n- does a duplex scan (there's no detection. It means that if it's a one sided paper the second page is just empty)\\n- `resolution 300`: this is the default. It is a pretty fast scan and the quality is good enough\\n\\nTry to call the script manually and then start `scanbd -f`. Now pressing the button will scan and upload to s3, whohoo!\\n\\n## Start scanbd at boot time, and secure it\\n\\nMake `scanbd` start at boot time: `sudo update-rc.d scanbd enable`.\\n\\nSecure it: tbd (what happens when you close the lid..?)\\n\\n## Cleaning up\\n\\nIf everything has worked this far you can decrease the logging level in scanbd.conf:\\n\\n- set `debug-level=3` as level 7 is much too verbose\\n- set `debug=false`\\n\\nremove the temp dirs:\\n\\n- `rm -rf /var/tmp/sane-backends`\\n- `rm -rf /var/tmp/1.5.1`\",\"source\":\"_posts/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF.md\",\"raw\":\"---\\ntitle: 'Scan with raspberry pi, convert with aws to searchable PDF'\\ndate: 2018-01-22 21:16:13\\ntags:\\n---\\n\\n![scan flow scanner to raspberry to s3 to lambda to s3](/images/scan_flow.png)\\n\\nI have long dreamed for a setup which lets me just press the scan button on my scanner and without any further input it uploads it as a searchable PDF onto some cloud store. Thanks to the good support of scanners by SANE and the ease of use of AWS lambda it's actually *quite* easy (judging to the length of this post it looks like quite a task, but in the end it is straightforwards and is - surprisingly - quite free of hacks).\\n\\nIn this solution you:\\n\\n- set up SANE on your raspberry pi 3 so it scans your document\\n- set up scanbd to detect the scan button\\n- set up a S3 bucket for uploading\\n- set up a lambda function which uses tesseract to create a searchable PDF\\n\\nWhat you need:\\n\\n- Raspberry Pi 3 (I guess the other models serve equally well)\\n- Paper scanner with a \\\"scan\\\" button.\\n- an AWS account\\n\\nPersonally I'm using Raspbian Stretch Lite as OS on my Raspberry and a Fujitsu S1300i.\\n\\n# Set up SANE\\n\\n\\n# sane\\n\\ncheck that your scanner is supported [here](http://www.sane-project.org/sane-mfgs.html)\\n\\n```\\nsudo apt install sane-utils -y\\nsane-find-scanner -q # shows scanner\\nusermod -a -G scanner pi # makes it available for pi\\ngrep 1300 /etc/sane.d/*.conf\\nsudo mkdir /usr/share/sane/epjitsu/\\nsudo wget https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -O /usr/share/sane/epjitsu/1300i_0D12.nal\\nscanimage >/tmp/out.pnm\\n```\\n\\n# scanbd\\n\\n```\\nsudo apt install scanbd -y\\nsudo vim /etc/scandb/scandb.conf # set debug-level=7, user=pi\\nsudo scanbd -f\\n```\\n\\n```\\nsudo vim /etc/scandb/scandb.conf # set script_dir=/etc/scanbd/scripts, in action 'scan': desc=\\\"Scan to a file and upload to s3\\\", script=\\\"scan.sh\\\"\\nsudo mkdir /etc/scanbd/scripts/\\nsudo vim /etc/scanbd/scripts/scan.sh\\nsudo chmod a+x /etc/scanbd/scripts/scan.sh\\n```\\n\\nreplug scanner, test with `sudo scanbd -f`\\nclose lid, open lid -> segementation fault\\n\\n```\\nsudo vim /lib/systemd/system/scanbd.service # add Restart=on-failure\\nsudo systemctl daemon-reload\\nsudo service scanbd start\\nsudo update-rc.d scanbd enable\\n```\\n\\n# s3 script\\n\\n```\\nsudo apt install python-pip -y\\nsudo pip install awscli\\naws configure\\naws s3 ls s3://scanner-upload/\\n```\\n\\n```\\n#!/bin/sh\\n\\nset -e\\nexport TMP_DIR=`mktemp -d`\\n\\necho 'scanning..'\\nscanimage --resolution 300 --batch=\\\"$TMP_DIR/scan_%03d.pnm\\\" --format=pnm --mode Gray --source \\\"ADF Duplex\\\"\\n\\necho 'packaging and uploading in subshell'\\n(tarname=scan_$(date \\\"+%Y-%m-%d_%H%M%S\\\").tar.gz\\ncd $TMP_DIR\\ntar -czf $tarname *.pnm\\necho 'uploading..'\\naws s3 cp $TMP_DIR/$tarname s3://scanner-upload/\\nrm -rf $TMP_DIR\\necho 'done') &\\n```\\n\\n\\n\\n# 1. Make sane work with fujitsu 1300i\\n\\nThere are plenty of howtos out there how to get Fujitsu 1300i running with raspberry pi (my favourite one was [this one](https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup)), but for completeness sake here it is again (and the bottom doc bases on this exact setup)\\n\\n## Install driver/sane/...\\n\\n\\n```\\nsudo apt install git-core libusb-dev -y\\ncd /var/tmp/\\ngit clone git://git.debian.org/sane/sane-backends.git\\ncd sane-backends/\\nBACKENDS=epjitsu ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var\\nmake\\nsudo make install\\ncd /usr/share/sane/epjitsu/\\nsudo curl https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -L -O\\n```\\n\\n\\n\\n```\\nsudo vim \\n```\\n\\n\\n## Test with root\\n\\nNow, `sudo sane-find-scanner -q` should show something like:\\n\\n```\\nfound USB scanner (vendor=0x04c6 [FUJITSU], product=0x128d [ScanSnap S1300i]) at libusb:001:011\\nfound USB scanner (vendor=0x0424, product=0xec00) at libusb:001:003\\n```\\n\\nDo a test scan: `sudo scanimage >/tmp/out.pnm`\\n\\nNow you could try to get it to run with user `pi` but after some messing around I gave it up. The setup [mentioned in this doc](https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup#sane_permissions) did not work for me\\n\\n# 2. Detect scanner button pressed\\n\\n## Install scanbd\\n\\nInstall scanbd via `apt`. Be sure to hit `N` when being asked about overwriting `dll.conf` and `epjitsu.conf`:\\n\\n```\\nsudo apt install scanbd\\n```\\n\\nScanbd is a daemon which polls the scanner button and starts a custom scripts when the button is pressed. In the script you'll use the sane setup you just did.\\n\\nFirst, we'll do a quick test just to see that scanbd does its job: Edit `/etc/scanbd/scanbd.conf` ((if the config file is missing, as it was in my case when I initially installed with `apt` you can take [this initial scanbd.conf](https://gist.github.com/philippkeller/f2dafcd8c9e22e691b2a21ca9746303c) as a start) and:\\n\\n- set `debug-level=7`, that's just for the beginning until we're sure that everything works\\n- set `user=root`, as we just made saned run in the root user\\n\\nStart scanbd with `sudo scanbd -f` and you'll the the polling. When you hit the scan button then you'll see that it tries running `/etc/scanbd/scripts/test.script` which doesn't exist yet. So far, so good!\\n\\n<!--\\n\\nUnfortunately the scanbd version which - at the time of this blog post - is in the repo has [an annoying bug which causes scanbd to crash (segfault) when you close/unplug the scanner and replug it again](https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095).\\n\\nIf `apt search scanbd` gives you a version > 1.5.1-1 then you can just install it with `sudo apt install scan scanbuttond` and skip to the next section.\\n\\nTo compile from source, do the following:\\n\\n```\\nsudo apt install libconfuse-dev libdbus-1-dev libsane-dev -y\\ncd /var/tmp/\\nwget https://sourceforge.net/projects/scanbd/files/latest/download?source=files -O scanbd.tar.gz\\ntar -xzvf scanbd.tar.gz\\ncd 1.5.1\\n./configure\\nmake\\nsudo make install\\n```\\n\\n\\n\\n## Configure scanbd\\n\\nContrary to some howtos on the net you don't need to copy files, etc. Scanbd just uses the just sane client to regularly poll the button and then starts a custom script.\\n\\nFirst, you need to check where the scanbd config file is. Do `man scanbd` and check the `-c` option. For older versions (ie.g. installed via apt) this is in `/etc/scanbd/scanbd.conf`, for newer (i.e. compiled from source) this is in `/usr/local/etc/scanbd/scanbd.conf`.\\n\\nNow, adapt your config file like this (if the config file is missing, as it was in my case when I initially installed with `apt` you can take [this initial scanbd.conf](https://gist.github.com/philippkeller/9d6a6ccea6c448bedd67338e8eb98870) as a start):\\n-->\\n\\n\\n## Configure scanbd\\n\\nIn `/etc/scanbd/scanbd.conf`:\\n\\n- set `scriptdir = /etc/scanbd/scripts`\\n- in action `scan` set `desc=\\\"Scan to file and upload to s3\\\"` and `script=scan.sh`\\n\\nThen, after `mkdir /etc/scanbd/scripts` put that into `/etc/scanbd/scripts/scan.sh` just to test (don't forget to `chmod a+x` the file):\\n\\n```\\n#!/bin/sh\\nscanimage > /tmp/foo.pnm\\n```\\n\\nStart scanbd with `sudo scanbd -f` and you should see the polling and your script being called. `cat /var/tmp/foo.txt` should show a bunch of \\\"scan button pressed\\\" lines. Wohoo!\\n\\n## Test via service\\n\\nNow, also test if it works when you start it with `sudo service scanbd start`. If you have any problems then you might need to correct `ExecStart` and `SANE_CONFIG_DIR` with the correct directories and reload it with `sudo systemctl daemon-reload`.\\n\\nTo see the logs, do `tail -f /var/log/syslog`\\n\\nNow, scanbd [has a bug so when you close/open your printer or reconnect the usb it segfaults](https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095). The versions > 1.5.1.1 have fixed this bug. I tried to use those but then it just didn't carry on after replugging so I went back to the version provided by `apt`.\\n\\nTo work around the segfault it is actually easier to\\n\\n- add `Restart=on-failure` to `/lib/systemd/system/scanbd.service`\\n- reload `sudo systemctl daemon-reload`\\n\\nNow you should be able to close the lid of the scanner, see the usb disconnect message in `/var/log/syslog`, then open the lid and the scanner button should still work.\\n\\n# 3. Make the scanner upload to s3\\n\\n## Preparing S3\\n\\n- create an s3 bucket, e.g. `scanner-upload` (be sure to choose a region close to you. Upload speed is a lot faster for closer regions). Note the ARN of the bucket.\\n- in IAM create a policy `scanner-upload`, swith into JSON editor and paste this (replace the arn):\\n\\n```\\n{\\n  \\\"Version\\\": \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\\"s3:ListBucket\\\"],\\n      \\\"Resource\\\": [\\\"arn:aws:s3:::scanner-upload\\\"]\\n    },\\n    {\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\n        \\\"s3:PutObject\\\",\\n        \\\"s3:GetObject\\\",\\n        \\\"s3:DeleteObject\\\"\\n      ],\\n      \\\"Resource\\\": [\\\"arn:aws:s3:::scanner-upload/*\\\"]\\n    }\\n  ]\\n}\\n```\\n\\n- in IAM create a user and attach the `scanner-upload` policy. Note the key/secret or download the csv\\n- install `aws cli` on raspberry pi: `sudo pip install awscli --upgrade --user` (be sure to use `sudo`, otherwise it'll be installed into `~/.local/bin/` which might not be in your `$PATH`)\\n- start `aws configure` to put the key/secret and aws region into your config\\n- test that s3 access works with `aws s3 ls s3://scanner-upload/` and uploading a file using `aws s3 cp some_file.txt s3://scanner-upload/`\\n\\n## Put `scan.sh` into place\\n\\nPut this into `/etc/scanbd/scan.sh` (replace `scanner-upload` with your bucket name):\\n\\n```\\n#!/bin/sh\\n\\nset -e\\nTMP_DIR=`mktemp -d`\\n\\necho 'scanning..'\\nscanimage --resolution 300 --batch=\\\"$TMP_DIR/scan_%03d.pnm\\\" --format=pnm --mode Gray --source \\\"ADF Duplex\\\"\\n\\necho 'packaging..'\\ntarname=scan_$(date \\\"+%Y-%m-%d_%H%M%S\\\").tar.gz\\ncd $TMP_DIR\\ntar -czf $tarname *.pnm\\n\\necho 'uploading..'\\naws s3 cp $TMP_DIR/$tarname s3://scanner-upload/\\nrm -rf $TMP_DIR\\n```\\n\\nYou might want to play around with the `scanimage` command. In the above script it\\n\\n- scans in batch mode: creates multiple files until the feeder is empty\\n- does a duplex scan (there's no detection. It means that if it's a one sided paper the second page is just empty)\\n- `resolution 300`: this is the default. It is a pretty fast scan and the quality is good enough\\n\\nTry to call the script manually and then start `scanbd -f`. Now pressing the button will scan and upload to s3, whohoo!\\n\\n## Start scanbd at boot time, and secure it\\n\\nMake `scanbd` start at boot time: `sudo update-rc.d scanbd enable`.\\n\\nSecure it: tbd (what happens when you close the lid..?)\\n\\n## Cleaning up\\n\\nIf everything has worked this far you can decrease the logging level in scanbd.conf:\\n\\n- set `debug-level=3` as level 7 is much too verbose\\n- set `debug=false`\\n\\nremove the temp dirs:\\n\\n- `rm -rf /var/tmp/sane-backends`\\n- `rm -rf /var/tmp/1.5.1`\",\"slug\":\"Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF\",\"published\":1,\"updated\":\"2018-01-22T20:55:56.210Z\",\"_id\":\"cjcqon60i000ki85penzq8u2r\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"content\":\"<p><img src=\\\"/images/scan_flow.png\\\" alt=\\\"scan flow scanner to raspberry to s3 to lambda to s3\\\"></p>\\n<p>I have long dreamed for a setup which lets me just press the scan button on my scanner and without any further input it uploads it as a searchable PDF onto some cloud store. Thanks to the good support of scanners by SANE and the ease of use of AWS lambda it’s actually <em>quite</em> easy (judging to the length of this post it looks like quite a task, but in the end it is straightforwards and is - surprisingly - quite free of hacks).</p>\\n<p>In this solution you:</p>\\n<ul>\\n<li>set up SANE on your raspberry pi 3 so it scans your document</li>\\n<li>set up scanbd to detect the scan button</li>\\n<li>set up a S3 bucket for uploading</li>\\n<li>set up a lambda function which uses tesseract to create a searchable PDF</li>\\n</ul>\\n<p>What you need:</p>\\n<ul>\\n<li>Raspberry Pi 3 (I guess the other models serve equally well)</li>\\n<li>Paper scanner with a “scan” button.</li>\\n<li>an AWS account</li>\\n</ul>\\n<p>Personally I’m using Raspbian Stretch Lite as OS on my Raspberry and a Fujitsu S1300i.</p>\\n<h1 id=\\\"Set-up-SANE\\\"><a href=\\\"#Set-up-SANE\\\" class=\\\"headerlink\\\" title=\\\"Set up SANE\\\"></a>Set up SANE</h1><h1 id=\\\"sane\\\"><a href=\\\"#sane\\\" class=\\\"headerlink\\\" title=\\\"sane\\\"></a>sane</h1><p>check that your scanner is supported <a href=\\\"http://www.sane-project.org/sane-mfgs.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a></p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install sane-utils -y</span><br><span class=\\\"line\\\">sane-find-scanner -q # shows scanner</span><br><span class=\\\"line\\\">usermod -a -G scanner pi # makes it available for pi</span><br><span class=\\\"line\\\">grep 1300 /etc/sane.d/*.conf</span><br><span class=\\\"line\\\">sudo mkdir /usr/share/sane/epjitsu/</span><br><span class=\\\"line\\\">sudo wget https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -O /usr/share/sane/epjitsu/1300i_0D12.nal</span><br><span class=\\\"line\\\">scanimage &gt;/tmp/out.pnm</span><br></pre></td></tr></table></figure>\\n<h1 id=\\\"scanbd\\\"><a href=\\\"#scanbd\\\" class=\\\"headerlink\\\" title=\\\"scanbd\\\"></a>scanbd</h1><figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install scanbd -y</span><br><span class=\\\"line\\\">sudo vim /etc/scandb/scandb.conf # set debug-level=7, user=pi</span><br><span class=\\\"line\\\">sudo scanbd -f</span><br></pre></td></tr></table></figure>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo vim /etc/scandb/scandb.conf # set script_dir=/etc/scanbd/scripts, in action &apos;scan&apos;: desc=&quot;Scan to a file and upload to s3&quot;, script=&quot;scan.sh&quot;</span><br><span class=\\\"line\\\">sudo mkdir /etc/scanbd/scripts/</span><br><span class=\\\"line\\\">sudo vim /etc/scanbd/scripts/scan.sh</span><br><span class=\\\"line\\\">sudo chmod a+x /etc/scanbd/scripts/scan.sh</span><br></pre></td></tr></table></figure>\\n<p>replug scanner, test with <code>sudo scanbd -f</code><br>close lid, open lid -&gt; segementation fault</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo vim /lib/systemd/system/scanbd.service # add Restart=on-failure</span><br><span class=\\\"line\\\">sudo systemctl daemon-reload</span><br><span class=\\\"line\\\">sudo service scanbd start</span><br><span class=\\\"line\\\">sudo update-rc.d scanbd enable</span><br></pre></td></tr></table></figure>\\n<h1 id=\\\"s3-script\\\"><a href=\\\"#s3-script\\\" class=\\\"headerlink\\\" title=\\\"s3 script\\\"></a>s3 script</h1><figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install python-pip -y</span><br><span class=\\\"line\\\">sudo pip install awscli</span><br><span class=\\\"line\\\">aws configure</span><br><span class=\\\"line\\\">aws s3 ls s3://scanner-upload/</span><br></pre></td></tr></table></figure>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/sh</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">set -e</span><br><span class=\\\"line\\\">export TMP_DIR=`mktemp -d`</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;scanning..&apos;</span><br><span class=\\\"line\\\">scanimage --resolution 300 --batch=&quot;$TMP_DIR/scan_%03d.pnm&quot; --format=pnm --mode Gray --source &quot;ADF Duplex&quot;</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;packaging and uploading in subshell&apos;</span><br><span class=\\\"line\\\">(tarname=scan_$(date &quot;+%Y-%m-%d_%H%M%S&quot;).tar.gz</span><br><span class=\\\"line\\\">cd $TMP_DIR</span><br><span class=\\\"line\\\">tar -czf $tarname *.pnm</span><br><span class=\\\"line\\\">echo &apos;uploading..&apos;</span><br><span class=\\\"line\\\">aws s3 cp $TMP_DIR/$tarname s3://scanner-upload/</span><br><span class=\\\"line\\\">rm -rf $TMP_DIR</span><br><span class=\\\"line\\\">echo &apos;done&apos;) &amp;</span><br></pre></td></tr></table></figure>\\n<h1 id=\\\"1-Make-sane-work-with-fujitsu-1300i\\\"><a href=\\\"#1-Make-sane-work-with-fujitsu-1300i\\\" class=\\\"headerlink\\\" title=\\\"1. Make sane work with fujitsu 1300i\\\"></a>1. Make sane work with fujitsu 1300i</h1><p>There are plenty of howtos out there how to get Fujitsu 1300i running with raspberry pi (my favourite one was <a href=\\\"https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this one</a>), but for completeness sake here it is again (and the bottom doc bases on this exact setup)</p>\\n<h2 id=\\\"Install-driver-sane-…\\\"><a href=\\\"#Install-driver-sane-…\\\" class=\\\"headerlink\\\" title=\\\"Install driver/sane/…\\\"></a>Install driver/sane/…</h2><figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install git-core libusb-dev -y</span><br><span class=\\\"line\\\">cd /var/tmp/</span><br><span class=\\\"line\\\">git clone git://git.debian.org/sane/sane-backends.git</span><br><span class=\\\"line\\\">cd sane-backends/</span><br><span class=\\\"line\\\">BACKENDS=epjitsu ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var</span><br><span class=\\\"line\\\">make</span><br><span class=\\\"line\\\">sudo make install</span><br><span class=\\\"line\\\">cd /usr/share/sane/epjitsu/</span><br><span class=\\\"line\\\">sudo curl https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -L -O</span><br></pre></td></tr></table></figure>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo vim</span><br></pre></td></tr></table></figure>\\n<h2 id=\\\"Test-with-root\\\"><a href=\\\"#Test-with-root\\\" class=\\\"headerlink\\\" title=\\\"Test with root\\\"></a>Test with root</h2><p>Now, <code>sudo sane-find-scanner -q</code> should show something like:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">found USB scanner (vendor=0x04c6 [FUJITSU], product=0x128d [ScanSnap S1300i]) at libusb:001:011</span><br><span class=\\\"line\\\">found USB scanner (vendor=0x0424, product=0xec00) at libusb:001:003</span><br></pre></td></tr></table></figure>\\n<p>Do a test scan: <code>sudo scanimage &gt;/tmp/out.pnm</code></p>\\n<p>Now you could try to get it to run with user <code>pi</code> but after some messing around I gave it up. The setup <a href=\\\"https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup#sane_permissions\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mentioned in this doc</a> did not work for me</p>\\n<h1 id=\\\"2-Detect-scanner-button-pressed\\\"><a href=\\\"#2-Detect-scanner-button-pressed\\\" class=\\\"headerlink\\\" title=\\\"2. Detect scanner button pressed\\\"></a>2. Detect scanner button pressed</h1><h2 id=\\\"Install-scanbd\\\"><a href=\\\"#Install-scanbd\\\" class=\\\"headerlink\\\" title=\\\"Install scanbd\\\"></a>Install scanbd</h2><p>Install scanbd via <code>apt</code>. Be sure to hit <code>N</code> when being asked about overwriting <code>dll.conf</code> and <code>epjitsu.conf</code>:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install scanbd</span><br></pre></td></tr></table></figure>\\n<p>Scanbd is a daemon which polls the scanner button and starts a custom scripts when the button is pressed. In the script you’ll use the sane setup you just did.</p>\\n<p>First, we’ll do a quick test just to see that scanbd does its job: Edit <code>/etc/scanbd/scanbd.conf</code> ((if the config file is missing, as it was in my case when I initially installed with <code>apt</code> you can take <a href=\\\"https://gist.github.com/philippkeller/f2dafcd8c9e22e691b2a21ca9746303c\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this initial scanbd.conf</a> as a start) and:</p>\\n<ul>\\n<li>set <code>debug-level=7</code>, that’s just for the beginning until we’re sure that everything works</li>\\n<li>set <code>user=root</code>, as we just made saned run in the root user</li>\\n</ul>\\n<p>Start scanbd with <code>sudo scanbd -f</code> and you’ll the the polling. When you hit the scan button then you’ll see that it tries running <code>/etc/scanbd/scripts/test.script</code> which doesn’t exist yet. So far, so good!</p>\\n<!--\\n\\nUnfortunately the scanbd version which - at the time of this blog post - is in the repo has [an annoying bug which causes scanbd to crash (segfault) when you close/unplug the scanner and replug it again](https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095).\\n\\nIf `apt search scanbd` gives you a version > 1.5.1-1 then you can just install it with `sudo apt install scan scanbuttond` and skip to the next section.\\n\\nTo compile from source, do the following:\\n\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install libconfuse-dev libdbus-1-dev libsane-dev -y</span><br><span class=\\\"line\\\">cd /var/tmp/</span><br><span class=\\\"line\\\">wget https://sourceforge.net/projects/scanbd/files/latest/download?source=files -O scanbd.tar.gz</span><br><span class=\\\"line\\\">tar -xzvf scanbd.tar.gz</span><br><span class=\\\"line\\\">cd 1.5.1</span><br><span class=\\\"line\\\">./configure</span><br><span class=\\\"line\\\">make</span><br><span class=\\\"line\\\">sudo make install</span><br></pre></td></tr></table></figure>\\n<h2 id=\\\"Configure-scanbd\\\"><a href=\\\"#Configure-scanbd\\\" class=\\\"headerlink\\\" title=\\\"Configure scanbd\\\"></a>Configure scanbd</h2><p>Contrary to some howtos on the net you don’t need to copy files, etc. Scanbd just uses the just sane client to regularly poll the button and then starts a custom script.</p>\\n<p>First, you need to check where the scanbd config file is. Do <code>man scanbd</code> and check the <code>-c</code> option. For older versions (ie.g. installed via apt) this is in <code>/etc/scanbd/scanbd.conf</code>, for newer (i.e. compiled from source) this is in <code>/usr/local/etc/scanbd/scanbd.conf</code>.</p>\\n<p>Now, adapt your config file like this (if the config file is missing, as it was in my case when I initially installed with <code>apt</code> you can take <a href=\\\"https://gist.github.com/philippkeller/9d6a6ccea6c448bedd67338e8eb98870\\\">this initial scanbd.conf</a> as a start):<br>–&gt;</p>\\n<h2 id=\\\"Configure-scanbd-1\\\"><a href=\\\"#Configure-scanbd-1\\\" class=\\\"headerlink\\\" title=\\\"Configure scanbd\\\"></a>Configure scanbd</h2><p>In <code>/etc/scanbd/scanbd.conf</code>:</p>\\n<ul>\\n<li>set <code>scriptdir = /etc/scanbd/scripts</code></li>\\n<li>in action <code>scan</code> set <code>desc=&quot;Scan to file and upload to s3&quot;</code> and <code>script=scan.sh</code></li>\\n</ul>\\n<p>Then, after <code>mkdir /etc/scanbd/scripts</code> put that into <code>/etc/scanbd/scripts/scan.sh</code> just to test (don’t forget to <code>chmod a+x</code> the file):</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/sh</span><br><span class=\\\"line\\\">scanimage &gt; /tmp/foo.pnm</span><br></pre></td></tr></table></figure>\\n<p>Start scanbd with <code>sudo scanbd -f</code> and you should see the polling and your script being called. <code>cat /var/tmp/foo.txt</code> should show a bunch of “scan button pressed” lines. Wohoo!</p>\\n<h2 id=\\\"Test-via-service\\\"><a href=\\\"#Test-via-service\\\" class=\\\"headerlink\\\" title=\\\"Test via service\\\"></a>Test via service</h2><p>Now, also test if it works when you start it with <code>sudo service scanbd start</code>. If you have any problems then you might need to correct <code>ExecStart</code> and <code>SANE_CONFIG_DIR</code> with the correct directories and reload it with <code>sudo systemctl daemon-reload</code>.</p>\\n<p>To see the logs, do <code>tail -f /var/log/syslog</code></p>\\n<p>Now, scanbd <a href=\\\"https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095\\\">has a bug so when you close/open your printer or reconnect the usb it segfaults</a>. The versions &gt; 1.5.1.1 have fixed this bug. I tried to use those but then it just didn’t carry on after replugging so I went back to the version provided by <code>apt</code>.</p>\\n<p>To work around the segfault it is actually easier to</p>\\n<ul>\\n<li>add <code>Restart=on-failure</code> to <code>/lib/systemd/system/scanbd.service</code></li>\\n<li>reload <code>sudo systemctl daemon-reload</code></li>\\n</ul>\\n<p>Now you should be able to close the lid of the scanner, see the usb disconnect message in <code>/var/log/syslog</code>, then open the lid and the scanner button should still work.</p>\\n<h1 id=\\\"3-Make-the-scanner-upload-to-s3\\\"><a href=\\\"#3-Make-the-scanner-upload-to-s3\\\" class=\\\"headerlink\\\" title=\\\"3. Make the scanner upload to s3\\\"></a>3. Make the scanner upload to s3</h1><h2 id=\\\"Preparing-S3\\\"><a href=\\\"#Preparing-S3\\\" class=\\\"headerlink\\\" title=\\\"Preparing S3\\\"></a>Preparing S3</h2><ul>\\n<li>create an s3 bucket, e.g. <code>scanner-upload</code> (be sure to choose a region close to you. Upload speed is a lot faster for closer regions). Note the ARN of the bucket.</li>\\n<li>in IAM create a policy <code>scanner-upload</code>, swith into JSON editor and paste this (replace the arn):</li>\\n</ul>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br><span class=\\\"line\\\">17</span><br><span class=\\\"line\\\">18</span><br><span class=\\\"line\\\">19</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">&#123;</span><br><span class=\\\"line\\\">  &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class=\\\"line\\\">  &quot;Statement&quot;: [</span><br><span class=\\\"line\\\">    &#123;</span><br><span class=\\\"line\\\">      &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class=\\\"line\\\">      &quot;Action&quot;: [&quot;s3:ListBucket&quot;],</span><br><span class=\\\"line\\\">      &quot;Resource&quot;: [&quot;arn:aws:s3:::scanner-upload&quot;]</span><br><span class=\\\"line\\\">    &#125;,</span><br><span class=\\\"line\\\">    &#123;</span><br><span class=\\\"line\\\">      &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class=\\\"line\\\">      &quot;Action&quot;: [</span><br><span class=\\\"line\\\">        &quot;s3:PutObject&quot;,</span><br><span class=\\\"line\\\">        &quot;s3:GetObject&quot;,</span><br><span class=\\\"line\\\">        &quot;s3:DeleteObject&quot;</span><br><span class=\\\"line\\\">      ],</span><br><span class=\\\"line\\\">      &quot;Resource&quot;: [&quot;arn:aws:s3:::scanner-upload/*&quot;]</span><br><span class=\\\"line\\\">    &#125;</span><br><span class=\\\"line\\\">  ]</span><br><span class=\\\"line\\\">&#125;</span><br></pre></td></tr></table></figure>\\n<ul>\\n<li>in IAM create a user and attach the <code>scanner-upload</code> policy. Note the key/secret or download the csv</li>\\n<li>install <code>aws cli</code> on raspberry pi: <code>sudo pip install awscli --upgrade --user</code> (be sure to use <code>sudo</code>, otherwise it’ll be installed into <code>~/.local/bin/</code> which might not be in your <code>$PATH</code>)</li>\\n<li>start <code>aws configure</code> to put the key/secret and aws region into your config</li>\\n<li>test that s3 access works with <code>aws s3 ls s3://scanner-upload/</code> and uploading a file using <code>aws s3 cp some_file.txt s3://scanner-upload/</code></li>\\n</ul>\\n<h2 id=\\\"Put-scan-sh-into-place\\\"><a href=\\\"#Put-scan-sh-into-place\\\" class=\\\"headerlink\\\" title=\\\"Put scan.sh into place\\\"></a>Put <code>scan.sh</code> into place</h2><p>Put this into <code>/etc/scanbd/scan.sh</code> (replace <code>scanner-upload</code> with your bucket name):</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/sh</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">set -e</span><br><span class=\\\"line\\\">TMP_DIR=`mktemp -d`</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;scanning..&apos;</span><br><span class=\\\"line\\\">scanimage --resolution 300 --batch=&quot;$TMP_DIR/scan_%03d.pnm&quot; --format=pnm --mode Gray --source &quot;ADF Duplex&quot;</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;packaging..&apos;</span><br><span class=\\\"line\\\">tarname=scan_$(date &quot;+%Y-%m-%d_%H%M%S&quot;).tar.gz</span><br><span class=\\\"line\\\">cd $TMP_DIR</span><br><span class=\\\"line\\\">tar -czf $tarname *.pnm</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;uploading..&apos;</span><br><span class=\\\"line\\\">aws s3 cp $TMP_DIR/$tarname s3://scanner-upload/</span><br><span class=\\\"line\\\">rm -rf $TMP_DIR</span><br></pre></td></tr></table></figure>\\n<p>You might want to play around with the <code>scanimage</code> command. In the above script it</p>\\n<ul>\\n<li>scans in batch mode: creates multiple files until the feeder is empty</li>\\n<li>does a duplex scan (there’s no detection. It means that if it’s a one sided paper the second page is just empty)</li>\\n<li><code>resolution 300</code>: this is the default. It is a pretty fast scan and the quality is good enough</li>\\n</ul>\\n<p>Try to call the script manually and then start <code>scanbd -f</code>. Now pressing the button will scan and upload to s3, whohoo!</p>\\n<h2 id=\\\"Start-scanbd-at-boot-time-and-secure-it\\\"><a href=\\\"#Start-scanbd-at-boot-time-and-secure-it\\\" class=\\\"headerlink\\\" title=\\\"Start scanbd at boot time, and secure it\\\"></a>Start scanbd at boot time, and secure it</h2><p>Make <code>scanbd</code> start at boot time: <code>sudo update-rc.d scanbd enable</code>.</p>\\n<p>Secure it: tbd (what happens when you close the lid..?)</p>\\n<h2 id=\\\"Cleaning-up\\\"><a href=\\\"#Cleaning-up\\\" class=\\\"headerlink\\\" title=\\\"Cleaning up\\\"></a>Cleaning up</h2><p>If everything has worked this far you can decrease the logging level in scanbd.conf:</p>\\n<ul>\\n<li>set <code>debug-level=3</code> as level 7 is much too verbose</li>\\n<li>set <code>debug=false</code></li>\\n</ul>\\n<p>remove the temp dirs:</p>\\n<ul>\\n<li><code>rm -rf /var/tmp/sane-backends</code></li>\\n<li><code>rm -rf /var/tmp/1.5.1</code></li>\\n</ul>\\n-->\",\"site\":{\"data\":{}},\"excerpt\":\"\",\"more\":\"<p><img src=\\\"/images/scan_flow.png\\\" alt=\\\"scan flow scanner to raspberry to s3 to lambda to s3\\\"></p>\\n<p>I have long dreamed for a setup which lets me just press the scan button on my scanner and without any further input it uploads it as a searchable PDF onto some cloud store. Thanks to the good support of scanners by SANE and the ease of use of AWS lambda it’s actually <em>quite</em> easy (judging to the length of this post it looks like quite a task, but in the end it is straightforwards and is - surprisingly - quite free of hacks).</p>\\n<p>In this solution you:</p>\\n<ul>\\n<li>set up SANE on your raspberry pi 3 so it scans your document</li>\\n<li>set up scanbd to detect the scan button</li>\\n<li>set up a S3 bucket for uploading</li>\\n<li>set up a lambda function which uses tesseract to create a searchable PDF</li>\\n</ul>\\n<p>What you need:</p>\\n<ul>\\n<li>Raspberry Pi 3 (I guess the other models serve equally well)</li>\\n<li>Paper scanner with a “scan” button.</li>\\n<li>an AWS account</li>\\n</ul>\\n<p>Personally I’m using Raspbian Stretch Lite as OS on my Raspberry and a Fujitsu S1300i.</p>\\n<h1 id=\\\"Set-up-SANE\\\"><a href=\\\"#Set-up-SANE\\\" class=\\\"headerlink\\\" title=\\\"Set up SANE\\\"></a>Set up SANE</h1><h1 id=\\\"sane\\\"><a href=\\\"#sane\\\" class=\\\"headerlink\\\" title=\\\"sane\\\"></a>sane</h1><p>check that your scanner is supported <a href=\\\"http://www.sane-project.org/sane-mfgs.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a></p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install sane-utils -y</span><br><span class=\\\"line\\\">sane-find-scanner -q # shows scanner</span><br><span class=\\\"line\\\">usermod -a -G scanner pi # makes it available for pi</span><br><span class=\\\"line\\\">grep 1300 /etc/sane.d/*.conf</span><br><span class=\\\"line\\\">sudo mkdir /usr/share/sane/epjitsu/</span><br><span class=\\\"line\\\">sudo wget https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -O /usr/share/sane/epjitsu/1300i_0D12.nal</span><br><span class=\\\"line\\\">scanimage &gt;/tmp/out.pnm</span><br></pre></td></tr></table></figure>\\n<h1 id=\\\"scanbd\\\"><a href=\\\"#scanbd\\\" class=\\\"headerlink\\\" title=\\\"scanbd\\\"></a>scanbd</h1><figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install scanbd -y</span><br><span class=\\\"line\\\">sudo vim /etc/scandb/scandb.conf # set debug-level=7, user=pi</span><br><span class=\\\"line\\\">sudo scanbd -f</span><br></pre></td></tr></table></figure>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo vim /etc/scandb/scandb.conf # set script_dir=/etc/scanbd/scripts, in action &apos;scan&apos;: desc=&quot;Scan to a file and upload to s3&quot;, script=&quot;scan.sh&quot;</span><br><span class=\\\"line\\\">sudo mkdir /etc/scanbd/scripts/</span><br><span class=\\\"line\\\">sudo vim /etc/scanbd/scripts/scan.sh</span><br><span class=\\\"line\\\">sudo chmod a+x /etc/scanbd/scripts/scan.sh</span><br></pre></td></tr></table></figure>\\n<p>replug scanner, test with <code>sudo scanbd -f</code><br>close lid, open lid -&gt; segementation fault</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo vim /lib/systemd/system/scanbd.service # add Restart=on-failure</span><br><span class=\\\"line\\\">sudo systemctl daemon-reload</span><br><span class=\\\"line\\\">sudo service scanbd start</span><br><span class=\\\"line\\\">sudo update-rc.d scanbd enable</span><br></pre></td></tr></table></figure>\\n<h1 id=\\\"s3-script\\\"><a href=\\\"#s3-script\\\" class=\\\"headerlink\\\" title=\\\"s3 script\\\"></a>s3 script</h1><figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install python-pip -y</span><br><span class=\\\"line\\\">sudo pip install awscli</span><br><span class=\\\"line\\\">aws configure</span><br><span class=\\\"line\\\">aws s3 ls s3://scanner-upload/</span><br></pre></td></tr></table></figure>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/sh</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">set -e</span><br><span class=\\\"line\\\">export TMP_DIR=`mktemp -d`</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;scanning..&apos;</span><br><span class=\\\"line\\\">scanimage --resolution 300 --batch=&quot;$TMP_DIR/scan_%03d.pnm&quot; --format=pnm --mode Gray --source &quot;ADF Duplex&quot;</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;packaging and uploading in subshell&apos;</span><br><span class=\\\"line\\\">(tarname=scan_$(date &quot;+%Y-%m-%d_%H%M%S&quot;).tar.gz</span><br><span class=\\\"line\\\">cd $TMP_DIR</span><br><span class=\\\"line\\\">tar -czf $tarname *.pnm</span><br><span class=\\\"line\\\">echo &apos;uploading..&apos;</span><br><span class=\\\"line\\\">aws s3 cp $TMP_DIR/$tarname s3://scanner-upload/</span><br><span class=\\\"line\\\">rm -rf $TMP_DIR</span><br><span class=\\\"line\\\">echo &apos;done&apos;) &amp;</span><br></pre></td></tr></table></figure>\\n<h1 id=\\\"1-Make-sane-work-with-fujitsu-1300i\\\"><a href=\\\"#1-Make-sane-work-with-fujitsu-1300i\\\" class=\\\"headerlink\\\" title=\\\"1. Make sane work with fujitsu 1300i\\\"></a>1. Make sane work with fujitsu 1300i</h1><p>There are plenty of howtos out there how to get Fujitsu 1300i running with raspberry pi (my favourite one was <a href=\\\"https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this one</a>), but for completeness sake here it is again (and the bottom doc bases on this exact setup)</p>\\n<h2 id=\\\"Install-driver-sane-…\\\"><a href=\\\"#Install-driver-sane-…\\\" class=\\\"headerlink\\\" title=\\\"Install driver/sane/…\\\"></a>Install driver/sane/…</h2><figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install git-core libusb-dev -y</span><br><span class=\\\"line\\\">cd /var/tmp/</span><br><span class=\\\"line\\\">git clone git://git.debian.org/sane/sane-backends.git</span><br><span class=\\\"line\\\">cd sane-backends/</span><br><span class=\\\"line\\\">BACKENDS=epjitsu ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var</span><br><span class=\\\"line\\\">make</span><br><span class=\\\"line\\\">sudo make install</span><br><span class=\\\"line\\\">cd /usr/share/sane/epjitsu/</span><br><span class=\\\"line\\\">sudo curl https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -L -O</span><br></pre></td></tr></table></figure>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo vim</span><br></pre></td></tr></table></figure>\\n<h2 id=\\\"Test-with-root\\\"><a href=\\\"#Test-with-root\\\" class=\\\"headerlink\\\" title=\\\"Test with root\\\"></a>Test with root</h2><p>Now, <code>sudo sane-find-scanner -q</code> should show something like:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">found USB scanner (vendor=0x04c6 [FUJITSU], product=0x128d [ScanSnap S1300i]) at libusb:001:011</span><br><span class=\\\"line\\\">found USB scanner (vendor=0x0424, product=0xec00) at libusb:001:003</span><br></pre></td></tr></table></figure>\\n<p>Do a test scan: <code>sudo scanimage &gt;/tmp/out.pnm</code></p>\\n<p>Now you could try to get it to run with user <code>pi</code> but after some messing around I gave it up. The setup <a href=\\\"https://www.splitbrain.org/blog/2014-08/23-paper_backup_1_scanner_setup#sane_permissions\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mentioned in this doc</a> did not work for me</p>\\n<h1 id=\\\"2-Detect-scanner-button-pressed\\\"><a href=\\\"#2-Detect-scanner-button-pressed\\\" class=\\\"headerlink\\\" title=\\\"2. Detect scanner button pressed\\\"></a>2. Detect scanner button pressed</h1><h2 id=\\\"Install-scanbd\\\"><a href=\\\"#Install-scanbd\\\" class=\\\"headerlink\\\" title=\\\"Install scanbd\\\"></a>Install scanbd</h2><p>Install scanbd via <code>apt</code>. Be sure to hit <code>N</code> when being asked about overwriting <code>dll.conf</code> and <code>epjitsu.conf</code>:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install scanbd</span><br></pre></td></tr></table></figure>\\n<p>Scanbd is a daemon which polls the scanner button and starts a custom scripts when the button is pressed. In the script you’ll use the sane setup you just did.</p>\\n<p>First, we’ll do a quick test just to see that scanbd does its job: Edit <code>/etc/scanbd/scanbd.conf</code> ((if the config file is missing, as it was in my case when I initially installed with <code>apt</code> you can take <a href=\\\"https://gist.github.com/philippkeller/f2dafcd8c9e22e691b2a21ca9746303c\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this initial scanbd.conf</a> as a start) and:</p>\\n<ul>\\n<li>set <code>debug-level=7</code>, that’s just for the beginning until we’re sure that everything works</li>\\n<li>set <code>user=root</code>, as we just made saned run in the root user</li>\\n</ul>\\n<p>Start scanbd with <code>sudo scanbd -f</code> and you’ll the the polling. When you hit the scan button then you’ll see that it tries running <code>/etc/scanbd/scripts/test.script</code> which doesn’t exist yet. So far, so good!</p>\\n<!--\\n\\nUnfortunately the scanbd version which - at the time of this blog post - is in the repo has [an annoying bug which causes scanbd to crash (segfault) when you close/unplug the scanner and replug it again](https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095).\\n\\nIf `apt search scanbd` gives you a version > 1.5.1-1 then you can just install it with `sudo apt install scan scanbuttond` and skip to the next section.\\n\\nTo compile from source, do the following:\\n\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt install libconfuse-dev libdbus-1-dev libsane-dev -y</span><br><span class=\\\"line\\\">cd /var/tmp/</span><br><span class=\\\"line\\\">wget https://sourceforge.net/projects/scanbd/files/latest/download?source=files -O scanbd.tar.gz</span><br><span class=\\\"line\\\">tar -xzvf scanbd.tar.gz</span><br><span class=\\\"line\\\">cd 1.5.1</span><br><span class=\\\"line\\\">./configure</span><br><span class=\\\"line\\\">make</span><br><span class=\\\"line\\\">sudo make install</span><br></pre></td></tr></table></figure>\\n<h2 id=\\\"Configure-scanbd\\\"><a href=\\\"#Configure-scanbd\\\" class=\\\"headerlink\\\" title=\\\"Configure scanbd\\\"></a>Configure scanbd</h2><p>Contrary to some howtos on the net you don’t need to copy files, etc. Scanbd just uses the just sane client to regularly poll the button and then starts a custom script.</p>\\n<p>First, you need to check where the scanbd config file is. Do <code>man scanbd</code> and check the <code>-c</code> option. For older versions (ie.g. installed via apt) this is in <code>/etc/scanbd/scanbd.conf</code>, for newer (i.e. compiled from source) this is in <code>/usr/local/etc/scanbd/scanbd.conf</code>.</p>\\n<p>Now, adapt your config file like this (if the config file is missing, as it was in my case when I initially installed with <code>apt</code> you can take <a href=\\\"https://gist.github.com/philippkeller/9d6a6ccea6c448bedd67338e8eb98870\\\">this initial scanbd.conf</a> as a start):<br>–&gt;</p>\\n<h2 id=\\\"Configure-scanbd-1\\\"><a href=\\\"#Configure-scanbd-1\\\" class=\\\"headerlink\\\" title=\\\"Configure scanbd\\\"></a>Configure scanbd</h2><p>In <code>/etc/scanbd/scanbd.conf</code>:</p>\\n<ul>\\n<li>set <code>scriptdir = /etc/scanbd/scripts</code></li>\\n<li>in action <code>scan</code> set <code>desc=&quot;Scan to file and upload to s3&quot;</code> and <code>script=scan.sh</code></li>\\n</ul>\\n<p>Then, after <code>mkdir /etc/scanbd/scripts</code> put that into <code>/etc/scanbd/scripts/scan.sh</code> just to test (don’t forget to <code>chmod a+x</code> the file):</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/sh</span><br><span class=\\\"line\\\">scanimage &gt; /tmp/foo.pnm</span><br></pre></td></tr></table></figure>\\n<p>Start scanbd with <code>sudo scanbd -f</code> and you should see the polling and your script being called. <code>cat /var/tmp/foo.txt</code> should show a bunch of “scan button pressed” lines. Wohoo!</p>\\n<h2 id=\\\"Test-via-service\\\"><a href=\\\"#Test-via-service\\\" class=\\\"headerlink\\\" title=\\\"Test via service\\\"></a>Test via service</h2><p>Now, also test if it works when you start it with <code>sudo service scanbd start</code>. If you have any problems then you might need to correct <code>ExecStart</code> and <code>SANE_CONFIG_DIR</code> with the correct directories and reload it with <code>sudo systemctl daemon-reload</code>.</p>\\n<p>To see the logs, do <code>tail -f /var/log/syslog</code></p>\\n<p>Now, scanbd <a href=\\\"https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095\\\">has a bug so when you close/open your printer or reconnect the usb it segfaults</a>. The versions &gt; 1.5.1.1 have fixed this bug. I tried to use those but then it just didn’t carry on after replugging so I went back to the version provided by <code>apt</code>.</p>\\n<p>To work around the segfault it is actually easier to</p>\\n<ul>\\n<li>add <code>Restart=on-failure</code> to <code>/lib/systemd/system/scanbd.service</code></li>\\n<li>reload <code>sudo systemctl daemon-reload</code></li>\\n</ul>\\n<p>Now you should be able to close the lid of the scanner, see the usb disconnect message in <code>/var/log/syslog</code>, then open the lid and the scanner button should still work.</p>\\n<h1 id=\\\"3-Make-the-scanner-upload-to-s3\\\"><a href=\\\"#3-Make-the-scanner-upload-to-s3\\\" class=\\\"headerlink\\\" title=\\\"3. Make the scanner upload to s3\\\"></a>3. Make the scanner upload to s3</h1><h2 id=\\\"Preparing-S3\\\"><a href=\\\"#Preparing-S3\\\" class=\\\"headerlink\\\" title=\\\"Preparing S3\\\"></a>Preparing S3</h2><ul>\\n<li>create an s3 bucket, e.g. <code>scanner-upload</code> (be sure to choose a region close to you. Upload speed is a lot faster for closer regions). Note the ARN of the bucket.</li>\\n<li>in IAM create a policy <code>scanner-upload</code>, swith into JSON editor and paste this (replace the arn):</li>\\n</ul>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br><span class=\\\"line\\\">17</span><br><span class=\\\"line\\\">18</span><br><span class=\\\"line\\\">19</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">&#123;</span><br><span class=\\\"line\\\">  &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class=\\\"line\\\">  &quot;Statement&quot;: [</span><br><span class=\\\"line\\\">    &#123;</span><br><span class=\\\"line\\\">      &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class=\\\"line\\\">      &quot;Action&quot;: [&quot;s3:ListBucket&quot;],</span><br><span class=\\\"line\\\">      &quot;Resource&quot;: [&quot;arn:aws:s3:::scanner-upload&quot;]</span><br><span class=\\\"line\\\">    &#125;,</span><br><span class=\\\"line\\\">    &#123;</span><br><span class=\\\"line\\\">      &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class=\\\"line\\\">      &quot;Action&quot;: [</span><br><span class=\\\"line\\\">        &quot;s3:PutObject&quot;,</span><br><span class=\\\"line\\\">        &quot;s3:GetObject&quot;,</span><br><span class=\\\"line\\\">        &quot;s3:DeleteObject&quot;</span><br><span class=\\\"line\\\">      ],</span><br><span class=\\\"line\\\">      &quot;Resource&quot;: [&quot;arn:aws:s3:::scanner-upload/*&quot;]</span><br><span class=\\\"line\\\">    &#125;</span><br><span class=\\\"line\\\">  ]</span><br><span class=\\\"line\\\">&#125;</span><br></pre></td></tr></table></figure>\\n<ul>\\n<li>in IAM create a user and attach the <code>scanner-upload</code> policy. Note the key/secret or download the csv</li>\\n<li>install <code>aws cli</code> on raspberry pi: <code>sudo pip install awscli --upgrade --user</code> (be sure to use <code>sudo</code>, otherwise it’ll be installed into <code>~/.local/bin/</code> which might not be in your <code>$PATH</code>)</li>\\n<li>start <code>aws configure</code> to put the key/secret and aws region into your config</li>\\n<li>test that s3 access works with <code>aws s3 ls s3://scanner-upload/</code> and uploading a file using <code>aws s3 cp some_file.txt s3://scanner-upload/</code></li>\\n</ul>\\n<h2 id=\\\"Put-scan-sh-into-place\\\"><a href=\\\"#Put-scan-sh-into-place\\\" class=\\\"headerlink\\\" title=\\\"Put scan.sh into place\\\"></a>Put <code>scan.sh</code> into place</h2><p>Put this into <code>/etc/scanbd/scan.sh</code> (replace <code>scanner-upload</code> with your bucket name):</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br><span class=\\\"line\\\">15</span><br><span class=\\\"line\\\">16</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">#!/bin/sh</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">set -e</span><br><span class=\\\"line\\\">TMP_DIR=`mktemp -d`</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;scanning..&apos;</span><br><span class=\\\"line\\\">scanimage --resolution 300 --batch=&quot;$TMP_DIR/scan_%03d.pnm&quot; --format=pnm --mode Gray --source &quot;ADF Duplex&quot;</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;packaging..&apos;</span><br><span class=\\\"line\\\">tarname=scan_$(date &quot;+%Y-%m-%d_%H%M%S&quot;).tar.gz</span><br><span class=\\\"line\\\">cd $TMP_DIR</span><br><span class=\\\"line\\\">tar -czf $tarname *.pnm</span><br><span class=\\\"line\\\"></span><br><span class=\\\"line\\\">echo &apos;uploading..&apos;</span><br><span class=\\\"line\\\">aws s3 cp $TMP_DIR/$tarname s3://scanner-upload/</span><br><span class=\\\"line\\\">rm -rf $TMP_DIR</span><br></pre></td></tr></table></figure>\\n<p>You might want to play around with the <code>scanimage</code> command. In the above script it</p>\\n<ul>\\n<li>scans in batch mode: creates multiple files until the feeder is empty</li>\\n<li>does a duplex scan (there’s no detection. It means that if it’s a one sided paper the second page is just empty)</li>\\n<li><code>resolution 300</code>: this is the default. It is a pretty fast scan and the quality is good enough</li>\\n</ul>\\n<p>Try to call the script manually and then start <code>scanbd -f</code>. Now pressing the button will scan and upload to s3, whohoo!</p>\\n<h2 id=\\\"Start-scanbd-at-boot-time-and-secure-it\\\"><a href=\\\"#Start-scanbd-at-boot-time-and-secure-it\\\" class=\\\"headerlink\\\" title=\\\"Start scanbd at boot time, and secure it\\\"></a>Start scanbd at boot time, and secure it</h2><p>Make <code>scanbd</code> start at boot time: <code>sudo update-rc.d scanbd enable</code>.</p>\\n<p>Secure it: tbd (what happens when you close the lid..?)</p>\\n<h2 id=\\\"Cleaning-up\\\"><a href=\\\"#Cleaning-up\\\" class=\\\"headerlink\\\" title=\\\"Cleaning up\\\"></a>Cleaning up</h2><p>If everything has worked this far you can decrease the logging level in scanbd.conf:</p>\\n<ul>\\n<li>set <code>debug-level=3</code> as level 7 is much too verbose</li>\\n<li>set <code>debug=false</code></li>\\n</ul>\\n<p>remove the temp dirs:</p>\\n<ul>\\n<li><code>rm -rf /var/tmp/sane-backends</code></li>\\n<li><code>rm -rf /var/tmp/1.5.1</code></li>\\n</ul>\\n-->\"},{\"title\":\"Tag history and gartners hype cycles\",\"date\":\"2007-05-12T14:21:00.000Z\",\"alias\":\"/post/37027751523/tag-history-and-gartners-hype-cycles\",\"_content\":\"\\nFor [last Webtuesday](http://www.webtuesday.ch/meetings/20070508) I gathered a few historic data of the «tag movement» (that got very quiet in the last two years).\\n\\n<div class=\\\"caption\\\">[![History of tags](https://lh3.googleusercontent.com/-EFKH93Nx_sA/UL0B68HClVI/AAAAAAAALHw/pa3Ba1ha7tU/s800/tagging_history_900.gif)](/phred/images/tagging_history_900.gif)</div>\\n<div class=\\\"caption\\\">**\\n**</div>\\n<div class=\\\"caption\\\">**Update September, 2007**<span>: </span>[Thomas Vander Wal wrote a very good roundup on the tag history](http://vanderwal.net/random/entrysel.php?blog=1945)[<span>.</span>](/phred/images/tagging_history_900.gif)</div>\\n\\n### <!-- more -->Gartners hype cycles applied to tag history\\n\\n<span>I think </span>[gartners hype cycles](http://en.wikipedia.org/wiki/Hype_cycle)<span> prove to be right when applied to the tag history (hype cycle descriptions taken from </span>[Floor eTrends](http://www.floor.nl/ebiz/gartnershypecycle.htm)<span>):</span>\\n\\n**<span>Technology trigger</span>**\\n\\n> <span>A breakthrough, public demonstration, product launch or other event that generates significant </span><span>press and industry interest.</span>\\n\\nThe technology trigger most likely was [del.icio.us](http://del.icio.us) and subsequently flickr adding tagging to their service.\\n\\n#### Peak of inflated expectations\\n\\n> <span>A phase of overenthusiasm and unrealistic projections during which a flurry of publicized </span><span>activity by technology leaders results in some successes but more failures as the technology is </span><span>pushed to its limits. The only enterprises making money at this stage are conference organizers </span><span>and magazine publishers.</span>\\n\\nIn this phase there were indeed many blog posts talking about this subject, as [Louis Rosenfeld](http://louisrosenfeld.com/home/bloug_archive/000330.html)\\nput it:\\n\\n> <span>Lately, you can&rsquo;t surf information architecture blogs for five minutes without stumbling on a </span><span>discussion of folksonomies</span>\\n\\n<span>I guess in this phase many people said things they now feel embarassed about.</span>\\n\\n**<span>Trough of disillusionment</span>**\\n\\n> <span>The point at which the technology becomes unfashionable and the press abandons the </span><span>topic, because the technology did not live up to its overinflated expectations.</span>\\n\\n<span>This is the phase we&rsquo;re in now. There are no blog posts any more. Tagging is not really</span>\\n\\nunfashionable but the topic is &ldquo;done&rdquo; à la «if that&rsquo;s all what&rsquo;s tagging adds to the web experience, I&rsquo;m not interested in this technology any more». There isn&rsquo;t much thinking and innovation going on.\\n\\n#### Slope of enlightenment\\n\\n> <span>Focused experimentation and solid hard work by an increasingly diverse range of organizations </span><span>lead to a true understanding of the technology&rsquo;s applicability, risks and benefits. Commercial </span><span>off-the-shelf methodologies and tools become available to ease the development process.</span>\\n\\n<span>Let&rsquo;s hope gartner is right about the future of folksonomies!</span>\\n\\n#### Plateau of productivity\\n\\n> <span>The real-world benefits of the technology are demonstrated and accepted. Tools and </span><span>methodologies are increasingly stable as they enter their second and third generation. The final </span><span>height of the plateau varies according to whether the technology is broadly applicable or only </span><span>benefits a niche market.</span>\\n\\nIt has yet to show if folksonomies such as in del.icio.us or flickr prove themselves for the masses.\\n\\n**<span>Update (September, 2007): Do folksonomies apply to hype cycles at all?</span>**\\n\\nJoe Lamantia [raises the question if tagging should be applied at all to Gartners Hype Cycles:](http://tagsonomy.com/index.php/the-tagging-hype-cycle/)\\n\\n> <span>Tagging in fact shows few characteristics of the enterprise technologies that Gartner&rsquo;s Hype Cycle is built around</span>\\n\\n<span>Joe argues rightly, that tagging has not yet reached the broad economy, it&rsquo;s not that Gartner would care to apply folksonomies to their Hype Cycles.</span>\\n\\n<span>Although: Gartner apply the hype cycle to technologies such as </span>[&ldquo;corporate blogging&rdquo; or wikis](http://www.gartner.com/DisplayDocument?doc_cd=140881&amp;ref=g_SiteLink)<span>. It seems it does not lie in the nature of tagging that it won&rsquo;t ever apply to hype cycles, the only fact that hinders Gartner to apply tagging to their hype cycles is that there is no money earned with it. I&rsquo;m not into business analysis at all so I am grateful for Joes insights which he concludes with:</span>\\n\\n> <span>If it doesn&rsquo;t cost money, the perceived risks of the technology are lower, and the big analysis firms pay less attention, because their customers see less need to pay for analysis</span>\\n<div class=\\\"blogger-post-footer\\\">![](https://blogger.googleusercontent.com/tracker/2748783673844839576-47667312269518886?l=theneachwenttohisownhome.blogspot.com)</div>\",\"source\":\"_posts/Tag-history-and-gartners-hype-cycles.md\",\"raw\":\"---\\ntitle: Tag history and gartners hype cycles\\ntags:\\n  - History\\n  - Tags\\ndate: 2007-05-12 16:21:00\\nalias: /post/37027751523/tag-history-and-gartners-hype-cycles\\n---\\n\\nFor [last Webtuesday](http://www.webtuesday.ch/meetings/20070508) I gathered a few historic data of the «tag movement» (that got very quiet in the last two years).\\n\\n<div class=\\\"caption\\\">[![History of tags](https://lh3.googleusercontent.com/-EFKH93Nx_sA/UL0B68HClVI/AAAAAAAALHw/pa3Ba1ha7tU/s800/tagging_history_900.gif)](/phred/images/tagging_history_900.gif)</div>\\n<div class=\\\"caption\\\">**\\n**</div>\\n<div class=\\\"caption\\\">**Update September, 2007**<span>: </span>[Thomas Vander Wal wrote a very good roundup on the tag history](http://vanderwal.net/random/entrysel.php?blog=1945)[<span>.</span>](/phred/images/tagging_history_900.gif)</div>\\n\\n### <!-- more -->Gartners hype cycles applied to tag history\\n\\n<span>I think </span>[gartners hype cycles](http://en.wikipedia.org/wiki/Hype_cycle)<span> prove to be right when applied to the tag history (hype cycle descriptions taken from </span>[Floor eTrends](http://www.floor.nl/ebiz/gartnershypecycle.htm)<span>):</span>\\n\\n**<span>Technology trigger</span>**\\n\\n> <span>A breakthrough, public demonstration, product launch or other event that generates significant </span><span>press and industry interest.</span>\\n\\nThe technology trigger most likely was [del.icio.us](http://del.icio.us) and subsequently flickr adding tagging to their service.\\n\\n#### Peak of inflated expectations\\n\\n> <span>A phase of overenthusiasm and unrealistic projections during which a flurry of publicized </span><span>activity by technology leaders results in some successes but more failures as the technology is </span><span>pushed to its limits. The only enterprises making money at this stage are conference organizers </span><span>and magazine publishers.</span>\\n\\nIn this phase there were indeed many blog posts talking about this subject, as [Louis Rosenfeld](http://louisrosenfeld.com/home/bloug_archive/000330.html)\\nput it:\\n\\n> <span>Lately, you can&rsquo;t surf information architecture blogs for five minutes without stumbling on a </span><span>discussion of folksonomies</span>\\n\\n<span>I guess in this phase many people said things they now feel embarassed about.</span>\\n\\n**<span>Trough of disillusionment</span>**\\n\\n> <span>The point at which the technology becomes unfashionable and the press abandons the </span><span>topic, because the technology did not live up to its overinflated expectations.</span>\\n\\n<span>This is the phase we&rsquo;re in now. There are no blog posts any more. Tagging is not really</span>\\n\\nunfashionable but the topic is &ldquo;done&rdquo; à la «if that&rsquo;s all what&rsquo;s tagging adds to the web experience, I&rsquo;m not interested in this technology any more». There isn&rsquo;t much thinking and innovation going on.\\n\\n#### Slope of enlightenment\\n\\n> <span>Focused experimentation and solid hard work by an increasingly diverse range of organizations </span><span>lead to a true understanding of the technology&rsquo;s applicability, risks and benefits. Commercial </span><span>off-the-shelf methodologies and tools become available to ease the development process.</span>\\n\\n<span>Let&rsquo;s hope gartner is right about the future of folksonomies!</span>\\n\\n#### Plateau of productivity\\n\\n> <span>The real-world benefits of the technology are demonstrated and accepted. Tools and </span><span>methodologies are increasingly stable as they enter their second and third generation. The final </span><span>height of the plateau varies according to whether the technology is broadly applicable or only </span><span>benefits a niche market.</span>\\n\\nIt has yet to show if folksonomies such as in del.icio.us or flickr prove themselves for the masses.\\n\\n**<span>Update (September, 2007): Do folksonomies apply to hype cycles at all?</span>**\\n\\nJoe Lamantia [raises the question if tagging should be applied at all to Gartners Hype Cycles:](http://tagsonomy.com/index.php/the-tagging-hype-cycle/)\\n\\n> <span>Tagging in fact shows few characteristics of the enterprise technologies that Gartner&rsquo;s Hype Cycle is built around</span>\\n\\n<span>Joe argues rightly, that tagging has not yet reached the broad economy, it&rsquo;s not that Gartner would care to apply folksonomies to their Hype Cycles.</span>\\n\\n<span>Although: Gartner apply the hype cycle to technologies such as </span>[&ldquo;corporate blogging&rdquo; or wikis](http://www.gartner.com/DisplayDocument?doc_cd=140881&amp;ref=g_SiteLink)<span>. It seems it does not lie in the nature of tagging that it won&rsquo;t ever apply to hype cycles, the only fact that hinders Gartner to apply tagging to their hype cycles is that there is no money earned with it. I&rsquo;m not into business analysis at all so I am grateful for Joes insights which he concludes with:</span>\\n\\n> <span>If it doesn&rsquo;t cost money, the perceived risks of the technology are lower, and the big analysis firms pay less attention, because their customers see less need to pay for analysis</span>\\n<div class=\\\"blogger-post-footer\\\">![](https://blogger.googleusercontent.com/tracker/2748783673844839576-47667312269518886?l=theneachwenttohisownhome.blogspot.com)</div>\",\"slug\":\"Tag-history-and-gartners-hype-cycles\",\"published\":1,\"updated\":\"2017-11-11T21:19:02.432Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60j000li85p3prpb8ol\",\"content\":\"<p>For <a href=\\\"http://www.webtuesday.ch/meetings/20070508\\\" target=\\\"_blank\\\" rel=\\\"external\\\">last Webtuesday</a> I gathered a few historic data of the «tag movement» (that got very quiet in the last two years).</p>\\n<div class=\\\"caption\\\"><a href=\\\"/phred/images/tagging_history_900.gif\\\"><img src=\\\"https://lh3.googleusercontent.com/-EFKH93Nx_sA/UL0B68HClVI/AAAAAAAALHw/pa3Ba1ha7tU/s800/tagging_history_900.gif\\\" alt=\\\"History of tags\\\"></a></div><br><div class=\\\"caption\\\"><strong>\\n</strong></div><br><div class=\\\"caption\\\"><strong>Update September, 2007</strong><span>: </span><a href=\\\"http://vanderwal.net/random/entrysel.php?blog=1945\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Thomas Vander Wal wrote a very good roundup on the tag history</a><a href=\\\"/phred/images/tagging_history_900.gif\\\"><span>.</span></a></div>\\n\\n<h3 id=\\\"Gartners-hype-cycles-applied-to-tag-history\\\"><a href=\\\"#Gartners-hype-cycles-applied-to-tag-history\\\" class=\\\"headerlink\\\" title=\\\"Gartners hype cycles applied to tag history\\\"></a><a id=\\\"more\\\"></a>Gartners hype cycles applied to tag history</h3><p><span>I think </span><a href=\\\"http://en.wikipedia.org/wiki/Hype_cycle\\\" target=\\\"_blank\\\" rel=\\\"external\\\">gartners hype cycles</a><span> prove to be right when applied to the tag history (hype cycle descriptions taken from </span><a href=\\\"http://www.floor.nl/ebiz/gartnershypecycle.htm\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Floor eTrends</a><span>):</span></p>\\n<p><strong><span>Technology trigger</span></strong></p>\\n<blockquote>\\n<p><span>A breakthrough, public demonstration, product launch or other event that generates significant </span><span>press and industry interest.</span></p>\\n</blockquote>\\n<p>The technology trigger most likely was <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a> and subsequently flickr adding tagging to their service.</p>\\n<h4 id=\\\"Peak-of-inflated-expectations\\\"><a href=\\\"#Peak-of-inflated-expectations\\\" class=\\\"headerlink\\\" title=\\\"Peak of inflated expectations\\\"></a>Peak of inflated expectations</h4><blockquote>\\n<p><span>A phase of overenthusiasm and unrealistic projections during which a flurry of publicized </span><span>activity by technology leaders results in some successes but more failures as the technology is </span><span>pushed to its limits. The only enterprises making money at this stage are conference organizers </span><span>and magazine publishers.</span></p>\\n</blockquote>\\n<p>In this phase there were indeed many blog posts talking about this subject, as <a href=\\\"http://louisrosenfeld.com/home/bloug_archive/000330.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Louis Rosenfeld</a><br>put it:</p>\\n<blockquote>\\n<p><span>Lately, you can&rsquo;t surf information architecture blogs for five minutes without stumbling on a </span><span>discussion of folksonomies</span></p>\\n</blockquote>\\n<p><span>I guess in this phase many people said things they now feel embarassed about.</span></p>\\n<p><strong><span>Trough of disillusionment</span></strong></p>\\n<blockquote>\\n<p><span>The point at which the technology becomes unfashionable and the press abandons the </span><span>topic, because the technology did not live up to its overinflated expectations.</span></p>\\n</blockquote>\\n<p><span>This is the phase we&rsquo;re in now. There are no blog posts any more. Tagging is not really</span></p>\\n<p>unfashionable but the topic is &ldquo;done&rdquo; à la «if that&rsquo;s all what&rsquo;s tagging adds to the web experience, I&rsquo;m not interested in this technology any more». There isn&rsquo;t much thinking and innovation going on.</p>\\n<h4 id=\\\"Slope-of-enlightenment\\\"><a href=\\\"#Slope-of-enlightenment\\\" class=\\\"headerlink\\\" title=\\\"Slope of enlightenment\\\"></a>Slope of enlightenment</h4><blockquote>\\n<p><span>Focused experimentation and solid hard work by an increasingly diverse range of organizations </span><span>lead to a true understanding of the technology&rsquo;s applicability, risks and benefits. Commercial </span><span>off-the-shelf methodologies and tools become available to ease the development process.</span></p>\\n</blockquote>\\n<p><span>Let&rsquo;s hope gartner is right about the future of folksonomies!</span></p>\\n<h4 id=\\\"Plateau-of-productivity\\\"><a href=\\\"#Plateau-of-productivity\\\" class=\\\"headerlink\\\" title=\\\"Plateau of productivity\\\"></a>Plateau of productivity</h4><blockquote>\\n<p><span>The real-world benefits of the technology are demonstrated and accepted. Tools and </span><span>methodologies are increasingly stable as they enter their second and third generation. The final </span><span>height of the plateau varies according to whether the technology is broadly applicable or only </span><span>benefits a niche market.</span></p>\\n</blockquote>\\n<p>It has yet to show if folksonomies such as in del.icio.us or flickr prove themselves for the masses.</p>\\n<p><strong><span>Update (September, 2007): Do folksonomies apply to hype cycles at all?</span></strong></p>\\n<p>Joe Lamantia <a href=\\\"http://tagsonomy.com/index.php/the-tagging-hype-cycle/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">raises the question if tagging should be applied at all to Gartners Hype Cycles:</a></p>\\n<blockquote>\\n<p><span>Tagging in fact shows few characteristics of the enterprise technologies that Gartner&rsquo;s Hype Cycle is built around</span></p>\\n</blockquote>\\n<p><span>Joe argues rightly, that tagging has not yet reached the broad economy, it&rsquo;s not that Gartner would care to apply folksonomies to their Hype Cycles.</span></p>\\n<p><span>Although: Gartner apply the hype cycle to technologies such as </span><a href=\\\"http://www.gartner.com/DisplayDocument?doc_cd=140881&amp;ref=g_SiteLink\\\" target=\\\"_blank\\\" rel=\\\"external\\\">&ldquo;corporate blogging&rdquo; or wikis</a><span>. It seems it does not lie in the nature of tagging that it won&rsquo;t ever apply to hype cycles, the only fact that hinders Gartner to apply tagging to their hype cycles is that there is no money earned with it. I&rsquo;m not into business analysis at all so I am grateful for Joes insights which he concludes with:</span></p>\\n<blockquote>\\n<p><span>If it doesn&rsquo;t cost money, the perceived risks of the technology are lower, and the big analysis firms pay less attention, because their customers see less need to pay for analysis</span></p>\\n<div class=\\\"blogger-post-footer\\\"><img src=\\\"https://blogger.googleusercontent.com/tracker/2748783673844839576-47667312269518886?l=theneachwenttohisownhome.blogspot.com\\\" alt=\\\"\\\"></div></blockquote>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>For <a href=\\\"http://www.webtuesday.ch/meetings/20070508\\\" target=\\\"_blank\\\" rel=\\\"external\\\">last Webtuesday</a> I gathered a few historic data of the «tag movement» (that got very quiet in the last two years).</p>\\n<div class=\\\"caption\\\"><a href=\\\"/phred/images/tagging_history_900.gif\\\"><img src=\\\"https://lh3.googleusercontent.com/-EFKH93Nx_sA/UL0B68HClVI/AAAAAAAALHw/pa3Ba1ha7tU/s800/tagging_history_900.gif\\\" alt=\\\"History of tags\\\"></a></div><br><div class=\\\"caption\\\"><strong>\\n</strong></div><br><div class=\\\"caption\\\"><strong>Update September, 2007</strong><span>: </span><a href=\\\"http://vanderwal.net/random/entrysel.php?blog=1945\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Thomas Vander Wal wrote a very good roundup on the tag history</a><a href=\\\"/phred/images/tagging_history_900.gif\\\"><span>.</span></a></div>\\n\\n<h3 id=\\\"Gartners-hype-cycles-applied-to-tag-history\\\"><a href=\\\"#Gartners-hype-cycles-applied-to-tag-history\\\" class=\\\"headerlink\\\" title=\\\"Gartners hype cycles applied to tag history\\\"></a>\",\"more\":\"Gartners hype cycles applied to tag history</h3><p><span>I think </span><a href=\\\"http://en.wikipedia.org/wiki/Hype_cycle\\\" target=\\\"_blank\\\" rel=\\\"external\\\">gartners hype cycles</a><span> prove to be right when applied to the tag history (hype cycle descriptions taken from </span><a href=\\\"http://www.floor.nl/ebiz/gartnershypecycle.htm\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Floor eTrends</a><span>):</span></p>\\n<p><strong><span>Technology trigger</span></strong></p>\\n<blockquote>\\n<p><span>A breakthrough, public demonstration, product launch or other event that generates significant </span><span>press and industry interest.</span></p>\\n</blockquote>\\n<p>The technology trigger most likely was <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a> and subsequently flickr adding tagging to their service.</p>\\n<h4 id=\\\"Peak-of-inflated-expectations\\\"><a href=\\\"#Peak-of-inflated-expectations\\\" class=\\\"headerlink\\\" title=\\\"Peak of inflated expectations\\\"></a>Peak of inflated expectations</h4><blockquote>\\n<p><span>A phase of overenthusiasm and unrealistic projections during which a flurry of publicized </span><span>activity by technology leaders results in some successes but more failures as the technology is </span><span>pushed to its limits. The only enterprises making money at this stage are conference organizers </span><span>and magazine publishers.</span></p>\\n</blockquote>\\n<p>In this phase there were indeed many blog posts talking about this subject, as <a href=\\\"http://louisrosenfeld.com/home/bloug_archive/000330.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Louis Rosenfeld</a><br>put it:</p>\\n<blockquote>\\n<p><span>Lately, you can&rsquo;t surf information architecture blogs for five minutes without stumbling on a </span><span>discussion of folksonomies</span></p>\\n</blockquote>\\n<p><span>I guess in this phase many people said things they now feel embarassed about.</span></p>\\n<p><strong><span>Trough of disillusionment</span></strong></p>\\n<blockquote>\\n<p><span>The point at which the technology becomes unfashionable and the press abandons the </span><span>topic, because the technology did not live up to its overinflated expectations.</span></p>\\n</blockquote>\\n<p><span>This is the phase we&rsquo;re in now. There are no blog posts any more. Tagging is not really</span></p>\\n<p>unfashionable but the topic is &ldquo;done&rdquo; à la «if that&rsquo;s all what&rsquo;s tagging adds to the web experience, I&rsquo;m not interested in this technology any more». There isn&rsquo;t much thinking and innovation going on.</p>\\n<h4 id=\\\"Slope-of-enlightenment\\\"><a href=\\\"#Slope-of-enlightenment\\\" class=\\\"headerlink\\\" title=\\\"Slope of enlightenment\\\"></a>Slope of enlightenment</h4><blockquote>\\n<p><span>Focused experimentation and solid hard work by an increasingly diverse range of organizations </span><span>lead to a true understanding of the technology&rsquo;s applicability, risks and benefits. Commercial </span><span>off-the-shelf methodologies and tools become available to ease the development process.</span></p>\\n</blockquote>\\n<p><span>Let&rsquo;s hope gartner is right about the future of folksonomies!</span></p>\\n<h4 id=\\\"Plateau-of-productivity\\\"><a href=\\\"#Plateau-of-productivity\\\" class=\\\"headerlink\\\" title=\\\"Plateau of productivity\\\"></a>Plateau of productivity</h4><blockquote>\\n<p><span>The real-world benefits of the technology are demonstrated and accepted. Tools and </span><span>methodologies are increasingly stable as they enter their second and third generation. The final </span><span>height of the plateau varies according to whether the technology is broadly applicable or only </span><span>benefits a niche market.</span></p>\\n</blockquote>\\n<p>It has yet to show if folksonomies such as in del.icio.us or flickr prove themselves for the masses.</p>\\n<p><strong><span>Update (September, 2007): Do folksonomies apply to hype cycles at all?</span></strong></p>\\n<p>Joe Lamantia <a href=\\\"http://tagsonomy.com/index.php/the-tagging-hype-cycle/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">raises the question if tagging should be applied at all to Gartners Hype Cycles:</a></p>\\n<blockquote>\\n<p><span>Tagging in fact shows few characteristics of the enterprise technologies that Gartner&rsquo;s Hype Cycle is built around</span></p>\\n</blockquote>\\n<p><span>Joe argues rightly, that tagging has not yet reached the broad economy, it&rsquo;s not that Gartner would care to apply folksonomies to their Hype Cycles.</span></p>\\n<p><span>Although: Gartner apply the hype cycle to technologies such as </span><a href=\\\"http://www.gartner.com/DisplayDocument?doc_cd=140881&amp;ref=g_SiteLink\\\" target=\\\"_blank\\\" rel=\\\"external\\\">&ldquo;corporate blogging&rdquo; or wikis</a><span>. It seems it does not lie in the nature of tagging that it won&rsquo;t ever apply to hype cycles, the only fact that hinders Gartner to apply tagging to their hype cycles is that there is no money earned with it. I&rsquo;m not into business analysis at all so I am grateful for Joes insights which he concludes with:</span></p>\\n<blockquote>\\n<p><span>If it doesn&rsquo;t cost money, the perceived risks of the technology are lower, and the big analysis firms pay less attention, because their customers see less need to pay for analysis</span></p>\\n<div class=\\\"blogger-post-footer\\\"><img src=\\\"https://blogger.googleusercontent.com/tracker/2748783673844839576-47667312269518886?l=theneachwenttohisownhome.blogspot.com\\\" alt=\\\"\\\"></div></blockquote>\"},{\"title\":\"Tags with MySQL fulltext\",\"date\":\"2005-05-05T17:09:00.000Z\",\"alias\":\"/post/37027745995/tags-with-mysql-fulltext\",\"_content\":\"\\nWhile setting up the promised performance test in my [last post](http://tagging.pui.ch/post/37027745720/tags-database-schemas), I did some tests with the [MySQL fulltext features](http://dev.mysql.com/doc/mysql/en/fulltext-search.html) and it seems that they are built for tagging systems. Take a look at the queries (if it is not clear for you what is done here, please read [my previous post](http://tagging.pui.ch/post/37027745720/tags-database-schemas)).<!-- more -->\\n\\nI took the [MySQLicious](http://nanovivid.com/projects/mysqlicious/) schema and added `ALTER TABLE `delicious` ADD FULLTEXT (`tags`)`. \\nThe full schema:\\n\\n> <div>\\n> <div>`CREATE TABLE `delicious` (\\n>  `id` int(11) NOT NULL auto_increment,\\n>  `url` text,\\n>  `description` text,\\n>  `extended` text,\\n>  `tags` text,\\n>  `date` datetime default NULL,\\n>  `hash` varchar(255) default NULL,\\n>  PRIMARY KEY (`id`),\\n>  KEY `date` (`date`),\\n>  FULLTEXT KEY `tags` (`tags`)\\n> ) ENGINE=MyISAM`</div>\\n> </div>\\n\\n## Queries\\n\\n### Intersection\\n\\nIntersections can be done using [boolean fulltext search](http://dev.mysql.com/doc/mysql/en/fulltext-boolean.html) (since MySQL 4.01):\\nQuery for semweb+search:\\n\\n`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('+semweb +search' IN BOOLEAN MODE)`\\n\\nNow this was easy. And, you guess it, Minus is very similar:\\n\\n### Minus\\n\\n<span>Query for search+webservice-search:</span>\\n\\n<span></span>`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('+search +webservice -search' IN BOOLEAN MODE)`\\n\\n### Brackets\\n\\n<span>Even brackets are possible:</span>\\nQuery for (del.icio.us|delicious)+(webservice|project):\\n\\n`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('+(del.icio.us delicious) +(webservice project)' IN BOOLEAN MODE)`\\n\\n### Union\\n\\n![union DB result](https://lh5.googleusercontent.com/-KI8lkatasrA/UL0A4ABDj4I/AAAAAAAALEY/X2i8ehJDAiE/s508/union_result.png)\\n\\n<span>For union you could use the already mentioned boolean mode, but if you want to have the results ordered so that the bookmark with the most &ldquo;hits&rdquo; is the first entry of the result try this sort of query:</span>\\n\\n`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('delicious clone project webservice')`\\n\\nIf you take a look at the screenshot of the first 7 results of the query run on my DB, you can see that the first hit has got all four tags we searched for, the second has got two and the rest has got just one of them. Like this you can do a &ldquo;find similar entries&rdquo; very easily.\\n\\n## Downsides and problems\\n\\n<span>There are two points where difficulties can accur: When MySQL builds its index out of the tags and when searching for specific tags. I stumbled on three problems:</span>\\n\\n### Stopcharacters\\n\\n<span>If you insert tags with characters like &ldquo;-&rdquo; (as in &ldquo;my-comment&rdquo;), then MySQL will make two index entries: One for &ldquo;my&rdquo; and one for &ldquo;comment&rdquo;. Vice versa if you search for &ldquo;my-comment&rdquo; you&rsquo;ll find bookmarks with tag &ldquo;my&rdquo; and those with tag &ldquo;comment&rdquo;. It seems that this problem can be eliminated by </span>[setting the character set of the column &ldquo;tags&rdquo; to `latin1_bin`](http://dev.mysql.com/doc/mysql/en/fulltext-search.html)<span> but this feature is not available before MySQL 4.1.</span>\\nBut nontheless this shouldn&rsquo;t be a showstopper. You could replace &ldquo;-&rdquo; with a string, say &ldquo;_minus_&rdquo;. This is ugly but should do it..\\n\\n### Stopwords\\n\\nWhen searching for or indexing tags like &ldquo;against&rdquo; or &ldquo;brief&rdquo; ([full list of stopwords](http://www.databasejournal.com/features/mysql/article.php/1578331)), these tags will not be regarded. \\nSince MySQL 4.0.10 you can [customize your stopwordlist](http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html).\\n\\n### Minimum length of a tag\\n\\nPer default, the minimal length of a word indexed by MySQL fulltext is 4 characters. You should therefor [edit `my.cnf`](http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html) in order to set the minimal tag length to 1.\\n\\n## Performance\\n\\nThis solution scales ok. I did tests with tables from 1000 to 1 million bookmarks.\\nThe time for inserting a bookmark is the same for small as for big tables. The time for an intersection query was 0.001 (finding 0.7 urls averaged) in the 1000-table and 0.1 seconds in the 1 million-table(finding 70 bookmarks averaged). There are some [discussions about if MySQLs fulltext search is fast or not (have a look at the user comments)](http://dev.mysql.com/doc/mysql/en/fulltext-search.html). Quick performance tests showed that it is about 10 times as fast as the LIKE-queries mentioned in [my previous post](http://tagging.pui.ch/post/37027745720/tags-database-schemas). But I guess it is not fast enough for webservices like [del.icio.us](http://del.icio.us), I guess this services have to run more than 10 queries a second and then this solution is too slow..\\nUpdate: [I tested the performance of this setup](http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests).\",\"source\":\"_posts/Tags-with-MySQL-fulltext.md\",\"raw\":\"---\\ntitle: Tags with MySQL fulltext\\ntags:\\n  - Tags\\n  - MySQL\\ndate: 2005-05-05 19:09:00\\nalias: /post/37027745995/tags-with-mysql-fulltext\\n---\\n\\nWhile setting up the promised performance test in my [last post](http://tagging.pui.ch/post/37027745720/tags-database-schemas), I did some tests with the [MySQL fulltext features](http://dev.mysql.com/doc/mysql/en/fulltext-search.html) and it seems that they are built for tagging systems. Take a look at the queries (if it is not clear for you what is done here, please read [my previous post](http://tagging.pui.ch/post/37027745720/tags-database-schemas)).<!-- more -->\\n\\nI took the [MySQLicious](http://nanovivid.com/projects/mysqlicious/) schema and added `ALTER TABLE `delicious` ADD FULLTEXT (`tags`)`. \\nThe full schema:\\n\\n> <div>\\n> <div>`CREATE TABLE `delicious` (\\n>  `id` int(11) NOT NULL auto_increment,\\n>  `url` text,\\n>  `description` text,\\n>  `extended` text,\\n>  `tags` text,\\n>  `date` datetime default NULL,\\n>  `hash` varchar(255) default NULL,\\n>  PRIMARY KEY (`id`),\\n>  KEY `date` (`date`),\\n>  FULLTEXT KEY `tags` (`tags`)\\n> ) ENGINE=MyISAM`</div>\\n> </div>\\n\\n## Queries\\n\\n### Intersection\\n\\nIntersections can be done using [boolean fulltext search](http://dev.mysql.com/doc/mysql/en/fulltext-boolean.html) (since MySQL 4.01):\\nQuery for semweb+search:\\n\\n`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('+semweb +search' IN BOOLEAN MODE)`\\n\\nNow this was easy. And, you guess it, Minus is very similar:\\n\\n### Minus\\n\\n<span>Query for search+webservice-search:</span>\\n\\n<span></span>`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('+search +webservice -search' IN BOOLEAN MODE)`\\n\\n### Brackets\\n\\n<span>Even brackets are possible:</span>\\nQuery for (del.icio.us|delicious)+(webservice|project):\\n\\n`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('+(del.icio.us delicious) +(webservice project)' IN BOOLEAN MODE)`\\n\\n### Union\\n\\n![union DB result](https://lh5.googleusercontent.com/-KI8lkatasrA/UL0A4ABDj4I/AAAAAAAALEY/X2i8ehJDAiE/s508/union_result.png)\\n\\n<span>For union you could use the already mentioned boolean mode, but if you want to have the results ordered so that the bookmark with the most &ldquo;hits&rdquo; is the first entry of the result try this sort of query:</span>\\n\\n`SELECT * FROM delicious WHERE MATCH (tags) AGAINST ('delicious clone project webservice')`\\n\\nIf you take a look at the screenshot of the first 7 results of the query run on my DB, you can see that the first hit has got all four tags we searched for, the second has got two and the rest has got just one of them. Like this you can do a &ldquo;find similar entries&rdquo; very easily.\\n\\n## Downsides and problems\\n\\n<span>There are two points where difficulties can accur: When MySQL builds its index out of the tags and when searching for specific tags. I stumbled on three problems:</span>\\n\\n### Stopcharacters\\n\\n<span>If you insert tags with characters like &ldquo;-&rdquo; (as in &ldquo;my-comment&rdquo;), then MySQL will make two index entries: One for &ldquo;my&rdquo; and one for &ldquo;comment&rdquo;. Vice versa if you search for &ldquo;my-comment&rdquo; you&rsquo;ll find bookmarks with tag &ldquo;my&rdquo; and those with tag &ldquo;comment&rdquo;. It seems that this problem can be eliminated by </span>[setting the character set of the column &ldquo;tags&rdquo; to `latin1_bin`](http://dev.mysql.com/doc/mysql/en/fulltext-search.html)<span> but this feature is not available before MySQL 4.1.</span>\\nBut nontheless this shouldn&rsquo;t be a showstopper. You could replace &ldquo;-&rdquo; with a string, say &ldquo;_minus_&rdquo;. This is ugly but should do it..\\n\\n### Stopwords\\n\\nWhen searching for or indexing tags like &ldquo;against&rdquo; or &ldquo;brief&rdquo; ([full list of stopwords](http://www.databasejournal.com/features/mysql/article.php/1578331)), these tags will not be regarded. \\nSince MySQL 4.0.10 you can [customize your stopwordlist](http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html).\\n\\n### Minimum length of a tag\\n\\nPer default, the minimal length of a word indexed by MySQL fulltext is 4 characters. You should therefor [edit `my.cnf`](http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html) in order to set the minimal tag length to 1.\\n\\n## Performance\\n\\nThis solution scales ok. I did tests with tables from 1000 to 1 million bookmarks.\\nThe time for inserting a bookmark is the same for small as for big tables. The time for an intersection query was 0.001 (finding 0.7 urls averaged) in the 1000-table and 0.1 seconds in the 1 million-table(finding 70 bookmarks averaged). There are some [discussions about if MySQLs fulltext search is fast or not (have a look at the user comments)](http://dev.mysql.com/doc/mysql/en/fulltext-search.html). Quick performance tests showed that it is about 10 times as fast as the LIKE-queries mentioned in [my previous post](http://tagging.pui.ch/post/37027745720/tags-database-schemas). But I guess it is not fast enough for webservices like [del.icio.us](http://del.icio.us), I guess this services have to run more than 10 queries a second and then this solution is too slow..\\nUpdate: [I tested the performance of this setup](http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests).\",\"slug\":\"Tags-with-MySQL-fulltext\",\"published\":1,\"updated\":\"2017-11-11T21:17:41.579Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon60k000mi85pm8uq9756\",\"content\":\"<p>While setting up the promised performance test in my <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">last post</a>, I did some tests with the <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQL fulltext features</a> and it seems that they are built for tagging systems. Take a look at the queries (if it is not clear for you what is done here, please read <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">my previous post</a>).<a id=\\\"more\\\"></a></p>\\n<p>I took the <a href=\\\"http://nanovivid.com/projects/mysqlicious/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQLicious</a> schema and added <code>ALTER TABLE</code>delicious<code>ADD FULLTEXT (</code>tags<code>)</code>.<br>The full schema:</p>\\n<blockquote>\\n<div><br><div><code>CREATE TABLE</code>delicious<code>(</code>id<code>int(11) NOT NULL auto_increment,</code>url<code>text,</code>description<code>text,</code>extended<code>text,</code>tags<code>text,</code>date<code>datetime default NULL,</code>hash<code>varchar(255) default NULL,\\n PRIMARY KEY (</code>id<code>),\\n KEY</code>date<code>(</code>date<code>),\\n FULLTEXT KEY</code>tags<code>(</code>tags<code>)\\n) ENGINE=MyISAM</code></div><br></div>\\n\\n</blockquote>\\n<h2 id=\\\"Queries\\\"><a href=\\\"#Queries\\\" class=\\\"headerlink\\\" title=\\\"Queries\\\"></a>Queries</h2><h3 id=\\\"Intersection\\\"><a href=\\\"#Intersection\\\" class=\\\"headerlink\\\" title=\\\"Intersection\\\"></a>Intersection</h3><p>Intersections can be done using <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-boolean.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">boolean fulltext search</a> (since MySQL 4.01):<br>Query for semweb+search:</p>\\n<p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+semweb +search&#39; IN BOOLEAN MODE)</code></p>\\n<p>Now this was easy. And, you guess it, Minus is very similar:</p>\\n<h3 id=\\\"Minus\\\"><a href=\\\"#Minus\\\" class=\\\"headerlink\\\" title=\\\"Minus\\\"></a>Minus</h3><p><span>Query for search+webservice-search:</span></p>\\n<p><span></span><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+search +webservice -search&#39; IN BOOLEAN MODE)</code></p>\\n<h3 id=\\\"Brackets\\\"><a href=\\\"#Brackets\\\" class=\\\"headerlink\\\" title=\\\"Brackets\\\"></a>Brackets</h3><p><span>Even brackets are possible:</span><br>Query for (del.icio.us|delicious)+(webservice|project):</p>\\n<p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+(del.icio.us delicious) +(webservice project)&#39; IN BOOLEAN MODE)</code></p>\\n<h3 id=\\\"Union\\\"><a href=\\\"#Union\\\" class=\\\"headerlink\\\" title=\\\"Union\\\"></a>Union</h3><p><img src=\\\"https://lh5.googleusercontent.com/-KI8lkatasrA/UL0A4ABDj4I/AAAAAAAALEY/X2i8ehJDAiE/s508/union_result.png\\\" alt=\\\"union DB result\\\"></p>\\n<p><span>For union you could use the already mentioned boolean mode, but if you want to have the results ordered so that the bookmark with the most &ldquo;hits&rdquo; is the first entry of the result try this sort of query:</span></p>\\n<p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;delicious clone project webservice&#39;)</code></p>\\n<p>If you take a look at the screenshot of the first 7 results of the query run on my DB, you can see that the first hit has got all four tags we searched for, the second has got two and the rest has got just one of them. Like this you can do a &ldquo;find similar entries&rdquo; very easily.</p>\\n<h2 id=\\\"Downsides-and-problems\\\"><a href=\\\"#Downsides-and-problems\\\" class=\\\"headerlink\\\" title=\\\"Downsides and problems\\\"></a>Downsides and problems</h2><p><span>There are two points where difficulties can accur: When MySQL builds its index out of the tags and when searching for specific tags. I stumbled on three problems:</span></p>\\n<h3 id=\\\"Stopcharacters\\\"><a href=\\\"#Stopcharacters\\\" class=\\\"headerlink\\\" title=\\\"Stopcharacters\\\"></a>Stopcharacters</h3><p><span>If you insert tags with characters like &ldquo;-&rdquo; (as in &ldquo;my-comment&rdquo;), then MySQL will make two index entries: One for &ldquo;my&rdquo; and one for &ldquo;comment&rdquo;. Vice versa if you search for &ldquo;my-comment&rdquo; you&rsquo;ll find bookmarks with tag &ldquo;my&rdquo; and those with tag &ldquo;comment&rdquo;. It seems that this problem can be eliminated by </span><a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">setting the character set of the column &ldquo;tags&rdquo; to <code>latin1_bin</code></a><span> but this feature is not available before MySQL 4.1.</span><br>But nontheless this shouldn&rsquo;t be a showstopper. You could replace &ldquo;-&rdquo; with a string, say &ldquo;<em>minus</em>&rdquo;. This is ugly but should do it..</p>\\n<h3 id=\\\"Stopwords\\\"><a href=\\\"#Stopwords\\\" class=\\\"headerlink\\\" title=\\\"Stopwords\\\"></a>Stopwords</h3><p>When searching for or indexing tags like &ldquo;against&rdquo; or &ldquo;brief&rdquo; (<a href=\\\"http://www.databasejournal.com/features/mysql/article.php/1578331\\\" target=\\\"_blank\\\" rel=\\\"external\\\">full list of stopwords</a>), these tags will not be regarded.<br>Since MySQL 4.0.10 you can <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">customize your stopwordlist</a>.</p>\\n<h3 id=\\\"Minimum-length-of-a-tag\\\"><a href=\\\"#Minimum-length-of-a-tag\\\" class=\\\"headerlink\\\" title=\\\"Minimum length of a tag\\\"></a>Minimum length of a tag</h3><p>Per default, the minimal length of a word indexed by MySQL fulltext is 4 characters. You should therefor <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">edit <code>my.cnf</code></a> in order to set the minimal tag length to 1.</p>\\n<h2 id=\\\"Performance\\\"><a href=\\\"#Performance\\\" class=\\\"headerlink\\\" title=\\\"Performance\\\"></a>Performance</h2><p>This solution scales ok. I did tests with tables from 1000 to 1 million bookmarks.<br>The time for inserting a bookmark is the same for small as for big tables. The time for an intersection query was 0.001 (finding 0.7 urls averaged) in the 1000-table and 0.1 seconds in the 1 million-table(finding 70 bookmarks averaged). There are some <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">discussions about if MySQLs fulltext search is fast or not (have a look at the user comments)</a>. Quick performance tests showed that it is about 10 times as fast as the LIKE-queries mentioned in <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">my previous post</a>. But I guess it is not fast enough for webservices like <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a>, I guess this services have to run more than 10 queries a second and then this solution is too slow..<br>Update: <a href=\\\"http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests\\\" target=\\\"_blank\\\" rel=\\\"external\\\">I tested the performance of this setup</a>.</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>While setting up the promised performance test in my <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">last post</a>, I did some tests with the <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQL fulltext features</a> and it seems that they are built for tagging systems. Take a look at the queries (if it is not clear for you what is done here, please read <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">my previous post</a>).\",\"more\":\"</p>\\n<p>I took the <a href=\\\"http://nanovivid.com/projects/mysqlicious/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQLicious</a> schema and added <code>ALTER TABLE</code>delicious<code>ADD FULLTEXT (</code>tags<code>)</code>.<br>The full schema:</p>\\n<blockquote>\\n<div><br><div><code>CREATE TABLE</code>delicious<code>(</code>id<code>int(11) NOT NULL auto_increment,</code>url<code>text,</code>description<code>text,</code>extended<code>text,</code>tags<code>text,</code>date<code>datetime default NULL,</code>hash<code>varchar(255) default NULL,\\n PRIMARY KEY (</code>id<code>),\\n KEY</code>date<code>(</code>date<code>),\\n FULLTEXT KEY</code>tags<code>(</code>tags<code>)\\n) ENGINE=MyISAM</code></div><br></div>\\n\\n</blockquote>\\n<h2 id=\\\"Queries\\\"><a href=\\\"#Queries\\\" class=\\\"headerlink\\\" title=\\\"Queries\\\"></a>Queries</h2><h3 id=\\\"Intersection\\\"><a href=\\\"#Intersection\\\" class=\\\"headerlink\\\" title=\\\"Intersection\\\"></a>Intersection</h3><p>Intersections can be done using <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-boolean.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">boolean fulltext search</a> (since MySQL 4.01):<br>Query for semweb+search:</p>\\n<p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+semweb +search&#39; IN BOOLEAN MODE)</code></p>\\n<p>Now this was easy. And, you guess it, Minus is very similar:</p>\\n<h3 id=\\\"Minus\\\"><a href=\\\"#Minus\\\" class=\\\"headerlink\\\" title=\\\"Minus\\\"></a>Minus</h3><p><span>Query for search+webservice-search:</span></p>\\n<p><span></span><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+search +webservice -search&#39; IN BOOLEAN MODE)</code></p>\\n<h3 id=\\\"Brackets\\\"><a href=\\\"#Brackets\\\" class=\\\"headerlink\\\" title=\\\"Brackets\\\"></a>Brackets</h3><p><span>Even brackets are possible:</span><br>Query for (del.icio.us|delicious)+(webservice|project):</p>\\n<p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+(del.icio.us delicious) +(webservice project)&#39; IN BOOLEAN MODE)</code></p>\\n<h3 id=\\\"Union\\\"><a href=\\\"#Union\\\" class=\\\"headerlink\\\" title=\\\"Union\\\"></a>Union</h3><p><img src=\\\"https://lh5.googleusercontent.com/-KI8lkatasrA/UL0A4ABDj4I/AAAAAAAALEY/X2i8ehJDAiE/s508/union_result.png\\\" alt=\\\"union DB result\\\"></p>\\n<p><span>For union you could use the already mentioned boolean mode, but if you want to have the results ordered so that the bookmark with the most &ldquo;hits&rdquo; is the first entry of the result try this sort of query:</span></p>\\n<p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;delicious clone project webservice&#39;)</code></p>\\n<p>If you take a look at the screenshot of the first 7 results of the query run on my DB, you can see that the first hit has got all four tags we searched for, the second has got two and the rest has got just one of them. Like this you can do a &ldquo;find similar entries&rdquo; very easily.</p>\\n<h2 id=\\\"Downsides-and-problems\\\"><a href=\\\"#Downsides-and-problems\\\" class=\\\"headerlink\\\" title=\\\"Downsides and problems\\\"></a>Downsides and problems</h2><p><span>There are two points where difficulties can accur: When MySQL builds its index out of the tags and when searching for specific tags. I stumbled on three problems:</span></p>\\n<h3 id=\\\"Stopcharacters\\\"><a href=\\\"#Stopcharacters\\\" class=\\\"headerlink\\\" title=\\\"Stopcharacters\\\"></a>Stopcharacters</h3><p><span>If you insert tags with characters like &ldquo;-&rdquo; (as in &ldquo;my-comment&rdquo;), then MySQL will make two index entries: One for &ldquo;my&rdquo; and one for &ldquo;comment&rdquo;. Vice versa if you search for &ldquo;my-comment&rdquo; you&rsquo;ll find bookmarks with tag &ldquo;my&rdquo; and those with tag &ldquo;comment&rdquo;. It seems that this problem can be eliminated by </span><a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">setting the character set of the column &ldquo;tags&rdquo; to <code>latin1_bin</code></a><span> but this feature is not available before MySQL 4.1.</span><br>But nontheless this shouldn&rsquo;t be a showstopper. You could replace &ldquo;-&rdquo; with a string, say &ldquo;<em>minus</em>&rdquo;. This is ugly but should do it..</p>\\n<h3 id=\\\"Stopwords\\\"><a href=\\\"#Stopwords\\\" class=\\\"headerlink\\\" title=\\\"Stopwords\\\"></a>Stopwords</h3><p>When searching for or indexing tags like &ldquo;against&rdquo; or &ldquo;brief&rdquo; (<a href=\\\"http://www.databasejournal.com/features/mysql/article.php/1578331\\\" target=\\\"_blank\\\" rel=\\\"external\\\">full list of stopwords</a>), these tags will not be regarded.<br>Since MySQL 4.0.10 you can <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">customize your stopwordlist</a>.</p>\\n<h3 id=\\\"Minimum-length-of-a-tag\\\"><a href=\\\"#Minimum-length-of-a-tag\\\" class=\\\"headerlink\\\" title=\\\"Minimum length of a tag\\\"></a>Minimum length of a tag</h3><p>Per default, the minimal length of a word indexed by MySQL fulltext is 4 characters. You should therefor <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">edit <code>my.cnf</code></a> in order to set the minimal tag length to 1.</p>\\n<h2 id=\\\"Performance\\\"><a href=\\\"#Performance\\\" class=\\\"headerlink\\\" title=\\\"Performance\\\"></a>Performance</h2><p>This solution scales ok. I did tests with tables from 1000 to 1 million bookmarks.<br>The time for inserting a bookmark is the same for small as for big tables. The time for an intersection query was 0.001 (finding 0.7 urls averaged) in the 1000-table and 0.1 seconds in the 1 million-table(finding 70 bookmarks averaged). There are some <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">discussions about if MySQLs fulltext search is fast or not (have a look at the user comments)</a>. Quick performance tests showed that it is about 10 times as fast as the LIKE-queries mentioned in <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">my previous post</a>. But I guess it is not fast enough for webservices like <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a>, I guess this services have to run more than 10 queries a second and then this solution is too slow..<br>Update: <a href=\\\"http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests\\\" target=\\\"_blank\\\" rel=\\\"external\\\">I tested the performance of this setup</a>.</p>\"},{\"title\":\"Turn demoscene modules into mp3s\",\"date\":\"2007-02-10T18:39:00.000Z\",\"alias\":\"/post/37471155417/turn-demoscene-modules-into-mp3s\",\"_content\":\"\\n![iTunes screenshot of purple motions tracks](https://lh3.googleusercontent.com/-31kHXDajZUM/UMZL5kXClbI/AAAAAAAALXE/S26QsfTYpHs/s498/itunes_purple_motion.png)\\n\\nIf you were part of the demoscene in your former life, if you were and still are fond of modules (those sound files with the mod, xm, s3m, it, &hellip; ending), if you are a linux user and if you still want to listen to this music on your computer without doing all the tweaks of installing (or even compiling) music player plugins for itunes or amarok or if you simply want to listen to Purple Motions tunes on your mp3 player then this little tutorial is for you. If not, then you won&rsquo;t have read that far anyway..\\n\\n<!-- more -->\\n\\n## short version for the impatient\\n\\ndownload [downloadmod.py](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs) and [mod2mp3.py](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE) into /usr/local/bin/\\n\\n```\\nsudo apt-get install xmp adplay unrar lame\\nmkdir ~/modules/\\ndownloadmod.py ~/modules/ \\\"Purple Motion\\\"\\nmod2mp3.py ~/modules/\\n```\\n\\n### First, get those modules\\n\\nThe first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)\\n\\nAfaik the most complete module resource is [modland](ftp://ftp.modland.com). The crux is that it&rsquo;s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.\\n\\nTo download all modules of a certain artist, I wrote a little [python script](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs) that downloads the module list, unrars it, caches it for further search requests, searches for the artist and downloads all modules of that particular artist.\\n\\n`downloadmod.py ~/modules/ \\\"Michael Land\\\"` downloads all Adlib songs of Michael Land and places them into ~/modules/Michael Land/ and writes some artist/album meta information into those newly created directories.\\n\\nAlternatively you can adapt a quick and dirty [bash function](http://pastie.org/private/nszifsjxnw5obz8bai3ng). It uses wget and is quite messy but it should do the task as well. You have to download and unpack the module list before you call the shell function.\\n\\n### Then, convert those modules into mp3 files\\n\\nTo convert the modules into mp3 files you usually take a module player and call with some special parameters in order to &ldquo;play&rdquo; the module into a wav-File and convert that wav into an mp3 file.\\n\\nOn linux, I&rsquo;d suggest to install this module players (both exist as debian packages and work without hassle on my ubuntu installation)\\n\\n- [xmp](http://xmp.sourceforge.net/) is *nix &ldquo;native&rdquo;\\n- [adplay](http://adplug.sourceforge.net/) supports many adlib formats\\n\\nI wrote a [python script](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE) that converts the downloaded modules into mp3s using the just mentioned module players. You need at least xmp or adplay. If you install both, you&rsquo;d be able to play about 90% of all modules.\\n\\nJust call `mod2mp3.py` with your root module directory as argument and the script creates a mp3 file for each module that is convertible and isn&rsquo;t already converted. If you downloaded the modules with my download script, this script will use the meta information of the first script to write the id3 tags of the mp3s.\\n\\nIf everything worked, you now should have mp3 files with correct id3 tags that can be imported into your amarok/itunes library.\\n\\n### What about us windows users?\\n\\nSorry guys. I&rsquo;ve got to let you down. One whole evening I tried to get any module player writing it&rsquo;s output to a wave file from the command line. I tried [modplug](http://www.modplug.com/playerinfo.html) and [Winamp](http://www.winamp.com) with a [module player plugin](http://www.winamp.com/plugins/details.php?id=132367) but without luck. If you succeed, let me know. Up to then, just take a linux box, copy/download all modules there and let the box convert your modules over night and import it back into your iTunes player. That&rsquo;s what I did.\",\"source\":\"_posts/Turn-demoscene-modules-into-mp3s.md\",\"raw\":\"---\\ntitle: Turn demoscene modules into mp3s\\ntags:\\n  - demoscene\\n  - music\\n  - python\\n  - modules\\ndate: 2007-02-10 19:39:00\\nalias: /post/37471155417/turn-demoscene-modules-into-mp3s\\n---\\n\\n![iTunes screenshot of purple motions tracks](https://lh3.googleusercontent.com/-31kHXDajZUM/UMZL5kXClbI/AAAAAAAALXE/S26QsfTYpHs/s498/itunes_purple_motion.png)\\n\\nIf you were part of the demoscene in your former life, if you were and still are fond of modules (those sound files with the mod, xm, s3m, it, &hellip; ending), if you are a linux user and if you still want to listen to this music on your computer without doing all the tweaks of installing (or even compiling) music player plugins for itunes or amarok or if you simply want to listen to Purple Motions tunes on your mp3 player then this little tutorial is for you. If not, then you won&rsquo;t have read that far anyway..\\n\\n<!-- more -->\\n\\n## short version for the impatient\\n\\ndownload [downloadmod.py](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs) and [mod2mp3.py](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE) into /usr/local/bin/\\n\\n```\\nsudo apt-get install xmp adplay unrar lame\\nmkdir ~/modules/\\ndownloadmod.py ~/modules/ \\\"Purple Motion\\\"\\nmod2mp3.py ~/modules/\\n```\\n\\n### First, get those modules\\n\\nThe first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)\\n\\nAfaik the most complete module resource is [modland](ftp://ftp.modland.com). The crux is that it&rsquo;s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.\\n\\nTo download all modules of a certain artist, I wrote a little [python script](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs) that downloads the module list, unrars it, caches it for further search requests, searches for the artist and downloads all modules of that particular artist.\\n\\n`downloadmod.py ~/modules/ \\\"Michael Land\\\"` downloads all Adlib songs of Michael Land and places them into ~/modules/Michael Land/ and writes some artist/album meta information into those newly created directories.\\n\\nAlternatively you can adapt a quick and dirty [bash function](http://pastie.org/private/nszifsjxnw5obz8bai3ng). It uses wget and is quite messy but it should do the task as well. You have to download and unpack the module list before you call the shell function.\\n\\n### Then, convert those modules into mp3 files\\n\\nTo convert the modules into mp3 files you usually take a module player and call with some special parameters in order to &ldquo;play&rdquo; the module into a wav-File and convert that wav into an mp3 file.\\n\\nOn linux, I&rsquo;d suggest to install this module players (both exist as debian packages and work without hassle on my ubuntu installation)\\n\\n- [xmp](http://xmp.sourceforge.net/) is *nix &ldquo;native&rdquo;\\n- [adplay](http://adplug.sourceforge.net/) supports many adlib formats\\n\\nI wrote a [python script](https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE) that converts the downloaded modules into mp3s using the just mentioned module players. You need at least xmp or adplay. If you install both, you&rsquo;d be able to play about 90% of all modules.\\n\\nJust call `mod2mp3.py` with your root module directory as argument and the script creates a mp3 file for each module that is convertible and isn&rsquo;t already converted. If you downloaded the modules with my download script, this script will use the meta information of the first script to write the id3 tags of the mp3s.\\n\\nIf everything worked, you now should have mp3 files with correct id3 tags that can be imported into your amarok/itunes library.\\n\\n### What about us windows users?\\n\\nSorry guys. I&rsquo;ve got to let you down. One whole evening I tried to get any module player writing it&rsquo;s output to a wave file from the command line. I tried [modplug](http://www.modplug.com/playerinfo.html) and [Winamp](http://www.winamp.com) with a [module player plugin](http://www.winamp.com/plugins/details.php?id=132367) but without luck. If you succeed, let me know. Up to then, just take a linux box, copy/download all modules there and let the box convert your modules over night and import it back into your iTunes player. That&rsquo;s what I did.\",\"slug\":\"Turn-demoscene-modules-into-mp3s\",\"published\":1,\"updated\":\"2017-11-11T21:08:56.692Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon613001ui85ppx86ggz8\",\"content\":\"<p><img src=\\\"https://lh3.googleusercontent.com/-31kHXDajZUM/UMZL5kXClbI/AAAAAAAALXE/S26QsfTYpHs/s498/itunes_purple_motion.png\\\" alt=\\\"iTunes screenshot of purple motions tracks\\\"></p>\\n<p>If you were part of the demoscene in your former life, if you were and still are fond of modules (those sound files with the mod, xm, s3m, it, &hellip; ending), if you are a linux user and if you still want to listen to this music on your computer without doing all the tweaks of installing (or even compiling) music player plugins for itunes or amarok or if you simply want to listen to Purple Motions tunes on your mp3 player then this little tutorial is for you. If not, then you won&rsquo;t have read that far anyway..</p>\\n<a id=\\\"more\\\"></a>\\n<h2 id=\\\"short-version-for-the-impatient\\\"><a href=\\\"#short-version-for-the-impatient\\\" class=\\\"headerlink\\\" title=\\\"short version for the impatient\\\"></a>short version for the impatient</h2><p>download <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs\\\" target=\\\"_blank\\\" rel=\\\"external\\\">downloadmod.py</a> and <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mod2mp3.py</a> into /usr/local/bin/</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt-get install xmp adplay unrar lame</span><br><span class=\\\"line\\\">mkdir ~/modules/</span><br><span class=\\\"line\\\">downloadmod.py ~/modules/ &quot;Purple Motion&quot;</span><br><span class=\\\"line\\\">mod2mp3.py ~/modules/</span><br></pre></td></tr></table></figure>\\n<h3 id=\\\"First-get-those-modules\\\"><a href=\\\"#First-get-those-modules\\\" class=\\\"headerlink\\\" title=\\\"First, get those modules\\\"></a>First, get those modules</h3><p>The first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)</p>\\n<p>Afaik the most complete module resource is <a href=\\\"ftp://ftp.modland.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">modland</a>. The crux is that it&rsquo;s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.</p>\\n<p>To download all modules of a certain artist, I wrote a little <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs\\\" target=\\\"_blank\\\" rel=\\\"external\\\">python script</a> that downloads the module list, unrars it, caches it for further search requests, searches for the artist and downloads all modules of that particular artist.</p>\\n<p><code>downloadmod.py ~/modules/ &quot;Michael Land&quot;</code> downloads all Adlib songs of Michael Land and places them into ~/modules/Michael Land/ and writes some artist/album meta information into those newly created directories.</p>\\n<p>Alternatively you can adapt a quick and dirty <a href=\\\"http://pastie.org/private/nszifsjxnw5obz8bai3ng\\\" target=\\\"_blank\\\" rel=\\\"external\\\">bash function</a>. It uses wget and is quite messy but it should do the task as well. You have to download and unpack the module list before you call the shell function.</p>\\n<h3 id=\\\"Then-convert-those-modules-into-mp3-files\\\"><a href=\\\"#Then-convert-those-modules-into-mp3-files\\\" class=\\\"headerlink\\\" title=\\\"Then, convert those modules into mp3 files\\\"></a>Then, convert those modules into mp3 files</h3><p>To convert the modules into mp3 files you usually take a module player and call with some special parameters in order to &ldquo;play&rdquo; the module into a wav-File and convert that wav into an mp3 file.</p>\\n<p>On linux, I&rsquo;d suggest to install this module players (both exist as debian packages and work without hassle on my ubuntu installation)</p>\\n<ul>\\n<li><a href=\\\"http://xmp.sourceforge.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">xmp</a> is *nix &ldquo;native&rdquo;</li>\\n<li><a href=\\\"http://adplug.sourceforge.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">adplay</a> supports many adlib formats</li>\\n</ul>\\n<p>I wrote a <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE\\\" target=\\\"_blank\\\" rel=\\\"external\\\">python script</a> that converts the downloaded modules into mp3s using the just mentioned module players. You need at least xmp or adplay. If you install both, you&rsquo;d be able to play about 90% of all modules.</p>\\n<p>Just call <code>mod2mp3.py</code> with your root module directory as argument and the script creates a mp3 file for each module that is convertible and isn&rsquo;t already converted. If you downloaded the modules with my download script, this script will use the meta information of the first script to write the id3 tags of the mp3s.</p>\\n<p>If everything worked, you now should have mp3 files with correct id3 tags that can be imported into your amarok/itunes library.</p>\\n<h3 id=\\\"What-about-us-windows-users\\\"><a href=\\\"#What-about-us-windows-users\\\" class=\\\"headerlink\\\" title=\\\"What about us windows users?\\\"></a>What about us windows users?</h3><p>Sorry guys. I&rsquo;ve got to let you down. One whole evening I tried to get any module player writing it&rsquo;s output to a wave file from the command line. I tried <a href=\\\"http://www.modplug.com/playerinfo.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">modplug</a> and <a href=\\\"http://www.winamp.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Winamp</a> with a <a href=\\\"http://www.winamp.com/plugins/details.php?id=132367\\\" target=\\\"_blank\\\" rel=\\\"external\\\">module player plugin</a> but without luck. If you succeed, let me know. Up to then, just take a linux box, copy/download all modules there and let the box convert your modules over night and import it back into your iTunes player. That&rsquo;s what I did.</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"https://lh3.googleusercontent.com/-31kHXDajZUM/UMZL5kXClbI/AAAAAAAALXE/S26QsfTYpHs/s498/itunes_purple_motion.png\\\" alt=\\\"iTunes screenshot of purple motions tracks\\\"></p>\\n<p>If you were part of the demoscene in your former life, if you were and still are fond of modules (those sound files with the mod, xm, s3m, it, &hellip; ending), if you are a linux user and if you still want to listen to this music on your computer without doing all the tweaks of installing (or even compiling) music player plugins for itunes or amarok or if you simply want to listen to Purple Motions tunes on your mp3 player then this little tutorial is for you. If not, then you won&rsquo;t have read that far anyway..</p>\",\"more\":\"<h2 id=\\\"short-version-for-the-impatient\\\"><a href=\\\"#short-version-for-the-impatient\\\" class=\\\"headerlink\\\" title=\\\"short version for the impatient\\\"></a>short version for the impatient</h2><p>download <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs\\\" target=\\\"_blank\\\" rel=\\\"external\\\">downloadmod.py</a> and <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mod2mp3.py</a> into /usr/local/bin/</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">sudo apt-get install xmp adplay unrar lame</span><br><span class=\\\"line\\\">mkdir ~/modules/</span><br><span class=\\\"line\\\">downloadmod.py ~/modules/ &quot;Purple Motion&quot;</span><br><span class=\\\"line\\\">mod2mp3.py ~/modules/</span><br></pre></td></tr></table></figure>\\n<h3 id=\\\"First-get-those-modules\\\"><a href=\\\"#First-get-those-modules\\\" class=\\\"headerlink\\\" title=\\\"First, get those modules\\\"></a>First, get those modules</h3><p>The first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)</p>\\n<p>Afaik the most complete module resource is <a href=\\\"ftp://ftp.modland.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">modland</a>. The crux is that it&rsquo;s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.</p>\\n<p>To download all modules of a certain artist, I wrote a little <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs\\\" target=\\\"_blank\\\" rel=\\\"external\\\">python script</a> that downloads the module list, unrars it, caches it for further search requests, searches for the artist and downloads all modules of that particular artist.</p>\\n<p><code>downloadmod.py ~/modules/ &quot;Michael Land&quot;</code> downloads all Adlib songs of Michael Land and places them into ~/modules/Michael Land/ and writes some artist/album meta information into those newly created directories.</p>\\n<p>Alternatively you can adapt a quick and dirty <a href=\\\"http://pastie.org/private/nszifsjxnw5obz8bai3ng\\\" target=\\\"_blank\\\" rel=\\\"external\\\">bash function</a>. It uses wget and is quite messy but it should do the task as well. You have to download and unpack the module list before you call the shell function.</p>\\n<h3 id=\\\"Then-convert-those-modules-into-mp3-files\\\"><a href=\\\"#Then-convert-those-modules-into-mp3-files\\\" class=\\\"headerlink\\\" title=\\\"Then, convert those modules into mp3 files\\\"></a>Then, convert those modules into mp3 files</h3><p>To convert the modules into mp3 files you usually take a module player and call with some special parameters in order to &ldquo;play&rdquo; the module into a wav-File and convert that wav into an mp3 file.</p>\\n<p>On linux, I&rsquo;d suggest to install this module players (both exist as debian packages and work without hassle on my ubuntu installation)</p>\\n<ul>\\n<li><a href=\\\"http://xmp.sourceforge.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">xmp</a> is *nix &ldquo;native&rdquo;</li>\\n<li><a href=\\\"http://adplug.sourceforge.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">adplay</a> supports many adlib formats</li>\\n</ul>\\n<p>I wrote a <a href=\\\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE\\\" target=\\\"_blank\\\" rel=\\\"external\\\">python script</a> that converts the downloaded modules into mp3s using the just mentioned module players. You need at least xmp or adplay. If you install both, you&rsquo;d be able to play about 90% of all modules.</p>\\n<p>Just call <code>mod2mp3.py</code> with your root module directory as argument and the script creates a mp3 file for each module that is convertible and isn&rsquo;t already converted. If you downloaded the modules with my download script, this script will use the meta information of the first script to write the id3 tags of the mp3s.</p>\\n<p>If everything worked, you now should have mp3 files with correct id3 tags that can be imported into your amarok/itunes library.</p>\\n<h3 id=\\\"What-about-us-windows-users\\\"><a href=\\\"#What-about-us-windows-users\\\" class=\\\"headerlink\\\" title=\\\"What about us windows users?\\\"></a>What about us windows users?</h3><p>Sorry guys. I&rsquo;ve got to let you down. One whole evening I tried to get any module player writing it&rsquo;s output to a wave file from the command line. I tried <a href=\\\"http://www.modplug.com/playerinfo.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">modplug</a> and <a href=\\\"http://www.winamp.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Winamp</a> with a <a href=\\\"http://www.winamp.com/plugins/details.php?id=132367\\\" target=\\\"_blank\\\" rel=\\\"external\\\">module player plugin</a> but without luck. If you succeed, let me know. Up to then, just take a linux box, copy/download all modules there and let the box convert your modules over night and import it back into your iTunes player. That&rsquo;s what I did.</p>\"},{\"title\":\"Tutorial: Django on Appengine using Google Cloud SQL - Adaptations for Python 2.5\",\"date\":\"2013-01-01T20:53:00.000Z\",\"alias\":\"/post/39406024646/tutorial-django-on-appengine-using-google-cloud\",\"_content\":\"\\nGoogle App Engine has two Python runtimes, [either 2.7.3 or 2.5.2](https://developers.google.com/appengine/docs/whatisgoogleappengine#The_Application_Environment). You should try to develop for 2.7, as it&rsquo;s the current default on GAE and all the documentations often only describe this Python version.\\n\\nAdditionally: If you use Python 2.5 you can only use Django up to version 1.3\\\\. (At least I couldn&rsquo;t find out how to get version 1.4 working, `use_library('django', '1.3')` would fail if setting 1.4\\n\\nIf you&rsquo;re stuck with Python below 2.7 for any reason, that&rsquo;s what you need to change following [my tutorial](http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL/) in order to get it working for Python 2.5:\\n\\n<!-- more -->\\n\\n1.  If you&rsquo;re Python version is 2.6, you need to get a 2.5 enviroment: either using virtualenv: <pre>virtualenv -p /usr/bin/python2.5</pre>\\n  or simply change the default python version:\\n\\n      OS X: <pre>defaults write com.apple.versioner.python Version 2.5</pre>\\n  Linux: <pre>ln -f /usr/bin/python2.6 /usr/local/bin/python</pre>\\n\\n2.  In order to make oauth work you need to install ssl (which comes preinstalled with 2.7): <pre>sudo /usr/bin/python2.5 /usr/local/bin/pip install ssl</pre>\\n3.  Instead of `app.yaml` [defined in the tutorial](http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL#create_the_django_project) you need to put 2 files into your project dir: app.yaml and main.py:\\n`app.yaml` (replace `appproject` with the id of your appspot.com instance):\\n<pre>\\napplication: appproject\\nversion: 1\\nruntime: python\\napi_version: 1\\n\\n    handlers:\\n- url: /static/admin\\n  static_dir: static/admin\\n  expiration: '0'\\n- url: /.*\\n  script: main.py\\n</pre>\\n`main.py` (normally those main.py snippets in the web set `DJANGO_SETTINGS_MODULE` to `mysite.settings`, but in my enviroment it only worked when omitting the project name):\\n<pre>\\nimport os\\nimport sys\\nimport logging\\n# Google App Hosting imports.\\nfrom google.appengine.ext.webapp import util\\nfrom google.appengine.dist import use_library\\nos.environ[\\\"DJANGO_SETTINGS_MODULE\\\"] = \\\"settings\\\"\\nuse_library('django', '1.3')\\n# Enable info logging by the app (this is separate from appserver's\\n# logging).\\nlogging.getLogger().setLevel(logging.DEBUG)\\ndef log_exception(*args, **kwds):\\n  logging.exception('Exception in request:')\\n# Force sys.path to have our own directory first, so we can import from it.\\nsys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))\\n# Force Django to reload its settings.\\nfrom django.conf import settings\\nsettings._target = None\\nimport django.core.handlers.wsgi\\nimport django.core.signals\\nimport django.db\\n# Log errors.\\ndjango.dispatch.Signal.connect(\\n   django.core.signals.got_request_exception, log_exception)\\n# Unregister the rollback event handler.\\ndjango.dispatch.Signal.disconnect(\\ndjango.core.signals.got_request_exception,\\ndjango.db._rollback_on_exception)\\ndef main():    # Create a Django application for WSGI.\\n    application = django.core.handlers.wsgi.WSGIHandler()\\n    # Run the WSGI CGI handler with that application.\\n    util.run_wsgi_app(application)\\nif __name__ == \\\"__main__\\\":\\n    main()\\n</pre>\\n\\n4.  That&rsquo;s it, the rest of the tutorial should work!\\n\\n### Troubleshooting\\n\\n**I get `pkg_resources.DistributionNotFound: pip==0.8` when trying to pip install**\\n\\nRun this first:\\n\\n<pre>sudo easy_install --upgrade pip</pre>\",\"source\":\"_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5.md\",\"raw\":\"---\\ntitle: >-\\n  Tutorial: Django on Appengine using Google Cloud SQL - Adaptations for Python\\n  2.5\\ntags:\\n  - django\\n  - python 2.5\\n  - google app engine\\n  - main.py\\ndate: 2013-01-01 21:53:00\\nalias: /post/39406024646/tutorial-django-on-appengine-using-google-cloud\\n---\\n\\nGoogle App Engine has two Python runtimes, [either 2.7.3 or 2.5.2](https://developers.google.com/appengine/docs/whatisgoogleappengine#The_Application_Environment). You should try to develop for 2.7, as it&rsquo;s the current default on GAE and all the documentations often only describe this Python version.\\n\\nAdditionally: If you use Python 2.5 you can only use Django up to version 1.3\\\\. (At least I couldn&rsquo;t find out how to get version 1.4 working, `use_library('django', '1.3')` would fail if setting 1.4\\n\\nIf you&rsquo;re stuck with Python below 2.7 for any reason, that&rsquo;s what you need to change following [my tutorial](http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL/) in order to get it working for Python 2.5:\\n\\n<!-- more -->\\n\\n1.  If you&rsquo;re Python version is 2.6, you need to get a 2.5 enviroment: either using virtualenv: <pre>virtualenv -p /usr/bin/python2.5</pre>\\n  or simply change the default python version:\\n\\n      OS X: <pre>defaults write com.apple.versioner.python Version 2.5</pre>\\n  Linux: <pre>ln -f /usr/bin/python2.6 /usr/local/bin/python</pre>\\n\\n2.  In order to make oauth work you need to install ssl (which comes preinstalled with 2.7): <pre>sudo /usr/bin/python2.5 /usr/local/bin/pip install ssl</pre>\\n3.  Instead of `app.yaml` [defined in the tutorial](http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL#create_the_django_project) you need to put 2 files into your project dir: app.yaml and main.py:\\n`app.yaml` (replace `appproject` with the id of your appspot.com instance):\\n<pre>\\napplication: appproject\\nversion: 1\\nruntime: python\\napi_version: 1\\n\\n    handlers:\\n- url: /static/admin\\n  static_dir: static/admin\\n  expiration: '0'\\n- url: /.*\\n  script: main.py\\n</pre>\\n`main.py` (normally those main.py snippets in the web set `DJANGO_SETTINGS_MODULE` to `mysite.settings`, but in my enviroment it only worked when omitting the project name):\\n<pre>\\nimport os\\nimport sys\\nimport logging\\n# Google App Hosting imports.\\nfrom google.appengine.ext.webapp import util\\nfrom google.appengine.dist import use_library\\nos.environ[\\\"DJANGO_SETTINGS_MODULE\\\"] = \\\"settings\\\"\\nuse_library('django', '1.3')\\n# Enable info logging by the app (this is separate from appserver's\\n# logging).\\nlogging.getLogger().setLevel(logging.DEBUG)\\ndef log_exception(*args, **kwds):\\n  logging.exception('Exception in request:')\\n# Force sys.path to have our own directory first, so we can import from it.\\nsys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))\\n# Force Django to reload its settings.\\nfrom django.conf import settings\\nsettings._target = None\\nimport django.core.handlers.wsgi\\nimport django.core.signals\\nimport django.db\\n# Log errors.\\ndjango.dispatch.Signal.connect(\\n   django.core.signals.got_request_exception, log_exception)\\n# Unregister the rollback event handler.\\ndjango.dispatch.Signal.disconnect(\\ndjango.core.signals.got_request_exception,\\ndjango.db._rollback_on_exception)\\ndef main():    # Create a Django application for WSGI.\\n    application = django.core.handlers.wsgi.WSGIHandler()\\n    # Run the WSGI CGI handler with that application.\\n    util.run_wsgi_app(application)\\nif __name__ == \\\"__main__\\\":\\n    main()\\n</pre>\\n\\n4.  That&rsquo;s it, the rest of the tutorial should work!\\n\\n### Troubleshooting\\n\\n**I get `pkg_resources.DistributionNotFound: pip==0.8` when trying to pip install**\\n\\nRun this first:\\n\\n<pre>sudo easy_install --upgrade pip</pre>\",\"slug\":\"Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5\",\"published\":1,\"updated\":\"2017-11-12T07:11:49.371Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon613001vi85pn3wy7qtg\",\"content\":\"<p>Google App Engine has two Python runtimes, <a href=\\\"https://developers.google.com/appengine/docs/whatisgoogleappengine#The_Application_Environment\\\" target=\\\"_blank\\\" rel=\\\"external\\\">either 2.7.3 or 2.5.2</a>. You should try to develop for 2.7, as it&rsquo;s the current default on GAE and all the documentations often only describe this Python version.</p>\\n<p>Additionally: If you use Python 2.5 you can only use Django up to version 1.3. (At least I couldn&rsquo;t find out how to get version 1.4 working, <code>use_library(&#39;django&#39;, &#39;1.3&#39;)</code> would fail if setting 1.4</p>\\n<p>If you&rsquo;re stuck with Python below 2.7 for any reason, that&rsquo;s what you need to change following <a href=\\\"http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL/\\\">my tutorial</a> in order to get it working for Python 2.5:</p>\\n<a id=\\\"more\\\"></a>\\n<ol>\\n<li><p>If you&rsquo;re Python version is 2.6, you need to get a 2.5 enviroment: either using virtualenv: <pre>virtualenv -p /usr/bin/python2.5</pre><br>or simply change the default python version:</p>\\n<p>  OS X: <pre>defaults write com.apple.versioner.python Version 2.5</pre><br>Linux: <pre>ln -f /usr/bin/python2.6 /usr/local/bin/python</pre></p>\\n</li>\\n<li><p>In order to make oauth work you need to install ssl (which comes preinstalled with 2.7): <pre>sudo /usr/bin/python2.5 /usr/local/bin/pip install ssl</pre></p>\\n</li>\\n<li><p>Instead of <code>app.yaml</code> <a href=\\\"http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL#create_the_django_project\\\">defined in the tutorial</a> you need to put 2 files into your project dir: app.yaml and main.py:<br><code>app.yaml</code> (replace <code>appproject</code> with the id of your appspot.com instance):<br><pre><br>application: appproject<br>version: 1<br>runtime: python<br>api_version: 1</pre></p>\\n<p>handlers:</p>\\n</li>\\n</ol>\\n<ul>\\n<li>url: /static/admin<br>static_dir: static/admin<br>expiration: ‘0’</li>\\n<li>url: /.*<br>script: main.py<br><br><code>main.py</code> (normally those main.py snippets in the web set <code>DJANGO_SETTINGS_MODULE</code> to <code>mysite.settings</code>, but in my enviroment it only worked when omitting the project name):<pre>\\nimport os\\nimport sys\\nimport logging\\n# Google App Hosting imports.\\nfrom google.appengine.ext.webapp import util\\nfrom google.appengine.dist import use_library\\nos.environ[\\\"DJANGO_SETTINGS_MODULE\\\"] = \\\"settings\\\"\\nuse_library('django', '1.3')\\n# Enable info logging by the app (this is separate from appserver's\\n# logging).\\nlogging.getLogger().setLevel(logging.DEBUG)\\ndef log_exception(*args, **kwds):\\nlogging.exception('Exception in request:')\\n# Force sys.path to have our own directory first, so we can import from it.\\nsys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))\\n# Force Django to reload its settings.\\nfrom django.conf import settings\\nsettings._target = None\\nimport django.core.handlers.wsgi\\nimport django.core.signals\\nimport django.db\\n# Log errors.\\ndjango.dispatch.Signal.connect(\\n django.core.signals.got_request_exception, log_exception)\\n# Unregister the rollback event handler.\\ndjango.dispatch.Signal.disconnect(\\ndjango.core.signals.got_request_exception,\\ndjango.db._rollback_on_exception)\\ndef main():    # Create a Django application for WSGI.\\n  application = django.core.handlers.wsgi.WSGIHandler()\\n  # Run the WSGI CGI handler with that application.\\n  util.run_wsgi_app(application)\\nif __name__ == \\\"__main__\\\":\\n  main()\\n</pre>\\n</li>\\n</ul>\\n<ol>\\n<li>That&rsquo;s it, the rest of the tutorial should work!</li>\\n</ol>\\n<h3 id=\\\"Troubleshooting\\\"><a href=\\\"#Troubleshooting\\\" class=\\\"headerlink\\\" title=\\\"Troubleshooting\\\"></a>Troubleshooting</h3><p><strong>I get <code>pkg_resources.DistributionNotFound: pip==0.8</code> when trying to pip install</strong></p>\\n<p>Run this first:</p>\\n<pre>sudo easy_install --upgrade pip</pre>\",\"site\":{\"data\":{}},\"excerpt\":\"<p>Google App Engine has two Python runtimes, <a href=\\\"https://developers.google.com/appengine/docs/whatisgoogleappengine#The_Application_Environment\\\" target=\\\"_blank\\\" rel=\\\"external\\\">either 2.7.3 or 2.5.2</a>. You should try to develop for 2.7, as it&rsquo;s the current default on GAE and all the documentations often only describe this Python version.</p>\\n<p>Additionally: If you use Python 2.5 you can only use Django up to version 1.3. (At least I couldn&rsquo;t find out how to get version 1.4 working, <code>use_library(&#39;django&#39;, &#39;1.3&#39;)</code> would fail if setting 1.4</p>\\n<p>If you&rsquo;re stuck with Python below 2.7 for any reason, that&rsquo;s what you need to change following <a href=\\\"http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL/\\\">my tutorial</a> in order to get it working for Python 2.5:</p>\",\"more\":\"<ol>\\n<li><p>If you&rsquo;re Python version is 2.6, you need to get a 2.5 enviroment: either using virtualenv: <pre>virtualenv -p /usr/bin/python2.5</pre><br>or simply change the default python version:</p>\\n<p>  OS X: <pre>defaults write com.apple.versioner.python Version 2.5</pre><br>Linux: <pre>ln -f /usr/bin/python2.6 /usr/local/bin/python</pre></p>\\n</li>\\n<li><p>In order to make oauth work you need to install ssl (which comes preinstalled with 2.7): <pre>sudo /usr/bin/python2.5 /usr/local/bin/pip install ssl</pre></p>\\n</li>\\n<li><p>Instead of <code>app.yaml</code> <a href=\\\"http://howto.philippkeller.com/2012/12/30/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL#create_the_django_project\\\">defined in the tutorial</a> you need to put 2 files into your project dir: app.yaml and main.py:<br><code>app.yaml</code> (replace <code>appproject</code> with the id of your appspot.com instance):<br><pre><br>application: appproject<br>version: 1<br>runtime: python<br>api_version: 1</pre></p>\\n<p>handlers:</p>\\n</li>\\n</ol>\\n<ul>\\n<li>url: /static/admin<br>static_dir: static/admin<br>expiration: ‘0’</li>\\n<li>url: /.*<br>script: main.py<br><br><code>main.py</code> (normally those main.py snippets in the web set <code>DJANGO_SETTINGS_MODULE</code> to <code>mysite.settings</code>, but in my enviroment it only worked when omitting the project name):<pre>\\nimport os\\nimport sys\\nimport logging\\n# Google App Hosting imports.\\nfrom google.appengine.ext.webapp import util\\nfrom google.appengine.dist import use_library\\nos.environ[\\\"DJANGO_SETTINGS_MODULE\\\"] = \\\"settings\\\"\\nuse_library('django', '1.3')\\n# Enable info logging by the app (this is separate from appserver's\\n# logging).\\nlogging.getLogger().setLevel(logging.DEBUG)\\ndef log_exception(*args, **kwds):\\nlogging.exception('Exception in request:')\\n# Force sys.path to have our own directory first, so we can import from it.\\nsys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))\\n# Force Django to reload its settings.\\nfrom django.conf import settings\\nsettings._target = None\\nimport django.core.handlers.wsgi\\nimport django.core.signals\\nimport django.db\\n# Log errors.\\ndjango.dispatch.Signal.connect(\\n django.core.signals.got_request_exception, log_exception)\\n# Unregister the rollback event handler.\\ndjango.dispatch.Signal.disconnect(\\ndjango.core.signals.got_request_exception,\\ndjango.db._rollback_on_exception)\\ndef main():    # Create a Django application for WSGI.\\n  application = django.core.handlers.wsgi.WSGIHandler()\\n  # Run the WSGI CGI handler with that application.\\n  util.run_wsgi_app(application)\\nif __name__ == \\\"__main__\\\":\\n  main()\\n</pre>\\n</li>\\n</ul>\\n<ol>\\n<li>That&rsquo;s it, the rest of the tutorial should work!</li>\\n</ol>\\n<h3 id=\\\"Troubleshooting\\\"><a href=\\\"#Troubleshooting\\\" class=\\\"headerlink\\\" title=\\\"Troubleshooting\\\"></a>Troubleshooting</h3><p><strong>I get <code>pkg_resources.DistributionNotFound: pip==0.8</code> when trying to pip install</strong></p>\\n<p>Run this first:</p>\\n<pre>sudo easy_install --upgrade pip</pre>\"},{\"title\":\"Tags: Database schemas\",\"date\":\"2005-04-24T14:35:00.000Z\",\"alias\":\"/post/37027745720/tags-database-schemas\",\"_content\":\"\\nRecently, [on del.icio.us mailinglist](http://lists.del.icio.us/pipermail/discuss/2005-April/002827.html), I asked the question &ldquo;Does anyone know the database schema of del.icio.us?&rdquo;. I got a few private responses so I wanted to share the knowledge with the world.\\n\\nThe Problem: You want to have a database schema where you can tag a bookmark (or a blog post or whatever) with as many [tags](http://en.wikipedia.org/wiki/Tags) as you want. Later then, you want to run queries to constrain the bookmarks to a [union](http://en.wikipedia.org/wiki/Union_%28set_theory%29) or [intersection](http://en.wikipedia.org/wiki/Intersection_%28set_theory%29) of tags. You also want to exclude (say: minus) some tags from the search result.\\n\\nApparently there are three different solutions (**Attention: **If you are building a websites that allows users to tag, be sure to have a look at [my performance tests](http://howto.philippkeller.com/2005/06/19/Tagsystems-performance-tests/) as performance seems to be a problem on larger scaled sites.)<!-- more -->\\n\\n## <a id=\\\"mysqlicious\\\" name=\\\"mysqlicious\\\"></a>&ldquo;MySQLicious&rdquo; solution\\n\\n![mysqlicious sample data](https://lh3.googleusercontent.com/-yV7B1_K6nEM/UL0AyrAz2yI/AAAAAAAALDc/3nRpzrNXMwM/s373/mysqlicious_data.png)![mysqlicious database stucture](https://lh4.googleusercontent.com/-PSV7DWIwy0Q/UL0AyyL_z0I/AAAAAAAALDg/vUhaDRz9b-4/s128/mysqlicious_structure.png)\\n\\n<span>In this solution, the schema has got just one table, it is </span>[denormalized](http://en.wikipedia.org/wiki/Denormalization)<span>.</span>\\n\\n<span></span><span>I named this solution &ldquo;MySQLicious solution&rdquo; because </span>[MySQLicious](http://nanovivid.com/projects/mysqlicious/)<span> imports del.icio.us data into a table with this structure.</span>\\n\\n### Intersection (AND)\\n\\nQuery for &ldquo;search+webservice+semweb&rdquo;:\\n`SELECT * \\nFROM `delicious` \\nWHERE tags LIKE \\\"%search%\\\" \\nAND tags LIKE \\\"%webservice%\\\" \\nAND tags LIKE \\\"%semweb%\\\"`\\n\\n### Union (OR)\\n\\n<span>Query for &ldquo;search|webservice|semweb&rdquo;:</span>\\n\\n<span></span>`SELECT * \\nFROM `delicious` \\nWHERE tags LIKE \\\"%search%\\\" \\nOR tags LIKE \\\"%webservice%\\\" \\nOR tags LIKE \\\"%semweb%\\\"`\\n\\n### Minus\\n\\nQuery for &ldquo;search+webservice-semweb&rdquo;\\n\\n`SELECT * \\nFROM `delicious` \\nWHERE tags LIKE \\\"%search%\\\" \\nAND tags LIKE \\\"%webservice%\\\" \\nAND tags NOT LIKE \\\"%semweb%\\\"`\\n\\n### Conclusion\\n\\n<span>The advantages of this solution:</span>\\n\\n*   just one table\\n*   the queries are very straightforward\\n*   one can also achieve results via fulltextsearch. That might be a little faster.\\n*   queries are quite slow according to some commenters. Fulltext search would speed up a bit. I [did some performance tests](http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests) to prove that.\\n*   [In my follow up post I dealt with MySQL fulltext concerning tagging](http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext)<span>.</span>\\n\\nDisadvantages:\\n\\n*   You have a limit on the number of tags per bookmark. Normally you use a 256byte field in your DB (`VARCHAR`). Otherwise, if you took a `text` field or similar, the query times would slow down, I suppose\\n*   Patrice [noticed](http://tagging.pui.ch/post/37027745720/tags-database-schemas#comment-725379777) that `LIKE \\\"%search\\\"` will also find tags with &ldquo;websearch&rdquo;. If you alter the query to `LIKE \\\" %search% \\\"` you end up having a messy solution: You have to add a space to the beginning of the tags value to make this work.\\n\\n## <a id=\\\"scuttle\\\" name=\\\"scuttle\\\"></a>&ldquo;Scuttle&rdquo; solution\\n\\nScuttle organizes its data in two tables. That table &ldquo;scCategories&rdquo; is the &ldquo;tag&rdquo;-table and has got a foreign key to the &ldquo;bookmark&rdquo;-table. ![database structure of scuttle](https://lh3.googleusercontent.com/-g9_LV4z_W5Q/UL0AzhvHefI/AAAAAAAALDo/LJYhO3RlaxQ/s206/scuttle_structure.png)\\n\\n### Intersection (AND)\\n\\nQuery for &ldquo;bookmark+webservice+semweb&rdquo;:\\n\\n`SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN ('bookmark', 'webservice', 'semweb'))\\nGROUP BY b.bId\\nHAVING COUNT( b.bId )=3`\\n\\n<span>First, all bookmark-tag combinations are searched, where the tag is &ldquo;bookmark&rdquo;, &ldquo;webservice&rdquo; or &ldquo;semweb&rdquo; (</span>`c.category IN ('bookmark', 'webservice', 'semweb')`<span>), then just the bookmarks that have got all three tags searched for are taken into account (</span>`HAVING COUNT(b.bId)=3`<span>).</span>\\n\\n### Union (OR)\\n\\nQuery for &ldquo;bookmark|webservice|semweb&rdquo;:\\n\\nJust leave out the `HAVING` clause and you have union:\\n\\n`SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN ('bookmark', 'webservice', 'semweb'))\\nGROUP BY b.bId`\\n\\n### Minus (Exclusion)\\n\\n<span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span>\\n`SELECT b. *\\nFROM scBookmarks b, scCategories c\\nWHERE b.bId = c.bId\\nAND (c.category IN ('bookmark', 'webservice'))\\nAND b.bId NOT\\nIN (SELECT b.bId FROM scBookmarks b, scCategories c WHERE b.bId = c.bId AND c.category = 'semweb')\\nGROUP BY b.bId\\nHAVING COUNT( b.bId ) =2`\\n\\nLeaving out the `HAVING COUNT` leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.\\nCredits go to [Rhomboid](http://www.metafilter.com/user/26222) for [helping me out with this query](http://ask.metafilter.com/mefi/34897#544185).\\n\\n### Conclusion\\n\\n<span>I guess the main advantage of this solution is that it is more normalized than the first solution, and that you can have unlimited number of tags per bookmark.</span>\\n\\n## <a id=\\\"toxi\\\" name=\\\"toxi\\\"></a>&ldquo;Toxi&rdquo; solution\\n\\n![image](https://lh3.googleusercontent.com/-WmVNkFcCHOI/UL0A3982dZI/AAAAAAAALEI/GC0DI-wfiIU/s330/toxi_structure.png)\\n\\n[Toxi](http://toxi.co.uk/)<span> came up with a three-table structure. Via the table &ldquo;tagmap&rdquo; the bookmarks and the tags are n-to-m related. Each tag can be used together with different bookmarks and vice versa. This DB-schema is also used by </span>[wordpress](http://wordpress.org/)<span>.</span>\\n\\n<span></span><span>The queries are quite the same as in the &ldquo;scuttle&rdquo; solution.</span>\\n\\n### Intersection (AND)\\n\\n<span>Query for &ldquo;bookmark+webservice+semweb&rdquo;</span>\\n\\n<span></span>`SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN ('bookmark', 'webservice', 'semweb'))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id\\nHAVING COUNT( b.id )=3`\\n\\n### Union (OR)\\n\\nQuery for “bookmark|webservice|semweb”\\n\\n`SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN ('bookmark', 'webservice', 'semweb'))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id`\\n\\n### Minus (Exclusion)\\n\\n<span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span>\\n`\\nSELECT b. *\\nFROM bookmark b, tagmap bt, tag t\\nWHERE b.id = bt.bookmark_id\\nAND bt.tag_id = t.tag_id \\nAND (t.name IN ('Programming', 'Algorithms'))\\nAND b.id NOT IN (SELECT b.id FROM bookmark b, tagmap bt, tag t WHERE b.id = bt.bookmark_id AND bt.tag_id = t.tag_id AND t.name = 'Python')\\nGROUP BY b.id\\nHAVING COUNT( b.id ) =2`\\nLeaving out the `HAVING COUNT` leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.\\nCredits go to [Rhomboid](http://www.metafilter.com/user/26222) for [helping me out with this query](http://ask.metafilter.com/mefi/34897#544185).\\n\\n### Conclusion\\n\\n<span>The advantages of this solution:</span>\\n\\n*   You can save extra information on each tag (description, tag hierarchy, &hellip;)\\n*   This is the most normalized solution (that is, if you go for [3NF](http://en.wikipedia.org/wiki/3NF): take this one :-)\\n\\n<span>Disadvantages:</span>\\n\\n*   When altering or deleting bookmarks you can end up with tag-orphans.\\n\\nIf you want to have more complicated queries like (bookmarks OR bookmark) AND (webservice or WS) AND NOT (semweb or semanticweb) the queries tend to become very complicated. In these cases I suggest the following query/computation process:\\n\\n1.  Run a query for each tag appearing in your &ldquo;tag-query&rdquo;: `SELECT b.id FROM tagmap bt, bookmark b, tag t WHERE bt.tag_id = t.tag_id AND b.id = bt.bookmark_id AND t.name = \\\"semweb\\\"`\\n2.  Put each id-set from the result into an array (that is: in your favourite coding language). You could cache this arrays if you want..\\n3.  Constrain the arrays with union or intersection or whatever.\\n\\nIn this way, you can also do queries like `(del.icio.us|delicious)+(semweb|semantic_web)-search`. This type of queries (that is: the brackets) cannot be done by using the denormalized &ldquo;MySQLicious solution&rdquo;. \\nThis is the most flexible data structure and I guess it should scale pretty good (that is: if you do some caching).\\n\\n**Update May, 2006**. This arcticle got quite some attention. I wasn&rsquo;t really prepared for that! It seems people keep referring to it and even some new sites that allow tagging give credit to my articles. I think the real credit goes to the contributers of the different schemas: [MySQLicious](http://nanovivid.com/projects/mysqlicious/), [scuttle](http://sourceforge.net/projects/scuttle/), [Toxi](http://toxi.co.uk/) and to all the contributors of the comments (be sure to read them!)\\n\\n<span>P.S. Thanks to </span>[Toxi](http://toxi.co.uk/)<span> for sending me the queries for the three-table-schema, Benjamin Reitzammer for pointing me to </span>[a loughing meme article](http://laughingmeme.org/archives/002918.html)<span> (a good reference for tag queries) and powerlinux for pointing me to </span>[scuttle](http://sourceforge.net/projects/scuttle/)<span>.</span>\\nFurther reading\\n\\n*   [Taglist: a mailing list dedicated to schemas with tagging](http://lists.tagschema.com/mailman/listinfo/tagdb)\\n*   [Tagschema: A blog dedicated to tagging schemas](http://tagschema.com/blogs/tagschema/)\\n*   [Tag-related Queries on Snippets](http://www.bigbold.com/snippets/tags/tagging)\\n*   [Freetag](http://www.getluky.net/freetag/)<span> is a php &ldquo;library&rdquo; with which you can add tags to whatever object you like. It actually uses the &ldquo;toxi schema&rdquo;.</span>\\n*   <span>Hammy </span>[gives an insight](http://hellojoseph.com/tags-howto.php)<span> how he did his tagging system with &ldquo;less DB and more code&rdquo; (that is: regular expressions), interesting!</span>\\n*   <span>Brad Choate </span>[has got some ideas](http://bradchoate.com/weblog/2004/10/06/delicious)<span> which tag queries should be possible</span>\\n*   <span>Feedmaker has written </span>[a sort of reply to this article](http://blog.feedmarker.com/2005/04/26/tagging-in-mysql/)\",\"source\":\"_posts/Tags-Database-schemas.md\",\"raw\":\"---\\ntitle: 'Tags: Database schemas'\\ntags:\\n  - Tags\\n  - Del.icio.us\\n  - MySQL\\ndate: 2005-04-24 16:35:00\\nalias: /post/37027745720/tags-database-schemas\\n---\\n\\nRecently, [on del.icio.us mailinglist](http://lists.del.icio.us/pipermail/discuss/2005-April/002827.html), I asked the question &ldquo;Does anyone know the database schema of del.icio.us?&rdquo;. I got a few private responses so I wanted to share the knowledge with the world.\\n\\nThe Problem: You want to have a database schema where you can tag a bookmark (or a blog post or whatever) with as many [tags](http://en.wikipedia.org/wiki/Tags) as you want. Later then, you want to run queries to constrain the bookmarks to a [union](http://en.wikipedia.org/wiki/Union_%28set_theory%29) or [intersection](http://en.wikipedia.org/wiki/Intersection_%28set_theory%29) of tags. You also want to exclude (say: minus) some tags from the search result.\\n\\nApparently there are three different solutions (**Attention: **If you are building a websites that allows users to tag, be sure to have a look at [my performance tests](http://howto.philippkeller.com/2005/06/19/Tagsystems-performance-tests/) as performance seems to be a problem on larger scaled sites.)<!-- more -->\\n\\n## <a id=\\\"mysqlicious\\\" name=\\\"mysqlicious\\\"></a>&ldquo;MySQLicious&rdquo; solution\\n\\n![mysqlicious sample data](https://lh3.googleusercontent.com/-yV7B1_K6nEM/UL0AyrAz2yI/AAAAAAAALDc/3nRpzrNXMwM/s373/mysqlicious_data.png)![mysqlicious database stucture](https://lh4.googleusercontent.com/-PSV7DWIwy0Q/UL0AyyL_z0I/AAAAAAAALDg/vUhaDRz9b-4/s128/mysqlicious_structure.png)\\n\\n<span>In this solution, the schema has got just one table, it is </span>[denormalized](http://en.wikipedia.org/wiki/Denormalization)<span>.</span>\\n\\n<span></span><span>I named this solution &ldquo;MySQLicious solution&rdquo; because </span>[MySQLicious](http://nanovivid.com/projects/mysqlicious/)<span> imports del.icio.us data into a table with this structure.</span>\\n\\n### Intersection (AND)\\n\\nQuery for &ldquo;search+webservice+semweb&rdquo;:\\n`SELECT * \\nFROM `delicious` \\nWHERE tags LIKE \\\"%search%\\\" \\nAND tags LIKE \\\"%webservice%\\\" \\nAND tags LIKE \\\"%semweb%\\\"`\\n\\n### Union (OR)\\n\\n<span>Query for &ldquo;search|webservice|semweb&rdquo;:</span>\\n\\n<span></span>`SELECT * \\nFROM `delicious` \\nWHERE tags LIKE \\\"%search%\\\" \\nOR tags LIKE \\\"%webservice%\\\" \\nOR tags LIKE \\\"%semweb%\\\"`\\n\\n### Minus\\n\\nQuery for &ldquo;search+webservice-semweb&rdquo;\\n\\n`SELECT * \\nFROM `delicious` \\nWHERE tags LIKE \\\"%search%\\\" \\nAND tags LIKE \\\"%webservice%\\\" \\nAND tags NOT LIKE \\\"%semweb%\\\"`\\n\\n### Conclusion\\n\\n<span>The advantages of this solution:</span>\\n\\n*   just one table\\n*   the queries are very straightforward\\n*   one can also achieve results via fulltextsearch. That might be a little faster.\\n*   queries are quite slow according to some commenters. Fulltext search would speed up a bit. I [did some performance tests](http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests) to prove that.\\n*   [In my follow up post I dealt with MySQL fulltext concerning tagging](http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext)<span>.</span>\\n\\nDisadvantages:\\n\\n*   You have a limit on the number of tags per bookmark. Normally you use a 256byte field in your DB (`VARCHAR`). Otherwise, if you took a `text` field or similar, the query times would slow down, I suppose\\n*   Patrice [noticed](http://tagging.pui.ch/post/37027745720/tags-database-schemas#comment-725379777) that `LIKE \\\"%search\\\"` will also find tags with &ldquo;websearch&rdquo;. If you alter the query to `LIKE \\\" %search% \\\"` you end up having a messy solution: You have to add a space to the beginning of the tags value to make this work.\\n\\n## <a id=\\\"scuttle\\\" name=\\\"scuttle\\\"></a>&ldquo;Scuttle&rdquo; solution\\n\\nScuttle organizes its data in two tables. That table &ldquo;scCategories&rdquo; is the &ldquo;tag&rdquo;-table and has got a foreign key to the &ldquo;bookmark&rdquo;-table. ![database structure of scuttle](https://lh3.googleusercontent.com/-g9_LV4z_W5Q/UL0AzhvHefI/AAAAAAAALDo/LJYhO3RlaxQ/s206/scuttle_structure.png)\\n\\n### Intersection (AND)\\n\\nQuery for &ldquo;bookmark+webservice+semweb&rdquo;:\\n\\n`SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN ('bookmark', 'webservice', 'semweb'))\\nGROUP BY b.bId\\nHAVING COUNT( b.bId )=3`\\n\\n<span>First, all bookmark-tag combinations are searched, where the tag is &ldquo;bookmark&rdquo;, &ldquo;webservice&rdquo; or &ldquo;semweb&rdquo; (</span>`c.category IN ('bookmark', 'webservice', 'semweb')`<span>), then just the bookmarks that have got all three tags searched for are taken into account (</span>`HAVING COUNT(b.bId)=3`<span>).</span>\\n\\n### Union (OR)\\n\\nQuery for &ldquo;bookmark|webservice|semweb&rdquo;:\\n\\nJust leave out the `HAVING` clause and you have union:\\n\\n`SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN ('bookmark', 'webservice', 'semweb'))\\nGROUP BY b.bId`\\n\\n### Minus (Exclusion)\\n\\n<span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span>\\n`SELECT b. *\\nFROM scBookmarks b, scCategories c\\nWHERE b.bId = c.bId\\nAND (c.category IN ('bookmark', 'webservice'))\\nAND b.bId NOT\\nIN (SELECT b.bId FROM scBookmarks b, scCategories c WHERE b.bId = c.bId AND c.category = 'semweb')\\nGROUP BY b.bId\\nHAVING COUNT( b.bId ) =2`\\n\\nLeaving out the `HAVING COUNT` leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.\\nCredits go to [Rhomboid](http://www.metafilter.com/user/26222) for [helping me out with this query](http://ask.metafilter.com/mefi/34897#544185).\\n\\n### Conclusion\\n\\n<span>I guess the main advantage of this solution is that it is more normalized than the first solution, and that you can have unlimited number of tags per bookmark.</span>\\n\\n## <a id=\\\"toxi\\\" name=\\\"toxi\\\"></a>&ldquo;Toxi&rdquo; solution\\n\\n![image](https://lh3.googleusercontent.com/-WmVNkFcCHOI/UL0A3982dZI/AAAAAAAALEI/GC0DI-wfiIU/s330/toxi_structure.png)\\n\\n[Toxi](http://toxi.co.uk/)<span> came up with a three-table structure. Via the table &ldquo;tagmap&rdquo; the bookmarks and the tags are n-to-m related. Each tag can be used together with different bookmarks and vice versa. This DB-schema is also used by </span>[wordpress](http://wordpress.org/)<span>.</span>\\n\\n<span></span><span>The queries are quite the same as in the &ldquo;scuttle&rdquo; solution.</span>\\n\\n### Intersection (AND)\\n\\n<span>Query for &ldquo;bookmark+webservice+semweb&rdquo;</span>\\n\\n<span></span>`SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN ('bookmark', 'webservice', 'semweb'))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id\\nHAVING COUNT( b.id )=3`\\n\\n### Union (OR)\\n\\nQuery for “bookmark|webservice|semweb”\\n\\n`SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN ('bookmark', 'webservice', 'semweb'))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id`\\n\\n### Minus (Exclusion)\\n\\n<span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span>\\n`\\nSELECT b. *\\nFROM bookmark b, tagmap bt, tag t\\nWHERE b.id = bt.bookmark_id\\nAND bt.tag_id = t.tag_id \\nAND (t.name IN ('Programming', 'Algorithms'))\\nAND b.id NOT IN (SELECT b.id FROM bookmark b, tagmap bt, tag t WHERE b.id = bt.bookmark_id AND bt.tag_id = t.tag_id AND t.name = 'Python')\\nGROUP BY b.id\\nHAVING COUNT( b.id ) =2`\\nLeaving out the `HAVING COUNT` leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.\\nCredits go to [Rhomboid](http://www.metafilter.com/user/26222) for [helping me out with this query](http://ask.metafilter.com/mefi/34897#544185).\\n\\n### Conclusion\\n\\n<span>The advantages of this solution:</span>\\n\\n*   You can save extra information on each tag (description, tag hierarchy, &hellip;)\\n*   This is the most normalized solution (that is, if you go for [3NF](http://en.wikipedia.org/wiki/3NF): take this one :-)\\n\\n<span>Disadvantages:</span>\\n\\n*   When altering or deleting bookmarks you can end up with tag-orphans.\\n\\nIf you want to have more complicated queries like (bookmarks OR bookmark) AND (webservice or WS) AND NOT (semweb or semanticweb) the queries tend to become very complicated. In these cases I suggest the following query/computation process:\\n\\n1.  Run a query for each tag appearing in your &ldquo;tag-query&rdquo;: `SELECT b.id FROM tagmap bt, bookmark b, tag t WHERE bt.tag_id = t.tag_id AND b.id = bt.bookmark_id AND t.name = \\\"semweb\\\"`\\n2.  Put each id-set from the result into an array (that is: in your favourite coding language). You could cache this arrays if you want..\\n3.  Constrain the arrays with union or intersection or whatever.\\n\\nIn this way, you can also do queries like `(del.icio.us|delicious)+(semweb|semantic_web)-search`. This type of queries (that is: the brackets) cannot be done by using the denormalized &ldquo;MySQLicious solution&rdquo;. \\nThis is the most flexible data structure and I guess it should scale pretty good (that is: if you do some caching).\\n\\n**Update May, 2006**. This arcticle got quite some attention. I wasn&rsquo;t really prepared for that! It seems people keep referring to it and even some new sites that allow tagging give credit to my articles. I think the real credit goes to the contributers of the different schemas: [MySQLicious](http://nanovivid.com/projects/mysqlicious/), [scuttle](http://sourceforge.net/projects/scuttle/), [Toxi](http://toxi.co.uk/) and to all the contributors of the comments (be sure to read them!)\\n\\n<span>P.S. Thanks to </span>[Toxi](http://toxi.co.uk/)<span> for sending me the queries for the three-table-schema, Benjamin Reitzammer for pointing me to </span>[a loughing meme article](http://laughingmeme.org/archives/002918.html)<span> (a good reference for tag queries) and powerlinux for pointing me to </span>[scuttle](http://sourceforge.net/projects/scuttle/)<span>.</span>\\nFurther reading\\n\\n*   [Taglist: a mailing list dedicated to schemas with tagging](http://lists.tagschema.com/mailman/listinfo/tagdb)\\n*   [Tagschema: A blog dedicated to tagging schemas](http://tagschema.com/blogs/tagschema/)\\n*   [Tag-related Queries on Snippets](http://www.bigbold.com/snippets/tags/tagging)\\n*   [Freetag](http://www.getluky.net/freetag/)<span> is a php &ldquo;library&rdquo; with which you can add tags to whatever object you like. It actually uses the &ldquo;toxi schema&rdquo;.</span>\\n*   <span>Hammy </span>[gives an insight](http://hellojoseph.com/tags-howto.php)<span> how he did his tagging system with &ldquo;less DB and more code&rdquo; (that is: regular expressions), interesting!</span>\\n*   <span>Brad Choate </span>[has got some ideas](http://bradchoate.com/weblog/2004/10/06/delicious)<span> which tag queries should be possible</span>\\n*   <span>Feedmaker has written </span>[a sort of reply to this article](http://blog.feedmarker.com/2005/04/26/tagging-in-mysql/)\",\"slug\":\"Tags-Database-schemas\",\"published\":1,\"updated\":\"2017-11-12T19:15:12.638Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon615001xi85pfli2hqwp\",\"content\":\"<p>Recently, <a href=\\\"http://lists.del.icio.us/pipermail/discuss/2005-April/002827.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">on del.icio.us mailinglist</a>, I asked the question &ldquo;Does anyone know the database schema of del.icio.us?&rdquo;. I got a few private responses so I wanted to share the knowledge with the world.</p>\\n<p>The Problem: You want to have a database schema where you can tag a bookmark (or a blog post or whatever) with as many <a href=\\\"http://en.wikipedia.org/wiki/Tags\\\" target=\\\"_blank\\\" rel=\\\"external\\\">tags</a> as you want. Later then, you want to run queries to constrain the bookmarks to a <a href=\\\"http://en.wikipedia.org/wiki/Union_%28set_theory%29\\\" target=\\\"_blank\\\" rel=\\\"external\\\">union</a> or <a href=\\\"http://en.wikipedia.org/wiki/Intersection_%28set_theory%29\\\" target=\\\"_blank\\\" rel=\\\"external\\\">intersection</a> of tags. You also want to exclude (say: minus) some tags from the search result.</p>\\n<p>Apparently there are three different solutions (<strong>Attention: </strong>If you are building a websites that allows users to tag, be sure to have a look at <a href=\\\"http://howto.philippkeller.com/2005/06/19/Tagsystems-performance-tests/\\\">my performance tests</a> as performance seems to be a problem on larger scaled sites.)<a id=\\\"more\\\"></a></p>\\n<h2 id=\\\"ldquo-MySQLicious-rdquo-solution\\\"><a href=\\\"#ldquo-MySQLicious-rdquo-solution\\\" class=\\\"headerlink\\\" title=\\\"&ldquo;MySQLicious&rdquo; solution\\\"></a><a id=\\\"mysqlicious\\\" name=\\\"mysqlicious\\\"></a>&ldquo;MySQLicious&rdquo; solution</h2><p><img src=\\\"https://lh3.googleusercontent.com/-yV7B1_K6nEM/UL0AyrAz2yI/AAAAAAAALDc/3nRpzrNXMwM/s373/mysqlicious_data.png\\\" alt=\\\"mysqlicious sample data\\\"><img src=\\\"https://lh4.googleusercontent.com/-PSV7DWIwy0Q/UL0AyyL_z0I/AAAAAAAALDg/vUhaDRz9b-4/s128/mysqlicious_structure.png\\\" alt=\\\"mysqlicious database stucture\\\"></p>\\n<p><span>In this solution, the schema has got just one table, it is </span><a href=\\\"http://en.wikipedia.org/wiki/Denormalization\\\" target=\\\"_blank\\\" rel=\\\"external\\\">denormalized</a><span>.</span></p>\\n<p><span></span><span>I named this solution &ldquo;MySQLicious solution&rdquo; because </span><a href=\\\"http://nanovivid.com/projects/mysqlicious/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQLicious</a><span> imports del.icio.us data into a table with this structure.</span></p>\\n<h3 id=\\\"Intersection-AND\\\"><a href=\\\"#Intersection-AND\\\" class=\\\"headerlink\\\" title=\\\"Intersection (AND)\\\"></a>Intersection (AND)</h3><p>Query for &ldquo;search+webservice+semweb&rdquo;:<br><code>SELECT * \\nFROM</code>delicious<code>WHERE tags LIKE &quot;%search%&quot; \\nAND tags LIKE &quot;%webservice%&quot; \\nAND tags LIKE &quot;%semweb%&quot;</code></p>\\n<h3 id=\\\"Union-OR\\\"><a href=\\\"#Union-OR\\\" class=\\\"headerlink\\\" title=\\\"Union (OR)\\\"></a>Union (OR)</h3><p><span>Query for &ldquo;search|webservice|semweb&rdquo;:</span></p>\\n<p><span></span><code>SELECT * \\nFROM</code>delicious<code>WHERE tags LIKE &quot;%search%&quot; \\nOR tags LIKE &quot;%webservice%&quot; \\nOR tags LIKE &quot;%semweb%&quot;</code></p>\\n<h3 id=\\\"Minus\\\"><a href=\\\"#Minus\\\" class=\\\"headerlink\\\" title=\\\"Minus\\\"></a>Minus</h3><p>Query for &ldquo;search+webservice-semweb&rdquo;</p>\\n<p><code>SELECT * \\nFROM</code>delicious<code>WHERE tags LIKE &quot;%search%&quot; \\nAND tags LIKE &quot;%webservice%&quot; \\nAND tags NOT LIKE &quot;%semweb%&quot;</code></p>\\n<h3 id=\\\"Conclusion\\\"><a href=\\\"#Conclusion\\\" class=\\\"headerlink\\\" title=\\\"Conclusion\\\"></a>Conclusion</h3><p><span>The advantages of this solution:</span></p>\\n<ul>\\n<li>just one table</li>\\n<li>the queries are very straightforward</li>\\n<li>one can also achieve results via fulltextsearch. That might be a little faster.</li>\\n<li>queries are quite slow according to some commenters. Fulltext search would speed up a bit. I <a href=\\\"http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests\\\" target=\\\"_blank\\\" rel=\\\"external\\\">did some performance tests</a> to prove that.</li>\\n<li><a href=\\\"http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext\\\" target=\\\"_blank\\\" rel=\\\"external\\\">In my follow up post I dealt with MySQL fulltext concerning tagging</a><span>.</span></li>\\n</ul>\\n<p>Disadvantages:</p>\\n<ul>\\n<li>You have a limit on the number of tags per bookmark. Normally you use a 256byte field in your DB (<code>VARCHAR</code>). Otherwise, if you took a <code>text</code> field or similar, the query times would slow down, I suppose</li>\\n<li>Patrice <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#comment-725379777\\\" target=\\\"_blank\\\" rel=\\\"external\\\">noticed</a> that <code>LIKE &quot;%search&quot;</code> will also find tags with &ldquo;websearch&rdquo;. If you alter the query to <code>LIKE &quot; %search% &quot;</code> you end up having a messy solution: You have to add a space to the beginning of the tags value to make this work.</li>\\n</ul>\\n<h2 id=\\\"ldquo-Scuttle-rdquo-solution\\\"><a href=\\\"#ldquo-Scuttle-rdquo-solution\\\" class=\\\"headerlink\\\" title=\\\"&ldquo;Scuttle&rdquo; solution\\\"></a><a id=\\\"scuttle\\\" name=\\\"scuttle\\\"></a>&ldquo;Scuttle&rdquo; solution</h2><p>Scuttle organizes its data in two tables. That table &ldquo;scCategories&rdquo; is the &ldquo;tag&rdquo;-table and has got a foreign key to the &ldquo;bookmark&rdquo;-table. <img src=\\\"https://lh3.googleusercontent.com/-g9_LV4z_W5Q/UL0AzhvHefI/AAAAAAAALDo/LJYhO3RlaxQ/s206/scuttle_structure.png\\\" alt=\\\"database structure of scuttle\\\"></p>\\n<h3 id=\\\"Intersection-AND-1\\\"><a href=\\\"#Intersection-AND-1\\\" class=\\\"headerlink\\\" title=\\\"Intersection (AND)\\\"></a>Intersection (AND)</h3><p>Query for &ldquo;bookmark+webservice+semweb&rdquo;:</p>\\n<p><code>SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nGROUP BY b.bId\\nHAVING COUNT( b.bId )=3</code></p>\\n<p><span>First, all bookmark-tag combinations are searched, where the tag is &ldquo;bookmark&rdquo;, &ldquo;webservice&rdquo; or &ldquo;semweb&rdquo; (</span><code>c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;)</code><span>), then just the bookmarks that have got all three tags searched for are taken into account (</span><code>HAVING COUNT(b.bId)=3</code><span>).</span></p>\\n<h3 id=\\\"Union-OR-1\\\"><a href=\\\"#Union-OR-1\\\" class=\\\"headerlink\\\" title=\\\"Union (OR)\\\"></a>Union (OR)</h3><p>Query for &ldquo;bookmark|webservice|semweb&rdquo;:</p>\\n<p>Just leave out the <code>HAVING</code> clause and you have union:</p>\\n<p><code>SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nGROUP BY b.bId</code></p>\\n<h3 id=\\\"Minus-Exclusion\\\"><a href=\\\"#Minus-Exclusion\\\" class=\\\"headerlink\\\" title=\\\"Minus (Exclusion)\\\"></a>Minus (Exclusion)</h3><p><span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span><br><code>SELECT b. *\\nFROM scBookmarks b, scCategories c\\nWHERE b.bId = c.bId\\nAND (c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;))\\nAND b.bId NOT\\nIN (SELECT b.bId FROM scBookmarks b, scCategories c WHERE b.bId = c.bId AND c.category = &#39;semweb&#39;)\\nGROUP BY b.bId\\nHAVING COUNT( b.bId ) =2</code></p>\\n<p>Leaving out the <code>HAVING COUNT</code> leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.<br>Credits go to <a href=\\\"http://www.metafilter.com/user/26222\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Rhomboid</a> for <a href=\\\"http://ask.metafilter.com/mefi/34897#544185\\\" target=\\\"_blank\\\" rel=\\\"external\\\">helping me out with this query</a>.</p>\\n<h3 id=\\\"Conclusion-1\\\"><a href=\\\"#Conclusion-1\\\" class=\\\"headerlink\\\" title=\\\"Conclusion\\\"></a>Conclusion</h3><p><span>I guess the main advantage of this solution is that it is more normalized than the first solution, and that you can have unlimited number of tags per bookmark.</span></p>\\n<h2 id=\\\"ldquo-Toxi-rdquo-solution\\\"><a href=\\\"#ldquo-Toxi-rdquo-solution\\\" class=\\\"headerlink\\\" title=\\\"&ldquo;Toxi&rdquo; solution\\\"></a><a id=\\\"toxi\\\" name=\\\"toxi\\\"></a>&ldquo;Toxi&rdquo; solution</h2><p><img src=\\\"https://lh3.googleusercontent.com/-WmVNkFcCHOI/UL0A3982dZI/AAAAAAAALEI/GC0DI-wfiIU/s330/toxi_structure.png\\\" alt=\\\"image\\\"></p>\\n<p><a href=\\\"http://toxi.co.uk/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Toxi</a><span> came up with a three-table structure. Via the table &ldquo;tagmap&rdquo; the bookmarks and the tags are n-to-m related. Each tag can be used together with different bookmarks and vice versa. This DB-schema is also used by </span><a href=\\\"http://wordpress.org/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">wordpress</a><span>.</span></p>\\n<p><span></span><span>The queries are quite the same as in the &ldquo;scuttle&rdquo; solution.</span></p>\\n<h3 id=\\\"Intersection-AND-2\\\"><a href=\\\"#Intersection-AND-2\\\" class=\\\"headerlink\\\" title=\\\"Intersection (AND)\\\"></a>Intersection (AND)</h3><p><span>Query for &ldquo;bookmark+webservice+semweb&rdquo;</span></p>\\n<p><span></span><code>SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id\\nHAVING COUNT( b.id )=3</code></p>\\n<h3 id=\\\"Union-OR-2\\\"><a href=\\\"#Union-OR-2\\\" class=\\\"headerlink\\\" title=\\\"Union (OR)\\\"></a>Union (OR)</h3><p>Query for “bookmark|webservice|semweb”</p>\\n<p><code>SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id</code></p>\\n<h3 id=\\\"Minus-Exclusion-1\\\"><a href=\\\"#Minus-Exclusion-1\\\" class=\\\"headerlink\\\" title=\\\"Minus (Exclusion)\\\"></a>Minus (Exclusion)</h3><p><span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span><br><code>SELECT b. *\\nFROM bookmark b, tagmap bt, tag t\\nWHERE b.id = bt.bookmark_id\\nAND bt.tag_id = t.tag_id \\nAND (t.name IN (&#39;Programming&#39;, &#39;Algorithms&#39;))\\nAND b.id NOT IN (SELECT b.id FROM bookmark b, tagmap bt, tag t WHERE b.id = bt.bookmark_id AND bt.tag_id = t.tag_id AND t.name = &#39;Python&#39;)\\nGROUP BY b.id\\nHAVING COUNT( b.id ) =2</code><br>Leaving out the <code>HAVING COUNT</code> leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.<br>Credits go to <a href=\\\"http://www.metafilter.com/user/26222\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Rhomboid</a> for <a href=\\\"http://ask.metafilter.com/mefi/34897#544185\\\" target=\\\"_blank\\\" rel=\\\"external\\\">helping me out with this query</a>.</p>\\n<h3 id=\\\"Conclusion-2\\\"><a href=\\\"#Conclusion-2\\\" class=\\\"headerlink\\\" title=\\\"Conclusion\\\"></a>Conclusion</h3><p><span>The advantages of this solution:</span></p>\\n<ul>\\n<li>You can save extra information on each tag (description, tag hierarchy, &hellip;)</li>\\n<li>This is the most normalized solution (that is, if you go for <a href=\\\"http://en.wikipedia.org/wiki/3NF\\\" target=\\\"_blank\\\" rel=\\\"external\\\">3NF</a>: take this one :-)</li>\\n</ul>\\n<p><span>Disadvantages:</span></p>\\n<ul>\\n<li>When altering or deleting bookmarks you can end up with tag-orphans.</li>\\n</ul>\\n<p>If you want to have more complicated queries like (bookmarks OR bookmark) AND (webservice or WS) AND NOT (semweb or semanticweb) the queries tend to become very complicated. In these cases I suggest the following query/computation process:</p>\\n<ol>\\n<li>Run a query for each tag appearing in your &ldquo;tag-query&rdquo;: <code>SELECT b.id FROM tagmap bt, bookmark b, tag t WHERE bt.tag_id = t.tag_id AND b.id = bt.bookmark_id AND t.name = &quot;semweb&quot;</code></li>\\n<li>Put each id-set from the result into an array (that is: in your favourite coding language). You could cache this arrays if you want..</li>\\n<li>Constrain the arrays with union or intersection or whatever.</li>\\n</ol>\\n<p>In this way, you can also do queries like <code>(del.icio.us|delicious)+(semweb|semantic_web)-search</code>. This type of queries (that is: the brackets) cannot be done by using the denormalized &ldquo;MySQLicious solution&rdquo;.<br>This is the most flexible data structure and I guess it should scale pretty good (that is: if you do some caching).</p>\\n<p><strong>Update May, 2006</strong>. This arcticle got quite some attention. I wasn&rsquo;t really prepared for that! It seems people keep referring to it and even some new sites that allow tagging give credit to my articles. I think the real credit goes to the contributers of the different schemas: <a href=\\\"http://nanovivid.com/projects/mysqlicious/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQLicious</a>, <a href=\\\"http://sourceforge.net/projects/scuttle/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">scuttle</a>, <a href=\\\"http://toxi.co.uk/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Toxi</a> and to all the contributors of the comments (be sure to read them!)</p>\\n<p><span>P.S. Thanks to </span><a href=\\\"http://toxi.co.uk/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Toxi</a><span> for sending me the queries for the three-table-schema, Benjamin Reitzammer for pointing me to </span><a href=\\\"http://laughingmeme.org/archives/002918.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a loughing meme article</a><span> (a good reference for tag queries) and powerlinux for pointing me to </span><a href=\\\"http://sourceforge.net/projects/scuttle/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">scuttle</a><span>.</span><br>Further reading</p>\\n<ul>\\n<li><a href=\\\"http://lists.tagschema.com/mailman/listinfo/tagdb\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Taglist: a mailing list dedicated to schemas with tagging</a></li>\\n<li><a href=\\\"http://tagschema.com/blogs/tagschema/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Tagschema: A blog dedicated to tagging schemas</a></li>\\n<li><a href=\\\"http://www.bigbold.com/snippets/tags/tagging\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Tag-related Queries on Snippets</a></li>\\n<li><a href=\\\"http://www.getluky.net/freetag/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Freetag</a><span> is a php &ldquo;library&rdquo; with which you can add tags to whatever object you like. It actually uses the &ldquo;toxi schema&rdquo;.</span></li>\\n<li><span>Hammy </span><a href=\\\"http://hellojoseph.com/tags-howto.php\\\" target=\\\"_blank\\\" rel=\\\"external\\\">gives an insight</a><span> how he did his tagging system with &ldquo;less DB and more code&rdquo; (that is: regular expressions), interesting!</span></li>\\n<li><span>Brad Choate </span><a href=\\\"http://bradchoate.com/weblog/2004/10/06/delicious\\\" target=\\\"_blank\\\" rel=\\\"external\\\">has got some ideas</a><span> which tag queries should be possible</span></li>\\n<li><span>Feedmaker has written </span><a href=\\\"http://blog.feedmarker.com/2005/04/26/tagging-in-mysql/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a sort of reply to this article</a></li>\\n</ul>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>Recently, <a href=\\\"http://lists.del.icio.us/pipermail/discuss/2005-April/002827.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">on del.icio.us mailinglist</a>, I asked the question &ldquo;Does anyone know the database schema of del.icio.us?&rdquo;. I got a few private responses so I wanted to share the knowledge with the world.</p>\\n<p>The Problem: You want to have a database schema where you can tag a bookmark (or a blog post or whatever) with as many <a href=\\\"http://en.wikipedia.org/wiki/Tags\\\" target=\\\"_blank\\\" rel=\\\"external\\\">tags</a> as you want. Later then, you want to run queries to constrain the bookmarks to a <a href=\\\"http://en.wikipedia.org/wiki/Union_%28set_theory%29\\\" target=\\\"_blank\\\" rel=\\\"external\\\">union</a> or <a href=\\\"http://en.wikipedia.org/wiki/Intersection_%28set_theory%29\\\" target=\\\"_blank\\\" rel=\\\"external\\\">intersection</a> of tags. You also want to exclude (say: minus) some tags from the search result.</p>\\n<p>Apparently there are three different solutions (<strong>Attention: </strong>If you are building a websites that allows users to tag, be sure to have a look at <a href=\\\"http://howto.philippkeller.com/2005/06/19/Tagsystems-performance-tests/\\\">my performance tests</a> as performance seems to be a problem on larger scaled sites.)\",\"more\":\"</p>\\n<h2 id=\\\"ldquo-MySQLicious-rdquo-solution\\\"><a href=\\\"#ldquo-MySQLicious-rdquo-solution\\\" class=\\\"headerlink\\\" title=\\\"&ldquo;MySQLicious&rdquo; solution\\\"></a><a id=\\\"mysqlicious\\\" name=\\\"mysqlicious\\\"></a>&ldquo;MySQLicious&rdquo; solution</h2><p><img src=\\\"https://lh3.googleusercontent.com/-yV7B1_K6nEM/UL0AyrAz2yI/AAAAAAAALDc/3nRpzrNXMwM/s373/mysqlicious_data.png\\\" alt=\\\"mysqlicious sample data\\\"><img src=\\\"https://lh4.googleusercontent.com/-PSV7DWIwy0Q/UL0AyyL_z0I/AAAAAAAALDg/vUhaDRz9b-4/s128/mysqlicious_structure.png\\\" alt=\\\"mysqlicious database stucture\\\"></p>\\n<p><span>In this solution, the schema has got just one table, it is </span><a href=\\\"http://en.wikipedia.org/wiki/Denormalization\\\" target=\\\"_blank\\\" rel=\\\"external\\\">denormalized</a><span>.</span></p>\\n<p><span></span><span>I named this solution &ldquo;MySQLicious solution&rdquo; because </span><a href=\\\"http://nanovivid.com/projects/mysqlicious/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQLicious</a><span> imports del.icio.us data into a table with this structure.</span></p>\\n<h3 id=\\\"Intersection-AND\\\"><a href=\\\"#Intersection-AND\\\" class=\\\"headerlink\\\" title=\\\"Intersection (AND)\\\"></a>Intersection (AND)</h3><p>Query for &ldquo;search+webservice+semweb&rdquo;:<br><code>SELECT * \\nFROM</code>delicious<code>WHERE tags LIKE &quot;%search%&quot; \\nAND tags LIKE &quot;%webservice%&quot; \\nAND tags LIKE &quot;%semweb%&quot;</code></p>\\n<h3 id=\\\"Union-OR\\\"><a href=\\\"#Union-OR\\\" class=\\\"headerlink\\\" title=\\\"Union (OR)\\\"></a>Union (OR)</h3><p><span>Query for &ldquo;search|webservice|semweb&rdquo;:</span></p>\\n<p><span></span><code>SELECT * \\nFROM</code>delicious<code>WHERE tags LIKE &quot;%search%&quot; \\nOR tags LIKE &quot;%webservice%&quot; \\nOR tags LIKE &quot;%semweb%&quot;</code></p>\\n<h3 id=\\\"Minus\\\"><a href=\\\"#Minus\\\" class=\\\"headerlink\\\" title=\\\"Minus\\\"></a>Minus</h3><p>Query for &ldquo;search+webservice-semweb&rdquo;</p>\\n<p><code>SELECT * \\nFROM</code>delicious<code>WHERE tags LIKE &quot;%search%&quot; \\nAND tags LIKE &quot;%webservice%&quot; \\nAND tags NOT LIKE &quot;%semweb%&quot;</code></p>\\n<h3 id=\\\"Conclusion\\\"><a href=\\\"#Conclusion\\\" class=\\\"headerlink\\\" title=\\\"Conclusion\\\"></a>Conclusion</h3><p><span>The advantages of this solution:</span></p>\\n<ul>\\n<li>just one table</li>\\n<li>the queries are very straightforward</li>\\n<li>one can also achieve results via fulltextsearch. That might be a little faster.</li>\\n<li>queries are quite slow according to some commenters. Fulltext search would speed up a bit. I <a href=\\\"http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests\\\" target=\\\"_blank\\\" rel=\\\"external\\\">did some performance tests</a> to prove that.</li>\\n<li><a href=\\\"http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext\\\" target=\\\"_blank\\\" rel=\\\"external\\\">In my follow up post I dealt with MySQL fulltext concerning tagging</a><span>.</span></li>\\n</ul>\\n<p>Disadvantages:</p>\\n<ul>\\n<li>You have a limit on the number of tags per bookmark. Normally you use a 256byte field in your DB (<code>VARCHAR</code>). Otherwise, if you took a <code>text</code> field or similar, the query times would slow down, I suppose</li>\\n<li>Patrice <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#comment-725379777\\\" target=\\\"_blank\\\" rel=\\\"external\\\">noticed</a> that <code>LIKE &quot;%search&quot;</code> will also find tags with &ldquo;websearch&rdquo;. If you alter the query to <code>LIKE &quot; %search% &quot;</code> you end up having a messy solution: You have to add a space to the beginning of the tags value to make this work.</li>\\n</ul>\\n<h2 id=\\\"ldquo-Scuttle-rdquo-solution\\\"><a href=\\\"#ldquo-Scuttle-rdquo-solution\\\" class=\\\"headerlink\\\" title=\\\"&ldquo;Scuttle&rdquo; solution\\\"></a><a id=\\\"scuttle\\\" name=\\\"scuttle\\\"></a>&ldquo;Scuttle&rdquo; solution</h2><p>Scuttle organizes its data in two tables. That table &ldquo;scCategories&rdquo; is the &ldquo;tag&rdquo;-table and has got a foreign key to the &ldquo;bookmark&rdquo;-table. <img src=\\\"https://lh3.googleusercontent.com/-g9_LV4z_W5Q/UL0AzhvHefI/AAAAAAAALDo/LJYhO3RlaxQ/s206/scuttle_structure.png\\\" alt=\\\"database structure of scuttle\\\"></p>\\n<h3 id=\\\"Intersection-AND-1\\\"><a href=\\\"#Intersection-AND-1\\\" class=\\\"headerlink\\\" title=\\\"Intersection (AND)\\\"></a>Intersection (AND)</h3><p>Query for &ldquo;bookmark+webservice+semweb&rdquo;:</p>\\n<p><code>SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nGROUP BY b.bId\\nHAVING COUNT( b.bId )=3</code></p>\\n<p><span>First, all bookmark-tag combinations are searched, where the tag is &ldquo;bookmark&rdquo;, &ldquo;webservice&rdquo; or &ldquo;semweb&rdquo; (</span><code>c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;)</code><span>), then just the bookmarks that have got all three tags searched for are taken into account (</span><code>HAVING COUNT(b.bId)=3</code><span>).</span></p>\\n<h3 id=\\\"Union-OR-1\\\"><a href=\\\"#Union-OR-1\\\" class=\\\"headerlink\\\" title=\\\"Union (OR)\\\"></a>Union (OR)</h3><p>Query for &ldquo;bookmark|webservice|semweb&rdquo;:</p>\\n<p>Just leave out the <code>HAVING</code> clause and you have union:</p>\\n<p><code>SELECT b.*\\nFROM scBookmarks b, scCategories c\\nWHERE c.bId = b.bId\\nAND (c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nGROUP BY b.bId</code></p>\\n<h3 id=\\\"Minus-Exclusion\\\"><a href=\\\"#Minus-Exclusion\\\" class=\\\"headerlink\\\" title=\\\"Minus (Exclusion)\\\"></a>Minus (Exclusion)</h3><p><span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span><br><code>SELECT b. *\\nFROM scBookmarks b, scCategories c\\nWHERE b.bId = c.bId\\nAND (c.category IN (&#39;bookmark&#39;, &#39;webservice&#39;))\\nAND b.bId NOT\\nIN (SELECT b.bId FROM scBookmarks b, scCategories c WHERE b.bId = c.bId AND c.category = &#39;semweb&#39;)\\nGROUP BY b.bId\\nHAVING COUNT( b.bId ) =2</code></p>\\n<p>Leaving out the <code>HAVING COUNT</code> leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.<br>Credits go to <a href=\\\"http://www.metafilter.com/user/26222\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Rhomboid</a> for <a href=\\\"http://ask.metafilter.com/mefi/34897#544185\\\" target=\\\"_blank\\\" rel=\\\"external\\\">helping me out with this query</a>.</p>\\n<h3 id=\\\"Conclusion-1\\\"><a href=\\\"#Conclusion-1\\\" class=\\\"headerlink\\\" title=\\\"Conclusion\\\"></a>Conclusion</h3><p><span>I guess the main advantage of this solution is that it is more normalized than the first solution, and that you can have unlimited number of tags per bookmark.</span></p>\\n<h2 id=\\\"ldquo-Toxi-rdquo-solution\\\"><a href=\\\"#ldquo-Toxi-rdquo-solution\\\" class=\\\"headerlink\\\" title=\\\"&ldquo;Toxi&rdquo; solution\\\"></a><a id=\\\"toxi\\\" name=\\\"toxi\\\"></a>&ldquo;Toxi&rdquo; solution</h2><p><img src=\\\"https://lh3.googleusercontent.com/-WmVNkFcCHOI/UL0A3982dZI/AAAAAAAALEI/GC0DI-wfiIU/s330/toxi_structure.png\\\" alt=\\\"image\\\"></p>\\n<p><a href=\\\"http://toxi.co.uk/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Toxi</a><span> came up with a three-table structure. Via the table &ldquo;tagmap&rdquo; the bookmarks and the tags are n-to-m related. Each tag can be used together with different bookmarks and vice versa. This DB-schema is also used by </span><a href=\\\"http://wordpress.org/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">wordpress</a><span>.</span></p>\\n<p><span></span><span>The queries are quite the same as in the &ldquo;scuttle&rdquo; solution.</span></p>\\n<h3 id=\\\"Intersection-AND-2\\\"><a href=\\\"#Intersection-AND-2\\\" class=\\\"headerlink\\\" title=\\\"Intersection (AND)\\\"></a>Intersection (AND)</h3><p><span>Query for &ldquo;bookmark+webservice+semweb&rdquo;</span></p>\\n<p><span></span><code>SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id\\nHAVING COUNT( b.id )=3</code></p>\\n<h3 id=\\\"Union-OR-2\\\"><a href=\\\"#Union-OR-2\\\" class=\\\"headerlink\\\" title=\\\"Union (OR)\\\"></a>Union (OR)</h3><p>Query for “bookmark|webservice|semweb”</p>\\n<p><code>SELECT b.*\\nFROM tagmap bt, bookmark b, tag t\\nWHERE bt.tag_id = t.tag_id\\nAND (t.name IN (&#39;bookmark&#39;, &#39;webservice&#39;, &#39;semweb&#39;))\\nAND b.id = bt.bookmark_id\\nGROUP BY b.id</code></p>\\n<h3 id=\\\"Minus-Exclusion-1\\\"><a href=\\\"#Minus-Exclusion-1\\\" class=\\\"headerlink\\\" title=\\\"Minus (Exclusion)\\\"></a>Minus (Exclusion)</h3><p><span>Query for &ldquo;bookmark+webservice-semweb&rdquo;, that is: bookmark AND webservice AND NOT semweb.</span><br><code>SELECT b. *\\nFROM bookmark b, tagmap bt, tag t\\nWHERE b.id = bt.bookmark_id\\nAND bt.tag_id = t.tag_id \\nAND (t.name IN (&#39;Programming&#39;, &#39;Algorithms&#39;))\\nAND b.id NOT IN (SELECT b.id FROM bookmark b, tagmap bt, tag t WHERE b.id = bt.bookmark_id AND bt.tag_id = t.tag_id AND t.name = &#39;Python&#39;)\\nGROUP BY b.id\\nHAVING COUNT( b.id ) =2</code><br>Leaving out the <code>HAVING COUNT</code> leads to the Query for &ldquo;bookmark|webservice-semweb&rdquo;.<br>Credits go to <a href=\\\"http://www.metafilter.com/user/26222\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Rhomboid</a> for <a href=\\\"http://ask.metafilter.com/mefi/34897#544185\\\" target=\\\"_blank\\\" rel=\\\"external\\\">helping me out with this query</a>.</p>\\n<h3 id=\\\"Conclusion-2\\\"><a href=\\\"#Conclusion-2\\\" class=\\\"headerlink\\\" title=\\\"Conclusion\\\"></a>Conclusion</h3><p><span>The advantages of this solution:</span></p>\\n<ul>\\n<li>You can save extra information on each tag (description, tag hierarchy, &hellip;)</li>\\n<li>This is the most normalized solution (that is, if you go for <a href=\\\"http://en.wikipedia.org/wiki/3NF\\\" target=\\\"_blank\\\" rel=\\\"external\\\">3NF</a>: take this one :-)</li>\\n</ul>\\n<p><span>Disadvantages:</span></p>\\n<ul>\\n<li>When altering or deleting bookmarks you can end up with tag-orphans.</li>\\n</ul>\\n<p>If you want to have more complicated queries like (bookmarks OR bookmark) AND (webservice or WS) AND NOT (semweb or semanticweb) the queries tend to become very complicated. In these cases I suggest the following query/computation process:</p>\\n<ol>\\n<li>Run a query for each tag appearing in your &ldquo;tag-query&rdquo;: <code>SELECT b.id FROM tagmap bt, bookmark b, tag t WHERE bt.tag_id = t.tag_id AND b.id = bt.bookmark_id AND t.name = &quot;semweb&quot;</code></li>\\n<li>Put each id-set from the result into an array (that is: in your favourite coding language). You could cache this arrays if you want..</li>\\n<li>Constrain the arrays with union or intersection or whatever.</li>\\n</ol>\\n<p>In this way, you can also do queries like <code>(del.icio.us|delicious)+(semweb|semantic_web)-search</code>. This type of queries (that is: the brackets) cannot be done by using the denormalized &ldquo;MySQLicious solution&rdquo;.<br>This is the most flexible data structure and I guess it should scale pretty good (that is: if you do some caching).</p>\\n<p><strong>Update May, 2006</strong>. This arcticle got quite some attention. I wasn&rsquo;t really prepared for that! It seems people keep referring to it and even some new sites that allow tagging give credit to my articles. I think the real credit goes to the contributers of the different schemas: <a href=\\\"http://nanovivid.com/projects/mysqlicious/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">MySQLicious</a>, <a href=\\\"http://sourceforge.net/projects/scuttle/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">scuttle</a>, <a href=\\\"http://toxi.co.uk/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Toxi</a> and to all the contributors of the comments (be sure to read them!)</p>\\n<p><span>P.S. Thanks to </span><a href=\\\"http://toxi.co.uk/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Toxi</a><span> for sending me the queries for the three-table-schema, Benjamin Reitzammer for pointing me to </span><a href=\\\"http://laughingmeme.org/archives/002918.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a loughing meme article</a><span> (a good reference for tag queries) and powerlinux for pointing me to </span><a href=\\\"http://sourceforge.net/projects/scuttle/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">scuttle</a><span>.</span><br>Further reading</p>\\n<ul>\\n<li><a href=\\\"http://lists.tagschema.com/mailman/listinfo/tagdb\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Taglist: a mailing list dedicated to schemas with tagging</a></li>\\n<li><a href=\\\"http://tagschema.com/blogs/tagschema/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Tagschema: A blog dedicated to tagging schemas</a></li>\\n<li><a href=\\\"http://www.bigbold.com/snippets/tags/tagging\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Tag-related Queries on Snippets</a></li>\\n<li><a href=\\\"http://www.getluky.net/freetag/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Freetag</a><span> is a php &ldquo;library&rdquo; with which you can add tags to whatever object you like. It actually uses the &ldquo;toxi schema&rdquo;.</span></li>\\n<li><span>Hammy </span><a href=\\\"http://hellojoseph.com/tags-howto.php\\\" target=\\\"_blank\\\" rel=\\\"external\\\">gives an insight</a><span> how he did his tagging system with &ldquo;less DB and more code&rdquo; (that is: regular expressions), interesting!</span></li>\\n<li><span>Brad Choate </span><a href=\\\"http://bradchoate.com/weblog/2004/10/06/delicious\\\" target=\\\"_blank\\\" rel=\\\"external\\\">has got some ideas</a><span> which tag queries should be possible</span></li>\\n<li><span>Feedmaker has written </span><a href=\\\"http://blog.feedmarker.com/2005/04/26/tagging-in-mysql/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a sort of reply to this article</a></li>\\n</ul>\"},{\"title\":\"How to fix Jambox’ “static noise and no bluetooth sound” problem(includes soldering)\",\"date\":\"2012-07-21T13:07:00.000Z\",\"alias\":\"/post/37471161448/how-to-fix-jambox-static-noise-and-no-bluetooth\",\"_content\":\"\\n<img alt=\\\"fixed!\\\" src=\\\"http://i.imgur.com/ofR49.png\\\" style=\\\"float: right;\\\"></div>\\n\\nJambox is a pretty cool device: The sound quality is very good, it is small, it has a battery. I liked it. Until it broke. It just didn't play music over bluetooth any more but instead uttered static noise. This seems to be a quite severe production problem as <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/Static-and-dropping-bluetooth-My-customer-service-call/m-p/37461\\\">many</a> <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/td-p/6676\\\">many</a> <a href=\\\"http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU\\\">many</a> people have devices with the exact same problem. So going down the \\\"Jambox please replace my device\\\" way didn't sound promising to me. The possibility that the replacement device is broken as well is just too high.\\n\\nThe problem lies in the aux in port. The device thinks there's an aux cable plugged in and outputs the signal from the aux input when in fact it should play the bluetooth sound.\\n\\n<!-- more -->\\n\\nIn my <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">last post</a> I described the different easy-to-do solutions to this problem, but today I needed to implement the soldering solution because nothing else worked. Implementing this solution means tricking the Jambox to think there's no aux cable plugged in.\\n\\n<strong>Update</strong>: My initial soldering was working, but after the first recharge the fix stopped working. Might be that the soldering melted and if you are a solder pro this might work for you. Anyway. I personally ended up putting a <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">screw into the aux port</a>\\n\\n## What do you need?\\n\\n- a star shaped screw driver (aka torx)\\n- Soldering equipment\\n- being ok that the aux cable will never work again\\n- desparation to get this machine working again (I'm not sure how safe this is, being not used to that kind of stuff)\\n- and of course it will void your warranty\\n\\nI personally hate soldering, I'm not good at it, but still I managed to get my Jambox working agagin so I thought I'd share with the world:\\n\\n### How to disassemble\\n\\nThere's <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps\\\">a good video describing how it should be done</a> (I did it just with the screwdriver. No gloves and no other equipment.)<br>\\n  You need to follow the video until 5:00\\n\\n### What to solder?\\n\\n<img class=\\\"caption\\\" alt=\\\"the two contacts you need to bridge\\\" src=\\\"http://i.imgur.com/cAWlo.jpg\\\" />\\n\\n<strong>Update</strong>: David Choi <a href=\\\"http://www.youtube.com/watch?v=nd5nF2hSFHw&amp;feature=youtu.be\\\">has made a video</a> that shows very well which two contacts to solder. He claims that with good soldering skills you can achieve that both bluetooth and aux will still work.\\n\\nIt's pretty simple: Follow the aux port and where the end of the aux jack would be there are 2 metal contacts which need to be soldered together. Turn on the jambox and try to push the upper metal contact so the two metal pieces touch and you'll hear the bluetooth sound. Hearing the music should give you enough motivation now to go on. Now:\\n\\n- Turn off the Jambox\\n- Try to solder (it is tricky because the spot is hard to reach)\\n- Try if it has worked. If it worked, wait some time. Shake the bluetooth device to really go sure the soldering joint is good (first time I was so happy that it worked, I assembled the device again and then it didn't work because the soldering joint was flaky)\\n\\n### How to assemble\\n\\n<img class=\\\"caption\\\" src=\\\"http://i.imgur.com/8YeqZ.jpg\\\" alt=\\\"I needed to bend the two metal pieces at the end of the grid to be able to assemble it\\\" />\\n\\nAgain <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps&amp;t=10m40s\\\">follow the video starting from 10:40</a>\\n\\nI found the assembling the hardest part. In the end I needed to bend the small metal pieces of the grid to be able to put it back together (although I didn't follow the video so you might be more successful).\\n\\n### Happy listening\\n\\nMy Jambox is now up and running again since 24h. I'm very very happy that this little thing did the trick.\",\"source\":\"_posts/how-to-fix-jambox-static-noise.md\",\"raw\":\"---\\ntitle: How to fix Jambox’ “static noise and no bluetooth sound” problem(includes soldering)\\ntags:\\n  - jambox\\ndate: 2012-07-21 15:07:00\\nalias: /post/37471161448/how-to-fix-jambox-static-noise-and-no-bluetooth\\n---\\n\\n<img alt=\\\"fixed!\\\" src=\\\"http://i.imgur.com/ofR49.png\\\" style=\\\"float: right;\\\"></div>\\n\\nJambox is a pretty cool device: The sound quality is very good, it is small, it has a battery. I liked it. Until it broke. It just didn't play music over bluetooth any more but instead uttered static noise. This seems to be a quite severe production problem as <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/Static-and-dropping-bluetooth-My-customer-service-call/m-p/37461\\\">many</a> <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/td-p/6676\\\">many</a> <a href=\\\"http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU\\\">many</a> people have devices with the exact same problem. So going down the \\\"Jambox please replace my device\\\" way didn't sound promising to me. The possibility that the replacement device is broken as well is just too high.\\n\\nThe problem lies in the aux in port. The device thinks there's an aux cable plugged in and outputs the signal from the aux input when in fact it should play the bluetooth sound.\\n\\n<!-- more -->\\n\\nIn my <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">last post</a> I described the different easy-to-do solutions to this problem, but today I needed to implement the soldering solution because nothing else worked. Implementing this solution means tricking the Jambox to think there's no aux cable plugged in.\\n\\n<strong>Update</strong>: My initial soldering was working, but after the first recharge the fix stopped working. Might be that the soldering melted and if you are a solder pro this might work for you. Anyway. I personally ended up putting a <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">screw into the aux port</a>\\n\\n## What do you need?\\n\\n- a star shaped screw driver (aka torx)\\n- Soldering equipment\\n- being ok that the aux cable will never work again\\n- desparation to get this machine working again (I'm not sure how safe this is, being not used to that kind of stuff)\\n- and of course it will void your warranty\\n\\nI personally hate soldering, I'm not good at it, but still I managed to get my Jambox working agagin so I thought I'd share with the world:\\n\\n### How to disassemble\\n\\nThere's <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps\\\">a good video describing how it should be done</a> (I did it just with the screwdriver. No gloves and no other equipment.)<br>\\n  You need to follow the video until 5:00\\n\\n### What to solder?\\n\\n<img class=\\\"caption\\\" alt=\\\"the two contacts you need to bridge\\\" src=\\\"http://i.imgur.com/cAWlo.jpg\\\" />\\n\\n<strong>Update</strong>: David Choi <a href=\\\"http://www.youtube.com/watch?v=nd5nF2hSFHw&amp;feature=youtu.be\\\">has made a video</a> that shows very well which two contacts to solder. He claims that with good soldering skills you can achieve that both bluetooth and aux will still work.\\n\\nIt's pretty simple: Follow the aux port and where the end of the aux jack would be there are 2 metal contacts which need to be soldered together. Turn on the jambox and try to push the upper metal contact so the two metal pieces touch and you'll hear the bluetooth sound. Hearing the music should give you enough motivation now to go on. Now:\\n\\n- Turn off the Jambox\\n- Try to solder (it is tricky because the spot is hard to reach)\\n- Try if it has worked. If it worked, wait some time. Shake the bluetooth device to really go sure the soldering joint is good (first time I was so happy that it worked, I assembled the device again and then it didn't work because the soldering joint was flaky)\\n\\n### How to assemble\\n\\n<img class=\\\"caption\\\" src=\\\"http://i.imgur.com/8YeqZ.jpg\\\" alt=\\\"I needed to bend the two metal pieces at the end of the grid to be able to assemble it\\\" />\\n\\nAgain <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps&amp;t=10m40s\\\">follow the video starting from 10:40</a>\\n\\nI found the assembling the hardest part. In the end I needed to bend the small metal pieces of the grid to be able to put it back together (although I didn't follow the video so you might be more successful).\\n\\n### Happy listening\\n\\nMy Jambox is now up and running again since 24h. I'm very very happy that this little thing did the trick.\",\"slug\":\"how-to-fix-jambox-static-noise\",\"published\":1,\"updated\":\"2017-11-12T07:13:13.634Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon616001yi85pcjvsyi0b\",\"content\":\"<p><img alt=\\\"fixed!\\\" src=\\\"http://i.imgur.com/ofR49.png\\\" style=\\\"float: right;\\\"></p>\\n<p>Jambox is a pretty cool device: The sound quality is very good, it is small, it has a battery. I liked it. Until it broke. It just didn’t play music over bluetooth any more but instead uttered static noise. This seems to be a quite severe production problem as <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/Static-and-dropping-bluetooth-My-customer-service-call/m-p/37461\\\" target=\\\"_blank\\\" rel=\\\"external\\\">many</a> <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/td-p/6676\\\" target=\\\"_blank\\\" rel=\\\"external\\\">many</a> <a href=\\\"http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU\\\" target=\\\"_blank\\\" rel=\\\"external\\\">many</a> people have devices with the exact same problem. So going down the “Jambox please replace my device” way didn’t sound promising to me. The possibility that the replacement device is broken as well is just too high.</p>\\n<p>The problem lies in the aux in port. The device thinks there’s an aux cable plugged in and outputs the signal from the aux input when in fact it should play the bluetooth sound.</p>\\n<a id=\\\"more\\\"></a>\\n<p>In my <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">last post</a> I described the different easy-to-do solutions to this problem, but today I needed to implement the soldering solution because nothing else worked. Implementing this solution means tricking the Jambox to think there’s no aux cable plugged in.</p>\\n<p><strong>Update</strong>: My initial soldering was working, but after the first recharge the fix stopped working. Might be that the soldering melted and if you are a solder pro this might work for you. Anyway. I personally ended up putting a <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">screw into the aux port</a></p>\\n<h2 id=\\\"What-do-you-need\\\"><a href=\\\"#What-do-you-need\\\" class=\\\"headerlink\\\" title=\\\"What do you need?\\\"></a>What do you need?</h2><ul>\\n<li>a star shaped screw driver (aka torx)</li>\\n<li>Soldering equipment</li>\\n<li>being ok that the aux cable will never work again</li>\\n<li>desparation to get this machine working again (I’m not sure how safe this is, being not used to that kind of stuff)</li>\\n<li>and of course it will void your warranty</li>\\n</ul>\\n<p>I personally hate soldering, I’m not good at it, but still I managed to get my Jambox working agagin so I thought I’d share with the world:</p>\\n<h3 id=\\\"How-to-disassemble\\\"><a href=\\\"#How-to-disassemble\\\" class=\\\"headerlink\\\" title=\\\"How to disassemble\\\"></a>How to disassemble</h3><p>There’s <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a good video describing how it should be done</a> (I did it just with the screwdriver. No gloves and no other equipment.)<br><br>  You need to follow the video until 5:00</p>\\n<h3 id=\\\"What-to-solder\\\"><a href=\\\"#What-to-solder\\\" class=\\\"headerlink\\\" title=\\\"What to solder?\\\"></a>What to solder?</h3><p><img class=\\\"caption\\\" alt=\\\"the two contacts you need to bridge\\\" src=\\\"http://i.imgur.com/cAWlo.jpg\\\"></p>\\n<p><strong>Update</strong>: David Choi <a href=\\\"http://www.youtube.com/watch?v=nd5nF2hSFHw&amp;feature=youtu.be\\\" target=\\\"_blank\\\" rel=\\\"external\\\">has made a video</a> that shows very well which two contacts to solder. He claims that with good soldering skills you can achieve that both bluetooth and aux will still work.</p>\\n<p>It’s pretty simple: Follow the aux port and where the end of the aux jack would be there are 2 metal contacts which need to be soldered together. Turn on the jambox and try to push the upper metal contact so the two metal pieces touch and you’ll hear the bluetooth sound. Hearing the music should give you enough motivation now to go on. Now:</p>\\n<ul>\\n<li>Turn off the Jambox</li>\\n<li>Try to solder (it is tricky because the spot is hard to reach)</li>\\n<li>Try if it has worked. If it worked, wait some time. Shake the bluetooth device to really go sure the soldering joint is good (first time I was so happy that it worked, I assembled the device again and then it didn’t work because the soldering joint was flaky)</li>\\n</ul>\\n<h3 id=\\\"How-to-assemble\\\"><a href=\\\"#How-to-assemble\\\" class=\\\"headerlink\\\" title=\\\"How to assemble\\\"></a>How to assemble</h3><p><img class=\\\"caption\\\" src=\\\"http://i.imgur.com/8YeqZ.jpg\\\" alt=\\\"I needed to bend the two metal pieces at the end of the grid to be able to assemble it\\\"></p>\\n<p>Again <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps&amp;t=10m40s\\\" target=\\\"_blank\\\" rel=\\\"external\\\">follow the video starting from 10:40</a></p>\\n<p>I found the assembling the hardest part. In the end I needed to bend the small metal pieces of the grid to be able to put it back together (although I didn’t follow the video so you might be more successful).</p>\\n<h3 id=\\\"Happy-listening\\\"><a href=\\\"#Happy-listening\\\" class=\\\"headerlink\\\" title=\\\"Happy listening\\\"></a>Happy listening</h3><p>My Jambox is now up and running again since 24h. I’m very very happy that this little thing did the trick.</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img alt=\\\"fixed!\\\" src=\\\"http://i.imgur.com/ofR49.png\\\" style=\\\"float: right;\\\"></p>\\n<p>Jambox is a pretty cool device: The sound quality is very good, it is small, it has a battery. I liked it. Until it broke. It just didn’t play music over bluetooth any more but instead uttered static noise. This seems to be a quite severe production problem as <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/Static-and-dropping-bluetooth-My-customer-service-call/m-p/37461\\\" target=\\\"_blank\\\" rel=\\\"external\\\">many</a> <a href=\\\"http://forums.jawbone.com/t5/JAMBOX-Troubleshooting/jambox-static-and-airplay/td-p/6676\\\" target=\\\"_blank\\\" rel=\\\"external\\\">many</a> <a href=\\\"http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU\\\" target=\\\"_blank\\\" rel=\\\"external\\\">many</a> people have devices with the exact same problem. So going down the “Jambox please replace my device” way didn’t sound promising to me. The possibility that the replacement device is broken as well is just too high.</p>\\n<p>The problem lies in the aux in port. The device thinks there’s an aux cable plugged in and outputs the signal from the aux input when in fact it should play the bluetooth sound.</p>\",\"more\":\"<p>In my <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">last post</a> I described the different easy-to-do solutions to this problem, but today I needed to implement the soldering solution because nothing else worked. Implementing this solution means tricking the Jambox to think there’s no aux cable plugged in.</p>\\n<p><strong>Update</strong>: My initial soldering was working, but after the first recharge the fix stopped working. Might be that the soldering melted and if you are a solder pro this might work for you. Anyway. I personally ended up putting a <a href=\\\"http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/\\\">screw into the aux port</a></p>\\n<h2 id=\\\"What-do-you-need\\\"><a href=\\\"#What-do-you-need\\\" class=\\\"headerlink\\\" title=\\\"What do you need?\\\"></a>What do you need?</h2><ul>\\n<li>a star shaped screw driver (aka torx)</li>\\n<li>Soldering equipment</li>\\n<li>being ok that the aux cable will never work again</li>\\n<li>desparation to get this machine working again (I’m not sure how safe this is, being not used to that kind of stuff)</li>\\n<li>and of course it will void your warranty</li>\\n</ul>\\n<p>I personally hate soldering, I’m not good at it, but still I managed to get my Jambox working agagin so I thought I’d share with the world:</p>\\n<h3 id=\\\"How-to-disassemble\\\"><a href=\\\"#How-to-disassemble\\\" class=\\\"headerlink\\\" title=\\\"How to disassemble\\\"></a>How to disassemble</h3><p>There’s <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a good video describing how it should be done</a> (I did it just with the screwdriver. No gloves and no other equipment.)<br><br>  You need to follow the video until 5:00</p>\\n<h3 id=\\\"What-to-solder\\\"><a href=\\\"#What-to-solder\\\" class=\\\"headerlink\\\" title=\\\"What to solder?\\\"></a>What to solder?</h3><p><img class=\\\"caption\\\" alt=\\\"the two contacts you need to bridge\\\" src=\\\"http://i.imgur.com/cAWlo.jpg\\\"></p>\\n<p><strong>Update</strong>: David Choi <a href=\\\"http://www.youtube.com/watch?v=nd5nF2hSFHw&amp;feature=youtu.be\\\" target=\\\"_blank\\\" rel=\\\"external\\\">has made a video</a> that shows very well which two contacts to solder. He claims that with good soldering skills you can achieve that both bluetooth and aux will still work.</p>\\n<p>It’s pretty simple: Follow the aux port and where the end of the aux jack would be there are 2 metal contacts which need to be soldered together. Turn on the jambox and try to push the upper metal contact so the two metal pieces touch and you’ll hear the bluetooth sound. Hearing the music should give you enough motivation now to go on. Now:</p>\\n<ul>\\n<li>Turn off the Jambox</li>\\n<li>Try to solder (it is tricky because the spot is hard to reach)</li>\\n<li>Try if it has worked. If it worked, wait some time. Shake the bluetooth device to really go sure the soldering joint is good (first time I was so happy that it worked, I assembled the device again and then it didn’t work because the soldering joint was flaky)</li>\\n</ul>\\n<h3 id=\\\"How-to-assemble\\\"><a href=\\\"#How-to-assemble\\\" class=\\\"headerlink\\\" title=\\\"How to assemble\\\"></a>How to assemble</h3><p><img class=\\\"caption\\\" src=\\\"http://i.imgur.com/8YeqZ.jpg\\\" alt=\\\"I needed to bend the two metal pieces at the end of the grid to be able to assemble it\\\"></p>\\n<p>Again <a href=\\\"http://www.youtube.com/watch?v=X5APtwqtEps&amp;t=10m40s\\\" target=\\\"_blank\\\" rel=\\\"external\\\">follow the video starting from 10:40</a></p>\\n<p>I found the assembling the hardest part. In the end I needed to bend the small metal pieces of the grid to be able to put it back together (although I didn’t follow the video so you might be more successful).</p>\\n<h3 id=\\\"Happy-listening\\\"><a href=\\\"#Happy-listening\\\" class=\\\"headerlink\\\" title=\\\"Happy listening\\\"></a>Happy listening</h3><p>My Jambox is now up and running again since 24h. I’m very very happy that this little thing did the trick.</p>\"},{\"title\":\"Set timeout for a shell command in python\",\"date\":\"2007-02-18T17:04:00.000Z\",\"alias\":\"/post/37471155682/set-timeout-for-a-shell-command-in-python\",\"_content\":\"\\nI wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href=\\\"http://adplug.sourceforge.net/\\\">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href=\\\"http://www.python.net/crew/hooft/\\\">the \\\"task\\\" module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br>\\n\\n<!-- more -->\\n\\n```\\n  def timeout_command(command, timeout):\\n    \\\"\\\"\\\"call shell-command and either return its output or kill it\\n    if it doesn't normally exit within timeout seconds and return None\\\"\\\"\\\"\\n    import subprocess, datetime, os, time, signal\\n    start = datetime.datetime.now()\\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n    while process.poll() is None:\\n      time.sleep(0.1)\\n      now = datetime.datetime.now()\\n      if (now - start).seconds&gt; timeout:\\n        os.kill(process.pid, signal.SIGKILL)\\n        os.waitpid(-1, os.WNOHANG)\\n        return None\\n    return process.stdout.read()\\n```\\n\\nNote especially lines 6, 11 and 12.<br>Usage:\\n\\n\\n```\\n>>> output = timeout_command([\\\"sleep\\\", \\\"10\\\"], 2)\\nNone\\n>>> output = timeout_command([\\\"sleep\\\", \\\"1\\\"], 2)\\n```\\n\\nThe process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen'ed process' printed is caught and returned if it doesn't timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn't passed to a shell and furthermore you can just call one command with options, nothing more.\",\"source\":\"_posts/set-timeout-for-a-shell-command-in-python.md\",\"raw\":\"---\\ntitle: \\\"Set timeout for a shell command in python\\\"\\ntags:\\n  - python\\ndate: 2007-02-18 18:04:00\\nalias: /post/37471155682/set-timeout-for-a-shell-command-in-python\\n---\\n\\nI wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href=\\\"http://adplug.sourceforge.net/\\\">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href=\\\"http://www.python.net/crew/hooft/\\\">the \\\"task\\\" module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br>\\n\\n<!-- more -->\\n\\n```\\n  def timeout_command(command, timeout):\\n    \\\"\\\"\\\"call shell-command and either return its output or kill it\\n    if it doesn't normally exit within timeout seconds and return None\\\"\\\"\\\"\\n    import subprocess, datetime, os, time, signal\\n    start = datetime.datetime.now()\\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n    while process.poll() is None:\\n      time.sleep(0.1)\\n      now = datetime.datetime.now()\\n      if (now - start).seconds&gt; timeout:\\n        os.kill(process.pid, signal.SIGKILL)\\n        os.waitpid(-1, os.WNOHANG)\\n        return None\\n    return process.stdout.read()\\n```\\n\\nNote especially lines 6, 11 and 12.<br>Usage:\\n\\n\\n```\\n>>> output = timeout_command([\\\"sleep\\\", \\\"10\\\"], 2)\\nNone\\n>>> output = timeout_command([\\\"sleep\\\", \\\"1\\\"], 2)\\n```\\n\\nThe process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen'ed process' printed is caught and returned if it doesn't timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn't passed to a shell and furthermore you can just call one command with options, nothing more.\",\"slug\":\"set-timeout-for-a-shell-command-in-python\",\"published\":1,\"updated\":\"2017-11-11T21:11:20.003Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6170020i85puhcl2q0i\",\"content\":\"<p>I wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href=\\\"http://adplug.sourceforge.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href=\\\"http://www.python.net/crew/hooft/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">the “task” module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br></p>\\n<a id=\\\"more\\\"></a>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">def timeout_command(command, timeout):</span><br><span class=\\\"line\\\">  &quot;&quot;&quot;call shell-command and either return its output or kill it</span><br><span class=\\\"line\\\">  if it doesn&apos;t normally exit within timeout seconds and return None&quot;&quot;&quot;</span><br><span class=\\\"line\\\">  import subprocess, datetime, os, time, signal</span><br><span class=\\\"line\\\">  start = datetime.datetime.now()</span><br><span class=\\\"line\\\">  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class=\\\"line\\\">  while process.poll() is None:</span><br><span class=\\\"line\\\">    time.sleep(0.1)</span><br><span class=\\\"line\\\">    now = datetime.datetime.now()</span><br><span class=\\\"line\\\">    if (now - start).seconds&amp;gt; timeout:</span><br><span class=\\\"line\\\">      os.kill(process.pid, signal.SIGKILL)</span><br><span class=\\\"line\\\">      os.waitpid(-1, os.WNOHANG)</span><br><span class=\\\"line\\\">      return None</span><br><span class=\\\"line\\\">  return process.stdout.read()</span><br></pre></td></tr></table></figure>\\n<p>Note especially lines 6, 11 and 12.<br>Usage:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;10&quot;], 2)</span><br><span class=\\\"line\\\">None</span><br><span class=\\\"line\\\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;1&quot;], 2)</span><br></pre></td></tr></table></figure>\\n<p>The process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen’ed process’ printed is caught and returned if it doesn’t timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn’t passed to a shell and furthermore you can just call one command with options, nothing more.</p>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>I wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href=\\\"http://adplug.sourceforge.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href=\\\"http://www.python.net/crew/hooft/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">the “task” module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br></p>\",\"more\":\"<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br><span class=\\\"line\\\">4</span><br><span class=\\\"line\\\">5</span><br><span class=\\\"line\\\">6</span><br><span class=\\\"line\\\">7</span><br><span class=\\\"line\\\">8</span><br><span class=\\\"line\\\">9</span><br><span class=\\\"line\\\">10</span><br><span class=\\\"line\\\">11</span><br><span class=\\\"line\\\">12</span><br><span class=\\\"line\\\">13</span><br><span class=\\\"line\\\">14</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">def timeout_command(command, timeout):</span><br><span class=\\\"line\\\">  &quot;&quot;&quot;call shell-command and either return its output or kill it</span><br><span class=\\\"line\\\">  if it doesn&apos;t normally exit within timeout seconds and return None&quot;&quot;&quot;</span><br><span class=\\\"line\\\">  import subprocess, datetime, os, time, signal</span><br><span class=\\\"line\\\">  start = datetime.datetime.now()</span><br><span class=\\\"line\\\">  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class=\\\"line\\\">  while process.poll() is None:</span><br><span class=\\\"line\\\">    time.sleep(0.1)</span><br><span class=\\\"line\\\">    now = datetime.datetime.now()</span><br><span class=\\\"line\\\">    if (now - start).seconds&amp;gt; timeout:</span><br><span class=\\\"line\\\">      os.kill(process.pid, signal.SIGKILL)</span><br><span class=\\\"line\\\">      os.waitpid(-1, os.WNOHANG)</span><br><span class=\\\"line\\\">      return None</span><br><span class=\\\"line\\\">  return process.stdout.read()</span><br></pre></td></tr></table></figure>\\n<p>Note especially lines 6, 11 and 12.<br>Usage:</p>\\n<figure class=\\\"highlight plain\\\"><table><tr><td class=\\\"gutter\\\"><pre><span class=\\\"line\\\">1</span><br><span class=\\\"line\\\">2</span><br><span class=\\\"line\\\">3</span><br></pre></td><td class=\\\"code\\\"><pre><span class=\\\"line\\\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;10&quot;], 2)</span><br><span class=\\\"line\\\">None</span><br><span class=\\\"line\\\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;1&quot;], 2)</span><br></pre></td></tr></table></figure>\\n<p>The process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen’ed process’ printed is caught and returned if it doesn’t timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn’t passed to a shell and furthermore you can just call one command with options, nothing more.</p>\"},{\"title\":\"How to migrate your wordpress to tumblr. Including images and comments.\",\"date\":\"2012-12-14T10:37:00.000Z\",\"alias\":\"/post/37850192094/how-to-migrate-your-wordpress-to-tumblr-including\",\"_content\":\"\\n![](https://lh3.googleusercontent.com/-Pn-aBqMjq9g/UMpMLdyLsgI/AAAAAAAALe0/zbopqqnD77M/s300/wordpresstumblr.jpg)So I&rsquo;ve decided to move my wordpress blogs to tumblr. Although apparently TechCrunch [thinks that&rsquo;s a bad idea](http://techcrunch.com/2010/09/18/stuff-white-person-doesnt-like/). And although [Moritz Adler](https://twitter.com/moritzadler) would kill me for that. (Although: He doesn&rsquo;t have a personal blog and hence has no licence to kill me). Anyway. With tumblr I don&rsquo;t need to host a blog software myself. And I don&rsquo;t end up having my blog hacked and then seeing my blog being displayed as a malware site in Chrome/Firefox (happened to me twice). And then with tumblr I create new blogs with subdomains within minutes. Cool stuff. Hail to the cloud, baby!\\n\\nSo here you go: A complete guide how to fully migrate your wordpress blog to tumblr. Including comments and pictures. And still supporting your old url scheme.\\n\\n**Update:** I ran into a tool that claims to do a lot for you: [import2.com/tumblr](http://www.import2.com/tumblr). It doesn&rsquo;t migrate images and 302 redirects. Not sure about comments migration. And it costs 24$. Still, if you can leave out some of the steps below that&rsquo;d be worth the money. [Comments of the author on quora](http://www.quora.com/Mark-Kofman/answers/Tumblr)\\n\\n<!-- more -->\\n\\n## Before you start\\n\\nBefore you start to actually move your blog, you need to consider a few things:\\n\\n### Where do you move your **DNS** to?\\n\\nIf you have a wordpress webhost, then this webhost most probably also does DNS for you. You need to replace that by a third party solution. I think these are good services:\\n\\n*   [he.net](https://dns.he.net/). Free service. No strings attached. The one I&rsquo;ve chosen. The interface is nice and very easy to add new CNAMES, MX records, etc. The uptime was [reported to be not so good](http://www.lowendtalk.com/discussion/262/which-dns-site-to-use-for-domains#Comment_3800), but I don&rsquo;t really care about uptime of my blogs. To host your tumblr blog on your domain, you add a `CNAME` to `domains.tumblr.com` and then configure your tumblr blog to listen to that domain. Very simple.\\n*   [Amazon Route 53](http://aws.amazon.com/route53/): They charge you $0.50 per hosted zone per month. That&rsquo;s a fair price and probably has a better uptime then he.net\\n\\n### What do you want to do with your **images**?\\n\\nAt default they&rsquo;re all located under `[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)`. To completely get rid of your old web host you need to move those to a different image hoster. I don&rsquo;t advice you to upload it to tumblr because if in future you want to move away from tumblr you run into the same problem again.\\n\\n### Would you like to keep your **comments**?\\n\\nDo you have comments at all? Tumblr doesn&rsquo;t support comments by itself. Most themes have disqus support. Moving comments to disqus is no big deal, but still it&rsquo;s some work, so you may decide to just not migrate comments.\\n\\n### Are you keen to not break your **old blog urls**?\\n\\nWordpress&rsquo; url scheme generally is e.g. `code.pui.ch/2007/01/05/print-hello-world/`.\\nThat same post ends up at this tumblr url: `howto.pui.ch/post/37471154429/print-hello-world`. Note that the last part of the url is optional, i.e. `howto.pui.ch/post/37471154429` works as well.\\nIf you care about incoming links to your blog not to break and if you care about your google ranking (I guess 302 redirects inherit the google ranking), there are two possibilities:\\n\\n1.  Stay on the same domain, handle the redirects in tumblr (tumblr supports that with the pages&rsquo; type &ldquo;redirect&rdquo;)\\n2.  Move to a different domain and put up e.g. `redirect permanent` in a .htaccess file on your web server\\n\\n## A rough outline of what you&rsquo;re up to\\n\\nAt a glance, that what you&rsquo;ll do:\\n\\n1.  Upload your images to a different hoster (if you want to get rid of your old webhost)\\n2.  Extract all blog posts+comment from wordpress\\n3.  Fix the export.xml: Replace images, more-tags and fix some additional stuff\\n4.  Migrate your wordpress blog to blogger\\n5.  Migrate your blogger blog to tumblr\\n6.  Install http redirects (on old webhost or on tumblr)\\n7.  Migrate your comments to disqus\\n8.  Clean up blog posts (might be a biggie if you&rsquo;re a perfectionist)\\n\\nAlright, let&rsquo;s specify those 8 steps.\\n\\n## Step 1: Upload your images to a different hoster\\n\\nIf you&rsquo;re ok with keeping your old webhost you can skip this point. Easiest thing to do would be to copy your wp-content directory one to one to a different hoster so `[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)` turns into `[www.imagehoster.com/my_user_name/img1.jpg](http://www.imagehoster.com/my_user_name/img1.jpg)`.\\n\\nI don&rsquo;t have experience with image hosting providers so I just uploaded my images to picasa, but that meant I needed to update every single image in all my blog posts to the new image url of picasa. That was quite a pain. I couldn&rsquo;t find a image hoster yet who meets the criterias above. Photobucket doesn&rsquo;t, Dropbox doesn&rsquo;t, Google Drive doesn&rsquo;t. Maybe Amazon S3\\n\\n## Step 2: Extract your blog posts+comment from wordpress\\n\\n1.  In your wordpress admin go to Tools → Export. On my blog that was `code.pui.ch/wp-admin/export.php`.\\n2.  Choose `All content`, `Download Export File`.\\n\\n## Step 3: Fix the export.xml\\n\\nYou have just downloaded an xml file, in my case the name was `coderandom.wordpress.2012-12-13.xml`. Open that file with your favourite text editor. Now you need to do a few things before you can go on:\\n\\n1.  Replace all &lt;!&ndash;more&ndash;&gt; by <span>[[</span>MORE<span>]]</span>. The uppercase actually matters. <span>[[</span>MORE<span>]]</span> is the divider that tumblr actually understands as the place where you want your excerpt to stop in the blog overview view.\\n2.  Replace all images by the new urls you got by uploading the images to the image hoster in step 1\\\\. It&rsquo;s much easier to do this at this stage than to replace the images once you&rsquo;ve migrated your blog to tumblr.\\n3.  You may have more wordpress plugins you used in your posts. I used `[python]...[/python]` to syntax highlight my python markup. I&rsquo;ve moved to [google code prettify](http://code.google.com/p/google-code-prettify/) which needs `&lt;pre class=\\\"prettyprint\\\"&gt;...&lt;/pre&gt;` as a syntax. So I needed to replace all occurrences by the new markup. Obviously, regex is your friend at this stage.\\n\\n## Step 4: Migrate your wordpress blog to blogger\\n\\nUnfortunately there&rsquo;s no direct way to directly import this xml file into tumblr. Instead, that&rsquo;s what you need to do:\\n\\n1.  **Convert** your xml file [on this website](http://wordpress2blogger.appspot.com/) to a file fit for importing into blogger.\\n\\n      This doesn&rsquo;t work for files bigger than 1MB. If that&rsquo;s the case then you can either convert the file on your own machine using [this sourcecode on google code](http://code.google.com/p/google-blog-converters-appengine/). Or you can follow the [instructions under step 3 on this blog post.](http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/)\\n2.  **Create a new blog** on [blogger.com](http://www.blogger.com).\\n3.  In blogger navigate to your new blog and do settings → other settings → **import blog**\\n4.  **Publish** all blog posts: Posts → All → Select all → Publish\\n\\nIf you have difficulties in this step you might try a different solution (didn&rsquo;t try any of these):\\n\\n*   [ideashowers PHP script on github](https://github.com/ideashower/Export-Wordpress-posts-to-Tumblr)\\n*   [Dave Lartigues php script (plus explanations)](http://www.daveexmachina.com/wordpress/?p=5974)\\n*   [Darshan Bavarians PHP script](http://dbavaria.tumblr.com/post/28193913/wp2tumblr-transfer-your-blog-from-wordpress-to-tumblr)\\n*   [shakefons php script](http://snipplr.com/view/14609/migrate-wordpress-to-tumblr/)\\n\\n## Step 5: Migrate your blogger blog to tumblr\\n\\n1.  Go to [bloggertotumblr.com](http://www.bloggertotumblr.com/) and enter your url for your newly created blogger and tumblr blogs. The conversion is very straight forward.\\n2.  Delete your blogger blog\\n3.  Enjoy. Your blog posts are now on tumblr. Still missing: Support of the old url scheme and comments\\n\\n## Step 6: Install http redirects (on old webhost or on tumblr)\\n\\nIn the section [before you start](#beforeyoustart) I asked you to decide if you&rsquo;re ok to break your old urls. If you don&rsquo;t care, then skip this step. Although: if you care about keeping your comments then you still might to do this step, as it makes migrating comments to disqus a lot easier\\n\\nIf you do care, then:\\n\\n*   If you keep the domain of your blog: You need to install tumblr redirect pages. See below.\\n*   If you changed the domain of your blog: You need to install redirects on your former wordpress webhost. I describe how this is done via .htaccess config below\\n\\n### Install tumblr redirect pages\\n\\n1.  go to your new tumblr blog\\n2.  click customize top right\\n3.  add a page (left column)\\n4.  instead of &ldquo;Standard Layout&rdquo; choose &ldquo;Redirect&rdquo; and add a posts&rsquo; old url on top, and the new url on bottom. Repeat this for every blog posts (yeah, lots of work here)\\n\\n### Install .htaccess on your old webhost\\n\\nIMO that&rsquo;s a bit simpler than installing a tumblr redirect for every blog post. Still it&rsquo;s a lot of work since you need to come up with a map of old_url → new_url for every blog post. If your webhost supports .htaccess then go for this method. Most probably you have such a file already for your wordpress installation.\\n\\nAn example of a .htaccess file:\\n\\n<pre>\\n  RewriteEngine On\\n  Redirect permanent /page/2/ [http://howto.pui.ch/page/2](http://howto.pui.ch/page/2)\\n  Redirect permanent /feed/ [http://howto.pui.ch/rss](http://howto.pui.ch/rss)\\n  RewriteRule ^$ [http://howto.pui.ch/](http://howto.pui.ch/) [R=301,L]\\n  Redirect permanent /2007/02/25/add-bandwidth-to-a-file-download-in-python/ [http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python](http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python)\\n  Redirect permanent /2007/06/08/python-find-out-cpu-time-of-a-certain-process/ [http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process](http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process)\\n  Redirect permanent /2007/07/23/python-sort-a-list-of-dicts-by-dict-key/ [http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key](http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key)\\n  Redirect permanent /2009/12/30/dealing-with-mysql-backend-does-not-support-timezone-aware-datetimes/ [http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support](http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support)\\n  Redirect permanent /2011/01/19/python-easy-way-to-show-progress/ [http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress](http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress)\\n  Redirect permanent /2012/07/17/how-to-detect-a-files-character-encoding/ [http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding](http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding)\\n  Redirect permanent /2010/04/04/python-display-refreshing-status-like-top/ [http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top](http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top)\\n  Redirect permanent /2011/11/03/how-to-switch-gnu-screen-windows-in-iterm2-via-keyboard-shortcuts/ [http://howto.pui.ch/404](http://howto.pui.ch/404)\\n  Redirect permanent /2007/01/19/sched-20-pizza-is-ready/ [http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready](http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready)\\n</pre>\\n\\nNote the first 3 lines, you will need the same for your redirects. Note the special syntax of line 3\\\\. That is important to not redirect a non existing url to the new domain.\\n\\n#### Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?\\n\\nUh, yes. Alternatively, you can move to a free hoster like google apps engine and e.g. [use this](http://blog.dantup.com/2010/01/generic-redirection-script-for-google-app-engine) to redirect. Or you just wait a few months and wait until all search engines have digested your redirects and kill your old webhost only then (that&rsquo;s what I&rsquo;m probably gonna do).\\n\\n## Step 7: Migrate your comments to disqus\\n\\nBecause tumblr doesn&rsquo;t offer comments by itself you need to migrate your comments to disqus:\\n\\n1.  [Register](http://disqus.com/admin/register/) your new tumblr blog url at disqus\\n2.  On disqus go to `Admin` → `Tools` → `Import/Export` → `Upload WXR`. Choose the XML file you downloaded from your wordpress installation (not that got converted for blogger). Upload that\\n3.  On the same page go to `Migrate Threads`. Choose &ldquo;Redirect crawler&rdquo; if you installed the redirects in step 6\\\\. Otherwise you need to use the &ldquo;Upload a URL map&rdquo; option\\n\\nVoilà! After a few minutes your comments should appear in your new tumblr blog.\\n\\n## Step 8: Clean up your tumblr posts\\n\\nMight be that the html markup of my wordpress posts were so bad, but I needed to fix a lot of spacing between paragraphs. I also had some CSS tweaks to right align the images which I needed to fix.\\n\\nLastly, blogger adds these paragraphs to the end of every blog post:\\n\\n<pre>\\n  &lt;div class=\\\"blogger-post-footer\\\"&gt;\\n    &lt;img alt=\\\"\\\" height=\\\"1\\\" src=\\\"https://blogger.googleusercontent.com/tracker/290349385069691835-5946149615494229188?l=coderandomm.blogspot.com\\\" width=\\\"1\\\"&gt;\\n  &lt;/div&gt;\\n</pre>\\n\\nIf you are a perfectionist you may want to remove this markup from every blog post.\\n\\nA word of caution: You can spend a lot of time at this step if you overdo it.\\n\\n## Thanks\\n\\n*   Thanks to **MG Siegler** (one of my favourite bloggers, although he is an Apple fanboy and I am a google disciple): He showed me that you can [perfectly write long blog posts on tumblr](http://parislemon.com/post/15604811641/why-i-hate-android) (that linked article is actually a must read about Android vs. iPhone)\\n*   **Julio Angel Ortiz**, who&rsquo;s [article](http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/) served as the base for this howto.\\n*   **TextMate** for making html editing so easy. Just found out that it&rsquo;s actually a pretty decent HTML editor. I&rsquo;ll write my blog posts in here and only then past them into the tiny tumblr HTML editor popup.\",\"source\":\"_posts/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments.md\",\"raw\":\"---\\ntitle: How to migrate your wordpress to tumblr. Including images and comments.\\ntags:\\n  - wordpress-to-tumblr\\n  - wordpress\\n  - tumblr\\n  - migration\\ndate: 2012-12-14 11:37:00\\nalias: /post/37850192094/how-to-migrate-your-wordpress-to-tumblr-including\\n---\\n\\n![](https://lh3.googleusercontent.com/-Pn-aBqMjq9g/UMpMLdyLsgI/AAAAAAAALe0/zbopqqnD77M/s300/wordpresstumblr.jpg)So I&rsquo;ve decided to move my wordpress blogs to tumblr. Although apparently TechCrunch [thinks that&rsquo;s a bad idea](http://techcrunch.com/2010/09/18/stuff-white-person-doesnt-like/). And although [Moritz Adler](https://twitter.com/moritzadler) would kill me for that. (Although: He doesn&rsquo;t have a personal blog and hence has no licence to kill me). Anyway. With tumblr I don&rsquo;t need to host a blog software myself. And I don&rsquo;t end up having my blog hacked and then seeing my blog being displayed as a malware site in Chrome/Firefox (happened to me twice). And then with tumblr I create new blogs with subdomains within minutes. Cool stuff. Hail to the cloud, baby!\\n\\nSo here you go: A complete guide how to fully migrate your wordpress blog to tumblr. Including comments and pictures. And still supporting your old url scheme.\\n\\n**Update:** I ran into a tool that claims to do a lot for you: [import2.com/tumblr](http://www.import2.com/tumblr). It doesn&rsquo;t migrate images and 302 redirects. Not sure about comments migration. And it costs 24$. Still, if you can leave out some of the steps below that&rsquo;d be worth the money. [Comments of the author on quora](http://www.quora.com/Mark-Kofman/answers/Tumblr)\\n\\n<!-- more -->\\n\\n## Before you start\\n\\nBefore you start to actually move your blog, you need to consider a few things:\\n\\n### Where do you move your **DNS** to?\\n\\nIf you have a wordpress webhost, then this webhost most probably also does DNS for you. You need to replace that by a third party solution. I think these are good services:\\n\\n*   [he.net](https://dns.he.net/). Free service. No strings attached. The one I&rsquo;ve chosen. The interface is nice and very easy to add new CNAMES, MX records, etc. The uptime was [reported to be not so good](http://www.lowendtalk.com/discussion/262/which-dns-site-to-use-for-domains#Comment_3800), but I don&rsquo;t really care about uptime of my blogs. To host your tumblr blog on your domain, you add a `CNAME` to `domains.tumblr.com` and then configure your tumblr blog to listen to that domain. Very simple.\\n*   [Amazon Route 53](http://aws.amazon.com/route53/): They charge you $0.50 per hosted zone per month. That&rsquo;s a fair price and probably has a better uptime then he.net\\n\\n### What do you want to do with your **images**?\\n\\nAt default they&rsquo;re all located under `[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)`. To completely get rid of your old web host you need to move those to a different image hoster. I don&rsquo;t advice you to upload it to tumblr because if in future you want to move away from tumblr you run into the same problem again.\\n\\n### Would you like to keep your **comments**?\\n\\nDo you have comments at all? Tumblr doesn&rsquo;t support comments by itself. Most themes have disqus support. Moving comments to disqus is no big deal, but still it&rsquo;s some work, so you may decide to just not migrate comments.\\n\\n### Are you keen to not break your **old blog urls**?\\n\\nWordpress&rsquo; url scheme generally is e.g. `code.pui.ch/2007/01/05/print-hello-world/`.\\nThat same post ends up at this tumblr url: `howto.pui.ch/post/37471154429/print-hello-world`. Note that the last part of the url is optional, i.e. `howto.pui.ch/post/37471154429` works as well.\\nIf you care about incoming links to your blog not to break and if you care about your google ranking (I guess 302 redirects inherit the google ranking), there are two possibilities:\\n\\n1.  Stay on the same domain, handle the redirects in tumblr (tumblr supports that with the pages&rsquo; type &ldquo;redirect&rdquo;)\\n2.  Move to a different domain and put up e.g. `redirect permanent` in a .htaccess file on your web server\\n\\n## A rough outline of what you&rsquo;re up to\\n\\nAt a glance, that what you&rsquo;ll do:\\n\\n1.  Upload your images to a different hoster (if you want to get rid of your old webhost)\\n2.  Extract all blog posts+comment from wordpress\\n3.  Fix the export.xml: Replace images, more-tags and fix some additional stuff\\n4.  Migrate your wordpress blog to blogger\\n5.  Migrate your blogger blog to tumblr\\n6.  Install http redirects (on old webhost or on tumblr)\\n7.  Migrate your comments to disqus\\n8.  Clean up blog posts (might be a biggie if you&rsquo;re a perfectionist)\\n\\nAlright, let&rsquo;s specify those 8 steps.\\n\\n## Step 1: Upload your images to a different hoster\\n\\nIf you&rsquo;re ok with keeping your old webhost you can skip this point. Easiest thing to do would be to copy your wp-content directory one to one to a different hoster so `[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)` turns into `[www.imagehoster.com/my_user_name/img1.jpg](http://www.imagehoster.com/my_user_name/img1.jpg)`.\\n\\nI don&rsquo;t have experience with image hosting providers so I just uploaded my images to picasa, but that meant I needed to update every single image in all my blog posts to the new image url of picasa. That was quite a pain. I couldn&rsquo;t find a image hoster yet who meets the criterias above. Photobucket doesn&rsquo;t, Dropbox doesn&rsquo;t, Google Drive doesn&rsquo;t. Maybe Amazon S3\\n\\n## Step 2: Extract your blog posts+comment from wordpress\\n\\n1.  In your wordpress admin go to Tools → Export. On my blog that was `code.pui.ch/wp-admin/export.php`.\\n2.  Choose `All content`, `Download Export File`.\\n\\n## Step 3: Fix the export.xml\\n\\nYou have just downloaded an xml file, in my case the name was `coderandom.wordpress.2012-12-13.xml`. Open that file with your favourite text editor. Now you need to do a few things before you can go on:\\n\\n1.  Replace all &lt;!&ndash;more&ndash;&gt; by <span>[[</span>MORE<span>]]</span>. The uppercase actually matters. <span>[[</span>MORE<span>]]</span> is the divider that tumblr actually understands as the place where you want your excerpt to stop in the blog overview view.\\n2.  Replace all images by the new urls you got by uploading the images to the image hoster in step 1\\\\. It&rsquo;s much easier to do this at this stage than to replace the images once you&rsquo;ve migrated your blog to tumblr.\\n3.  You may have more wordpress plugins you used in your posts. I used `[python]...[/python]` to syntax highlight my python markup. I&rsquo;ve moved to [google code prettify](http://code.google.com/p/google-code-prettify/) which needs `&lt;pre class=\\\"prettyprint\\\"&gt;...&lt;/pre&gt;` as a syntax. So I needed to replace all occurrences by the new markup. Obviously, regex is your friend at this stage.\\n\\n## Step 4: Migrate your wordpress blog to blogger\\n\\nUnfortunately there&rsquo;s no direct way to directly import this xml file into tumblr. Instead, that&rsquo;s what you need to do:\\n\\n1.  **Convert** your xml file [on this website](http://wordpress2blogger.appspot.com/) to a file fit for importing into blogger.\\n\\n      This doesn&rsquo;t work for files bigger than 1MB. If that&rsquo;s the case then you can either convert the file on your own machine using [this sourcecode on google code](http://code.google.com/p/google-blog-converters-appengine/). Or you can follow the [instructions under step 3 on this blog post.](http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/)\\n2.  **Create a new blog** on [blogger.com](http://www.blogger.com).\\n3.  In blogger navigate to your new blog and do settings → other settings → **import blog**\\n4.  **Publish** all blog posts: Posts → All → Select all → Publish\\n\\nIf you have difficulties in this step you might try a different solution (didn&rsquo;t try any of these):\\n\\n*   [ideashowers PHP script on github](https://github.com/ideashower/Export-Wordpress-posts-to-Tumblr)\\n*   [Dave Lartigues php script (plus explanations)](http://www.daveexmachina.com/wordpress/?p=5974)\\n*   [Darshan Bavarians PHP script](http://dbavaria.tumblr.com/post/28193913/wp2tumblr-transfer-your-blog-from-wordpress-to-tumblr)\\n*   [shakefons php script](http://snipplr.com/view/14609/migrate-wordpress-to-tumblr/)\\n\\n## Step 5: Migrate your blogger blog to tumblr\\n\\n1.  Go to [bloggertotumblr.com](http://www.bloggertotumblr.com/) and enter your url for your newly created blogger and tumblr blogs. The conversion is very straight forward.\\n2.  Delete your blogger blog\\n3.  Enjoy. Your blog posts are now on tumblr. Still missing: Support of the old url scheme and comments\\n\\n## Step 6: Install http redirects (on old webhost or on tumblr)\\n\\nIn the section [before you start](#beforeyoustart) I asked you to decide if you&rsquo;re ok to break your old urls. If you don&rsquo;t care, then skip this step. Although: if you care about keeping your comments then you still might to do this step, as it makes migrating comments to disqus a lot easier\\n\\nIf you do care, then:\\n\\n*   If you keep the domain of your blog: You need to install tumblr redirect pages. See below.\\n*   If you changed the domain of your blog: You need to install redirects on your former wordpress webhost. I describe how this is done via .htaccess config below\\n\\n### Install tumblr redirect pages\\n\\n1.  go to your new tumblr blog\\n2.  click customize top right\\n3.  add a page (left column)\\n4.  instead of &ldquo;Standard Layout&rdquo; choose &ldquo;Redirect&rdquo; and add a posts&rsquo; old url on top, and the new url on bottom. Repeat this for every blog posts (yeah, lots of work here)\\n\\n### Install .htaccess on your old webhost\\n\\nIMO that&rsquo;s a bit simpler than installing a tumblr redirect for every blog post. Still it&rsquo;s a lot of work since you need to come up with a map of old_url → new_url for every blog post. If your webhost supports .htaccess then go for this method. Most probably you have such a file already for your wordpress installation.\\n\\nAn example of a .htaccess file:\\n\\n<pre>\\n  RewriteEngine On\\n  Redirect permanent /page/2/ [http://howto.pui.ch/page/2](http://howto.pui.ch/page/2)\\n  Redirect permanent /feed/ [http://howto.pui.ch/rss](http://howto.pui.ch/rss)\\n  RewriteRule ^$ [http://howto.pui.ch/](http://howto.pui.ch/) [R=301,L]\\n  Redirect permanent /2007/02/25/add-bandwidth-to-a-file-download-in-python/ [http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python](http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python)\\n  Redirect permanent /2007/06/08/python-find-out-cpu-time-of-a-certain-process/ [http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process](http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process)\\n  Redirect permanent /2007/07/23/python-sort-a-list-of-dicts-by-dict-key/ [http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key](http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key)\\n  Redirect permanent /2009/12/30/dealing-with-mysql-backend-does-not-support-timezone-aware-datetimes/ [http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support](http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support)\\n  Redirect permanent /2011/01/19/python-easy-way-to-show-progress/ [http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress](http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress)\\n  Redirect permanent /2012/07/17/how-to-detect-a-files-character-encoding/ [http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding](http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding)\\n  Redirect permanent /2010/04/04/python-display-refreshing-status-like-top/ [http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top](http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top)\\n  Redirect permanent /2011/11/03/how-to-switch-gnu-screen-windows-in-iterm2-via-keyboard-shortcuts/ [http://howto.pui.ch/404](http://howto.pui.ch/404)\\n  Redirect permanent /2007/01/19/sched-20-pizza-is-ready/ [http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready](http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready)\\n</pre>\\n\\nNote the first 3 lines, you will need the same for your redirects. Note the special syntax of line 3\\\\. That is important to not redirect a non existing url to the new domain.\\n\\n#### Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?\\n\\nUh, yes. Alternatively, you can move to a free hoster like google apps engine and e.g. [use this](http://blog.dantup.com/2010/01/generic-redirection-script-for-google-app-engine) to redirect. Or you just wait a few months and wait until all search engines have digested your redirects and kill your old webhost only then (that&rsquo;s what I&rsquo;m probably gonna do).\\n\\n## Step 7: Migrate your comments to disqus\\n\\nBecause tumblr doesn&rsquo;t offer comments by itself you need to migrate your comments to disqus:\\n\\n1.  [Register](http://disqus.com/admin/register/) your new tumblr blog url at disqus\\n2.  On disqus go to `Admin` → `Tools` → `Import/Export` → `Upload WXR`. Choose the XML file you downloaded from your wordpress installation (not that got converted for blogger). Upload that\\n3.  On the same page go to `Migrate Threads`. Choose &ldquo;Redirect crawler&rdquo; if you installed the redirects in step 6\\\\. Otherwise you need to use the &ldquo;Upload a URL map&rdquo; option\\n\\nVoilà! After a few minutes your comments should appear in your new tumblr blog.\\n\\n## Step 8: Clean up your tumblr posts\\n\\nMight be that the html markup of my wordpress posts were so bad, but I needed to fix a lot of spacing between paragraphs. I also had some CSS tweaks to right align the images which I needed to fix.\\n\\nLastly, blogger adds these paragraphs to the end of every blog post:\\n\\n<pre>\\n  &lt;div class=\\\"blogger-post-footer\\\"&gt;\\n    &lt;img alt=\\\"\\\" height=\\\"1\\\" src=\\\"https://blogger.googleusercontent.com/tracker/290349385069691835-5946149615494229188?l=coderandomm.blogspot.com\\\" width=\\\"1\\\"&gt;\\n  &lt;/div&gt;\\n</pre>\\n\\nIf you are a perfectionist you may want to remove this markup from every blog post.\\n\\nA word of caution: You can spend a lot of time at this step if you overdo it.\\n\\n## Thanks\\n\\n*   Thanks to **MG Siegler** (one of my favourite bloggers, although he is an Apple fanboy and I am a google disciple): He showed me that you can [perfectly write long blog posts on tumblr](http://parislemon.com/post/15604811641/why-i-hate-android) (that linked article is actually a must read about Android vs. iPhone)\\n*   **Julio Angel Ortiz**, who&rsquo;s [article](http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/) served as the base for this howto.\\n*   **TextMate** for making html editing so easy. Just found out that it&rsquo;s actually a pretty decent HTML editor. I&rsquo;ll write my blog posts in here and only then past them into the tiny tumblr HTML editor popup.\",\"slug\":\"How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments\",\"published\":1,\"updated\":\"2017-11-11T21:14:04.026Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6180023i85pl4ddyb3o\",\"content\":\"<p><img src=\\\"https://lh3.googleusercontent.com/-Pn-aBqMjq9g/UMpMLdyLsgI/AAAAAAAALe0/zbopqqnD77M/s300/wordpresstumblr.jpg\\\" alt=\\\"\\\">So I&rsquo;ve decided to move my wordpress blogs to tumblr. Although apparently TechCrunch <a href=\\\"http://techcrunch.com/2010/09/18/stuff-white-person-doesnt-like/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">thinks that&rsquo;s a bad idea</a>. And although <a href=\\\"https://twitter.com/moritzadler\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Moritz Adler</a> would kill me for that. (Although: He doesn&rsquo;t have a personal blog and hence has no licence to kill me). Anyway. With tumblr I don&rsquo;t need to host a blog software myself. And I don&rsquo;t end up having my blog hacked and then seeing my blog being displayed as a malware site in Chrome/Firefox (happened to me twice). And then with tumblr I create new blogs with subdomains within minutes. Cool stuff. Hail to the cloud, baby!</p>\\n<p>So here you go: A complete guide how to fully migrate your wordpress blog to tumblr. Including comments and pictures. And still supporting your old url scheme.</p>\\n<p><strong>Update:</strong> I ran into a tool that claims to do a lot for you: <a href=\\\"http://www.import2.com/tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">import2.com/tumblr</a>. It doesn&rsquo;t migrate images and 302 redirects. Not sure about comments migration. And it costs 24$. Still, if you can leave out some of the steps below that&rsquo;d be worth the money. <a href=\\\"http://www.quora.com/Mark-Kofman/answers/Tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Comments of the author on quora</a></p>\\n<a id=\\\"more\\\"></a>\\n<h2 id=\\\"Before-you-start\\\"><a href=\\\"#Before-you-start\\\" class=\\\"headerlink\\\" title=\\\"Before you start\\\"></a>Before you start</h2><p>Before you start to actually move your blog, you need to consider a few things:</p>\\n<h3 id=\\\"Where-do-you-move-your-DNS-to\\\"><a href=\\\"#Where-do-you-move-your-DNS-to\\\" class=\\\"headerlink\\\" title=\\\"Where do you move your DNS to?\\\"></a>Where do you move your <strong>DNS</strong> to?</h3><p>If you have a wordpress webhost, then this webhost most probably also does DNS for you. You need to replace that by a third party solution. I think these are good services:</p>\\n<ul>\\n<li><a href=\\\"https://dns.he.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">he.net</a>. Free service. No strings attached. The one I&rsquo;ve chosen. The interface is nice and very easy to add new CNAMES, MX records, etc. The uptime was <a href=\\\"http://www.lowendtalk.com/discussion/262/which-dns-site-to-use-for-domains#Comment_3800\\\" target=\\\"_blank\\\" rel=\\\"external\\\">reported to be not so good</a>, but I don&rsquo;t really care about uptime of my blogs. To host your tumblr blog on your domain, you add a <code>CNAME</code> to <code>domains.tumblr.com</code> and then configure your tumblr blog to listen to that domain. Very simple.</li>\\n<li><a href=\\\"http://aws.amazon.com/route53/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Amazon Route 53</a>: They charge you $0.50 per hosted zone per month. That&rsquo;s a fair price and probably has a better uptime then he.net</li>\\n</ul>\\n<h3 id=\\\"What-do-you-want-to-do-with-your-images\\\"><a href=\\\"#What-do-you-want-to-do-with-your-images\\\" class=\\\"headerlink\\\" title=\\\"What do you want to do with your images?\\\"></a>What do you want to do with your <strong>images</strong>?</h3><p>At default they&rsquo;re all located under <code>[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)</code>. To completely get rid of your old web host you need to move those to a different image hoster. I don&rsquo;t advice you to upload it to tumblr because if in future you want to move away from tumblr you run into the same problem again.</p>\\n<h3 id=\\\"Would-you-like-to-keep-your-comments\\\"><a href=\\\"#Would-you-like-to-keep-your-comments\\\" class=\\\"headerlink\\\" title=\\\"Would you like to keep your comments?\\\"></a>Would you like to keep your <strong>comments</strong>?</h3><p>Do you have comments at all? Tumblr doesn&rsquo;t support comments by itself. Most themes have disqus support. Moving comments to disqus is no big deal, but still it&rsquo;s some work, so you may decide to just not migrate comments.</p>\\n<h3 id=\\\"Are-you-keen-to-not-break-your-old-blog-urls\\\"><a href=\\\"#Are-you-keen-to-not-break-your-old-blog-urls\\\" class=\\\"headerlink\\\" title=\\\"Are you keen to not break your old blog urls?\\\"></a>Are you keen to not break your <strong>old blog urls</strong>?</h3><p>Wordpress&rsquo; url scheme generally is e.g. <code>code.pui.ch/2007/01/05/print-hello-world/</code>.<br>That same post ends up at this tumblr url: <code>howto.pui.ch/post/37471154429/print-hello-world</code>. Note that the last part of the url is optional, i.e. <code>howto.pui.ch/post/37471154429</code> works as well.<br>If you care about incoming links to your blog not to break and if you care about your google ranking (I guess 302 redirects inherit the google ranking), there are two possibilities:</p>\\n<ol>\\n<li>Stay on the same domain, handle the redirects in tumblr (tumblr supports that with the pages&rsquo; type &ldquo;redirect&rdquo;)</li>\\n<li>Move to a different domain and put up e.g. <code>redirect permanent</code> in a .htaccess file on your web server</li>\\n</ol>\\n<h2 id=\\\"A-rough-outline-of-what-you-rsquo-re-up-to\\\"><a href=\\\"#A-rough-outline-of-what-you-rsquo-re-up-to\\\" class=\\\"headerlink\\\" title=\\\"A rough outline of what you&rsquo;re up to\\\"></a>A rough outline of what you&rsquo;re up to</h2><p>At a glance, that what you&rsquo;ll do:</p>\\n<ol>\\n<li>Upload your images to a different hoster (if you want to get rid of your old webhost)</li>\\n<li>Extract all blog posts+comment from wordpress</li>\\n<li>Fix the export.xml: Replace images, more-tags and fix some additional stuff</li>\\n<li>Migrate your wordpress blog to blogger</li>\\n<li>Migrate your blogger blog to tumblr</li>\\n<li>Install http redirects (on old webhost or on tumblr)</li>\\n<li>Migrate your comments to disqus</li>\\n<li>Clean up blog posts (might be a biggie if you&rsquo;re a perfectionist)</li>\\n</ol>\\n<p>Alright, let&rsquo;s specify those 8 steps.</p>\\n<h2 id=\\\"Step-1-Upload-your-images-to-a-different-hoster\\\"><a href=\\\"#Step-1-Upload-your-images-to-a-different-hoster\\\" class=\\\"headerlink\\\" title=\\\"Step 1: Upload your images to a different hoster\\\"></a>Step 1: Upload your images to a different hoster</h2><p>If you&rsquo;re ok with keeping your old webhost you can skip this point. Easiest thing to do would be to copy your wp-content directory one to one to a different hoster so <code>[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)</code> turns into <code>[www.imagehoster.com/my_user_name/img1.jpg](http://www.imagehoster.com/my_user_name/img1.jpg)</code>.</p>\\n<p>I don&rsquo;t have experience with image hosting providers so I just uploaded my images to picasa, but that meant I needed to update every single image in all my blog posts to the new image url of picasa. That was quite a pain. I couldn&rsquo;t find a image hoster yet who meets the criterias above. Photobucket doesn&rsquo;t, Dropbox doesn&rsquo;t, Google Drive doesn&rsquo;t. Maybe Amazon S3</p>\\n<h2 id=\\\"Step-2-Extract-your-blog-posts-comment-from-wordpress\\\"><a href=\\\"#Step-2-Extract-your-blog-posts-comment-from-wordpress\\\" class=\\\"headerlink\\\" title=\\\"Step 2: Extract your blog posts+comment from wordpress\\\"></a>Step 2: Extract your blog posts+comment from wordpress</h2><ol>\\n<li>In your wordpress admin go to Tools → Export. On my blog that was <code>code.pui.ch/wp-admin/export.php</code>.</li>\\n<li>Choose <code>All content</code>, <code>Download Export File</code>.</li>\\n</ol>\\n<h2 id=\\\"Step-3-Fix-the-export-xml\\\"><a href=\\\"#Step-3-Fix-the-export-xml\\\" class=\\\"headerlink\\\" title=\\\"Step 3: Fix the export.xml\\\"></a>Step 3: Fix the export.xml</h2><p>You have just downloaded an xml file, in my case the name was <code>coderandom.wordpress.2012-12-13.xml</code>. Open that file with your favourite text editor. Now you need to do a few things before you can go on:</p>\\n<ol>\\n<li>Replace all &lt;!&ndash;more&ndash;&gt; by <span>[[</span>MORE<span>]]</span>. The uppercase actually matters. <span>[[</span>MORE<span>]]</span> is the divider that tumblr actually understands as the place where you want your excerpt to stop in the blog overview view.</li>\\n<li>Replace all images by the new urls you got by uploading the images to the image hoster in step 1. It&rsquo;s much easier to do this at this stage than to replace the images once you&rsquo;ve migrated your blog to tumblr.</li>\\n<li>You may have more wordpress plugins you used in your posts. I used <code>[python]...[/python]</code> to syntax highlight my python markup. I&rsquo;ve moved to <a href=\\\"http://code.google.com/p/google-code-prettify/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">google code prettify</a> which needs <code>&amp;lt;pre class=&quot;prettyprint&quot;&amp;gt;...&amp;lt;/pre&amp;gt;</code> as a syntax. So I needed to replace all occurrences by the new markup. Obviously, regex is your friend at this stage.</li>\\n</ol>\\n<h2 id=\\\"Step-4-Migrate-your-wordpress-blog-to-blogger\\\"><a href=\\\"#Step-4-Migrate-your-wordpress-blog-to-blogger\\\" class=\\\"headerlink\\\" title=\\\"Step 4: Migrate your wordpress blog to blogger\\\"></a>Step 4: Migrate your wordpress blog to blogger</h2><p>Unfortunately there&rsquo;s no direct way to directly import this xml file into tumblr. Instead, that&rsquo;s what you need to do:</p>\\n<ol>\\n<li><p><strong>Convert</strong> your xml file <a href=\\\"http://wordpress2blogger.appspot.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">on this website</a> to a file fit for importing into blogger.</p>\\n<p>  This doesn&rsquo;t work for files bigger than 1MB. If that&rsquo;s the case then you can either convert the file on your own machine using <a href=\\\"http://code.google.com/p/google-blog-converters-appengine/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this sourcecode on google code</a>. Or you can follow the <a href=\\\"http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">instructions under step 3 on this blog post.</a></p>\\n</li>\\n<li><strong>Create a new blog</strong> on <a href=\\\"http://www.blogger.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">blogger.com</a>.</li>\\n<li>In blogger navigate to your new blog and do settings → other settings → <strong>import blog</strong></li>\\n<li><strong>Publish</strong> all blog posts: Posts → All → Select all → Publish</li>\\n</ol>\\n<p>If you have difficulties in this step you might try a different solution (didn&rsquo;t try any of these):</p>\\n<ul>\\n<li><a href=\\\"https://github.com/ideashower/Export-Wordpress-posts-to-Tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">ideashowers PHP script on github</a></li>\\n<li><a href=\\\"http://www.daveexmachina.com/wordpress/?p=5974\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Dave Lartigues php script (plus explanations)</a></li>\\n<li><a href=\\\"http://dbavaria.tumblr.com/post/28193913/wp2tumblr-transfer-your-blog-from-wordpress-to-tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Darshan Bavarians PHP script</a></li>\\n<li><a href=\\\"http://snipplr.com/view/14609/migrate-wordpress-to-tumblr/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">shakefons php script</a></li>\\n</ul>\\n<h2 id=\\\"Step-5-Migrate-your-blogger-blog-to-tumblr\\\"><a href=\\\"#Step-5-Migrate-your-blogger-blog-to-tumblr\\\" class=\\\"headerlink\\\" title=\\\"Step 5: Migrate your blogger blog to tumblr\\\"></a>Step 5: Migrate your blogger blog to tumblr</h2><ol>\\n<li>Go to <a href=\\\"http://www.bloggertotumblr.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">bloggertotumblr.com</a> and enter your url for your newly created blogger and tumblr blogs. The conversion is very straight forward.</li>\\n<li>Delete your blogger blog</li>\\n<li>Enjoy. Your blog posts are now on tumblr. Still missing: Support of the old url scheme and comments</li>\\n</ol>\\n<h2 id=\\\"Step-6-Install-http-redirects-on-old-webhost-or-on-tumblr\\\"><a href=\\\"#Step-6-Install-http-redirects-on-old-webhost-or-on-tumblr\\\" class=\\\"headerlink\\\" title=\\\"Step 6: Install http redirects (on old webhost or on tumblr)\\\"></a>Step 6: Install http redirects (on old webhost or on tumblr)</h2><p>In the section <a href=\\\"#beforeyoustart\\\">before you start</a> I asked you to decide if you&rsquo;re ok to break your old urls. If you don&rsquo;t care, then skip this step. Although: if you care about keeping your comments then you still might to do this step, as it makes migrating comments to disqus a lot easier</p>\\n<p>If you do care, then:</p>\\n<ul>\\n<li>If you keep the domain of your blog: You need to install tumblr redirect pages. See below.</li>\\n<li>If you changed the domain of your blog: You need to install redirects on your former wordpress webhost. I describe how this is done via .htaccess config below</li>\\n</ul>\\n<h3 id=\\\"Install-tumblr-redirect-pages\\\"><a href=\\\"#Install-tumblr-redirect-pages\\\" class=\\\"headerlink\\\" title=\\\"Install tumblr redirect pages\\\"></a>Install tumblr redirect pages</h3><ol>\\n<li>go to your new tumblr blog</li>\\n<li>click customize top right</li>\\n<li>add a page (left column)</li>\\n<li>instead of &ldquo;Standard Layout&rdquo; choose &ldquo;Redirect&rdquo; and add a posts&rsquo; old url on top, and the new url on bottom. Repeat this for every blog posts (yeah, lots of work here)</li>\\n</ol>\\n<h3 id=\\\"Install-htaccess-on-your-old-webhost\\\"><a href=\\\"#Install-htaccess-on-your-old-webhost\\\" class=\\\"headerlink\\\" title=\\\"Install .htaccess on your old webhost\\\"></a>Install .htaccess on your old webhost</h3><p>IMO that&rsquo;s a bit simpler than installing a tumblr redirect for every blog post. Still it&rsquo;s a lot of work since you need to come up with a map of old_url → new_url for every blog post. If your webhost supports .htaccess then go for this method. Most probably you have such a file already for your wordpress installation.</p>\\n<p>An example of a .htaccess file:</p>\\n<pre>\\n  RewriteEngine On\\n  Redirect permanent /page/2/ [http://howto.pui.ch/page/2](http://howto.pui.ch/page/2)\\n  Redirect permanent /feed/ [http://howto.pui.ch/rss](http://howto.pui.ch/rss)\\n  RewriteRule ^$ [http://howto.pui.ch/](http://howto.pui.ch/) [R=301,L]\\n  Redirect permanent /2007/02/25/add-bandwidth-to-a-file-download-in-python/ [http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python](http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python)\\n  Redirect permanent /2007/06/08/python-find-out-cpu-time-of-a-certain-process/ [http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process](http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process)\\n  Redirect permanent /2007/07/23/python-sort-a-list-of-dicts-by-dict-key/ [http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key](http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key)\\n  Redirect permanent /2009/12/30/dealing-with-mysql-backend-does-not-support-timezone-aware-datetimes/ [http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support](http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support)\\n  Redirect permanent /2011/01/19/python-easy-way-to-show-progress/ [http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress](http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress)\\n  Redirect permanent /2012/07/17/how-to-detect-a-files-character-encoding/ [http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding](http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding)\\n  Redirect permanent /2010/04/04/python-display-refreshing-status-like-top/ [http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top](http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top)\\n  Redirect permanent /2011/11/03/how-to-switch-gnu-screen-windows-in-iterm2-via-keyboard-shortcuts/ [http://howto.pui.ch/404](http://howto.pui.ch/404)\\n  Redirect permanent /2007/01/19/sched-20-pizza-is-ready/ [http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready](http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready)\\n</pre>\\n\\n<p>Note the first 3 lines, you will need the same for your redirects. Note the special syntax of line 3. That is important to not redirect a non existing url to the new domain.</p>\\n<h4 id=\\\"Wait-I-just-moved-my-blog-away-from-my-old-webhost-and-now-I-need-to-keep-it-to-have-http-redirects-in-place\\\"><a href=\\\"#Wait-I-just-moved-my-blog-away-from-my-old-webhost-and-now-I-need-to-keep-it-to-have-http-redirects-in-place\\\" class=\\\"headerlink\\\" title=\\\"Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?\\\"></a>Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?</h4><p>Uh, yes. Alternatively, you can move to a free hoster like google apps engine and e.g. <a href=\\\"http://blog.dantup.com/2010/01/generic-redirection-script-for-google-app-engine\\\" target=\\\"_blank\\\" rel=\\\"external\\\">use this</a> to redirect. Or you just wait a few months and wait until all search engines have digested your redirects and kill your old webhost only then (that&rsquo;s what I&rsquo;m probably gonna do).</p>\\n<h2 id=\\\"Step-7-Migrate-your-comments-to-disqus\\\"><a href=\\\"#Step-7-Migrate-your-comments-to-disqus\\\" class=\\\"headerlink\\\" title=\\\"Step 7: Migrate your comments to disqus\\\"></a>Step 7: Migrate your comments to disqus</h2><p>Because tumblr doesn&rsquo;t offer comments by itself you need to migrate your comments to disqus:</p>\\n<ol>\\n<li><a href=\\\"http://disqus.com/admin/register/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Register</a> your new tumblr blog url at disqus</li>\\n<li>On disqus go to <code>Admin</code> → <code>Tools</code> → <code>Import/Export</code> → <code>Upload WXR</code>. Choose the XML file you downloaded from your wordpress installation (not that got converted for blogger). Upload that</li>\\n<li>On the same page go to <code>Migrate Threads</code>. Choose &ldquo;Redirect crawler&rdquo; if you installed the redirects in step 6. Otherwise you need to use the &ldquo;Upload a URL map&rdquo; option</li>\\n</ol>\\n<p>Voilà! After a few minutes your comments should appear in your new tumblr blog.</p>\\n<h2 id=\\\"Step-8-Clean-up-your-tumblr-posts\\\"><a href=\\\"#Step-8-Clean-up-your-tumblr-posts\\\" class=\\\"headerlink\\\" title=\\\"Step 8: Clean up your tumblr posts\\\"></a>Step 8: Clean up your tumblr posts</h2><p>Might be that the html markup of my wordpress posts were so bad, but I needed to fix a lot of spacing between paragraphs. I also had some CSS tweaks to right align the images which I needed to fix.</p>\\n<p>Lastly, blogger adds these paragraphs to the end of every blog post:</p>\\n<pre>\\n  &lt;div class=\\\"blogger-post-footer\\\"&gt;\\n    &lt;img alt=\\\"\\\" height=\\\"1\\\" src=\\\"https://blogger.googleusercontent.com/tracker/290349385069691835-5946149615494229188?l=coderandomm.blogspot.com\\\" width=\\\"1\\\"&gt;\\n  &lt;/div&gt;\\n</pre>\\n\\n<p>If you are a perfectionist you may want to remove this markup from every blog post.</p>\\n<p>A word of caution: You can spend a lot of time at this step if you overdo it.</p>\\n<h2 id=\\\"Thanks\\\"><a href=\\\"#Thanks\\\" class=\\\"headerlink\\\" title=\\\"Thanks\\\"></a>Thanks</h2><ul>\\n<li>Thanks to <strong>MG Siegler</strong> (one of my favourite bloggers, although he is an Apple fanboy and I am a google disciple): He showed me that you can <a href=\\\"http://parislemon.com/post/15604811641/why-i-hate-android\\\" target=\\\"_blank\\\" rel=\\\"external\\\">perfectly write long blog posts on tumblr</a> (that linked article is actually a must read about Android vs. iPhone)</li>\\n<li><strong>Julio Angel Ortiz</strong>, who&rsquo;s <a href=\\\"http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">article</a> served as the base for this howto.</li>\\n<li><strong>TextMate</strong> for making html editing so easy. Just found out that it&rsquo;s actually a pretty decent HTML editor. I&rsquo;ll write my blog posts in here and only then past them into the tiny tumblr HTML editor popup.</li>\\n</ul>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"https://lh3.googleusercontent.com/-Pn-aBqMjq9g/UMpMLdyLsgI/AAAAAAAALe0/zbopqqnD77M/s300/wordpresstumblr.jpg\\\" alt=\\\"\\\">So I&rsquo;ve decided to move my wordpress blogs to tumblr. Although apparently TechCrunch <a href=\\\"http://techcrunch.com/2010/09/18/stuff-white-person-doesnt-like/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">thinks that&rsquo;s a bad idea</a>. And although <a href=\\\"https://twitter.com/moritzadler\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Moritz Adler</a> would kill me for that. (Although: He doesn&rsquo;t have a personal blog and hence has no licence to kill me). Anyway. With tumblr I don&rsquo;t need to host a blog software myself. And I don&rsquo;t end up having my blog hacked and then seeing my blog being displayed as a malware site in Chrome/Firefox (happened to me twice). And then with tumblr I create new blogs with subdomains within minutes. Cool stuff. Hail to the cloud, baby!</p>\\n<p>So here you go: A complete guide how to fully migrate your wordpress blog to tumblr. Including comments and pictures. And still supporting your old url scheme.</p>\\n<p><strong>Update:</strong> I ran into a tool that claims to do a lot for you: <a href=\\\"http://www.import2.com/tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">import2.com/tumblr</a>. It doesn&rsquo;t migrate images and 302 redirects. Not sure about comments migration. And it costs 24$. Still, if you can leave out some of the steps below that&rsquo;d be worth the money. <a href=\\\"http://www.quora.com/Mark-Kofman/answers/Tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Comments of the author on quora</a></p>\",\"more\":\"<h2 id=\\\"Before-you-start\\\"><a href=\\\"#Before-you-start\\\" class=\\\"headerlink\\\" title=\\\"Before you start\\\"></a>Before you start</h2><p>Before you start to actually move your blog, you need to consider a few things:</p>\\n<h3 id=\\\"Where-do-you-move-your-DNS-to\\\"><a href=\\\"#Where-do-you-move-your-DNS-to\\\" class=\\\"headerlink\\\" title=\\\"Where do you move your DNS to?\\\"></a>Where do you move your <strong>DNS</strong> to?</h3><p>If you have a wordpress webhost, then this webhost most probably also does DNS for you. You need to replace that by a third party solution. I think these are good services:</p>\\n<ul>\\n<li><a href=\\\"https://dns.he.net/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">he.net</a>. Free service. No strings attached. The one I&rsquo;ve chosen. The interface is nice and very easy to add new CNAMES, MX records, etc. The uptime was <a href=\\\"http://www.lowendtalk.com/discussion/262/which-dns-site-to-use-for-domains#Comment_3800\\\" target=\\\"_blank\\\" rel=\\\"external\\\">reported to be not so good</a>, but I don&rsquo;t really care about uptime of my blogs. To host your tumblr blog on your domain, you add a <code>CNAME</code> to <code>domains.tumblr.com</code> and then configure your tumblr blog to listen to that domain. Very simple.</li>\\n<li><a href=\\\"http://aws.amazon.com/route53/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Amazon Route 53</a>: They charge you $0.50 per hosted zone per month. That&rsquo;s a fair price and probably has a better uptime then he.net</li>\\n</ul>\\n<h3 id=\\\"What-do-you-want-to-do-with-your-images\\\"><a href=\\\"#What-do-you-want-to-do-with-your-images\\\" class=\\\"headerlink\\\" title=\\\"What do you want to do with your images?\\\"></a>What do you want to do with your <strong>images</strong>?</h3><p>At default they&rsquo;re all located under <code>[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)</code>. To completely get rid of your old web host you need to move those to a different image hoster. I don&rsquo;t advice you to upload it to tumblr because if in future you want to move away from tumblr you run into the same problem again.</p>\\n<h3 id=\\\"Would-you-like-to-keep-your-comments\\\"><a href=\\\"#Would-you-like-to-keep-your-comments\\\" class=\\\"headerlink\\\" title=\\\"Would you like to keep your comments?\\\"></a>Would you like to keep your <strong>comments</strong>?</h3><p>Do you have comments at all? Tumblr doesn&rsquo;t support comments by itself. Most themes have disqus support. Moving comments to disqus is no big deal, but still it&rsquo;s some work, so you may decide to just not migrate comments.</p>\\n<h3 id=\\\"Are-you-keen-to-not-break-your-old-blog-urls\\\"><a href=\\\"#Are-you-keen-to-not-break-your-old-blog-urls\\\" class=\\\"headerlink\\\" title=\\\"Are you keen to not break your old blog urls?\\\"></a>Are you keen to not break your <strong>old blog urls</strong>?</h3><p>Wordpress&rsquo; url scheme generally is e.g. <code>code.pui.ch/2007/01/05/print-hello-world/</code>.<br>That same post ends up at this tumblr url: <code>howto.pui.ch/post/37471154429/print-hello-world</code>. Note that the last part of the url is optional, i.e. <code>howto.pui.ch/post/37471154429</code> works as well.<br>If you care about incoming links to your blog not to break and if you care about your google ranking (I guess 302 redirects inherit the google ranking), there are two possibilities:</p>\\n<ol>\\n<li>Stay on the same domain, handle the redirects in tumblr (tumblr supports that with the pages&rsquo; type &ldquo;redirect&rdquo;)</li>\\n<li>Move to a different domain and put up e.g. <code>redirect permanent</code> in a .htaccess file on your web server</li>\\n</ol>\\n<h2 id=\\\"A-rough-outline-of-what-you-rsquo-re-up-to\\\"><a href=\\\"#A-rough-outline-of-what-you-rsquo-re-up-to\\\" class=\\\"headerlink\\\" title=\\\"A rough outline of what you&rsquo;re up to\\\"></a>A rough outline of what you&rsquo;re up to</h2><p>At a glance, that what you&rsquo;ll do:</p>\\n<ol>\\n<li>Upload your images to a different hoster (if you want to get rid of your old webhost)</li>\\n<li>Extract all blog posts+comment from wordpress</li>\\n<li>Fix the export.xml: Replace images, more-tags and fix some additional stuff</li>\\n<li>Migrate your wordpress blog to blogger</li>\\n<li>Migrate your blogger blog to tumblr</li>\\n<li>Install http redirects (on old webhost or on tumblr)</li>\\n<li>Migrate your comments to disqus</li>\\n<li>Clean up blog posts (might be a biggie if you&rsquo;re a perfectionist)</li>\\n</ol>\\n<p>Alright, let&rsquo;s specify those 8 steps.</p>\\n<h2 id=\\\"Step-1-Upload-your-images-to-a-different-hoster\\\"><a href=\\\"#Step-1-Upload-your-images-to-a-different-hoster\\\" class=\\\"headerlink\\\" title=\\\"Step 1: Upload your images to a different hoster\\\"></a>Step 1: Upload your images to a different hoster</h2><p>If you&rsquo;re ok with keeping your old webhost you can skip this point. Easiest thing to do would be to copy your wp-content directory one to one to a different hoster so <code>[www.yourolddomain.com/wp-content/img1.jpg](http://www.yourolddomain.com/wp-content/img1.jpg)</code> turns into <code>[www.imagehoster.com/my_user_name/img1.jpg](http://www.imagehoster.com/my_user_name/img1.jpg)</code>.</p>\\n<p>I don&rsquo;t have experience with image hosting providers so I just uploaded my images to picasa, but that meant I needed to update every single image in all my blog posts to the new image url of picasa. That was quite a pain. I couldn&rsquo;t find a image hoster yet who meets the criterias above. Photobucket doesn&rsquo;t, Dropbox doesn&rsquo;t, Google Drive doesn&rsquo;t. Maybe Amazon S3</p>\\n<h2 id=\\\"Step-2-Extract-your-blog-posts-comment-from-wordpress\\\"><a href=\\\"#Step-2-Extract-your-blog-posts-comment-from-wordpress\\\" class=\\\"headerlink\\\" title=\\\"Step 2: Extract your blog posts+comment from wordpress\\\"></a>Step 2: Extract your blog posts+comment from wordpress</h2><ol>\\n<li>In your wordpress admin go to Tools → Export. On my blog that was <code>code.pui.ch/wp-admin/export.php</code>.</li>\\n<li>Choose <code>All content</code>, <code>Download Export File</code>.</li>\\n</ol>\\n<h2 id=\\\"Step-3-Fix-the-export-xml\\\"><a href=\\\"#Step-3-Fix-the-export-xml\\\" class=\\\"headerlink\\\" title=\\\"Step 3: Fix the export.xml\\\"></a>Step 3: Fix the export.xml</h2><p>You have just downloaded an xml file, in my case the name was <code>coderandom.wordpress.2012-12-13.xml</code>. Open that file with your favourite text editor. Now you need to do a few things before you can go on:</p>\\n<ol>\\n<li>Replace all &lt;!&ndash;more&ndash;&gt; by <span>[[</span>MORE<span>]]</span>. The uppercase actually matters. <span>[[</span>MORE<span>]]</span> is the divider that tumblr actually understands as the place where you want your excerpt to stop in the blog overview view.</li>\\n<li>Replace all images by the new urls you got by uploading the images to the image hoster in step 1. It&rsquo;s much easier to do this at this stage than to replace the images once you&rsquo;ve migrated your blog to tumblr.</li>\\n<li>You may have more wordpress plugins you used in your posts. I used <code>[python]...[/python]</code> to syntax highlight my python markup. I&rsquo;ve moved to <a href=\\\"http://code.google.com/p/google-code-prettify/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">google code prettify</a> which needs <code>&amp;lt;pre class=&quot;prettyprint&quot;&amp;gt;...&amp;lt;/pre&amp;gt;</code> as a syntax. So I needed to replace all occurrences by the new markup. Obviously, regex is your friend at this stage.</li>\\n</ol>\\n<h2 id=\\\"Step-4-Migrate-your-wordpress-blog-to-blogger\\\"><a href=\\\"#Step-4-Migrate-your-wordpress-blog-to-blogger\\\" class=\\\"headerlink\\\" title=\\\"Step 4: Migrate your wordpress blog to blogger\\\"></a>Step 4: Migrate your wordpress blog to blogger</h2><p>Unfortunately there&rsquo;s no direct way to directly import this xml file into tumblr. Instead, that&rsquo;s what you need to do:</p>\\n<ol>\\n<li><p><strong>Convert</strong> your xml file <a href=\\\"http://wordpress2blogger.appspot.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">on this website</a> to a file fit for importing into blogger.</p>\\n<p>  This doesn&rsquo;t work for files bigger than 1MB. If that&rsquo;s the case then you can either convert the file on your own machine using <a href=\\\"http://code.google.com/p/google-blog-converters-appengine/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this sourcecode on google code</a>. Or you can follow the <a href=\\\"http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">instructions under step 3 on this blog post.</a></p>\\n</li>\\n<li><strong>Create a new blog</strong> on <a href=\\\"http://www.blogger.com\\\" target=\\\"_blank\\\" rel=\\\"external\\\">blogger.com</a>.</li>\\n<li>In blogger navigate to your new blog and do settings → other settings → <strong>import blog</strong></li>\\n<li><strong>Publish</strong> all blog posts: Posts → All → Select all → Publish</li>\\n</ol>\\n<p>If you have difficulties in this step you might try a different solution (didn&rsquo;t try any of these):</p>\\n<ul>\\n<li><a href=\\\"https://github.com/ideashower/Export-Wordpress-posts-to-Tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">ideashowers PHP script on github</a></li>\\n<li><a href=\\\"http://www.daveexmachina.com/wordpress/?p=5974\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Dave Lartigues php script (plus explanations)</a></li>\\n<li><a href=\\\"http://dbavaria.tumblr.com/post/28193913/wp2tumblr-transfer-your-blog-from-wordpress-to-tumblr\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Darshan Bavarians PHP script</a></li>\\n<li><a href=\\\"http://snipplr.com/view/14609/migrate-wordpress-to-tumblr/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">shakefons php script</a></li>\\n</ul>\\n<h2 id=\\\"Step-5-Migrate-your-blogger-blog-to-tumblr\\\"><a href=\\\"#Step-5-Migrate-your-blogger-blog-to-tumblr\\\" class=\\\"headerlink\\\" title=\\\"Step 5: Migrate your blogger blog to tumblr\\\"></a>Step 5: Migrate your blogger blog to tumblr</h2><ol>\\n<li>Go to <a href=\\\"http://www.bloggertotumblr.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">bloggertotumblr.com</a> and enter your url for your newly created blogger and tumblr blogs. The conversion is very straight forward.</li>\\n<li>Delete your blogger blog</li>\\n<li>Enjoy. Your blog posts are now on tumblr. Still missing: Support of the old url scheme and comments</li>\\n</ol>\\n<h2 id=\\\"Step-6-Install-http-redirects-on-old-webhost-or-on-tumblr\\\"><a href=\\\"#Step-6-Install-http-redirects-on-old-webhost-or-on-tumblr\\\" class=\\\"headerlink\\\" title=\\\"Step 6: Install http redirects (on old webhost or on tumblr)\\\"></a>Step 6: Install http redirects (on old webhost or on tumblr)</h2><p>In the section <a href=\\\"#beforeyoustart\\\">before you start</a> I asked you to decide if you&rsquo;re ok to break your old urls. If you don&rsquo;t care, then skip this step. Although: if you care about keeping your comments then you still might to do this step, as it makes migrating comments to disqus a lot easier</p>\\n<p>If you do care, then:</p>\\n<ul>\\n<li>If you keep the domain of your blog: You need to install tumblr redirect pages. See below.</li>\\n<li>If you changed the domain of your blog: You need to install redirects on your former wordpress webhost. I describe how this is done via .htaccess config below</li>\\n</ul>\\n<h3 id=\\\"Install-tumblr-redirect-pages\\\"><a href=\\\"#Install-tumblr-redirect-pages\\\" class=\\\"headerlink\\\" title=\\\"Install tumblr redirect pages\\\"></a>Install tumblr redirect pages</h3><ol>\\n<li>go to your new tumblr blog</li>\\n<li>click customize top right</li>\\n<li>add a page (left column)</li>\\n<li>instead of &ldquo;Standard Layout&rdquo; choose &ldquo;Redirect&rdquo; and add a posts&rsquo; old url on top, and the new url on bottom. Repeat this for every blog posts (yeah, lots of work here)</li>\\n</ol>\\n<h3 id=\\\"Install-htaccess-on-your-old-webhost\\\"><a href=\\\"#Install-htaccess-on-your-old-webhost\\\" class=\\\"headerlink\\\" title=\\\"Install .htaccess on your old webhost\\\"></a>Install .htaccess on your old webhost</h3><p>IMO that&rsquo;s a bit simpler than installing a tumblr redirect for every blog post. Still it&rsquo;s a lot of work since you need to come up with a map of old_url → new_url for every blog post. If your webhost supports .htaccess then go for this method. Most probably you have such a file already for your wordpress installation.</p>\\n<p>An example of a .htaccess file:</p>\\n<pre>\\n  RewriteEngine On\\n  Redirect permanent /page/2/ [http://howto.pui.ch/page/2](http://howto.pui.ch/page/2)\\n  Redirect permanent /feed/ [http://howto.pui.ch/rss](http://howto.pui.ch/rss)\\n  RewriteRule ^$ [http://howto.pui.ch/](http://howto.pui.ch/) [R=301,L]\\n  Redirect permanent /2007/02/25/add-bandwidth-to-a-file-download-in-python/ [http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python](http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-python)\\n  Redirect permanent /2007/06/08/python-find-out-cpu-time-of-a-certain-process/ [http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process](http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-process)\\n  Redirect permanent /2007/07/23/python-sort-a-list-of-dicts-by-dict-key/ [http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key](http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-key)\\n  Redirect permanent /2009/12/30/dealing-with-mysql-backend-does-not-support-timezone-aware-datetimes/ [http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support](http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-support)\\n  Redirect permanent /2011/01/19/python-easy-way-to-show-progress/ [http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress](http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progress)\\n  Redirect permanent /2012/07/17/how-to-detect-a-files-character-encoding/ [http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding](http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encoding)\\n  Redirect permanent /2010/04/04/python-display-refreshing-status-like-top/ [http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top](http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-top)\\n  Redirect permanent /2011/11/03/how-to-switch-gnu-screen-windows-in-iterm2-via-keyboard-shortcuts/ [http://howto.pui.ch/404](http://howto.pui.ch/404)\\n  Redirect permanent /2007/01/19/sched-20-pizza-is-ready/ [http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready](http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready)\\n</pre>\\n\\n<p>Note the first 3 lines, you will need the same for your redirects. Note the special syntax of line 3. That is important to not redirect a non existing url to the new domain.</p>\\n<h4 id=\\\"Wait-I-just-moved-my-blog-away-from-my-old-webhost-and-now-I-need-to-keep-it-to-have-http-redirects-in-place\\\"><a href=\\\"#Wait-I-just-moved-my-blog-away-from-my-old-webhost-and-now-I-need-to-keep-it-to-have-http-redirects-in-place\\\" class=\\\"headerlink\\\" title=\\\"Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?\\\"></a>Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?</h4><p>Uh, yes. Alternatively, you can move to a free hoster like google apps engine and e.g. <a href=\\\"http://blog.dantup.com/2010/01/generic-redirection-script-for-google-app-engine\\\" target=\\\"_blank\\\" rel=\\\"external\\\">use this</a> to redirect. Or you just wait a few months and wait until all search engines have digested your redirects and kill your old webhost only then (that&rsquo;s what I&rsquo;m probably gonna do).</p>\\n<h2 id=\\\"Step-7-Migrate-your-comments-to-disqus\\\"><a href=\\\"#Step-7-Migrate-your-comments-to-disqus\\\" class=\\\"headerlink\\\" title=\\\"Step 7: Migrate your comments to disqus\\\"></a>Step 7: Migrate your comments to disqus</h2><p>Because tumblr doesn&rsquo;t offer comments by itself you need to migrate your comments to disqus:</p>\\n<ol>\\n<li><a href=\\\"http://disqus.com/admin/register/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Register</a> your new tumblr blog url at disqus</li>\\n<li>On disqus go to <code>Admin</code> → <code>Tools</code> → <code>Import/Export</code> → <code>Upload WXR</code>. Choose the XML file you downloaded from your wordpress installation (not that got converted for blogger). Upload that</li>\\n<li>On the same page go to <code>Migrate Threads</code>. Choose &ldquo;Redirect crawler&rdquo; if you installed the redirects in step 6. Otherwise you need to use the &ldquo;Upload a URL map&rdquo; option</li>\\n</ol>\\n<p>Voilà! After a few minutes your comments should appear in your new tumblr blog.</p>\\n<h2 id=\\\"Step-8-Clean-up-your-tumblr-posts\\\"><a href=\\\"#Step-8-Clean-up-your-tumblr-posts\\\" class=\\\"headerlink\\\" title=\\\"Step 8: Clean up your tumblr posts\\\"></a>Step 8: Clean up your tumblr posts</h2><p>Might be that the html markup of my wordpress posts were so bad, but I needed to fix a lot of spacing between paragraphs. I also had some CSS tweaks to right align the images which I needed to fix.</p>\\n<p>Lastly, blogger adds these paragraphs to the end of every blog post:</p>\\n<pre>\\n  &lt;div class=\\\"blogger-post-footer\\\"&gt;\\n    &lt;img alt=\\\"\\\" height=\\\"1\\\" src=\\\"https://blogger.googleusercontent.com/tracker/290349385069691835-5946149615494229188?l=coderandomm.blogspot.com\\\" width=\\\"1\\\"&gt;\\n  &lt;/div&gt;\\n</pre>\\n\\n<p>If you are a perfectionist you may want to remove this markup from every blog post.</p>\\n<p>A word of caution: You can spend a lot of time at this step if you overdo it.</p>\\n<h2 id=\\\"Thanks\\\"><a href=\\\"#Thanks\\\" class=\\\"headerlink\\\" title=\\\"Thanks\\\"></a>Thanks</h2><ul>\\n<li>Thanks to <strong>MG Siegler</strong> (one of my favourite bloggers, although he is an Apple fanboy and I am a google disciple): He showed me that you can <a href=\\\"http://parislemon.com/post/15604811641/why-i-hate-android\\\" target=\\\"_blank\\\" rel=\\\"external\\\">perfectly write long blog posts on tumblr</a> (that linked article is actually a must read about Android vs. iPhone)</li>\\n<li><strong>Julio Angel Ortiz</strong>, who&rsquo;s <a href=\\\"http://julioinprogress.com/2011/09/10/guide-to-moving-from-wordpress-to-tumblr/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">article</a> served as the base for this howto.</li>\\n<li><strong>TextMate</strong> for making html editing so easy. Just found out that it&rsquo;s actually a pretty decent HTML editor. I&rsquo;ll write my blog posts in here and only then past them into the tiny tumblr HTML editor popup.</li>\\n</ul>\"},{\"title\":\"Tutorial: Django on Appengine using Google Cloud SQL\",\"date\":\"2012-12-30T21:47:00.000Z\",\"alias\":\"/post/39245389801/tutorial-django-on-appengine-using-google-cloud\",\"_content\":\"\\n![](https://lh5.googleusercontent.com/-lX6aq3qvV50/UOC0ONuosVI/AAAAAAAAMUE/Q_occPtbmnQ/s230/Untitled-1.png)\\nGoogle is running an [introductory trial for Cloud SQL that runs since Nov 2012 until June 1, 2013](https://developers.google.com/cloud-sql/docs/billing#intro_trial). That&rsquo;s the right hour to test Django on Google App Engine. No need to mess around with their non relational datastore. Just use their MySQL 5.5 in the cloud.\\n\\nHence I decided to give it a try and documented all into a very complete tutorial how to start a Django 1.4 project running on &ldquo;Google App Engine&rdquo;.\\n<!-- more -->\\n\\nIf you run into exceptions, check the troubleshooting part at the bottom\\n\\n# Requirements\\n\\n*   Python 2.7\\\\. If you can&rsquo;t use 2.7 for any reason, no worries. [Here are the adaptions](http://howto.philippkeller.com/2013/01/01/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5/) you need to make for this tutorial to work\\n*   OS X or Linux. I&rsquo;m on OS X 10.8.2, I marked the steps that are OS X specific. For Linux users it&rsquo;s most probably very easy to adapt those. For Windows you certainly need to do some bigger adaptations.\\n*   MySQL and its python bindings (for local development)\\n\\n## What about Django &lt; 1.4?\\n\\nAppengine supports the versions 0.96, 1.2, 1.3 and 1.4\\\\. This tutorial should work with all those versions. I only tested 1.3 and 1.4 though.\\nAll you need to do with this tutorial is to change 1.4 to 1.3 and keep in mind that the [Django directory structure slightly changed](https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py) in version 1.4 so you need to adapt some of the shell commands.\\n\\n# Create a Google App Engine Instance\\n\\n  Create new instance on [appengine](https://appengine.google.com/).\\n\\n  Your instance will be located in the US unless you&rsquo;re willing to pay [500$ a month to register for a premium account](https://cloud.google.com/pricing/)\\n  (Europe hosting is [for premium accounts only](https://developers.google.com/appengine/docs/premier/location))\\n\\n# Install Google App Engine (OS X specific)\\n\\n1.  Download the [GoogleAppEngineLauncher-x.x.x.dmg](https://developers.google.com/appengine/downloads#Google_App_Engine_SDK_for_Python)\\n2.  Open the dmg, move `GoogleAppEngineLauncher` to Applications\\n3.  Open GoogleAppEngineLauncher, say yes to the symlinks\\n4.  Add `$PATH` and `$PYTHONPATH` to shell environment: Add these lines to `.bash_profile` (`.bashrc` on Linux):\\n    <pre>\\nexport GAE=\\\"/usr/local/google_appengine\\\"\\nexport PYTHONPATH=\\\"$PYTHONPATH:$GAE:$GAE/lib/django_1_4\\\"\\nexport PATH=${PATH}:$GAE/lib/django_1_4/django/bin/</pre>Load these settings into the current session with <pre>source ~/.bash_profile</pre> and make the django binaries executable: <pre>chmod a+x $GAE/lib/django_1_4/django/bin/[a-z]*.py</pre>\\n\\n# Create the django project\\n\\n1.  run this in a directory of your choice (I chose `~/python/`). This generates a stub django project. Replace mysite with the name of your django project. <pre>django-admin.py startproject mysite</pre>Switch into mysite (where `manage.py` resides, only do this if you run Django 1.4):<pre>cd mysite</pre>\\n2.  create the file `mysite/app.yaml` with this content (replace `appproject` with the id of your appspot.com instance):\\n<pre>\\napplication: appproject\\nversion: 1\\nruntime: python27\\napi_version: 1\\nthreadsafe: true\\n\\n    libraries:\\n- name: django\\n  version: \\\"1.4\\\"\\n\\n    builtins:\\n- django_wsgi: on\\n\\n    handlers:\\n- url: /static/admin\\n  static_dir: static/admin\\n  expiration: '0'\\n</pre>\\n\\n3.  edit `mysite/settings.py`: Change the value of `ROOT_URLCONF` from `mysite.urls` to `urls` (else you run into an exception in your live instance)\\n4.  also in `settings.py` add these 2 lines anywhere at the top:\\n<pre>\\nimport os\\nBASE_DIR = os.path.abspath(os.path.dirname(__file__)) + os.sep\\n</pre>\\nThis is the path prefix you&rsquo;ll put before all the `xyz_ROOT` settings later.\\n5.  run this one level up of your python project directory: <pre>dev_appserver.py mysite</pre>\\n\\nCongrats! Your [local instance](http://localhost:8080) now shows [this](http://i.imgur.com/rXh74.png) - hopefully :-)\\n\\n# Set up Google Cloud SQL\\n\\n1.  Register Cloud SQL in the [Google API Console](https://code.google.com/apis/console/) (I think you need to add billing, but currently there&rsquo;s a free plan until June 1, 2013)\\n2.  create a new instance in the **United States** (even when you&rsquo;re located in Europe). The reason is that your Cloud SQL instance needs to be at the same location as your GAE instance. Put your ID of your appspot.com instance to the Authorized Applications.\\n3.  create a new database using the SQL Prompt: <pre>CREATE DATABASE my_database;</pre>\\n4.  replace the `DATABASES` section of your `settings.py` with the snippet below: (Replace `my_project:instance1` with your Cloud SQL Instance id and `my_database` with your created database name).\\n<pre>\\nimport os\\nif (os.getenv('SERVER_SOFTWARE', '').startswith('Google App Engine') or\\n    os.getenv('SETTINGS_MODE') == 'prod'):\\n    # Running on production App Engine, so use a Google Cloud SQL database.\\n    DATABASES = {\\n        'default': {\\n            'ENGINE': 'google.appengine.ext.django.backends.rdbms',\\n            'INSTANCE': 'my_project:instance1',\\n            'NAME': 'my_database',\\n        }\\n    }\\nelse:\\n    # Running in development, so use a local MySQL database\\n    DATABASES = {\\n        'default': {\\n            'ENGINE': 'django.db.backends.mysql',\\n            'USER': 'root',\\n            'PASSWORD': '',\\n            'HOST': 'localhost',\\n            'NAME': 'my_db',\\n        }\\n    }\\n</pre>\\nThese settings configure django to use a local MySQL storage for development. That&rsquo;s very close to the cloud setup, as Google Cloud SQL is [powered by Mysql (currently 5.5)](https://developers.google.com/cloud-sql/faq#databaseengine)\\n\\n    I highly recommend this as on my machine every SQL query took about 1 second when run against Google Cloud SQL.\\n\\n    That comes from the fact as first the SQL queries run over HTTP and second the Cloud SQL Instance [runs in California](https://ipdb.at/ip/74.125.132.95).\\n\\n5.  To trigger the oauth authorization (stored in `~/.googlesql_oauth2.dat`) run this:<pre>SETTINGS_MODE='prod' python manage.py syncdb</pre>\\n\\nIf that last command worked that proves that your Cloud SQL worked so far. Congrats!\\n\\nYour local MySQL instance is now ready as well. You should check if `MySQLdb` is installed:\\n\\n<pre>python -c \\\"import MySQLdb\\\"</pre>\\nTo test the Django↔MySQL connection run\\n<pre>python mysite/manage.py syncdb</pre>\\n\\nWhenever you want to sync your django models to:\\n\\na) the _live_ db: `SETTINGS_MODE='prod' python manage.py syncdb`\\n\\nb) the _local mysql_ db: `python manage.py syncdb`\\n\\n# Deploy your stub app to appspot\\n\\n  Ready to deploy your fresh app to the cloud?\\n\\n  Run this (replace mysite with your project name): \\n<pre>appcfg.py --oauth2 update mysite</pre>\\n\\n  After about 1 minute your fresh Django project should run perfectly on [http://your-id.appspot.com/](http://your-id.appspot.com/)\\n\\n**Why not sqlite?**\\n\\nSqlite would be a lot easier to set up, actually there is nothing to install and no server to start, no passwords, etc.\\n\\nApart from the fact that I couldn&rsquo;t get it working (details see [here](http://stackoverflow.com/questions/14080430)) it&rsquo;s certainly not a smart idea to run sqlite locally and MySQL (as used by Cloud SQL) in production, [it&rsquo;s very likely that you&rsquo;ll run into issues](http://stackoverflow.com/questions/2306048/django-sqlite-for-dev-mysql-for-prod).\\n\\n# Serving static files\\n\\nDjango [supports serving static files](https://docs.djangoproject.com/en/dev/howto/static-files/) via `django.contrib.staticfiles`. However, I didn&rsquo;t get this to work. And since serving these files directly via GAE is faster anyways, add this to your `app.yaml`:\\n\\n<pre>\\n- url: /media\\n  static_dir: media\\n  expiration: '0'\\n</pre>\\n\\nThis assumes your static files are under `mysite/media`. Your static files now serve under [/media/](http://localhost:8080/media/)\\n\\n# Enable Admin (optional)\\n\\nYou probably want to enable the admin interface (Steps 2-4 are actually all about getting the static admin files to serve. Full discussion see [here](http://stackoverflow.com/questions/9860610).)\\n\\n1.  Uncomment all admin specific lines in `settings.py` (in `INSTALLED_APPS`) and `urls.py` (header and urlpatterns).\\n\\n        Go sure you don&rsquo;t miss any of these lines by double checking [here, under &ldquo;Activate the admin site&rdquo;](https://docs.djangoproject.com/en/1.3/intro/tutorial02/#activate-the-admin-site).\\n2.  Sync the new models agains live<pre>SETTINGS_MODE='prod' python mysite/manage.py syncdb</pre>and local MySQL<pre>python mysite/manage.py syncdb</pre>\\n3.  in `settings.py` replace the `STATIC_ROOT` line with (you defined BASE_DIR [above](#create_the_django_project)):\\n    <pre>STATIC_ROOT = BASE_DIR + 'static'</pre>\\n4.  To copy all the admin media assets into `mysite/static` run:\\n    <pre>python mysite/manage.py collectstatic</pre>\\n5.  now, [/admin](http://localhost:8080/admin/) should show your admin site, with CSS.\\n\\n# And now?\\n\\n*   If you&rsquo;re new to Django or if you want to be 100% sure everything works as expected follow the [django tutorial](https://docs.djangoproject.com/en/1.4/intro/tutorial01/)\\n*   Want to port your Django app to Google App Engine? I&rsquo;ll likely come up with another article about that.\\n\\n# Troubleshooting\\n\\n**on my development machine the web app is _veeery_ slow**\\n\\nChances are high that you&rsquo;re not using the local MySQL. Start dev_appserver.py with the `--debug` flag and see if it does any RPC calls (SQL queries wrapped into HTTP)\\n\\nIf that isn&rsquo;t the issue you might want to [track performance with appstats](https://developers.google.com/appengine/docs/python/tools/appstats#EventRecorders).\\n\\n**I wanted to use sqlite instead of mysql as a backend, but I run into `ImportError`, `cannot import name utils`**\\n\\nSo did I. I don&rsquo;t know how to solve it. See [here](http://stackoverflow.com/questions/14080430) for details.\\n\\n**I get an `unknown locale` exception when running syncdb against MySQL**\\n\\nI personally got `ValueError: unknown locale: UTF-8`. There is a [solution for that](http://patrick.arminio.info/blog/2012/02/fix-valueerror-unknown-locale-utf8/)\\n\\n**I get a `DoesNotExist` exception when accessing /admin/**\\n\\nAt one point I got this exception: `DoesNotExist at /admin/`, `Site matching query does not exist`\\n\\nSolution is [described here](http://stackoverflow.com/questions/9736975/django-admin-doesnotexist-at-admin)\\n\\n**I get an ImportError for mysite.urls**\\n\\nI got the exception `No module named mysite.urls` before I replaced\\n\\n<pre>ROOT_URLCONF = 'mysite.urls'</pre>\\nwith\\n<pre>ROOT_URLCONF = 'urls'</pre>\\nI didn&rsquo;t really understand why that error occurs.\\n\\n# Further reading\\n\\n**Official documentation**\\n\\n*   [Official Google Documentation on how to use Django with Google Cloud SQL](https://developers.google.com/appengine/docs/python/cloud-sql/django)**Other tutorials**\\n\\n*   Google App Engine, Django and Cloud SQL [Part 1](http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql) and [2](http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql-part-ii) (Björnalycke)\\n*   [Running Django 1.3 in Google App Engine with Google Cloud SQL (Joemar Taganna)](http://www.joemartaganna.com/web-development/running-django-13-in-google-app-engine-with-google-cloud-sql/)**Outdated tutorials (based on Datastore, e.g. django-nonrel)**\\n\\n*   [Django on Google App Engine in 13 simple steps (by Thomas Brox Røst)](http://thomas.broxrost.com/2008/04/08/django-on-google-app-engine/)\\n*   [Using Django with Appengine (2 tutorials by Shabda Raaj)](http://agiliq.com/blog/2008/04/two-djangoappengine-tutorials/)\",\"source\":\"_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL.md\",\"raw\":\"---\\ntitle: 'Tutorial: Django on Appengine using Google Cloud SQL'\\ntags:\\n  - django\\n  - appengine\\n  - google cloud sql\\n  - python\\n  - mysql\\ndate: 2012-12-30 22:47:00\\nalias: /post/39245389801/tutorial-django-on-appengine-using-google-cloud\\n---\\n\\n![](https://lh5.googleusercontent.com/-lX6aq3qvV50/UOC0ONuosVI/AAAAAAAAMUE/Q_occPtbmnQ/s230/Untitled-1.png)\\nGoogle is running an [introductory trial for Cloud SQL that runs since Nov 2012 until June 1, 2013](https://developers.google.com/cloud-sql/docs/billing#intro_trial). That&rsquo;s the right hour to test Django on Google App Engine. No need to mess around with their non relational datastore. Just use their MySQL 5.5 in the cloud.\\n\\nHence I decided to give it a try and documented all into a very complete tutorial how to start a Django 1.4 project running on &ldquo;Google App Engine&rdquo;.\\n<!-- more -->\\n\\nIf you run into exceptions, check the troubleshooting part at the bottom\\n\\n# Requirements\\n\\n*   Python 2.7\\\\. If you can&rsquo;t use 2.7 for any reason, no worries. [Here are the adaptions](http://howto.philippkeller.com/2013/01/01/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5/) you need to make for this tutorial to work\\n*   OS X or Linux. I&rsquo;m on OS X 10.8.2, I marked the steps that are OS X specific. For Linux users it&rsquo;s most probably very easy to adapt those. For Windows you certainly need to do some bigger adaptations.\\n*   MySQL and its python bindings (for local development)\\n\\n## What about Django &lt; 1.4?\\n\\nAppengine supports the versions 0.96, 1.2, 1.3 and 1.4\\\\. This tutorial should work with all those versions. I only tested 1.3 and 1.4 though.\\nAll you need to do with this tutorial is to change 1.4 to 1.3 and keep in mind that the [Django directory structure slightly changed](https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py) in version 1.4 so you need to adapt some of the shell commands.\\n\\n# Create a Google App Engine Instance\\n\\n  Create new instance on [appengine](https://appengine.google.com/).\\n\\n  Your instance will be located in the US unless you&rsquo;re willing to pay [500$ a month to register for a premium account](https://cloud.google.com/pricing/)\\n  (Europe hosting is [for premium accounts only](https://developers.google.com/appengine/docs/premier/location))\\n\\n# Install Google App Engine (OS X specific)\\n\\n1.  Download the [GoogleAppEngineLauncher-x.x.x.dmg](https://developers.google.com/appengine/downloads#Google_App_Engine_SDK_for_Python)\\n2.  Open the dmg, move `GoogleAppEngineLauncher` to Applications\\n3.  Open GoogleAppEngineLauncher, say yes to the symlinks\\n4.  Add `$PATH` and `$PYTHONPATH` to shell environment: Add these lines to `.bash_profile` (`.bashrc` on Linux):\\n    <pre>\\nexport GAE=\\\"/usr/local/google_appengine\\\"\\nexport PYTHONPATH=\\\"$PYTHONPATH:$GAE:$GAE/lib/django_1_4\\\"\\nexport PATH=${PATH}:$GAE/lib/django_1_4/django/bin/</pre>Load these settings into the current session with <pre>source ~/.bash_profile</pre> and make the django binaries executable: <pre>chmod a+x $GAE/lib/django_1_4/django/bin/[a-z]*.py</pre>\\n\\n# Create the django project\\n\\n1.  run this in a directory of your choice (I chose `~/python/`). This generates a stub django project. Replace mysite with the name of your django project. <pre>django-admin.py startproject mysite</pre>Switch into mysite (where `manage.py` resides, only do this if you run Django 1.4):<pre>cd mysite</pre>\\n2.  create the file `mysite/app.yaml` with this content (replace `appproject` with the id of your appspot.com instance):\\n<pre>\\napplication: appproject\\nversion: 1\\nruntime: python27\\napi_version: 1\\nthreadsafe: true\\n\\n    libraries:\\n- name: django\\n  version: \\\"1.4\\\"\\n\\n    builtins:\\n- django_wsgi: on\\n\\n    handlers:\\n- url: /static/admin\\n  static_dir: static/admin\\n  expiration: '0'\\n</pre>\\n\\n3.  edit `mysite/settings.py`: Change the value of `ROOT_URLCONF` from `mysite.urls` to `urls` (else you run into an exception in your live instance)\\n4.  also in `settings.py` add these 2 lines anywhere at the top:\\n<pre>\\nimport os\\nBASE_DIR = os.path.abspath(os.path.dirname(__file__)) + os.sep\\n</pre>\\nThis is the path prefix you&rsquo;ll put before all the `xyz_ROOT` settings later.\\n5.  run this one level up of your python project directory: <pre>dev_appserver.py mysite</pre>\\n\\nCongrats! Your [local instance](http://localhost:8080) now shows [this](http://i.imgur.com/rXh74.png) - hopefully :-)\\n\\n# Set up Google Cloud SQL\\n\\n1.  Register Cloud SQL in the [Google API Console](https://code.google.com/apis/console/) (I think you need to add billing, but currently there&rsquo;s a free plan until June 1, 2013)\\n2.  create a new instance in the **United States** (even when you&rsquo;re located in Europe). The reason is that your Cloud SQL instance needs to be at the same location as your GAE instance. Put your ID of your appspot.com instance to the Authorized Applications.\\n3.  create a new database using the SQL Prompt: <pre>CREATE DATABASE my_database;</pre>\\n4.  replace the `DATABASES` section of your `settings.py` with the snippet below: (Replace `my_project:instance1` with your Cloud SQL Instance id and `my_database` with your created database name).\\n<pre>\\nimport os\\nif (os.getenv('SERVER_SOFTWARE', '').startswith('Google App Engine') or\\n    os.getenv('SETTINGS_MODE') == 'prod'):\\n    # Running on production App Engine, so use a Google Cloud SQL database.\\n    DATABASES = {\\n        'default': {\\n            'ENGINE': 'google.appengine.ext.django.backends.rdbms',\\n            'INSTANCE': 'my_project:instance1',\\n            'NAME': 'my_database',\\n        }\\n    }\\nelse:\\n    # Running in development, so use a local MySQL database\\n    DATABASES = {\\n        'default': {\\n            'ENGINE': 'django.db.backends.mysql',\\n            'USER': 'root',\\n            'PASSWORD': '',\\n            'HOST': 'localhost',\\n            'NAME': 'my_db',\\n        }\\n    }\\n</pre>\\nThese settings configure django to use a local MySQL storage for development. That&rsquo;s very close to the cloud setup, as Google Cloud SQL is [powered by Mysql (currently 5.5)](https://developers.google.com/cloud-sql/faq#databaseengine)\\n\\n    I highly recommend this as on my machine every SQL query took about 1 second when run against Google Cloud SQL.\\n\\n    That comes from the fact as first the SQL queries run over HTTP and second the Cloud SQL Instance [runs in California](https://ipdb.at/ip/74.125.132.95).\\n\\n5.  To trigger the oauth authorization (stored in `~/.googlesql_oauth2.dat`) run this:<pre>SETTINGS_MODE='prod' python manage.py syncdb</pre>\\n\\nIf that last command worked that proves that your Cloud SQL worked so far. Congrats!\\n\\nYour local MySQL instance is now ready as well. You should check if `MySQLdb` is installed:\\n\\n<pre>python -c \\\"import MySQLdb\\\"</pre>\\nTo test the Django↔MySQL connection run\\n<pre>python mysite/manage.py syncdb</pre>\\n\\nWhenever you want to sync your django models to:\\n\\na) the _live_ db: `SETTINGS_MODE='prod' python manage.py syncdb`\\n\\nb) the _local mysql_ db: `python manage.py syncdb`\\n\\n# Deploy your stub app to appspot\\n\\n  Ready to deploy your fresh app to the cloud?\\n\\n  Run this (replace mysite with your project name): \\n<pre>appcfg.py --oauth2 update mysite</pre>\\n\\n  After about 1 minute your fresh Django project should run perfectly on [http://your-id.appspot.com/](http://your-id.appspot.com/)\\n\\n**Why not sqlite?**\\n\\nSqlite would be a lot easier to set up, actually there is nothing to install and no server to start, no passwords, etc.\\n\\nApart from the fact that I couldn&rsquo;t get it working (details see [here](http://stackoverflow.com/questions/14080430)) it&rsquo;s certainly not a smart idea to run sqlite locally and MySQL (as used by Cloud SQL) in production, [it&rsquo;s very likely that you&rsquo;ll run into issues](http://stackoverflow.com/questions/2306048/django-sqlite-for-dev-mysql-for-prod).\\n\\n# Serving static files\\n\\nDjango [supports serving static files](https://docs.djangoproject.com/en/dev/howto/static-files/) via `django.contrib.staticfiles`. However, I didn&rsquo;t get this to work. And since serving these files directly via GAE is faster anyways, add this to your `app.yaml`:\\n\\n<pre>\\n- url: /media\\n  static_dir: media\\n  expiration: '0'\\n</pre>\\n\\nThis assumes your static files are under `mysite/media`. Your static files now serve under [/media/](http://localhost:8080/media/)\\n\\n# Enable Admin (optional)\\n\\nYou probably want to enable the admin interface (Steps 2-4 are actually all about getting the static admin files to serve. Full discussion see [here](http://stackoverflow.com/questions/9860610).)\\n\\n1.  Uncomment all admin specific lines in `settings.py` (in `INSTALLED_APPS`) and `urls.py` (header and urlpatterns).\\n\\n        Go sure you don&rsquo;t miss any of these lines by double checking [here, under &ldquo;Activate the admin site&rdquo;](https://docs.djangoproject.com/en/1.3/intro/tutorial02/#activate-the-admin-site).\\n2.  Sync the new models agains live<pre>SETTINGS_MODE='prod' python mysite/manage.py syncdb</pre>and local MySQL<pre>python mysite/manage.py syncdb</pre>\\n3.  in `settings.py` replace the `STATIC_ROOT` line with (you defined BASE_DIR [above](#create_the_django_project)):\\n    <pre>STATIC_ROOT = BASE_DIR + 'static'</pre>\\n4.  To copy all the admin media assets into `mysite/static` run:\\n    <pre>python mysite/manage.py collectstatic</pre>\\n5.  now, [/admin](http://localhost:8080/admin/) should show your admin site, with CSS.\\n\\n# And now?\\n\\n*   If you&rsquo;re new to Django or if you want to be 100% sure everything works as expected follow the [django tutorial](https://docs.djangoproject.com/en/1.4/intro/tutorial01/)\\n*   Want to port your Django app to Google App Engine? I&rsquo;ll likely come up with another article about that.\\n\\n# Troubleshooting\\n\\n**on my development machine the web app is _veeery_ slow**\\n\\nChances are high that you&rsquo;re not using the local MySQL. Start dev_appserver.py with the `--debug` flag and see if it does any RPC calls (SQL queries wrapped into HTTP)\\n\\nIf that isn&rsquo;t the issue you might want to [track performance with appstats](https://developers.google.com/appengine/docs/python/tools/appstats#EventRecorders).\\n\\n**I wanted to use sqlite instead of mysql as a backend, but I run into `ImportError`, `cannot import name utils`**\\n\\nSo did I. I don&rsquo;t know how to solve it. See [here](http://stackoverflow.com/questions/14080430) for details.\\n\\n**I get an `unknown locale` exception when running syncdb against MySQL**\\n\\nI personally got `ValueError: unknown locale: UTF-8`. There is a [solution for that](http://patrick.arminio.info/blog/2012/02/fix-valueerror-unknown-locale-utf8/)\\n\\n**I get a `DoesNotExist` exception when accessing /admin/**\\n\\nAt one point I got this exception: `DoesNotExist at /admin/`, `Site matching query does not exist`\\n\\nSolution is [described here](http://stackoverflow.com/questions/9736975/django-admin-doesnotexist-at-admin)\\n\\n**I get an ImportError for mysite.urls**\\n\\nI got the exception `No module named mysite.urls` before I replaced\\n\\n<pre>ROOT_URLCONF = 'mysite.urls'</pre>\\nwith\\n<pre>ROOT_URLCONF = 'urls'</pre>\\nI didn&rsquo;t really understand why that error occurs.\\n\\n# Further reading\\n\\n**Official documentation**\\n\\n*   [Official Google Documentation on how to use Django with Google Cloud SQL](https://developers.google.com/appengine/docs/python/cloud-sql/django)**Other tutorials**\\n\\n*   Google App Engine, Django and Cloud SQL [Part 1](http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql) and [2](http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql-part-ii) (Björnalycke)\\n*   [Running Django 1.3 in Google App Engine with Google Cloud SQL (Joemar Taganna)](http://www.joemartaganna.com/web-development/running-django-13-in-google-app-engine-with-google-cloud-sql/)**Outdated tutorials (based on Datastore, e.g. django-nonrel)**\\n\\n*   [Django on Google App Engine in 13 simple steps (by Thomas Brox Røst)](http://thomas.broxrost.com/2008/04/08/django-on-google-app-engine/)\\n*   [Using Django with Appengine (2 tutorials by Shabda Raaj)](http://agiliq.com/blog/2008/04/two-djangoappengine-tutorials/)\",\"slug\":\"Tutorial-Django-on-Appengine-using-Google-Cloud-SQL\",\"published\":1,\"updated\":\"2017-11-12T07:09:24.902Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon6190025i85p2x1vd0ui\",\"content\":\"<p><img src=\\\"https://lh5.googleusercontent.com/-lX6aq3qvV50/UOC0ONuosVI/AAAAAAAAMUE/Q_occPtbmnQ/s230/Untitled-1.png\\\" alt=\\\"\\\"><br>Google is running an <a href=\\\"https://developers.google.com/cloud-sql/docs/billing#intro_trial\\\" target=\\\"_blank\\\" rel=\\\"external\\\">introductory trial for Cloud SQL that runs since Nov 2012 until June 1, 2013</a>. That&rsquo;s the right hour to test Django on Google App Engine. No need to mess around with their non relational datastore. Just use their MySQL 5.5 in the cloud.</p>\\n<p>Hence I decided to give it a try and documented all into a very complete tutorial how to start a Django 1.4 project running on &ldquo;Google App Engine&rdquo;.<br><a id=\\\"more\\\"></a></p>\\n<p>If you run into exceptions, check the troubleshooting part at the bottom</p>\\n<h1 id=\\\"Requirements\\\"><a href=\\\"#Requirements\\\" class=\\\"headerlink\\\" title=\\\"Requirements\\\"></a>Requirements</h1><ul>\\n<li>Python 2.7. If you can&rsquo;t use 2.7 for any reason, no worries. <a href=\\\"http://howto.philippkeller.com/2013/01/01/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5/\\\">Here are the adaptions</a> you need to make for this tutorial to work</li>\\n<li>OS X or Linux. I&rsquo;m on OS X 10.8.2, I marked the steps that are OS X specific. For Linux users it&rsquo;s most probably very easy to adapt those. For Windows you certainly need to do some bigger adaptations.</li>\\n<li>MySQL and its python bindings (for local development)</li>\\n</ul>\\n<h2 id=\\\"What-about-Django-lt-1-4\\\"><a href=\\\"#What-about-Django-lt-1-4\\\" class=\\\"headerlink\\\" title=\\\"What about Django &lt; 1.4?\\\"></a>What about Django &lt; 1.4?</h2><p>Appengine supports the versions 0.96, 1.2, 1.3 and 1.4. This tutorial should work with all those versions. I only tested 1.3 and 1.4 though.<br>All you need to do with this tutorial is to change 1.4 to 1.3 and keep in mind that the <a href=\\\"https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Django directory structure slightly changed</a> in version 1.4 so you need to adapt some of the shell commands.</p>\\n<h1 id=\\\"Create-a-Google-App-Engine-Instance\\\"><a href=\\\"#Create-a-Google-App-Engine-Instance\\\" class=\\\"headerlink\\\" title=\\\"Create a Google App Engine Instance\\\"></a>Create a Google App Engine Instance</h1><p>  Create new instance on <a href=\\\"https://appengine.google.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">appengine</a>.</p>\\n<p>  Your instance will be located in the US unless you&rsquo;re willing to pay <a href=\\\"https://cloud.google.com/pricing/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">500$ a month to register for a premium account</a><br>  (Europe hosting is <a href=\\\"https://developers.google.com/appengine/docs/premier/location\\\" target=\\\"_blank\\\" rel=\\\"external\\\">for premium accounts only</a>)</p>\\n<h1 id=\\\"Install-Google-App-Engine-OS-X-specific\\\"><a href=\\\"#Install-Google-App-Engine-OS-X-specific\\\" class=\\\"headerlink\\\" title=\\\"Install Google App Engine (OS X specific)\\\"></a>Install Google App Engine (OS X specific)</h1><ol>\\n<li>Download the <a href=\\\"https://developers.google.com/appengine/downloads#Google_App_Engine_SDK_for_Python\\\" target=\\\"_blank\\\" rel=\\\"external\\\">GoogleAppEngineLauncher-x.x.x.dmg</a></li>\\n<li>Open the dmg, move <code>GoogleAppEngineLauncher</code> to Applications</li>\\n<li>Open GoogleAppEngineLauncher, say yes to the symlinks</li>\\n<li>Add <code>$PATH</code> and <code>$PYTHONPATH</code> to shell environment: Add these lines to <code>.bash_profile</code> (<code>.bashrc</code> on Linux):<pre>\\nexport GAE=\\\"/usr/local/google_appengine\\\"\\nexport PYTHONPATH=\\\"$PYTHONPATH:$GAE:$GAE/lib/django_1_4\\\"\\nexport PATH=${PATH}:$GAE/lib/django_1_4/django/bin/</pre>Load these settings into the current session with <pre>source ~/.bash_profile</pre> and make the django binaries executable: <pre>chmod a+x $GAE/lib/django_1_4/django/bin/[a-z]*.py</pre>\\n\\n</li>\\n</ol>\\n<h1 id=\\\"Create-the-django-project\\\"><a href=\\\"#Create-the-django-project\\\" class=\\\"headerlink\\\" title=\\\"Create the django project\\\"></a>Create the django project</h1><ol>\\n<li>run this in a directory of your choice (I chose <code>~/python/</code>). This generates a stub django project. Replace mysite with the name of your django project. <pre>django-admin.py startproject mysite</pre>Switch into mysite (where <code>manage.py</code> resides, only do this if you run Django 1.4):<pre>cd mysite</pre></li>\\n<li><p>create the file <code>mysite/app.yaml</code> with this content (replace <code>appproject</code> with the id of your appspot.com instance):<br><pre><br>application: appproject<br>version: 1<br>runtime: python27<br>api_version: 1<br>threadsafe: true</pre></p>\\n<p>libraries:</p>\\n</li>\\n</ol>\\n<ul>\\n<li><p>name: django<br>version: “1.4”</p>\\n<p>  builtins:</p>\\n</li>\\n<li><p>django_wsgi: on</p>\\n<p>  handlers:</p>\\n</li>\\n<li>url: /static/admin<br>static_dir: static/admin<br>expiration: ‘0’<br></li>\\n</ul>\\n<ol>\\n<li>edit <code>mysite/settings.py</code>: Change the value of <code>ROOT_URLCONF</code> from <code>mysite.urls</code> to <code>urls</code> (else you run into an exception in your live instance)</li>\\n<li>also in <code>settings.py</code> add these 2 lines anywhere at the top:<br><pre><br>import os<br>BASE_DIR = os.path.abspath(os.path.dirname(<strong>file</strong>)) + os.sep<br></pre><br>This is the path prefix you&rsquo;ll put before all the <code>xyz_ROOT</code> settings later.</li>\\n<li>run this one level up of your python project directory: <pre>dev_appserver.py mysite</pre></li>\\n</ol>\\n<p>Congrats! Your <a href=\\\"http://localhost:8080\\\" target=\\\"_blank\\\" rel=\\\"external\\\">local instance</a> now shows <a href=\\\"http://i.imgur.com/rXh74.png\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this</a> - hopefully :-)</p>\\n<h1 id=\\\"Set-up-Google-Cloud-SQL\\\"><a href=\\\"#Set-up-Google-Cloud-SQL\\\" class=\\\"headerlink\\\" title=\\\"Set up Google Cloud SQL\\\"></a>Set up Google Cloud SQL</h1><ol>\\n<li>Register Cloud SQL in the <a href=\\\"https://code.google.com/apis/console/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Google API Console</a> (I think you need to add billing, but currently there&rsquo;s a free plan until June 1, 2013)</li>\\n<li>create a new instance in the <strong>United States</strong> (even when you&rsquo;re located in Europe). The reason is that your Cloud SQL instance needs to be at the same location as your GAE instance. Put your ID of your appspot.com instance to the Authorized Applications.</li>\\n<li>create a new database using the SQL Prompt: <pre>CREATE DATABASE my_database;</pre></li>\\n<li><p>replace the <code>DATABASES</code> section of your <code>settings.py</code> with the snippet below: (Replace <code>my_project:instance1</code> with your Cloud SQL Instance id and <code>my_database</code> with your created database name).<br><pre><br>import os<br>if (os.getenv(‘SERVER_SOFTWARE’, ‘’).startswith(‘Google App Engine’) or<br>os.getenv(‘SETTINGS_MODE’) == ‘prod’):</pre></p>\\n<h1 id=\\\"Running-on-production-App-Engine-so-use-a-Google-Cloud-SQL-database\\\"><a href=\\\"#Running-on-production-App-Engine-so-use-a-Google-Cloud-SQL-database\\\" class=\\\"headerlink\\\" title=\\\"Running on production App Engine, so use a Google Cloud SQL database.\\\"></a>Running on production App Engine, so use a Google Cloud SQL database.</h1><p>DATABASES = {</p>\\n<pre><code>&apos;default&apos;: {\\n    &apos;ENGINE&apos;: &apos;google.appengine.ext.django.backends.rdbms&apos;,\\n    &apos;INSTANCE&apos;: &apos;my_project:instance1&apos;,\\n    &apos;NAME&apos;: &apos;my_database&apos;,\\n}\\n</code></pre><p>}<br>else:</p>\\n<h1 id=\\\"Running-in-development-so-use-a-local-MySQL-database\\\"><a href=\\\"#Running-in-development-so-use-a-local-MySQL-database\\\" class=\\\"headerlink\\\" title=\\\"Running in development, so use a local MySQL database\\\"></a>Running in development, so use a local MySQL database</h1><p>DATABASES = {</p>\\n<pre><code>&apos;default&apos;: {\\n    &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,\\n    &apos;USER&apos;: &apos;root&apos;,\\n    &apos;PASSWORD&apos;: &apos;&apos;,\\n    &apos;HOST&apos;: &apos;localhost&apos;,\\n    &apos;NAME&apos;: &apos;my_db&apos;,\\n}\\n</code></pre><p>}<br><br>These settings configure django to use a local MySQL storage for development. That&rsquo;s very close to the cloud setup, as Google Cloud SQL is <a href=\\\"https://developers.google.com/cloud-sql/faq#databaseengine\\\" target=\\\"_blank\\\" rel=\\\"external\\\">powered by Mysql (currently 5.5)</a></p>\\n<p>I highly recommend this as on my machine every SQL query took about 1 second when run against Google Cloud SQL.</p>\\n<p>That comes from the fact as first the SQL queries run over HTTP and second the Cloud SQL Instance <a href=\\\"https://ipdb.at/ip/74.125.132.95\\\" target=\\\"_blank\\\" rel=\\\"external\\\">runs in California</a>.</p>\\n</li>\\n<li><p>To trigger the oauth authorization (stored in <code>~/.googlesql_oauth2.dat</code>) run this:<pre>SETTINGS_MODE=’prod’ python manage.py syncdb</pre></p>\\n</li>\\n</ol>\\n<p>If that last command worked that proves that your Cloud SQL worked so far. Congrats!</p>\\n<p>Your local MySQL instance is now ready as well. You should check if <code>MySQLdb</code> is installed:</p>\\n<pre>python -c \\\"import MySQLdb\\\"</pre>\\nTo test the Django↔MySQL connection run\\n<pre>python mysite/manage.py syncdb</pre>\\n\\n<p>Whenever you want to sync your django models to:</p>\\n<p>a) the <em>live</em> db: <code>SETTINGS_MODE=&#39;prod&#39; python manage.py syncdb</code></p>\\n<p>b) the <em>local mysql</em> db: <code>python manage.py syncdb</code></p>\\n<h1 id=\\\"Deploy-your-stub-app-to-appspot\\\"><a href=\\\"#Deploy-your-stub-app-to-appspot\\\" class=\\\"headerlink\\\" title=\\\"Deploy your stub app to appspot\\\"></a>Deploy your stub app to appspot</h1><p>  Ready to deploy your fresh app to the cloud?</p>\\n<p>  Run this (replace mysite with your project name): </p>\\n<pre>appcfg.py --oauth2 update mysite</pre>\\n\\n<p>  After about 1 minute your fresh Django project should run perfectly on <a href=\\\"http://your-id.appspot.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">http://your-id.appspot.com/</a></p>\\n<p><strong>Why not sqlite?</strong></p>\\n<p>Sqlite would be a lot easier to set up, actually there is nothing to install and no server to start, no passwords, etc.</p>\\n<p>Apart from the fact that I couldn&rsquo;t get it working (details see <a href=\\\"http://stackoverflow.com/questions/14080430\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>) it&rsquo;s certainly not a smart idea to run sqlite locally and MySQL (as used by Cloud SQL) in production, <a href=\\\"http://stackoverflow.com/questions/2306048/django-sqlite-for-dev-mysql-for-prod\\\" target=\\\"_blank\\\" rel=\\\"external\\\">it&rsquo;s very likely that you&rsquo;ll run into issues</a>.</p>\\n<h1 id=\\\"Serving-static-files\\\"><a href=\\\"#Serving-static-files\\\" class=\\\"headerlink\\\" title=\\\"Serving static files\\\"></a>Serving static files</h1><p>Django <a href=\\\"https://docs.djangoproject.com/en/dev/howto/static-files/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">supports serving static files</a> via <code>django.contrib.staticfiles</code>. However, I didn&rsquo;t get this to work. And since serving these files directly via GAE is faster anyways, add this to your <code>app.yaml</code>:</p>\\n<pre>\\n- url: /media\\n  static_dir: media\\n  expiration: '0'\\n</pre>\\n\\n<p>This assumes your static files are under <code>mysite/media</code>. Your static files now serve under <a href=\\\"http://localhost:8080/media/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">/media/</a></p>\\n<h1 id=\\\"Enable-Admin-optional\\\"><a href=\\\"#Enable-Admin-optional\\\" class=\\\"headerlink\\\" title=\\\"Enable Admin (optional)\\\"></a>Enable Admin (optional)</h1><p>You probably want to enable the admin interface (Steps 2-4 are actually all about getting the static admin files to serve. Full discussion see <a href=\\\"http://stackoverflow.com/questions/9860610\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>.)</p>\\n<ol>\\n<li><p>Uncomment all admin specific lines in <code>settings.py</code> (in <code>INSTALLED_APPS</code>) and <code>urls.py</code> (header and urlpatterns).</p>\\n<pre><code>Go sure you don&amp;rsquo;t miss any of these lines by double checking [here, under &amp;ldquo;Activate the admin site&amp;rdquo;](https://docs.djangoproject.com/en/1.3/intro/tutorial02/#activate-the-admin-site).\\n</code></pre></li>\\n<li>Sync the new models agains live<pre>SETTINGS_MODE=’prod’ python mysite/manage.py syncdb</pre>and local MySQL<pre>python mysite/manage.py syncdb</pre></li>\\n<li>in <code>settings.py</code> replace the <code>STATIC_ROOT</code> line with (you defined BASE_DIR <a href=\\\"#create_the_django_project\\\">above</a>):<pre>STATIC_ROOT = BASE_DIR + 'static'</pre></li>\\n<li>To copy all the admin media assets into <code>mysite/static</code> run:<pre>python mysite/manage.py collectstatic</pre></li>\\n<li>now, <a href=\\\"http://localhost:8080/admin/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">/admin</a> should show your admin site, with CSS.</li>\\n</ol>\\n<h1 id=\\\"And-now\\\"><a href=\\\"#And-now\\\" class=\\\"headerlink\\\" title=\\\"And now?\\\"></a>And now?</h1><ul>\\n<li>If you&rsquo;re new to Django or if you want to be 100% sure everything works as expected follow the <a href=\\\"https://docs.djangoproject.com/en/1.4/intro/tutorial01/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">django tutorial</a></li>\\n<li>Want to port your Django app to Google App Engine? I&rsquo;ll likely come up with another article about that.</li>\\n</ul>\\n<h1 id=\\\"Troubleshooting\\\"><a href=\\\"#Troubleshooting\\\" class=\\\"headerlink\\\" title=\\\"Troubleshooting\\\"></a>Troubleshooting</h1><p><strong>on my development machine the web app is <em>veeery</em> slow</strong></p>\\n<p>Chances are high that you&rsquo;re not using the local MySQL. Start dev_appserver.py with the <code>--debug</code> flag and see if it does any RPC calls (SQL queries wrapped into HTTP)</p>\\n<p>If that isn&rsquo;t the issue you might want to <a href=\\\"https://developers.google.com/appengine/docs/python/tools/appstats#EventRecorders\\\" target=\\\"_blank\\\" rel=\\\"external\\\">track performance with appstats</a>.</p>\\n<p><strong>I wanted to use sqlite instead of mysql as a backend, but I run into <code>ImportError</code>, <code>cannot import name utils</code></strong></p>\\n<p>So did I. I don&rsquo;t know how to solve it. See <a href=\\\"http://stackoverflow.com/questions/14080430\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a> for details.</p>\\n<p><strong>I get an <code>unknown locale</code> exception when running syncdb against MySQL</strong></p>\\n<p>I personally got <code>ValueError: unknown locale: UTF-8</code>. There is a <a href=\\\"http://patrick.arminio.info/blog/2012/02/fix-valueerror-unknown-locale-utf8/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">solution for that</a></p>\\n<p><strong>I get a <code>DoesNotExist</code> exception when accessing /admin/</strong></p>\\n<p>At one point I got this exception: <code>DoesNotExist at /admin/</code>, <code>Site matching query does not exist</code></p>\\n<p>Solution is <a href=\\\"http://stackoverflow.com/questions/9736975/django-admin-doesnotexist-at-admin\\\" target=\\\"_blank\\\" rel=\\\"external\\\">described here</a></p>\\n<p><strong>I get an ImportError for mysite.urls</strong></p>\\n<p>I got the exception <code>No module named mysite.urls</code> before I replaced</p>\\n<p><pre>ROOT_URLCONF = ‘mysite.urls’</pre><br>with</p>\\n<p><pre>ROOT_URLCONF = ‘urls’</pre><br>I didn&rsquo;t really understand why that error occurs.</p>\\n<h1 id=\\\"Further-reading\\\"><a href=\\\"#Further-reading\\\" class=\\\"headerlink\\\" title=\\\"Further reading\\\"></a>Further reading</h1><p><strong>Official documentation</strong></p>\\n<ul>\\n<li><p><a href=\\\"https://developers.google.com/appengine/docs/python/cloud-sql/django\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Official Google Documentation on how to use Django with Google Cloud SQL</a><strong>Other tutorials</strong></p>\\n</li>\\n<li><p>Google App Engine, Django and Cloud SQL <a href=\\\"http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Part 1</a> and <a href=\\\"http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql-part-ii\\\" target=\\\"_blank\\\" rel=\\\"external\\\">2</a> (Björnalycke)</p>\\n</li>\\n<li><p><a href=\\\"http://www.joemartaganna.com/web-development/running-django-13-in-google-app-engine-with-google-cloud-sql/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Running Django 1.3 in Google App Engine with Google Cloud SQL (Joemar Taganna)</a><strong>Outdated tutorials (based on Datastore, e.g. django-nonrel)</strong></p>\\n</li>\\n<li><p><a href=\\\"http://thomas.broxrost.com/2008/04/08/django-on-google-app-engine/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Django on Google App Engine in 13 simple steps (by Thomas Brox Røst)</a></p>\\n</li>\\n<li><a href=\\\"http://agiliq.com/blog/2008/04/two-djangoappengine-tutorials/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Using Django with Appengine (2 tutorials by Shabda Raaj)</a></li>\\n</ul>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p><img src=\\\"https://lh5.googleusercontent.com/-lX6aq3qvV50/UOC0ONuosVI/AAAAAAAAMUE/Q_occPtbmnQ/s230/Untitled-1.png\\\" alt=\\\"\\\"><br>Google is running an <a href=\\\"https://developers.google.com/cloud-sql/docs/billing#intro_trial\\\" target=\\\"_blank\\\" rel=\\\"external\\\">introductory trial for Cloud SQL that runs since Nov 2012 until June 1, 2013</a>. That&rsquo;s the right hour to test Django on Google App Engine. No need to mess around with their non relational datastore. Just use their MySQL 5.5 in the cloud.</p>\\n<p>Hence I decided to give it a try and documented all into a very complete tutorial how to start a Django 1.4 project running on &ldquo;Google App Engine&rdquo;.<br>\",\"more\":\"</p>\\n<p>If you run into exceptions, check the troubleshooting part at the bottom</p>\\n<h1 id=\\\"Requirements\\\"><a href=\\\"#Requirements\\\" class=\\\"headerlink\\\" title=\\\"Requirements\\\"></a>Requirements</h1><ul>\\n<li>Python 2.7. If you can&rsquo;t use 2.7 for any reason, no worries. <a href=\\\"http://howto.philippkeller.com/2013/01/01/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5/\\\">Here are the adaptions</a> you need to make for this tutorial to work</li>\\n<li>OS X or Linux. I&rsquo;m on OS X 10.8.2, I marked the steps that are OS X specific. For Linux users it&rsquo;s most probably very easy to adapt those. For Windows you certainly need to do some bigger adaptations.</li>\\n<li>MySQL and its python bindings (for local development)</li>\\n</ul>\\n<h2 id=\\\"What-about-Django-lt-1-4\\\"><a href=\\\"#What-about-Django-lt-1-4\\\" class=\\\"headerlink\\\" title=\\\"What about Django &lt; 1.4?\\\"></a>What about Django &lt; 1.4?</h2><p>Appengine supports the versions 0.96, 1.2, 1.3 and 1.4. This tutorial should work with all those versions. I only tested 1.3 and 1.4 though.<br>All you need to do with this tutorial is to change 1.4 to 1.3 and keep in mind that the <a href=\\\"https://docs.djangoproject.com/en/dev/releases/1.4/#updated-default-project-layout-and-manage-py\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Django directory structure slightly changed</a> in version 1.4 so you need to adapt some of the shell commands.</p>\\n<h1 id=\\\"Create-a-Google-App-Engine-Instance\\\"><a href=\\\"#Create-a-Google-App-Engine-Instance\\\" class=\\\"headerlink\\\" title=\\\"Create a Google App Engine Instance\\\"></a>Create a Google App Engine Instance</h1><p>  Create new instance on <a href=\\\"https://appengine.google.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">appengine</a>.</p>\\n<p>  Your instance will be located in the US unless you&rsquo;re willing to pay <a href=\\\"https://cloud.google.com/pricing/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">500$ a month to register for a premium account</a><br>  (Europe hosting is <a href=\\\"https://developers.google.com/appengine/docs/premier/location\\\" target=\\\"_blank\\\" rel=\\\"external\\\">for premium accounts only</a>)</p>\\n<h1 id=\\\"Install-Google-App-Engine-OS-X-specific\\\"><a href=\\\"#Install-Google-App-Engine-OS-X-specific\\\" class=\\\"headerlink\\\" title=\\\"Install Google App Engine (OS X specific)\\\"></a>Install Google App Engine (OS X specific)</h1><ol>\\n<li>Download the <a href=\\\"https://developers.google.com/appengine/downloads#Google_App_Engine_SDK_for_Python\\\" target=\\\"_blank\\\" rel=\\\"external\\\">GoogleAppEngineLauncher-x.x.x.dmg</a></li>\\n<li>Open the dmg, move <code>GoogleAppEngineLauncher</code> to Applications</li>\\n<li>Open GoogleAppEngineLauncher, say yes to the symlinks</li>\\n<li>Add <code>$PATH</code> and <code>$PYTHONPATH</code> to shell environment: Add these lines to <code>.bash_profile</code> (<code>.bashrc</code> on Linux):<pre>\\nexport GAE=\\\"/usr/local/google_appengine\\\"\\nexport PYTHONPATH=\\\"$PYTHONPATH:$GAE:$GAE/lib/django_1_4\\\"\\nexport PATH=${PATH}:$GAE/lib/django_1_4/django/bin/</pre>Load these settings into the current session with <pre>source ~/.bash_profile</pre> and make the django binaries executable: <pre>chmod a+x $GAE/lib/django_1_4/django/bin/[a-z]*.py</pre>\\n\\n</li>\\n</ol>\\n<h1 id=\\\"Create-the-django-project\\\"><a href=\\\"#Create-the-django-project\\\" class=\\\"headerlink\\\" title=\\\"Create the django project\\\"></a>Create the django project</h1><ol>\\n<li>run this in a directory of your choice (I chose <code>~/python/</code>). This generates a stub django project. Replace mysite with the name of your django project. <pre>django-admin.py startproject mysite</pre>Switch into mysite (where <code>manage.py</code> resides, only do this if you run Django 1.4):<pre>cd mysite</pre></li>\\n<li><p>create the file <code>mysite/app.yaml</code> with this content (replace <code>appproject</code> with the id of your appspot.com instance):<br><pre><br>application: appproject<br>version: 1<br>runtime: python27<br>api_version: 1<br>threadsafe: true</pre></p>\\n<p>libraries:</p>\\n</li>\\n</ol>\\n<ul>\\n<li><p>name: django<br>version: “1.4”</p>\\n<p>  builtins:</p>\\n</li>\\n<li><p>django_wsgi: on</p>\\n<p>  handlers:</p>\\n</li>\\n<li>url: /static/admin<br>static_dir: static/admin<br>expiration: ‘0’<br></li>\\n</ul>\\n<ol>\\n<li>edit <code>mysite/settings.py</code>: Change the value of <code>ROOT_URLCONF</code> from <code>mysite.urls</code> to <code>urls</code> (else you run into an exception in your live instance)</li>\\n<li>also in <code>settings.py</code> add these 2 lines anywhere at the top:<br><pre><br>import os<br>BASE_DIR = os.path.abspath(os.path.dirname(<strong>file</strong>)) + os.sep<br></pre><br>This is the path prefix you&rsquo;ll put before all the <code>xyz_ROOT</code> settings later.</li>\\n<li>run this one level up of your python project directory: <pre>dev_appserver.py mysite</pre></li>\\n</ol>\\n<p>Congrats! Your <a href=\\\"http://localhost:8080\\\" target=\\\"_blank\\\" rel=\\\"external\\\">local instance</a> now shows <a href=\\\"http://i.imgur.com/rXh74.png\\\" target=\\\"_blank\\\" rel=\\\"external\\\">this</a> - hopefully :-)</p>\\n<h1 id=\\\"Set-up-Google-Cloud-SQL\\\"><a href=\\\"#Set-up-Google-Cloud-SQL\\\" class=\\\"headerlink\\\" title=\\\"Set up Google Cloud SQL\\\"></a>Set up Google Cloud SQL</h1><ol>\\n<li>Register Cloud SQL in the <a href=\\\"https://code.google.com/apis/console/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Google API Console</a> (I think you need to add billing, but currently there&rsquo;s a free plan until June 1, 2013)</li>\\n<li>create a new instance in the <strong>United States</strong> (even when you&rsquo;re located in Europe). The reason is that your Cloud SQL instance needs to be at the same location as your GAE instance. Put your ID of your appspot.com instance to the Authorized Applications.</li>\\n<li>create a new database using the SQL Prompt: <pre>CREATE DATABASE my_database;</pre></li>\\n<li><p>replace the <code>DATABASES</code> section of your <code>settings.py</code> with the snippet below: (Replace <code>my_project:instance1</code> with your Cloud SQL Instance id and <code>my_database</code> with your created database name).<br><pre><br>import os<br>if (os.getenv(‘SERVER_SOFTWARE’, ‘’).startswith(‘Google App Engine’) or<br>os.getenv(‘SETTINGS_MODE’) == ‘prod’):</pre></p>\\n<h1 id=\\\"Running-on-production-App-Engine-so-use-a-Google-Cloud-SQL-database\\\"><a href=\\\"#Running-on-production-App-Engine-so-use-a-Google-Cloud-SQL-database\\\" class=\\\"headerlink\\\" title=\\\"Running on production App Engine, so use a Google Cloud SQL database.\\\"></a>Running on production App Engine, so use a Google Cloud SQL database.</h1><p>DATABASES = {</p>\\n<pre><code>&apos;default&apos;: {\\n    &apos;ENGINE&apos;: &apos;google.appengine.ext.django.backends.rdbms&apos;,\\n    &apos;INSTANCE&apos;: &apos;my_project:instance1&apos;,\\n    &apos;NAME&apos;: &apos;my_database&apos;,\\n}\\n</code></pre><p>}<br>else:</p>\\n<h1 id=\\\"Running-in-development-so-use-a-local-MySQL-database\\\"><a href=\\\"#Running-in-development-so-use-a-local-MySQL-database\\\" class=\\\"headerlink\\\" title=\\\"Running in development, so use a local MySQL database\\\"></a>Running in development, so use a local MySQL database</h1><p>DATABASES = {</p>\\n<pre><code>&apos;default&apos;: {\\n    &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,\\n    &apos;USER&apos;: &apos;root&apos;,\\n    &apos;PASSWORD&apos;: &apos;&apos;,\\n    &apos;HOST&apos;: &apos;localhost&apos;,\\n    &apos;NAME&apos;: &apos;my_db&apos;,\\n}\\n</code></pre><p>}<br><br>These settings configure django to use a local MySQL storage for development. That&rsquo;s very close to the cloud setup, as Google Cloud SQL is <a href=\\\"https://developers.google.com/cloud-sql/faq#databaseengine\\\" target=\\\"_blank\\\" rel=\\\"external\\\">powered by Mysql (currently 5.5)</a></p>\\n<p>I highly recommend this as on my machine every SQL query took about 1 second when run against Google Cloud SQL.</p>\\n<p>That comes from the fact as first the SQL queries run over HTTP and second the Cloud SQL Instance <a href=\\\"https://ipdb.at/ip/74.125.132.95\\\" target=\\\"_blank\\\" rel=\\\"external\\\">runs in California</a>.</p>\\n</li>\\n<li><p>To trigger the oauth authorization (stored in <code>~/.googlesql_oauth2.dat</code>) run this:<pre>SETTINGS_MODE=’prod’ python manage.py syncdb</pre></p>\\n</li>\\n</ol>\\n<p>If that last command worked that proves that your Cloud SQL worked so far. Congrats!</p>\\n<p>Your local MySQL instance is now ready as well. You should check if <code>MySQLdb</code> is installed:</p>\\n<pre>python -c \\\"import MySQLdb\\\"</pre>\\nTo test the Django↔MySQL connection run\\n<pre>python mysite/manage.py syncdb</pre>\\n\\n<p>Whenever you want to sync your django models to:</p>\\n<p>a) the <em>live</em> db: <code>SETTINGS_MODE=&#39;prod&#39; python manage.py syncdb</code></p>\\n<p>b) the <em>local mysql</em> db: <code>python manage.py syncdb</code></p>\\n<h1 id=\\\"Deploy-your-stub-app-to-appspot\\\"><a href=\\\"#Deploy-your-stub-app-to-appspot\\\" class=\\\"headerlink\\\" title=\\\"Deploy your stub app to appspot\\\"></a>Deploy your stub app to appspot</h1><p>  Ready to deploy your fresh app to the cloud?</p>\\n<p>  Run this (replace mysite with your project name): </p>\\n<pre>appcfg.py --oauth2 update mysite</pre>\\n\\n<p>  After about 1 minute your fresh Django project should run perfectly on <a href=\\\"http://your-id.appspot.com/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">http://your-id.appspot.com/</a></p>\\n<p><strong>Why not sqlite?</strong></p>\\n<p>Sqlite would be a lot easier to set up, actually there is nothing to install and no server to start, no passwords, etc.</p>\\n<p>Apart from the fact that I couldn&rsquo;t get it working (details see <a href=\\\"http://stackoverflow.com/questions/14080430\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>) it&rsquo;s certainly not a smart idea to run sqlite locally and MySQL (as used by Cloud SQL) in production, <a href=\\\"http://stackoverflow.com/questions/2306048/django-sqlite-for-dev-mysql-for-prod\\\" target=\\\"_blank\\\" rel=\\\"external\\\">it&rsquo;s very likely that you&rsquo;ll run into issues</a>.</p>\\n<h1 id=\\\"Serving-static-files\\\"><a href=\\\"#Serving-static-files\\\" class=\\\"headerlink\\\" title=\\\"Serving static files\\\"></a>Serving static files</h1><p>Django <a href=\\\"https://docs.djangoproject.com/en/dev/howto/static-files/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">supports serving static files</a> via <code>django.contrib.staticfiles</code>. However, I didn&rsquo;t get this to work. And since serving these files directly via GAE is faster anyways, add this to your <code>app.yaml</code>:</p>\\n<pre>\\n- url: /media\\n  static_dir: media\\n  expiration: '0'\\n</pre>\\n\\n<p>This assumes your static files are under <code>mysite/media</code>. Your static files now serve under <a href=\\\"http://localhost:8080/media/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">/media/</a></p>\\n<h1 id=\\\"Enable-Admin-optional\\\"><a href=\\\"#Enable-Admin-optional\\\" class=\\\"headerlink\\\" title=\\\"Enable Admin (optional)\\\"></a>Enable Admin (optional)</h1><p>You probably want to enable the admin interface (Steps 2-4 are actually all about getting the static admin files to serve. Full discussion see <a href=\\\"http://stackoverflow.com/questions/9860610\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a>.)</p>\\n<ol>\\n<li><p>Uncomment all admin specific lines in <code>settings.py</code> (in <code>INSTALLED_APPS</code>) and <code>urls.py</code> (header and urlpatterns).</p>\\n<pre><code>Go sure you don&amp;rsquo;t miss any of these lines by double checking [here, under &amp;ldquo;Activate the admin site&amp;rdquo;](https://docs.djangoproject.com/en/1.3/intro/tutorial02/#activate-the-admin-site).\\n</code></pre></li>\\n<li>Sync the new models agains live<pre>SETTINGS_MODE=’prod’ python mysite/manage.py syncdb</pre>and local MySQL<pre>python mysite/manage.py syncdb</pre></li>\\n<li>in <code>settings.py</code> replace the <code>STATIC_ROOT</code> line with (you defined BASE_DIR <a href=\\\"#create_the_django_project\\\">above</a>):<pre>STATIC_ROOT = BASE_DIR + 'static'</pre></li>\\n<li>To copy all the admin media assets into <code>mysite/static</code> run:<pre>python mysite/manage.py collectstatic</pre></li>\\n<li>now, <a href=\\\"http://localhost:8080/admin/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">/admin</a> should show your admin site, with CSS.</li>\\n</ol>\\n<h1 id=\\\"And-now\\\"><a href=\\\"#And-now\\\" class=\\\"headerlink\\\" title=\\\"And now?\\\"></a>And now?</h1><ul>\\n<li>If you&rsquo;re new to Django or if you want to be 100% sure everything works as expected follow the <a href=\\\"https://docs.djangoproject.com/en/1.4/intro/tutorial01/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">django tutorial</a></li>\\n<li>Want to port your Django app to Google App Engine? I&rsquo;ll likely come up with another article about that.</li>\\n</ul>\\n<h1 id=\\\"Troubleshooting\\\"><a href=\\\"#Troubleshooting\\\" class=\\\"headerlink\\\" title=\\\"Troubleshooting\\\"></a>Troubleshooting</h1><p><strong>on my development machine the web app is <em>veeery</em> slow</strong></p>\\n<p>Chances are high that you&rsquo;re not using the local MySQL. Start dev_appserver.py with the <code>--debug</code> flag and see if it does any RPC calls (SQL queries wrapped into HTTP)</p>\\n<p>If that isn&rsquo;t the issue you might want to <a href=\\\"https://developers.google.com/appengine/docs/python/tools/appstats#EventRecorders\\\" target=\\\"_blank\\\" rel=\\\"external\\\">track performance with appstats</a>.</p>\\n<p><strong>I wanted to use sqlite instead of mysql as a backend, but I run into <code>ImportError</code>, <code>cannot import name utils</code></strong></p>\\n<p>So did I. I don&rsquo;t know how to solve it. See <a href=\\\"http://stackoverflow.com/questions/14080430\\\" target=\\\"_blank\\\" rel=\\\"external\\\">here</a> for details.</p>\\n<p><strong>I get an <code>unknown locale</code> exception when running syncdb against MySQL</strong></p>\\n<p>I personally got <code>ValueError: unknown locale: UTF-8</code>. There is a <a href=\\\"http://patrick.arminio.info/blog/2012/02/fix-valueerror-unknown-locale-utf8/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">solution for that</a></p>\\n<p><strong>I get a <code>DoesNotExist</code> exception when accessing /admin/</strong></p>\\n<p>At one point I got this exception: <code>DoesNotExist at /admin/</code>, <code>Site matching query does not exist</code></p>\\n<p>Solution is <a href=\\\"http://stackoverflow.com/questions/9736975/django-admin-doesnotexist-at-admin\\\" target=\\\"_blank\\\" rel=\\\"external\\\">described here</a></p>\\n<p><strong>I get an ImportError for mysite.urls</strong></p>\\n<p>I got the exception <code>No module named mysite.urls</code> before I replaced</p>\\n<p><pre>ROOT_URLCONF = ‘mysite.urls’</pre><br>with</p>\\n<p><pre>ROOT_URLCONF = ‘urls’</pre><br>I didn&rsquo;t really understand why that error occurs.</p>\\n<h1 id=\\\"Further-reading\\\"><a href=\\\"#Further-reading\\\" class=\\\"headerlink\\\" title=\\\"Further reading\\\"></a>Further reading</h1><p><strong>Official documentation</strong></p>\\n<ul>\\n<li><p><a href=\\\"https://developers.google.com/appengine/docs/python/cloud-sql/django\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Official Google Documentation on how to use Django with Google Cloud SQL</a><strong>Other tutorials</strong></p>\\n</li>\\n<li><p>Google App Engine, Django and Cloud SQL <a href=\\\"http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Part 1</a> and <a href=\\\"http://bjornalycke.se/articles/google-app-engine-django-and-cloud-sql-part-ii\\\" target=\\\"_blank\\\" rel=\\\"external\\\">2</a> (Björnalycke)</p>\\n</li>\\n<li><p><a href=\\\"http://www.joemartaganna.com/web-development/running-django-13-in-google-app-engine-with-google-cloud-sql/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Running Django 1.3 in Google App Engine with Google Cloud SQL (Joemar Taganna)</a><strong>Outdated tutorials (based on Datastore, e.g. django-nonrel)</strong></p>\\n</li>\\n<li><p><a href=\\\"http://thomas.broxrost.com/2008/04/08/django-on-google-app-engine/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Django on Google App Engine in 13 simple steps (by Thomas Brox Røst)</a></p>\\n</li>\\n<li><a href=\\\"http://agiliq.com/blog/2008/04/two-djangoappengine-tutorials/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Using Django with Appengine (2 tutorials by Shabda Raaj)</a></li>\\n</ul>\"},{\"title\":\"Tagsystems: performance tests\",\"date\":\"2005-06-19T15:09:00.000Z\",\"alias\":\"/post/37027746608/tagsystems-performance-tests\",\"_content\":\"\\nIn my [previous article named &ldquo;Tags: database schemas&rdquo;](http://tagging.pui.ch/post/37027745720/tags-database-schemas \\\"Tags: database schemas\\\") we analysed different database schemas on how they could meet the needs of tag systems. In this article, the focus is on performance (speed). That is: if you want to build a tagsystem that performs good with about 1 million items (bookmarks for instance), then you may want to have a look at the following result of my performance tests.\\nIn this article I tested tagging of bookmarks, but as you can tag pretty much anything, this goes for tagging systems in general.<!-- more -->\\n\\nI tested the following schemas (I keep the naming from the previous article):\\n\\n*   **mysqlicious**: One table. Tags are space separated in column &ldquo;tags&rdquo;; [as introduced](http://tagging.pui.ch/post/37027745720/tags-database-schemas#mysqlicious)\\n*   **mysqlicious fulltext**: Same schema but with [mysql fulltext](http://dev.mysql.com/doc/mysql/en/fulltext-search.html) on the tag column; [as introduced](http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext)\\n*   **scuttle**: Two tables: One for bookmarks, one for tags. Tag-table has foreign key to bookmark table; [as introduced](http://tagging.pui.ch/post/37027745720/tags-database-schemas#scuttle)\\n*   **toxi**: Three tables: One for bookmarks, one for tags, one for junction; [as introduced](http://tagging.pui.ch/post/37027745720/tags-database-schemas#toxi)\\n\\n<span>You may want to have a close watch at the details of the schemas when having a look at the </span>[sql-create-table-queries](http://pastie.org/5480706)<span>.</span>\\n\\n<span></span>But let&rsquo;s go directly to the results. The details about the setup of this tests are mentioned at the [end of this article](#setup). The x-axis depicts the number of bookmarks in the corresponding database, on the y-axis you see how much time each query took to execute.<!-- more -->\\n\\n### <a name=\\\"#results\\\" id=\\\"#results\\\"></a>Results\\n\\n#### Intersection: 250 tag set\\n\\n![Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset](https://lh4.googleusercontent.com/-3MTMt9iTACc/UL0Axe4hHMI/AAAAAAAALDM/cGcmhMoMo20/s400/intersection_250_3_i300.png \\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\")\\n\\nThe first two tests are done with 250 tags in the small dataset ([see below](#setup) for explanation). I think the queries in the &ldquo;1 million bookmarks database&rdquo; are the only size we should pay attention to. I mean if you have a small number of bookmarks, performance isn&rsquo;t really a thing to bother..\\n\\nWe run intersection queries, like\\n\\n> <div>I want to search for bookmarks tagged with &ldquo;design&rdquo; and &ldquo;html&rdquo;</div>\\n\\nYou see that, not surprisingly, mysqlicious with its `WHERE tag LIKE \\\"% tag %\\\"` is very slow. That is, MySQL has to go through the whole dataset and test each bookmark against the query.\\nWhat actually **is** surprising me, is that the fulltext search of mysql is not that high-performance. In fact it is not faster then the `LIKE`-query in the MySQLicious DB. This really disappointed me. I tried to do any quirks possible to make this faster as [I think, a tag-database-system with mysql fulltext would be very easy and like the only thing you should head to..](http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext).\\nWhat is surprising me too, is that the queries on the 3 table schema are about double as fast the the ones on the two-table ones([take a look at the queries](http://pastie.org/5480722) if you think you could give me a hint on this). Noticeable is, that in the scuttle and toxi-variant, the more queries were run, the faster they were. I didn&rsquo;t do any tests with queries and inserts mixed so this may be coming from just plain good caching and this effect possible doesn&rsquo;t show up on live bookmark management systems.\\n\\n#### Intersection: 999 tag set\\n\\n![Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset](https://lh4.googleusercontent.com/-4awEHoQC8w8/UL0Ax6ZbRNI/AAAAAAAALDY/rSvIp_iaqGA/s400/intersection_999_3_300.png \\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\")\\nNow have a look to what happens if we broaden our small tag set: MySQLicious with fulltext suddenly gets the performance leader. That means, if you have a bookmark management system with diverse tags (this most probably comes from the fact that there are many users), the fulltext solution is possibly the way to go.\\nSo now, as you see, choosing the right schema is all about tag distribution. In my previous post about guessing the overall tag distribution on [del.icio.us](http://del.icio.us), I came to the conclusion, that delicious&rsquo; most popular tag &ldquo;design&rdquo; is showing up in 3.2% of all bookmarks on [del.icio.us](http://del.icio.us). So then, what is the mean tag distribution?\\n\\n*   If we say 1% (a tag shows up in 1/100 of all bookmarks on an average) that makes our small tag set 250 tags big\\n*   If we say 0.25%, the small tag set grows to a size of 1000\\n*   If we say 0.1%, the small set will contain 2500 tags\\n\\n<span>So I&rsquo;d suggest that if your average distribution is 1%, take &ldquo;toxi&rdquo;, if the distribution is broader, take &ldquo;MySQLicious fulltext&rdquo;.</span>\\n\\n<span></span>If you take a closer look, you can see that the fulltext schema stayed as fast as when queried in the 250 tag set. That means, if you want to go sure your tag system responds ok in every situation, you should go with the &ldquo;mysql fulltext&rdquo; schema.\\n[Hannes has done some further investigation on mysql fulltext running on MySQL 4.1](http://hannes.magiccards.info/get/results.html) (my tests were on MySQL 4.0.21)\\n\\n#### Union\\n\\n![Union test with 250 tags in small dataset](https://lh5.googleusercontent.com/-Ze5AtV5GPMQ/UL0A35Lc2aI/AAAAAAAALEQ/Y9b0Qs9daAU/s400/union_full_250_3.png)\\nWhen doing a union query we say\\n\\n> <div>I want to search for all the bookmarks that are tagged either with &ldquo;delicious&rdquo; or &ldquo;del.icio.us&rdquo;</div>\\n\\nThis queries, you guessed, are handled the fastest by &ldquo;MySQLicious schema&rdquo; with its `LIKE`-queries: MySQL seeks through the bookmarks, harvesting all bookmarks with one of the given tags and says &ldquo;I&rsquo;m finished!&rdquo; when it was at bookmark number #968, because it found 50 bookmarks. Whereas in the other schemas, MySQL has to join the tags with the bookmarks first and only then could search though it..\\n\\n#### Insert\\n\\n![Setup database schemas with the data: 250 tags in small dataset](https://lh5.googleusercontent.com/-0HAVj_cQ5dM/UL0A2DwvC5I/AAAAAAAALDw/X4DmJIwk8nk/s400/setup_250.png)\\nWhen comparing the different schemas on the time of the insert-&ldquo;statements&rdquo; of one bookmark, the result isn&rsquo;t very surprising (notice that I&rsquo;ve changed the scale of the y-axis).\\nMysqlicious with it&rsquo;s 1 table is very fast indeed, its variation with fulltext had to create the fulltext index and therefore is a bit slower. Scuttle, with its 2 tables and toxi with its 3 tables are at least two respectively three times as slow. I have to remark, that I used quite a bit of caching for the toxi schema, as I didn&rsquo;t want hours to have the data ready..\\n\\nI guess it doesn&rsquo;t really make sense to base your decision, which schema to take on the time for an insert: Bookmark inserts are about 100 times as fast as the intersection queries..\\n\\n#### «What? That slow??»\\n\\nYou said it. You don&rsquo;t want your intersection queries take 0.2 seconds each. That would bring your system to its knees.\\n\\n<span>There are some recipes to avoid that:</span>\\n\\n##### Caching\\n\\nI think, you don&rsquo;t come around good old caching. I think that you could cache results to a query like &ldquo;mysql+tagging&rdquo; for about an hour or so. If a user queries his own items, I would lower the cache time (as up-to-dateness is more important with his own items).\\nThen, I expect if you for instance cache items per tag and intersection them with a decent algorithm, that could be faster..\\n\\n##### The Best Of Both Worlds\\n\\nI think you could have &ldquo;mysqlicous fulltext&rdquo; and &ldquo;toxi&rdquo; running at the same time. That means you have to update/insert in both schemas but when you have to query, you could take the one you think is faster: For simple union the mysqlicious without fulltext search, for intersection queries with common tags the toxi, and for those with uncommon tags the mysqlicious fulltext variant.\\n\\n##### Slicing and dicing\\n\\nYou could &ldquo;slice and dice&rdquo; data (as Nitin proposed it in [two](http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-1.html) of his [posts](http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-2.html)): That is: you slice your user/tag/item-room and build fact tables. You &ldquo;prebuild&rdquo; your results in a way. This way, inserts take long but queries themself should be much faster. In our examples, you would for instance first query the tag-intersections on &ldquo;toxi&rdquo; and then get the facts about each bookmark out of the &ldquo;mysqlicious&rdquo;-fact-table. But you really should read Nitins posts, as they give a lot of insight.\\n\\n##### Using a non RDBMS system\\n\\n**Update:** It&rsquo;s been about a year since I wrote that article, and during that year I came to the conclusion that [RDBMS](http://en.wikipedia.org/wiki/RDBMS) systems don&rsquo;t scale good in systems that have more than 1 million items. Yes, this is a warning: If you are planning to build a large scale system then look for alternatives to [RDBMS](http://en.wikipedia.org/wiki/RDBMS) systems. To quote Joshua Schachter, founder of [delicious](http://del.icio.us):\\n«tags doesn&rsquo;t map to sql at all. so use partial indexing.»[[Joshua Schachter at Carson Summit](http://www.redmonk.com/jgovernor/2006/02/08/things-weve-learned-josh-schachter-quotes-of-the-day/)]\\nI didn&rsquo;t try any of the non-RDBMS system but it looks like [Apache Lucene](http://lucene.apache.org/java/docs/) and [Hadoop](http://lucene.apache.org/hadoop/). There has been [a discussion on the Tagdb Mailing list](http://nelson.textdrive.com/pipermail/tagdb/2006-March/thread.html#164) about these solutions.\\n\\n#### «I don&rsquo;t believe you! I want to try it at home»\\n\\n[Download the source code (PHP)](https://docs.google.com/file/d/0B0uw1JCogWHubEJhdFhub0VjbkE/edit) I used to run the queries and test yourself, extend them as you like. The source is published as [LGPL](http://en.wikipedia.org/wiki/LGPL).\\n\\n### <a id=\\\"setup\\\" name=\\\"setup\\\"></a>Performance Tests Setup\\n\\n<span>Now, if you have read that far, you probably want to know some background information: As you noticed, for each schema, I set up 4 databases, one database holding 1000 bookmarks, the next 10'000, then 100'000 and the fourth 1 million bookmarks. The inserted tags (as well as urls) are random English words taken from two sets of tags:</span>\\n\\n*   the large set containing about 44'000 tags (that are simple English words)\\n*   the small set is varying in size (the results shown here are taken from 250 and 999 tag sets)\\n\\nEvery bookmark gets one to ten tags attached. Every odd tag is from the large set, alternately taken from small and large set. Every schema got exactly the same bookmarks and tag data.\\n\\nThen every schema got queried with an alternately 1-3 tag query. So the first query is for instance just &ldquo;blog&rdquo;, the second &ldquo;design+css&rdquo;, the third &ldquo;webdesign+music+software&rdquo;, the fourth again with just one tag an so forth..\\nAll the tags for the queries are taken from the small set so that the queries don&rsquo;t all end in empty results..\\nAll the queries are tested and work. The outcome of each query on the three schemas is exactly the same.\\n\\n#### Mysql Setup\\n\\nI used mysql 4.0.21.\\nAn excerpt from `/etc/my.cnf` (I think these are the relevant settings to this performance test)\\n\\n<pre>key_buffer=300M\\nquery_cache_size=30M\\nquery_cache_limit=30M\\ntable_cache = 64\\nft_min_word_len = 2\\nft_stopword_file = ''</pre>\\n\\n#### System\\n\\n> <div>CPU: 3GHz Dual Xeon\\n> Cache: 1MB\\n> Harddisk: SCSI Ultra 320 Atlas 10K, no RAID\\n> RAM: 3GB</div>\\n\\n#### Assumptions\\n\\n*   Queries select just the id of a bookmark. I assume that you have to do a second query to get all the wished data to display. I know that this is not fair towards the mysqlicious schema.\\n*   I left out user data, as I assume, user data columns wouldn&rsquo;t change the outcome of this tests. I wanted to keep the schemas as simple as possible.\\n*   Each query is done with `LIMIT 50` as I assume that a normal application doesn&rsquo;t want to get all bookmarks. I assume nobody wants to `order` bookmarks by any dimension, because this would be **very** expensive (ever wondered why you cannot sort bookmarks on [del.icio.us](http://del.icio.us) by date or similar? You get it..)\\n\\n### Acknowledgements\\n\\nThanks to [Citrin](http://www.citrin.ch), the company I work, to let me use our new server to run the queries. The server didn&rsquo;t have much anything else to do so the results should be accurate.\\nThe graphs are done using [JpGraph](http://www.aditus.nu/jpgraph/). Very easy to use and produces beautiful images.\\n\\n### Further reading\\n\\n*   [Flickr architecture](http://www.niallkennedy.com/blog/archives/2004/10/flickr_architec.html)\\n*   [Lab notes: Fulltext not so fast](http://labnotes.blogsome.com/2005/06/06/lab-notes-5-fulltext-not-so-fast/): Fulltext performance issues\\n*   [WebmasterWorld forum: mysql fulltext performance issues](http://www.webmasterworld.com/forum23/3557.htm)\\n*   [Mysql Supersmack: Mysql performance tool](http://vegan.net/tony/supersmack/)\\n*   [Mysql Benchmark](http://dev.mysql.com/doc/mysql/en/mysql-benchmarks.html)\\n*   [Powerpoint article of jeremy zawodny](http://jeremy.zawodny.com/mysql/mysql-optimization.html)on Mysql optimisation\\n*   [Pete Freitag did a sort of review of this article](http://www.petefreitag.com/item/389.cfm)<div class=\\\"blogger-post-footer\\\">![](https://blogger.googleusercontent.com/tracker/2748783673844839576-5133448602510209729?l=theneachwenttohisownhome.blogspot.com)</div>\",\"source\":\"_posts/Tagsystems-performance-tests.md\",\"raw\":\"---\\ntitle: 'Tagsystems: performance tests'\\ntags:\\n  - Performance\\n  - Tags\\n  - Del.icio.us\\n  - MySQL\\ndate: 2005-06-19 17:09:00\\nalias: /post/37027746608/tagsystems-performance-tests\\n---\\n\\nIn my [previous article named &ldquo;Tags: database schemas&rdquo;](http://tagging.pui.ch/post/37027745720/tags-database-schemas \\\"Tags: database schemas\\\") we analysed different database schemas on how they could meet the needs of tag systems. In this article, the focus is on performance (speed). That is: if you want to build a tagsystem that performs good with about 1 million items (bookmarks for instance), then you may want to have a look at the following result of my performance tests.\\nIn this article I tested tagging of bookmarks, but as you can tag pretty much anything, this goes for tagging systems in general.<!-- more -->\\n\\nI tested the following schemas (I keep the naming from the previous article):\\n\\n*   **mysqlicious**: One table. Tags are space separated in column &ldquo;tags&rdquo;; [as introduced](http://tagging.pui.ch/post/37027745720/tags-database-schemas#mysqlicious)\\n*   **mysqlicious fulltext**: Same schema but with [mysql fulltext](http://dev.mysql.com/doc/mysql/en/fulltext-search.html) on the tag column; [as introduced](http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext)\\n*   **scuttle**: Two tables: One for bookmarks, one for tags. Tag-table has foreign key to bookmark table; [as introduced](http://tagging.pui.ch/post/37027745720/tags-database-schemas#scuttle)\\n*   **toxi**: Three tables: One for bookmarks, one for tags, one for junction; [as introduced](http://tagging.pui.ch/post/37027745720/tags-database-schemas#toxi)\\n\\n<span>You may want to have a close watch at the details of the schemas when having a look at the </span>[sql-create-table-queries](http://pastie.org/5480706)<span>.</span>\\n\\n<span></span>But let&rsquo;s go directly to the results. The details about the setup of this tests are mentioned at the [end of this article](#setup). The x-axis depicts the number of bookmarks in the corresponding database, on the y-axis you see how much time each query took to execute.<!-- more -->\\n\\n### <a name=\\\"#results\\\" id=\\\"#results\\\"></a>Results\\n\\n#### Intersection: 250 tag set\\n\\n![Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset](https://lh4.googleusercontent.com/-3MTMt9iTACc/UL0Axe4hHMI/AAAAAAAALDM/cGcmhMoMo20/s400/intersection_250_3_i300.png \\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\")\\n\\nThe first two tests are done with 250 tags in the small dataset ([see below](#setup) for explanation). I think the queries in the &ldquo;1 million bookmarks database&rdquo; are the only size we should pay attention to. I mean if you have a small number of bookmarks, performance isn&rsquo;t really a thing to bother..\\n\\nWe run intersection queries, like\\n\\n> <div>I want to search for bookmarks tagged with &ldquo;design&rdquo; and &ldquo;html&rdquo;</div>\\n\\nYou see that, not surprisingly, mysqlicious with its `WHERE tag LIKE \\\"% tag %\\\"` is very slow. That is, MySQL has to go through the whole dataset and test each bookmark against the query.\\nWhat actually **is** surprising me, is that the fulltext search of mysql is not that high-performance. In fact it is not faster then the `LIKE`-query in the MySQLicious DB. This really disappointed me. I tried to do any quirks possible to make this faster as [I think, a tag-database-system with mysql fulltext would be very easy and like the only thing you should head to..](http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext).\\nWhat is surprising me too, is that the queries on the 3 table schema are about double as fast the the ones on the two-table ones([take a look at the queries](http://pastie.org/5480722) if you think you could give me a hint on this). Noticeable is, that in the scuttle and toxi-variant, the more queries were run, the faster they were. I didn&rsquo;t do any tests with queries and inserts mixed so this may be coming from just plain good caching and this effect possible doesn&rsquo;t show up on live bookmark management systems.\\n\\n#### Intersection: 999 tag set\\n\\n![Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset](https://lh4.googleusercontent.com/-4awEHoQC8w8/UL0Ax6ZbRNI/AAAAAAAALDY/rSvIp_iaqGA/s400/intersection_999_3_300.png \\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\")\\nNow have a look to what happens if we broaden our small tag set: MySQLicious with fulltext suddenly gets the performance leader. That means, if you have a bookmark management system with diverse tags (this most probably comes from the fact that there are many users), the fulltext solution is possibly the way to go.\\nSo now, as you see, choosing the right schema is all about tag distribution. In my previous post about guessing the overall tag distribution on [del.icio.us](http://del.icio.us), I came to the conclusion, that delicious&rsquo; most popular tag &ldquo;design&rdquo; is showing up in 3.2% of all bookmarks on [del.icio.us](http://del.icio.us). So then, what is the mean tag distribution?\\n\\n*   If we say 1% (a tag shows up in 1/100 of all bookmarks on an average) that makes our small tag set 250 tags big\\n*   If we say 0.25%, the small tag set grows to a size of 1000\\n*   If we say 0.1%, the small set will contain 2500 tags\\n\\n<span>So I&rsquo;d suggest that if your average distribution is 1%, take &ldquo;toxi&rdquo;, if the distribution is broader, take &ldquo;MySQLicious fulltext&rdquo;.</span>\\n\\n<span></span>If you take a closer look, you can see that the fulltext schema stayed as fast as when queried in the 250 tag set. That means, if you want to go sure your tag system responds ok in every situation, you should go with the &ldquo;mysql fulltext&rdquo; schema.\\n[Hannes has done some further investigation on mysql fulltext running on MySQL 4.1](http://hannes.magiccards.info/get/results.html) (my tests were on MySQL 4.0.21)\\n\\n#### Union\\n\\n![Union test with 250 tags in small dataset](https://lh5.googleusercontent.com/-Ze5AtV5GPMQ/UL0A35Lc2aI/AAAAAAAALEQ/Y9b0Qs9daAU/s400/union_full_250_3.png)\\nWhen doing a union query we say\\n\\n> <div>I want to search for all the bookmarks that are tagged either with &ldquo;delicious&rdquo; or &ldquo;del.icio.us&rdquo;</div>\\n\\nThis queries, you guessed, are handled the fastest by &ldquo;MySQLicious schema&rdquo; with its `LIKE`-queries: MySQL seeks through the bookmarks, harvesting all bookmarks with one of the given tags and says &ldquo;I&rsquo;m finished!&rdquo; when it was at bookmark number #968, because it found 50 bookmarks. Whereas in the other schemas, MySQL has to join the tags with the bookmarks first and only then could search though it..\\n\\n#### Insert\\n\\n![Setup database schemas with the data: 250 tags in small dataset](https://lh5.googleusercontent.com/-0HAVj_cQ5dM/UL0A2DwvC5I/AAAAAAAALDw/X4DmJIwk8nk/s400/setup_250.png)\\nWhen comparing the different schemas on the time of the insert-&ldquo;statements&rdquo; of one bookmark, the result isn&rsquo;t very surprising (notice that I&rsquo;ve changed the scale of the y-axis).\\nMysqlicious with it&rsquo;s 1 table is very fast indeed, its variation with fulltext had to create the fulltext index and therefore is a bit slower. Scuttle, with its 2 tables and toxi with its 3 tables are at least two respectively three times as slow. I have to remark, that I used quite a bit of caching for the toxi schema, as I didn&rsquo;t want hours to have the data ready..\\n\\nI guess it doesn&rsquo;t really make sense to base your decision, which schema to take on the time for an insert: Bookmark inserts are about 100 times as fast as the intersection queries..\\n\\n#### «What? That slow??»\\n\\nYou said it. You don&rsquo;t want your intersection queries take 0.2 seconds each. That would bring your system to its knees.\\n\\n<span>There are some recipes to avoid that:</span>\\n\\n##### Caching\\n\\nI think, you don&rsquo;t come around good old caching. I think that you could cache results to a query like &ldquo;mysql+tagging&rdquo; for about an hour or so. If a user queries his own items, I would lower the cache time (as up-to-dateness is more important with his own items).\\nThen, I expect if you for instance cache items per tag and intersection them with a decent algorithm, that could be faster..\\n\\n##### The Best Of Both Worlds\\n\\nI think you could have &ldquo;mysqlicous fulltext&rdquo; and &ldquo;toxi&rdquo; running at the same time. That means you have to update/insert in both schemas but when you have to query, you could take the one you think is faster: For simple union the mysqlicious without fulltext search, for intersection queries with common tags the toxi, and for those with uncommon tags the mysqlicious fulltext variant.\\n\\n##### Slicing and dicing\\n\\nYou could &ldquo;slice and dice&rdquo; data (as Nitin proposed it in [two](http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-1.html) of his [posts](http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-2.html)): That is: you slice your user/tag/item-room and build fact tables. You &ldquo;prebuild&rdquo; your results in a way. This way, inserts take long but queries themself should be much faster. In our examples, you would for instance first query the tag-intersections on &ldquo;toxi&rdquo; and then get the facts about each bookmark out of the &ldquo;mysqlicious&rdquo;-fact-table. But you really should read Nitins posts, as they give a lot of insight.\\n\\n##### Using a non RDBMS system\\n\\n**Update:** It&rsquo;s been about a year since I wrote that article, and during that year I came to the conclusion that [RDBMS](http://en.wikipedia.org/wiki/RDBMS) systems don&rsquo;t scale good in systems that have more than 1 million items. Yes, this is a warning: If you are planning to build a large scale system then look for alternatives to [RDBMS](http://en.wikipedia.org/wiki/RDBMS) systems. To quote Joshua Schachter, founder of [delicious](http://del.icio.us):\\n«tags doesn&rsquo;t map to sql at all. so use partial indexing.»[[Joshua Schachter at Carson Summit](http://www.redmonk.com/jgovernor/2006/02/08/things-weve-learned-josh-schachter-quotes-of-the-day/)]\\nI didn&rsquo;t try any of the non-RDBMS system but it looks like [Apache Lucene](http://lucene.apache.org/java/docs/) and [Hadoop](http://lucene.apache.org/hadoop/). There has been [a discussion on the Tagdb Mailing list](http://nelson.textdrive.com/pipermail/tagdb/2006-March/thread.html#164) about these solutions.\\n\\n#### «I don&rsquo;t believe you! I want to try it at home»\\n\\n[Download the source code (PHP)](https://docs.google.com/file/d/0B0uw1JCogWHubEJhdFhub0VjbkE/edit) I used to run the queries and test yourself, extend them as you like. The source is published as [LGPL](http://en.wikipedia.org/wiki/LGPL).\\n\\n### <a id=\\\"setup\\\" name=\\\"setup\\\"></a>Performance Tests Setup\\n\\n<span>Now, if you have read that far, you probably want to know some background information: As you noticed, for each schema, I set up 4 databases, one database holding 1000 bookmarks, the next 10'000, then 100'000 and the fourth 1 million bookmarks. The inserted tags (as well as urls) are random English words taken from two sets of tags:</span>\\n\\n*   the large set containing about 44'000 tags (that are simple English words)\\n*   the small set is varying in size (the results shown here are taken from 250 and 999 tag sets)\\n\\nEvery bookmark gets one to ten tags attached. Every odd tag is from the large set, alternately taken from small and large set. Every schema got exactly the same bookmarks and tag data.\\n\\nThen every schema got queried with an alternately 1-3 tag query. So the first query is for instance just &ldquo;blog&rdquo;, the second &ldquo;design+css&rdquo;, the third &ldquo;webdesign+music+software&rdquo;, the fourth again with just one tag an so forth..\\nAll the tags for the queries are taken from the small set so that the queries don&rsquo;t all end in empty results..\\nAll the queries are tested and work. The outcome of each query on the three schemas is exactly the same.\\n\\n#### Mysql Setup\\n\\nI used mysql 4.0.21.\\nAn excerpt from `/etc/my.cnf` (I think these are the relevant settings to this performance test)\\n\\n<pre>key_buffer=300M\\nquery_cache_size=30M\\nquery_cache_limit=30M\\ntable_cache = 64\\nft_min_word_len = 2\\nft_stopword_file = ''</pre>\\n\\n#### System\\n\\n> <div>CPU: 3GHz Dual Xeon\\n> Cache: 1MB\\n> Harddisk: SCSI Ultra 320 Atlas 10K, no RAID\\n> RAM: 3GB</div>\\n\\n#### Assumptions\\n\\n*   Queries select just the id of a bookmark. I assume that you have to do a second query to get all the wished data to display. I know that this is not fair towards the mysqlicious schema.\\n*   I left out user data, as I assume, user data columns wouldn&rsquo;t change the outcome of this tests. I wanted to keep the schemas as simple as possible.\\n*   Each query is done with `LIMIT 50` as I assume that a normal application doesn&rsquo;t want to get all bookmarks. I assume nobody wants to `order` bookmarks by any dimension, because this would be **very** expensive (ever wondered why you cannot sort bookmarks on [del.icio.us](http://del.icio.us) by date or similar? You get it..)\\n\\n### Acknowledgements\\n\\nThanks to [Citrin](http://www.citrin.ch), the company I work, to let me use our new server to run the queries. The server didn&rsquo;t have much anything else to do so the results should be accurate.\\nThe graphs are done using [JpGraph](http://www.aditus.nu/jpgraph/). Very easy to use and produces beautiful images.\\n\\n### Further reading\\n\\n*   [Flickr architecture](http://www.niallkennedy.com/blog/archives/2004/10/flickr_architec.html)\\n*   [Lab notes: Fulltext not so fast](http://labnotes.blogsome.com/2005/06/06/lab-notes-5-fulltext-not-so-fast/): Fulltext performance issues\\n*   [WebmasterWorld forum: mysql fulltext performance issues](http://www.webmasterworld.com/forum23/3557.htm)\\n*   [Mysql Supersmack: Mysql performance tool](http://vegan.net/tony/supersmack/)\\n*   [Mysql Benchmark](http://dev.mysql.com/doc/mysql/en/mysql-benchmarks.html)\\n*   [Powerpoint article of jeremy zawodny](http://jeremy.zawodny.com/mysql/mysql-optimization.html)on Mysql optimisation\\n*   [Pete Freitag did a sort of review of this article](http://www.petefreitag.com/item/389.cfm)<div class=\\\"blogger-post-footer\\\">![](https://blogger.googleusercontent.com/tracker/2748783673844839576-5133448602510209729?l=theneachwenttohisownhome.blogspot.com)</div>\",\"slug\":\"Tagsystems-performance-tests\",\"published\":1,\"updated\":\"2017-11-11T21:17:54.698Z\",\"comments\":1,\"layout\":\"post\",\"photos\":[],\"link\":\"\",\"_id\":\"cjcqon61a0028i85pb8zwag61\",\"content\":\"<p>In my <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" title=\\\"Tags: database schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">previous article named &ldquo;Tags: database schemas&rdquo;</a> we analysed different database schemas on how they could meet the needs of tag systems. In this article, the focus is on performance (speed). That is: if you want to build a tagsystem that performs good with about 1 million items (bookmarks for instance), then you may want to have a look at the following result of my performance tests.<br>In this article I tested tagging of bookmarks, but as you can tag pretty much anything, this goes for tagging systems in general.<a id=\\\"more\\\"></a></p>\\n<p>I tested the following schemas (I keep the naming from the previous article):</p>\\n<ul>\\n<li><strong>mysqlicious</strong>: One table. Tags are space separated in column &ldquo;tags&rdquo;; <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#mysqlicious\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n<li><strong>mysqlicious fulltext</strong>: Same schema but with <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mysql fulltext</a> on the tag column; <a href=\\\"http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n<li><strong>scuttle</strong>: Two tables: One for bookmarks, one for tags. Tag-table has foreign key to bookmark table; <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#scuttle\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n<li><strong>toxi</strong>: Three tables: One for bookmarks, one for tags, one for junction; <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#toxi\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n</ul>\\n<p><span>You may want to have a close watch at the details of the schemas when having a look at the </span><a href=\\\"http://pastie.org/5480706\\\" target=\\\"_blank\\\" rel=\\\"external\\\">sql-create-table-queries</a><span>.</span></p>\\n<p><span></span>But let&rsquo;s go directly to the results. The details about the setup of this tests are mentioned at the <a href=\\\"#setup\\\">end of this article</a>. The x-axis depicts the number of bookmarks in the corresponding database, on the y-axis you see how much time each query took to execute.<!-- more --></p>\\n<h3 id=\\\"Results\\\"><a href=\\\"#Results\\\" class=\\\"headerlink\\\" title=\\\"Results\\\"></a><a name=\\\"#results\\\" id=\\\"#results\\\"></a>Results</h3><h4 id=\\\"Intersection-250-tag-set\\\"><a href=\\\"#Intersection-250-tag-set\\\" class=\\\"headerlink\\\" title=\\\"Intersection: 250 tag set\\\"></a>Intersection: 250 tag set</h4><p><img src=\\\"https://lh4.googleusercontent.com/-3MTMt9iTACc/UL0Axe4hHMI/AAAAAAAALDM/cGcmhMoMo20/s400/intersection_250_3_i300.png\\\" alt=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\" title=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\"></p>\\n<p>The first two tests are done with 250 tags in the small dataset (<a href=\\\"#setup\\\">see below</a> for explanation). I think the queries in the &ldquo;1 million bookmarks database&rdquo; are the only size we should pay attention to. I mean if you have a small number of bookmarks, performance isn&rsquo;t really a thing to bother..</p>\\n<p>We run intersection queries, like</p>\\n<blockquote>\\n<div>I want to search for bookmarks tagged with &ldquo;design&rdquo; and &ldquo;html&rdquo;</div>\\n\\n</blockquote>\\n<p>You see that, not surprisingly, mysqlicious with its <code>WHERE tag LIKE &quot;% tag %&quot;</code> is very slow. That is, MySQL has to go through the whole dataset and test each bookmark against the query.<br>What actually <strong>is</strong> surprising me, is that the fulltext search of mysql is not that high-performance. In fact it is not faster then the <code>LIKE</code>-query in the MySQLicious DB. This really disappointed me. I tried to do any quirks possible to make this faster as <a href=\\\"http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext\\\" target=\\\"_blank\\\" rel=\\\"external\\\">I think, a tag-database-system with mysql fulltext would be very easy and like the only thing you should head to..</a>.<br>What is surprising me too, is that the queries on the 3 table schema are about double as fast the the ones on the two-table ones(<a href=\\\"http://pastie.org/5480722\\\" target=\\\"_blank\\\" rel=\\\"external\\\">take a look at the queries</a> if you think you could give me a hint on this). Noticeable is, that in the scuttle and toxi-variant, the more queries were run, the faster they were. I didn&rsquo;t do any tests with queries and inserts mixed so this may be coming from just plain good caching and this effect possible doesn&rsquo;t show up on live bookmark management systems.</p>\\n<h4 id=\\\"Intersection-999-tag-set\\\"><a href=\\\"#Intersection-999-tag-set\\\" class=\\\"headerlink\\\" title=\\\"Intersection: 999 tag set\\\"></a>Intersection: 999 tag set</h4><p><img src=\\\"https://lh4.googleusercontent.com/-4awEHoQC8w8/UL0Ax6ZbRNI/AAAAAAAALDY/rSvIp_iaqGA/s400/intersection_999_3_300.png\\\" alt=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\" title=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\"><br>Now have a look to what happens if we broaden our small tag set: MySQLicious with fulltext suddenly gets the performance leader. That means, if you have a bookmark management system with diverse tags (this most probably comes from the fact that there are many users), the fulltext solution is possibly the way to go.<br>So now, as you see, choosing the right schema is all about tag distribution. In my previous post about guessing the overall tag distribution on <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a>, I came to the conclusion, that delicious&rsquo; most popular tag &ldquo;design&rdquo; is showing up in 3.2% of all bookmarks on <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a>. So then, what is the mean tag distribution?</p>\\n<ul>\\n<li>If we say 1% (a tag shows up in 1/100 of all bookmarks on an average) that makes our small tag set 250 tags big</li>\\n<li>If we say 0.25%, the small tag set grows to a size of 1000</li>\\n<li>If we say 0.1%, the small set will contain 2500 tags</li>\\n</ul>\\n<p><span>So I&rsquo;d suggest that if your average distribution is 1%, take &ldquo;toxi&rdquo;, if the distribution is broader, take &ldquo;MySQLicious fulltext&rdquo;.</span></p>\\n<p><span></span>If you take a closer look, you can see that the fulltext schema stayed as fast as when queried in the 250 tag set. That means, if you want to go sure your tag system responds ok in every situation, you should go with the &ldquo;mysql fulltext&rdquo; schema.<br><a href=\\\"http://hannes.magiccards.info/get/results.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Hannes has done some further investigation on mysql fulltext running on MySQL 4.1</a> (my tests were on MySQL 4.0.21)</p>\\n<h4 id=\\\"Union\\\"><a href=\\\"#Union\\\" class=\\\"headerlink\\\" title=\\\"Union\\\"></a>Union</h4><p><img src=\\\"https://lh5.googleusercontent.com/-Ze5AtV5GPMQ/UL0A35Lc2aI/AAAAAAAALEQ/Y9b0Qs9daAU/s400/union_full_250_3.png\\\" alt=\\\"Union test with 250 tags in small dataset\\\"><br>When doing a union query we say</p>\\n<blockquote>\\n<div>I want to search for all the bookmarks that are tagged either with &ldquo;delicious&rdquo; or &ldquo;del.icio.us&rdquo;</div>\\n\\n</blockquote>\\n<p>This queries, you guessed, are handled the fastest by &ldquo;MySQLicious schema&rdquo; with its <code>LIKE</code>-queries: MySQL seeks through the bookmarks, harvesting all bookmarks with one of the given tags and says &ldquo;I&rsquo;m finished!&rdquo; when it was at bookmark number #968, because it found 50 bookmarks. Whereas in the other schemas, MySQL has to join the tags with the bookmarks first and only then could search though it..</p>\\n<h4 id=\\\"Insert\\\"><a href=\\\"#Insert\\\" class=\\\"headerlink\\\" title=\\\"Insert\\\"></a>Insert</h4><p><img src=\\\"https://lh5.googleusercontent.com/-0HAVj_cQ5dM/UL0A2DwvC5I/AAAAAAAALDw/X4DmJIwk8nk/s400/setup_250.png\\\" alt=\\\"Setup database schemas with the data: 250 tags in small dataset\\\"><br>When comparing the different schemas on the time of the insert-&ldquo;statements&rdquo; of one bookmark, the result isn&rsquo;t very surprising (notice that I&rsquo;ve changed the scale of the y-axis).<br>Mysqlicious with it&rsquo;s 1 table is very fast indeed, its variation with fulltext had to create the fulltext index and therefore is a bit slower. Scuttle, with its 2 tables and toxi with its 3 tables are at least two respectively three times as slow. I have to remark, that I used quite a bit of caching for the toxi schema, as I didn&rsquo;t want hours to have the data ready..</p>\\n<p>I guess it doesn&rsquo;t really make sense to base your decision, which schema to take on the time for an insert: Bookmark inserts are about 100 times as fast as the intersection queries..</p>\\n<h4 id=\\\"«What-That-slow-»\\\"><a href=\\\"#«What-That-slow-»\\\" class=\\\"headerlink\\\" title=\\\"«What? That slow??»\\\"></a>«What? That slow??»</h4><p>You said it. You don&rsquo;t want your intersection queries take 0.2 seconds each. That would bring your system to its knees.</p>\\n<p><span>There are some recipes to avoid that:</span></p>\\n<h5 id=\\\"Caching\\\"><a href=\\\"#Caching\\\" class=\\\"headerlink\\\" title=\\\"Caching\\\"></a>Caching</h5><p>I think, you don&rsquo;t come around good old caching. I think that you could cache results to a query like &ldquo;mysql+tagging&rdquo; for about an hour or so. If a user queries his own items, I would lower the cache time (as up-to-dateness is more important with his own items).<br>Then, I expect if you for instance cache items per tag and intersection them with a decent algorithm, that could be faster..</p>\\n<h5 id=\\\"The-Best-Of-Both-Worlds\\\"><a href=\\\"#The-Best-Of-Both-Worlds\\\" class=\\\"headerlink\\\" title=\\\"The Best Of Both Worlds\\\"></a>The Best Of Both Worlds</h5><p>I think you could have &ldquo;mysqlicous fulltext&rdquo; and &ldquo;toxi&rdquo; running at the same time. That means you have to update/insert in both schemas but when you have to query, you could take the one you think is faster: For simple union the mysqlicious without fulltext search, for intersection queries with common tags the toxi, and for those with uncommon tags the mysqlicious fulltext variant.</p>\\n<h5 id=\\\"Slicing-and-dicing\\\"><a href=\\\"#Slicing-and-dicing\\\" class=\\\"headerlink\\\" title=\\\"Slicing and dicing\\\"></a>Slicing and dicing</h5><p>You could &ldquo;slice and dice&rdquo; data (as Nitin proposed it in <a href=\\\"http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-1.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">two</a> of his <a href=\\\"http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-2.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">posts</a>): That is: you slice your user/tag/item-room and build fact tables. You &ldquo;prebuild&rdquo; your results in a way. This way, inserts take long but queries themself should be much faster. In our examples, you would for instance first query the tag-intersections on &ldquo;toxi&rdquo; and then get the facts about each bookmark out of the &ldquo;mysqlicious&rdquo;-fact-table. But you really should read Nitins posts, as they give a lot of insight.</p>\\n<h5 id=\\\"Using-a-non-RDBMS-system\\\"><a href=\\\"#Using-a-non-RDBMS-system\\\" class=\\\"headerlink\\\" title=\\\"Using a non RDBMS system\\\"></a>Using a non RDBMS system</h5><p><strong>Update:</strong> It&rsquo;s been about a year since I wrote that article, and during that year I came to the conclusion that <a href=\\\"http://en.wikipedia.org/wiki/RDBMS\\\" target=\\\"_blank\\\" rel=\\\"external\\\">RDBMS</a> systems don&rsquo;t scale good in systems that have more than 1 million items. Yes, this is a warning: If you are planning to build a large scale system then look for alternatives to <a href=\\\"http://en.wikipedia.org/wiki/RDBMS\\\" target=\\\"_blank\\\" rel=\\\"external\\\">RDBMS</a> systems. To quote Joshua Schachter, founder of <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">delicious</a>:<br>«tags doesn&rsquo;t map to sql at all. so use partial indexing.»[<a href=\\\"http://www.redmonk.com/jgovernor/2006/02/08/things-weve-learned-josh-schachter-quotes-of-the-day/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Joshua Schachter at Carson Summit</a>]<br>I didn&rsquo;t try any of the non-RDBMS system but it looks like <a href=\\\"http://lucene.apache.org/java/docs/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Apache Lucene</a> and <a href=\\\"http://lucene.apache.org/hadoop/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Hadoop</a>. There has been <a href=\\\"http://nelson.textdrive.com/pipermail/tagdb/2006-March/thread.html#164\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a discussion on the Tagdb Mailing list</a> about these solutions.</p>\\n<h4 id=\\\"«I-don-rsquo-t-believe-you-I-want-to-try-it-at-home»\\\"><a href=\\\"#«I-don-rsquo-t-believe-you-I-want-to-try-it-at-home»\\\" class=\\\"headerlink\\\" title=\\\"«I don&rsquo;t believe you! I want to try it at home»\\\"></a>«I don&rsquo;t believe you! I want to try it at home»</h4><p><a href=\\\"https://docs.google.com/file/d/0B0uw1JCogWHubEJhdFhub0VjbkE/edit\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Download the source code (PHP)</a> I used to run the queries and test yourself, extend them as you like. The source is published as <a href=\\\"http://en.wikipedia.org/wiki/LGPL\\\" target=\\\"_blank\\\" rel=\\\"external\\\">LGPL</a>.</p>\\n<h3 id=\\\"Performance-Tests-Setup\\\"><a href=\\\"#Performance-Tests-Setup\\\" class=\\\"headerlink\\\" title=\\\"Performance Tests Setup\\\"></a><a id=\\\"setup\\\" name=\\\"setup\\\"></a>Performance Tests Setup</h3><p><span>Now, if you have read that far, you probably want to know some background information: As you noticed, for each schema, I set up 4 databases, one database holding 1000 bookmarks, the next 10’000, then 100’000 and the fourth 1 million bookmarks. The inserted tags (as well as urls) are random English words taken from two sets of tags:</span></p>\\n<ul>\\n<li>the large set containing about 44’000 tags (that are simple English words)</li>\\n<li>the small set is varying in size (the results shown here are taken from 250 and 999 tag sets)</li>\\n</ul>\\n<p>Every bookmark gets one to ten tags attached. Every odd tag is from the large set, alternately taken from small and large set. Every schema got exactly the same bookmarks and tag data.</p>\\n<p>Then every schema got queried with an alternately 1-3 tag query. So the first query is for instance just &ldquo;blog&rdquo;, the second &ldquo;design+css&rdquo;, the third &ldquo;webdesign+music+software&rdquo;, the fourth again with just one tag an so forth..<br>All the tags for the queries are taken from the small set so that the queries don&rsquo;t all end in empty results..<br>All the queries are tested and work. The outcome of each query on the three schemas is exactly the same.</p>\\n<h4 id=\\\"Mysql-Setup\\\"><a href=\\\"#Mysql-Setup\\\" class=\\\"headerlink\\\" title=\\\"Mysql Setup\\\"></a>Mysql Setup</h4><p>I used mysql 4.0.21.<br>An excerpt from <code>/etc/my.cnf</code> (I think these are the relevant settings to this performance test)</p>\\n<pre>key_buffer=300M\\nquery_cache_size=30M\\nquery_cache_limit=30M\\ntable_cache = 64\\nft_min_word_len = 2\\nft_stopword_file = ''</pre>\\n\\n<h4 id=\\\"System\\\"><a href=\\\"#System\\\" class=\\\"headerlink\\\" title=\\\"System\\\"></a>System</h4><blockquote>\\n<div>CPU: 3GHz Dual Xeon<br>Cache: 1MB<br>Harddisk: SCSI Ultra 320 Atlas 10K, no RAID<br>RAM: 3GB</div>\\n\\n</blockquote>\\n<h4 id=\\\"Assumptions\\\"><a href=\\\"#Assumptions\\\" class=\\\"headerlink\\\" title=\\\"Assumptions\\\"></a>Assumptions</h4><ul>\\n<li>Queries select just the id of a bookmark. I assume that you have to do a second query to get all the wished data to display. I know that this is not fair towards the mysqlicious schema.</li>\\n<li>I left out user data, as I assume, user data columns wouldn&rsquo;t change the outcome of this tests. I wanted to keep the schemas as simple as possible.</li>\\n<li>Each query is done with <code>LIMIT 50</code> as I assume that a normal application doesn&rsquo;t want to get all bookmarks. I assume nobody wants to <code>order</code> bookmarks by any dimension, because this would be <strong>very</strong> expensive (ever wondered why you cannot sort bookmarks on <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a> by date or similar? You get it..)</li>\\n</ul>\\n<h3 id=\\\"Acknowledgements\\\"><a href=\\\"#Acknowledgements\\\" class=\\\"headerlink\\\" title=\\\"Acknowledgements\\\"></a>Acknowledgements</h3><p>Thanks to <a href=\\\"http://www.citrin.ch\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Citrin</a>, the company I work, to let me use our new server to run the queries. The server didn&rsquo;t have much anything else to do so the results should be accurate.<br>The graphs are done using <a href=\\\"http://www.aditus.nu/jpgraph/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">JpGraph</a>. Very easy to use and produces beautiful images.</p>\\n<h3 id=\\\"Further-reading\\\"><a href=\\\"#Further-reading\\\" class=\\\"headerlink\\\" title=\\\"Further reading\\\"></a>Further reading</h3><ul>\\n<li><a href=\\\"http://www.niallkennedy.com/blog/archives/2004/10/flickr_architec.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Flickr architecture</a></li>\\n<li><a href=\\\"http://labnotes.blogsome.com/2005/06/06/lab-notes-5-fulltext-not-so-fast/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Lab notes: Fulltext not so fast</a>: Fulltext performance issues</li>\\n<li><a href=\\\"http://www.webmasterworld.com/forum23/3557.htm\\\" target=\\\"_blank\\\" rel=\\\"external\\\">WebmasterWorld forum: mysql fulltext performance issues</a></li>\\n<li><a href=\\\"http://vegan.net/tony/supersmack/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Mysql Supersmack: Mysql performance tool</a></li>\\n<li><a href=\\\"http://dev.mysql.com/doc/mysql/en/mysql-benchmarks.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Mysql Benchmark</a></li>\\n<li><a href=\\\"http://jeremy.zawodny.com/mysql/mysql-optimization.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Powerpoint article of jeremy zawodny</a>on Mysql optimisation</li>\\n<li><a href=\\\"http://www.petefreitag.com/item/389.cfm\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Pete Freitag did a sort of review of this article</a><div class=\\\"blogger-post-footer\\\"><img src=\\\"https://blogger.googleusercontent.com/tracker/2748783673844839576-5133448602510209729?l=theneachwenttohisownhome.blogspot.com\\\" alt=\\\"\\\"></div></li>\\n</ul>\\n\",\"site\":{\"data\":{}},\"excerpt\":\"<p>In my <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas\\\" title=\\\"Tags: database schemas\\\" target=\\\"_blank\\\" rel=\\\"external\\\">previous article named &ldquo;Tags: database schemas&rdquo;</a> we analysed different database schemas on how they could meet the needs of tag systems. In this article, the focus is on performance (speed). That is: if you want to build a tagsystem that performs good with about 1 million items (bookmarks for instance), then you may want to have a look at the following result of my performance tests.<br>In this article I tested tagging of bookmarks, but as you can tag pretty much anything, this goes for tagging systems in general.\",\"more\":\"</p>\\n<p>I tested the following schemas (I keep the naming from the previous article):</p>\\n<ul>\\n<li><strong>mysqlicious</strong>: One table. Tags are space separated in column &ldquo;tags&rdquo;; <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#mysqlicious\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n<li><strong>mysqlicious fulltext</strong>: Same schema but with <a href=\\\"http://dev.mysql.com/doc/mysql/en/fulltext-search.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">mysql fulltext</a> on the tag column; <a href=\\\"http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n<li><strong>scuttle</strong>: Two tables: One for bookmarks, one for tags. Tag-table has foreign key to bookmark table; <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#scuttle\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n<li><strong>toxi</strong>: Three tables: One for bookmarks, one for tags, one for junction; <a href=\\\"http://tagging.pui.ch/post/37027745720/tags-database-schemas#toxi\\\" target=\\\"_blank\\\" rel=\\\"external\\\">as introduced</a></li>\\n</ul>\\n<p><span>You may want to have a close watch at the details of the schemas when having a look at the </span><a href=\\\"http://pastie.org/5480706\\\" target=\\\"_blank\\\" rel=\\\"external\\\">sql-create-table-queries</a><span>.</span></p>\\n<p><span></span>But let&rsquo;s go directly to the results. The details about the setup of this tests are mentioned at the <a href=\\\"#setup\\\">end of this article</a>. The x-axis depicts the number of bookmarks in the corresponding database, on the y-axis you see how much time each query took to execute.<!-- more --></p>\\n<h3 id=\\\"Results\\\"><a href=\\\"#Results\\\" class=\\\"headerlink\\\" title=\\\"Results\\\"></a><a name=\\\"#results\\\" id=\\\"#results\\\"></a>Results</h3><h4 id=\\\"Intersection-250-tag-set\\\"><a href=\\\"#Intersection-250-tag-set\\\" class=\\\"headerlink\\\" title=\\\"Intersection: 250 tag set\\\"></a>Intersection: 250 tag set</h4><p><img src=\\\"https://lh4.googleusercontent.com/-3MTMt9iTACc/UL0Axe4hHMI/AAAAAAAALDM/cGcmhMoMo20/s400/intersection_250_3_i300.png\\\" alt=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\" title=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\"></p>\\n<p>The first two tests are done with 250 tags in the small dataset (<a href=\\\"#setup\\\">see below</a> for explanation). I think the queries in the &ldquo;1 million bookmarks database&rdquo; are the only size we should pay attention to. I mean if you have a small number of bookmarks, performance isn&rsquo;t really a thing to bother..</p>\\n<p>We run intersection queries, like</p>\\n<blockquote>\\n<div>I want to search for bookmarks tagged with &ldquo;design&rdquo; and &ldquo;html&rdquo;</div>\\n\\n</blockquote>\\n<p>You see that, not surprisingly, mysqlicious with its <code>WHERE tag LIKE &quot;% tag %&quot;</code> is very slow. That is, MySQL has to go through the whole dataset and test each bookmark against the query.<br>What actually <strong>is</strong> surprising me, is that the fulltext search of mysql is not that high-performance. In fact it is not faster then the <code>LIKE</code>-query in the MySQLicious DB. This really disappointed me. I tried to do any quirks possible to make this faster as <a href=\\\"http://tagging.pui.ch/post/37027745995/tags-with-mysql-fulltext\\\" target=\\\"_blank\\\" rel=\\\"external\\\">I think, a tag-database-system with mysql fulltext would be very easy and like the only thing you should head to..</a>.<br>What is surprising me too, is that the queries on the 3 table schema are about double as fast the the ones on the two-table ones(<a href=\\\"http://pastie.org/5480722\\\" target=\\\"_blank\\\" rel=\\\"external\\\">take a look at the queries</a> if you think you could give me a hint on this). Noticeable is, that in the scuttle and toxi-variant, the more queries were run, the faster they were. I didn&rsquo;t do any tests with queries and inserts mixed so this may be coming from just plain good caching and this effect possible doesn&rsquo;t show up on live bookmark management systems.</p>\\n<h4 id=\\\"Intersection-999-tag-set\\\"><a href=\\\"#Intersection-999-tag-set\\\" class=\\\"headerlink\\\" title=\\\"Intersection: 999 tag set\\\"></a>Intersection: 999 tag set</h4><p><img src=\\\"https://lh4.googleusercontent.com/-4awEHoQC8w8/UL0Ax6ZbRNI/AAAAAAAALDY/rSvIp_iaqGA/s400/intersection_999_3_300.png\\\" alt=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\" title=\\\"Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset\\\"><br>Now have a look to what happens if we broaden our small tag set: MySQLicious with fulltext suddenly gets the performance leader. That means, if you have a bookmark management system with diverse tags (this most probably comes from the fact that there are many users), the fulltext solution is possibly the way to go.<br>So now, as you see, choosing the right schema is all about tag distribution. In my previous post about guessing the overall tag distribution on <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a>, I came to the conclusion, that delicious&rsquo; most popular tag &ldquo;design&rdquo; is showing up in 3.2% of all bookmarks on <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a>. So then, what is the mean tag distribution?</p>\\n<ul>\\n<li>If we say 1% (a tag shows up in 1/100 of all bookmarks on an average) that makes our small tag set 250 tags big</li>\\n<li>If we say 0.25%, the small tag set grows to a size of 1000</li>\\n<li>If we say 0.1%, the small set will contain 2500 tags</li>\\n</ul>\\n<p><span>So I&rsquo;d suggest that if your average distribution is 1%, take &ldquo;toxi&rdquo;, if the distribution is broader, take &ldquo;MySQLicious fulltext&rdquo;.</span></p>\\n<p><span></span>If you take a closer look, you can see that the fulltext schema stayed as fast as when queried in the 250 tag set. That means, if you want to go sure your tag system responds ok in every situation, you should go with the &ldquo;mysql fulltext&rdquo; schema.<br><a href=\\\"http://hannes.magiccards.info/get/results.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Hannes has done some further investigation on mysql fulltext running on MySQL 4.1</a> (my tests were on MySQL 4.0.21)</p>\\n<h4 id=\\\"Union\\\"><a href=\\\"#Union\\\" class=\\\"headerlink\\\" title=\\\"Union\\\"></a>Union</h4><p><img src=\\\"https://lh5.googleusercontent.com/-Ze5AtV5GPMQ/UL0A35Lc2aI/AAAAAAAALEQ/Y9b0Qs9daAU/s400/union_full_250_3.png\\\" alt=\\\"Union test with 250 tags in small dataset\\\"><br>When doing a union query we say</p>\\n<blockquote>\\n<div>I want to search for all the bookmarks that are tagged either with &ldquo;delicious&rdquo; or &ldquo;del.icio.us&rdquo;</div>\\n\\n</blockquote>\\n<p>This queries, you guessed, are handled the fastest by &ldquo;MySQLicious schema&rdquo; with its <code>LIKE</code>-queries: MySQL seeks through the bookmarks, harvesting all bookmarks with one of the given tags and says &ldquo;I&rsquo;m finished!&rdquo; when it was at bookmark number #968, because it found 50 bookmarks. Whereas in the other schemas, MySQL has to join the tags with the bookmarks first and only then could search though it..</p>\\n<h4 id=\\\"Insert\\\"><a href=\\\"#Insert\\\" class=\\\"headerlink\\\" title=\\\"Insert\\\"></a>Insert</h4><p><img src=\\\"https://lh5.googleusercontent.com/-0HAVj_cQ5dM/UL0A2DwvC5I/AAAAAAAALDw/X4DmJIwk8nk/s400/setup_250.png\\\" alt=\\\"Setup database schemas with the data: 250 tags in small dataset\\\"><br>When comparing the different schemas on the time of the insert-&ldquo;statements&rdquo; of one bookmark, the result isn&rsquo;t very surprising (notice that I&rsquo;ve changed the scale of the y-axis).<br>Mysqlicious with it&rsquo;s 1 table is very fast indeed, its variation with fulltext had to create the fulltext index and therefore is a bit slower. Scuttle, with its 2 tables and toxi with its 3 tables are at least two respectively three times as slow. I have to remark, that I used quite a bit of caching for the toxi schema, as I didn&rsquo;t want hours to have the data ready..</p>\\n<p>I guess it doesn&rsquo;t really make sense to base your decision, which schema to take on the time for an insert: Bookmark inserts are about 100 times as fast as the intersection queries..</p>\\n<h4 id=\\\"«What-That-slow-»\\\"><a href=\\\"#«What-That-slow-»\\\" class=\\\"headerlink\\\" title=\\\"«What? That slow??»\\\"></a>«What? That slow??»</h4><p>You said it. You don&rsquo;t want your intersection queries take 0.2 seconds each. That would bring your system to its knees.</p>\\n<p><span>There are some recipes to avoid that:</span></p>\\n<h5 id=\\\"Caching\\\"><a href=\\\"#Caching\\\" class=\\\"headerlink\\\" title=\\\"Caching\\\"></a>Caching</h5><p>I think, you don&rsquo;t come around good old caching. I think that you could cache results to a query like &ldquo;mysql+tagging&rdquo; for about an hour or so. If a user queries his own items, I would lower the cache time (as up-to-dateness is more important with his own items).<br>Then, I expect if you for instance cache items per tag and intersection them with a decent algorithm, that could be faster..</p>\\n<h5 id=\\\"The-Best-Of-Both-Worlds\\\"><a href=\\\"#The-Best-Of-Both-Worlds\\\" class=\\\"headerlink\\\" title=\\\"The Best Of Both Worlds\\\"></a>The Best Of Both Worlds</h5><p>I think you could have &ldquo;mysqlicous fulltext&rdquo; and &ldquo;toxi&rdquo; running at the same time. That means you have to update/insert in both schemas but when you have to query, you could take the one you think is faster: For simple union the mysqlicious without fulltext search, for intersection queries with common tags the toxi, and for those with uncommon tags the mysqlicious fulltext variant.</p>\\n<h5 id=\\\"Slicing-and-dicing\\\"><a href=\\\"#Slicing-and-dicing\\\" class=\\\"headerlink\\\" title=\\\"Slicing and dicing\\\"></a>Slicing and dicing</h5><p>You could &ldquo;slice and dice&rdquo; data (as Nitin proposed it in <a href=\\\"http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-1.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">two</a> of his <a href=\\\"http://tagschema.com/blogs/tagschema/2005/06/slicing-and-dicing-data-20-part-2.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">posts</a>): That is: you slice your user/tag/item-room and build fact tables. You &ldquo;prebuild&rdquo; your results in a way. This way, inserts take long but queries themself should be much faster. In our examples, you would for instance first query the tag-intersections on &ldquo;toxi&rdquo; and then get the facts about each bookmark out of the &ldquo;mysqlicious&rdquo;-fact-table. But you really should read Nitins posts, as they give a lot of insight.</p>\\n<h5 id=\\\"Using-a-non-RDBMS-system\\\"><a href=\\\"#Using-a-non-RDBMS-system\\\" class=\\\"headerlink\\\" title=\\\"Using a non RDBMS system\\\"></a>Using a non RDBMS system</h5><p><strong>Update:</strong> It&rsquo;s been about a year since I wrote that article, and during that year I came to the conclusion that <a href=\\\"http://en.wikipedia.org/wiki/RDBMS\\\" target=\\\"_blank\\\" rel=\\\"external\\\">RDBMS</a> systems don&rsquo;t scale good in systems that have more than 1 million items. Yes, this is a warning: If you are planning to build a large scale system then look for alternatives to <a href=\\\"http://en.wikipedia.org/wiki/RDBMS\\\" target=\\\"_blank\\\" rel=\\\"external\\\">RDBMS</a> systems. To quote Joshua Schachter, founder of <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">delicious</a>:<br>«tags doesn&rsquo;t map to sql at all. so use partial indexing.»[<a href=\\\"http://www.redmonk.com/jgovernor/2006/02/08/things-weve-learned-josh-schachter-quotes-of-the-day/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Joshua Schachter at Carson Summit</a>]<br>I didn&rsquo;t try any of the non-RDBMS system but it looks like <a href=\\\"http://lucene.apache.org/java/docs/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Apache Lucene</a> and <a href=\\\"http://lucene.apache.org/hadoop/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Hadoop</a>. There has been <a href=\\\"http://nelson.textdrive.com/pipermail/tagdb/2006-March/thread.html#164\\\" target=\\\"_blank\\\" rel=\\\"external\\\">a discussion on the Tagdb Mailing list</a> about these solutions.</p>\\n<h4 id=\\\"«I-don-rsquo-t-believe-you-I-want-to-try-it-at-home»\\\"><a href=\\\"#«I-don-rsquo-t-believe-you-I-want-to-try-it-at-home»\\\" class=\\\"headerlink\\\" title=\\\"«I don&rsquo;t believe you! I want to try it at home»\\\"></a>«I don&rsquo;t believe you! I want to try it at home»</h4><p><a href=\\\"https://docs.google.com/file/d/0B0uw1JCogWHubEJhdFhub0VjbkE/edit\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Download the source code (PHP)</a> I used to run the queries and test yourself, extend them as you like. The source is published as <a href=\\\"http://en.wikipedia.org/wiki/LGPL\\\" target=\\\"_blank\\\" rel=\\\"external\\\">LGPL</a>.</p>\\n<h3 id=\\\"Performance-Tests-Setup\\\"><a href=\\\"#Performance-Tests-Setup\\\" class=\\\"headerlink\\\" title=\\\"Performance Tests Setup\\\"></a><a id=\\\"setup\\\" name=\\\"setup\\\"></a>Performance Tests Setup</h3><p><span>Now, if you have read that far, you probably want to know some background information: As you noticed, for each schema, I set up 4 databases, one database holding 1000 bookmarks, the next 10’000, then 100’000 and the fourth 1 million bookmarks. The inserted tags (as well as urls) are random English words taken from two sets of tags:</span></p>\\n<ul>\\n<li>the large set containing about 44’000 tags (that are simple English words)</li>\\n<li>the small set is varying in size (the results shown here are taken from 250 and 999 tag sets)</li>\\n</ul>\\n<p>Every bookmark gets one to ten tags attached. Every odd tag is from the large set, alternately taken from small and large set. Every schema got exactly the same bookmarks and tag data.</p>\\n<p>Then every schema got queried with an alternately 1-3 tag query. So the first query is for instance just &ldquo;blog&rdquo;, the second &ldquo;design+css&rdquo;, the third &ldquo;webdesign+music+software&rdquo;, the fourth again with just one tag an so forth..<br>All the tags for the queries are taken from the small set so that the queries don&rsquo;t all end in empty results..<br>All the queries are tested and work. The outcome of each query on the three schemas is exactly the same.</p>\\n<h4 id=\\\"Mysql-Setup\\\"><a href=\\\"#Mysql-Setup\\\" class=\\\"headerlink\\\" title=\\\"Mysql Setup\\\"></a>Mysql Setup</h4><p>I used mysql 4.0.21.<br>An excerpt from <code>/etc/my.cnf</code> (I think these are the relevant settings to this performance test)</p>\\n<pre>key_buffer=300M\\nquery_cache_size=30M\\nquery_cache_limit=30M\\ntable_cache = 64\\nft_min_word_len = 2\\nft_stopword_file = ''</pre>\\n\\n<h4 id=\\\"System\\\"><a href=\\\"#System\\\" class=\\\"headerlink\\\" title=\\\"System\\\"></a>System</h4><blockquote>\\n<div>CPU: 3GHz Dual Xeon<br>Cache: 1MB<br>Harddisk: SCSI Ultra 320 Atlas 10K, no RAID<br>RAM: 3GB</div>\\n\\n</blockquote>\\n<h4 id=\\\"Assumptions\\\"><a href=\\\"#Assumptions\\\" class=\\\"headerlink\\\" title=\\\"Assumptions\\\"></a>Assumptions</h4><ul>\\n<li>Queries select just the id of a bookmark. I assume that you have to do a second query to get all the wished data to display. I know that this is not fair towards the mysqlicious schema.</li>\\n<li>I left out user data, as I assume, user data columns wouldn&rsquo;t change the outcome of this tests. I wanted to keep the schemas as simple as possible.</li>\\n<li>Each query is done with <code>LIMIT 50</code> as I assume that a normal application doesn&rsquo;t want to get all bookmarks. I assume nobody wants to <code>order</code> bookmarks by any dimension, because this would be <strong>very</strong> expensive (ever wondered why you cannot sort bookmarks on <a href=\\\"http://del.icio.us\\\" target=\\\"_blank\\\" rel=\\\"external\\\">del.icio.us</a> by date or similar? You get it..)</li>\\n</ul>\\n<h3 id=\\\"Acknowledgements\\\"><a href=\\\"#Acknowledgements\\\" class=\\\"headerlink\\\" title=\\\"Acknowledgements\\\"></a>Acknowledgements</h3><p>Thanks to <a href=\\\"http://www.citrin.ch\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Citrin</a>, the company I work, to let me use our new server to run the queries. The server didn&rsquo;t have much anything else to do so the results should be accurate.<br>The graphs are done using <a href=\\\"http://www.aditus.nu/jpgraph/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">JpGraph</a>. Very easy to use and produces beautiful images.</p>\\n<h3 id=\\\"Further-reading\\\"><a href=\\\"#Further-reading\\\" class=\\\"headerlink\\\" title=\\\"Further reading\\\"></a>Further reading</h3><ul>\\n<li><a href=\\\"http://www.niallkennedy.com/blog/archives/2004/10/flickr_architec.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Flickr architecture</a></li>\\n<li><a href=\\\"http://labnotes.blogsome.com/2005/06/06/lab-notes-5-fulltext-not-so-fast/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Lab notes: Fulltext not so fast</a>: Fulltext performance issues</li>\\n<li><a href=\\\"http://www.webmasterworld.com/forum23/3557.htm\\\" target=\\\"_blank\\\" rel=\\\"external\\\">WebmasterWorld forum: mysql fulltext performance issues</a></li>\\n<li><a href=\\\"http://vegan.net/tony/supersmack/\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Mysql Supersmack: Mysql performance tool</a></li>\\n<li><a href=\\\"http://dev.mysql.com/doc/mysql/en/mysql-benchmarks.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Mysql Benchmark</a></li>\\n<li><a href=\\\"http://jeremy.zawodny.com/mysql/mysql-optimization.html\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Powerpoint article of jeremy zawodny</a>on Mysql optimisation</li>\\n<li><a href=\\\"http://www.petefreitag.com/item/389.cfm\\\" target=\\\"_blank\\\" rel=\\\"external\\\">Pete Freitag did a sort of review of this article</a><div class=\\\"blogger-post-footer\\\"><img src=\\\"https://blogger.googleusercontent.com/tracker/2748783673844839576-5133448602510209729?l=theneachwenttohisownhome.blogspot.com\\\" alt=\\\"\\\"></div></li>\\n</ul>\"}],\"PostAsset\":[],\"PostCategory\":[],\"PostTag\":[{\"post_id\":\"cjcqon6010000i85pj87vf4yy\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon60e000bi85pcnza8sax\"},{\"post_id\":\"cjcqon6010000i85pj87vf4yy\",\"tag_id\":\"cjcqon60b0006i85pq1l5pl2c\",\"_id\":\"cjcqon60f000di85p98j07t44\"},{\"post_id\":\"cjcqon60f000ci85p0k3hdc7d\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon60h000gi85pjv18c6jk\"},{\"post_id\":\"cjcqon60g000fi85p5naditwi\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon60i000ii85pftcnl77k\"},{\"post_id\":\"cjcqon6050001i85p377a2aml\",\"tag_id\":\"cjcqon60d0009i85p2skp5wuw\",\"_id\":\"cjcqon60l000oi85pv8qvlbt0\"},{\"post_id\":\"cjcqon6050001i85p377a2aml\",\"tag_id\":\"cjcqon60f000ei85p8x7ztxl5\",\"_id\":\"cjcqon60l000pi85pizey5mx6\"},{\"post_id\":\"cjcqon6050001i85p377a2aml\",\"tag_id\":\"cjcqon60i000ji85pab6fq8un\",\"_id\":\"cjcqon60l000ri85pnf3tr7kn\"},{\"post_id\":\"cjcqon6080003i85posj73dhw\",\"tag_id\":\"cjcqon60k000ni85pkpl8xad3\",\"_id\":\"cjcqon60m000wi85pz6o6rrgt\"},{\"post_id\":\"cjcqon6080003i85posj73dhw\",\"tag_id\":\"cjcqon60l000qi85p5vmcq6jp\",\"_id\":\"cjcqon60m000xi85pgcr4b0yh\"},{\"post_id\":\"cjcqon6080003i85posj73dhw\",\"tag_id\":\"cjcqon60l000si85p6zwef24v\",\"_id\":\"cjcqon60m000zi85pmdtnzag2\"},{\"post_id\":\"cjcqon6080003i85posj73dhw\",\"tag_id\":\"cjcqon60m000ti85p5354zd7j\",\"_id\":\"cjcqon60m0010i85pmkawf6zd\"},{\"post_id\":\"cjcqon6080003i85posj73dhw\",\"tag_id\":\"cjcqon60m000ui85pu7wkr7t0\",\"_id\":\"cjcqon60n0012i85pp8f72d70\"},{\"post_id\":\"cjcqon6090004i85p0e6xutyk\",\"tag_id\":\"cjcqon60m000vi85py0qxx68k\",\"_id\":\"cjcqon60n0014i85p6tx5i5tv\"},{\"post_id\":\"cjcqon6090004i85p0e6xutyk\",\"tag_id\":\"cjcqon60m000yi85pe6ajupdu\",\"_id\":\"cjcqon60n0015i85pj9smgy4t\"},{\"post_id\":\"cjcqon6090004i85p0e6xutyk\",\"tag_id\":\"cjcqon60m0011i85pfwi7tvk2\",\"_id\":\"cjcqon60n0017i85psoydcomo\"},{\"post_id\":\"cjcqon60a0005i85prebk9zdp\",\"tag_id\":\"cjcqon60n0013i85p5dkkhwkm\",\"_id\":\"cjcqon60o001ai85pnklt42x5\"},{\"post_id\":\"cjcqon60a0005i85prebk9zdp\",\"tag_id\":\"cjcqon60n0016i85pd8nagckb\",\"_id\":\"cjcqon60o001bi85po9t3kg92\"},{\"post_id\":\"cjcqon60a0005i85prebk9zdp\",\"tag_id\":\"cjcqon60n0018i85pvzi72dux\",\"_id\":\"cjcqon60o001di85pg039gr4t\"},{\"post_id\":\"cjcqon60b0007i85pb083htuz\",\"tag_id\":\"cjcqon60o0019i85ptkm15p1w\",\"_id\":\"cjcqon60o001ei85plyxt9rnw\"},{\"post_id\":\"cjcqon60c0008i85p866f4juy\",\"tag_id\":\"cjcqon60o001ci85pi97yeuh0\",\"_id\":\"cjcqon60p001hi85pn5ov6hp4\"},{\"post_id\":\"cjcqon60c0008i85p866f4juy\",\"tag_id\":\"cjcqon60p001fi85po3x507rp\",\"_id\":\"cjcqon60q001ii85pl6uevy6t\"},{\"post_id\":\"cjcqon60h000hi85pejrwvch3\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon60q001ki85p7ysb4ric\"},{\"post_id\":\"cjcqon60h000hi85pejrwvch3\",\"tag_id\":\"cjcqon60b0006i85pq1l5pl2c\",\"_id\":\"cjcqon60q001li85pt0kkhrnm\"},{\"post_id\":\"cjcqon60h000hi85pejrwvch3\",\"tag_id\":\"cjcqon60p001gi85pr7fs1m5x\",\"_id\":\"cjcqon60s001ni85p7vgpk04b\"},{\"post_id\":\"cjcqon60j000li85p3prpb8ol\",\"tag_id\":\"cjcqon60q001ji85p1i2ent2h\",\"_id\":\"cjcqon60s001pi85pw2imhk87\"},{\"post_id\":\"cjcqon60j000li85p3prpb8ol\",\"tag_id\":\"cjcqon60l000si85p6zwef24v\",\"_id\":\"cjcqon60t001qi85p68ig9jlh\"},{\"post_id\":\"cjcqon60k000mi85pm8uq9756\",\"tag_id\":\"cjcqon60l000si85p6zwef24v\",\"_id\":\"cjcqon60t001si85psz0ay2sr\"},{\"post_id\":\"cjcqon60k000mi85pm8uq9756\",\"tag_id\":\"cjcqon60t001ri85p5ahzkz2o\",\"_id\":\"cjcqon60t001ti85pqhetgtsk\"},{\"post_id\":\"cjcqon615001xi85pfli2hqwp\",\"tag_id\":\"cjcqon60l000si85p6zwef24v\",\"_id\":\"cjcqon617001zi85pnep9i13o\"},{\"post_id\":\"cjcqon615001xi85pfli2hqwp\",\"tag_id\":\"cjcqon60m000ui85pu7wkr7t0\",\"_id\":\"cjcqon6180022i85pg23n64g8\"},{\"post_id\":\"cjcqon615001xi85pfli2hqwp\",\"tag_id\":\"cjcqon60t001ri85p5ahzkz2o\",\"_id\":\"cjcqon6190024i85p8508fjvv\"},{\"post_id\":\"cjcqon6170020i85puhcl2q0i\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon61a0027i85pufgqqt3o\"},{\"post_id\":\"cjcqon613001ui85ppx86ggz8\",\"tag_id\":\"cjcqon615001wi85p62qjzs4a\",\"_id\":\"cjcqon61b0029i85p6biuznui\"},{\"post_id\":\"cjcqon613001ui85ppx86ggz8\",\"tag_id\":\"cjcqon60p001fi85po3x507rp\",\"_id\":\"cjcqon61c002bi85pryejvyec\"},{\"post_id\":\"cjcqon613001ui85ppx86ggz8\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon61c002ci85p1sy63zs6\"},{\"post_id\":\"cjcqon613001ui85ppx86ggz8\",\"tag_id\":\"cjcqon6180021i85pz8mxfv3i\",\"_id\":\"cjcqon61c002di85p6xkz2k1w\"},{\"post_id\":\"cjcqon613001vi85pn3wy7qtg\",\"tag_id\":\"cjcqon60b0006i85pq1l5pl2c\",\"_id\":\"cjcqon61d002gi85pf45wd2s4\"},{\"post_id\":\"cjcqon613001vi85pn3wy7qtg\",\"tag_id\":\"cjcqon61a0026i85pvt07nvpc\",\"_id\":\"cjcqon61e002hi85pd9mzk6om\"},{\"post_id\":\"cjcqon613001vi85pn3wy7qtg\",\"tag_id\":\"cjcqon61c002ai85pk02x7fvv\",\"_id\":\"cjcqon61f002ji85pj207rc06\"},{\"post_id\":\"cjcqon613001vi85pn3wy7qtg\",\"tag_id\":\"cjcqon61c002ei85pawspqoix\",\"_id\":\"cjcqon61f002ki85pyorwrusu\"},{\"post_id\":\"cjcqon616001yi85pcjvsyi0b\",\"tag_id\":\"cjcqon61d002fi85p6xey6h2b\",\"_id\":\"cjcqon61f002mi85phv0ipp77\"},{\"post_id\":\"cjcqon6180023i85pl4ddyb3o\",\"tag_id\":\"cjcqon61e002ii85p8pkei749\",\"_id\":\"cjcqon61i002qi85px2cxesnv\"},{\"post_id\":\"cjcqon6180023i85pl4ddyb3o\",\"tag_id\":\"cjcqon61f002li85p76vopyns\",\"_id\":\"cjcqon61i002ri85p0czclvvm\"},{\"post_id\":\"cjcqon6180023i85pl4ddyb3o\",\"tag_id\":\"cjcqon61g002ni85p51fkh0ds\",\"_id\":\"cjcqon61j002ti85p3iaqs9da\"},{\"post_id\":\"cjcqon6180023i85pl4ddyb3o\",\"tag_id\":\"cjcqon61h002oi85plco8v3k8\",\"_id\":\"cjcqon61j002ui85pf4blkvbt\"},{\"post_id\":\"cjcqon6190025i85p2x1vd0ui\",\"tag_id\":\"cjcqon60b0006i85pq1l5pl2c\",\"_id\":\"cjcqon61k002xi85pep8mwumw\"},{\"post_id\":\"cjcqon6190025i85p2x1vd0ui\",\"tag_id\":\"cjcqon61i002pi85ps5mvqebx\",\"_id\":\"cjcqon61l002yi85puv4qlnnx\"},{\"post_id\":\"cjcqon6190025i85p2x1vd0ui\",\"tag_id\":\"cjcqon61i002si85pdlhh80i3\",\"_id\":\"cjcqon61l002zi85pzbhiex2f\"},{\"post_id\":\"cjcqon6190025i85p2x1vd0ui\",\"tag_id\":\"cjcqon6070002i85pgxylerqd\",\"_id\":\"cjcqon61m0030i85p65yew13a\"},{\"post_id\":\"cjcqon6190025i85p2x1vd0ui\",\"tag_id\":\"cjcqon61j002vi85pe3wgmu8d\",\"_id\":\"cjcqon61m0031i85psbf4yxm0\"},{\"post_id\":\"cjcqon61a0028i85pb8zwag61\",\"tag_id\":\"cjcqon61j002wi85p14utqsdb\",\"_id\":\"cjcqon61m0032i85p1dkznq50\"},{\"post_id\":\"cjcqon61a0028i85pb8zwag61\",\"tag_id\":\"cjcqon60l000si85p6zwef24v\",\"_id\":\"cjcqon61m0033i85phzib1d0o\"},{\"post_id\":\"cjcqon61a0028i85pb8zwag61\",\"tag_id\":\"cjcqon60m000ui85pu7wkr7t0\",\"_id\":\"cjcqon61m0034i85pszvw3rcm\"},{\"post_id\":\"cjcqon61a0028i85pb8zwag61\",\"tag_id\":\"cjcqon60t001ri85p5ahzkz2o\",\"_id\":\"cjcqon61m0035i85pd1p8aje8\"}],\"Tag\":[{\"name\":\"python\",\"_id\":\"cjcqon6070002i85pgxylerqd\"},{\"name\":\"django\",\"_id\":\"cjcqon60b0006i85pq1l5pl2c\"},{\"name\":\"nokia asha 302\",\"_id\":\"cjcqon60d0009i85p2skp5wuw\"},{\"name\":\"nvidia shield\",\"_id\":\"cjcqon60f000ei85p8x7ztxl5\"},{\"name\":\"tethering\",\"_id\":\"cjcqon60i000ji85pab6fq8un\"},{\"name\":\"RawSugar\",\"_id\":\"cjcqon60k000ni85pkpl8xad3\"},{\"name\":\"Research\",\"_id\":\"cjcqon60l000qi85p5vmcq6jp\"},{\"name\":\"Tags\",\"_id\":\"cjcqon60l000si85p6zwef24v\"},{\"name\":\"Clustering\",\"_id\":\"cjcqon60m000ti85p5354zd7j\"},{\"name\":\"Del.icio.us\",\"_id\":\"cjcqon60m000ui85pu7wkr7t0\"},{\"name\":\"google-spreadsheet\",\"_id\":\"cjcqon60m000vi85py0qxx68k\"},{\"name\":\"google-apps-scripts\",\"_id\":\"cjcqon60m000yi85pe6ajupdu\"},{\"name\":\"attachments\",\"_id\":\"cjcqon60m0011i85pfwi7tvk2\"},{\"name\":\"ffmpeg\",\"_id\":\"cjcqon60n0013i85p5dkkhwkm\"},{\"name\":\"mp3\",\"_id\":\"cjcqon60n0016i85pd8nagckb\"},{\"name\":\"aac\",\"_id\":\"cjcqon60n0018i85pvzi72dux\"},{\"name\":\"gadgets\",\"_id\":\"cjcqon60o0019i85ptkm15p1w\"},{\"name\":\"ripping\",\"_id\":\"cjcqon60o001ci85pi97yeuh0\"},{\"name\":\"music\",\"_id\":\"cjcqon60p001fi85po3x507rp\"},{\"name\":\"javascript\",\"_id\":\"cjcqon60p001gi85pr7fs1m5x\"},{\"name\":\"History\",\"_id\":\"cjcqon60q001ji85p1i2ent2h\"},{\"name\":\"MySQL\",\"_id\":\"cjcqon60t001ri85p5ahzkz2o\"},{\"name\":\"demoscene\",\"_id\":\"cjcqon615001wi85p62qjzs4a\"},{\"name\":\"modules\",\"_id\":\"cjcqon6180021i85pz8mxfv3i\"},{\"name\":\"python 2.5\",\"_id\":\"cjcqon61a0026i85pvt07nvpc\"},{\"name\":\"google app engine\",\"_id\":\"cjcqon61c002ai85pk02x7fvv\"},{\"name\":\"main.py\",\"_id\":\"cjcqon61c002ei85pawspqoix\"},{\"name\":\"jambox\",\"_id\":\"cjcqon61d002fi85p6xey6h2b\"},{\"name\":\"wordpress-to-tumblr\",\"_id\":\"cjcqon61e002ii85p8pkei749\"},{\"name\":\"wordpress\",\"_id\":\"cjcqon61f002li85p76vopyns\"},{\"name\":\"tumblr\",\"_id\":\"cjcqon61g002ni85p51fkh0ds\"},{\"name\":\"migration\",\"_id\":\"cjcqon61h002oi85plco8v3k8\"},{\"name\":\"appengine\",\"_id\":\"cjcqon61i002pi85ps5mvqebx\"},{\"name\":\"google cloud sql\",\"_id\":\"cjcqon61i002si85pdlhh80i3\"},{\"name\":\"mysql\",\"_id\":\"cjcqon61j002vi85pe3wgmu8d\"},{\"name\":\"Performance\",\"_id\":\"cjcqon61j002wi85p14utqsdb\"}]}}\n\n/home/philipp/blogs/howto/.deploy_git/index.html:\n  198  <p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p>\n  199  <h1 id=\"No-words-I-just-want-to-copy-paste\"><a href=\"#No-words-I-just-want-to-copy-paste\" class=\"headerlink\" title=\"No words! I just want to copy-paste\"></a>No words! I just want to copy-paste</h1><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p>\n  200: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">detox *.mp3</span><br><span class=\"line\">fmpeg -i *.mp3([1]) artwork.jpg</span><br><span class=\"line\">for i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 $&#123;i/mp3/m4a&#125;; done</span><br><span class=\"line\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done</span><br><span class=\"line\">rm artwork.jpg &amp;&amp; rm *.mp3</span><br></pre></td></tr></table></figure>\n  201      \n  202    </div>\n\n/home/philipp/blogs/howto/.deploy_git/2007/02/10/Turn-demoscene-modules-into-mp3s/index.html:\n   90  <a id=\"more\"></a>\n   91  <h2 id=\"short-version-for-the-impatient\"><a href=\"#short-version-for-the-impatient\" class=\"headerlink\" title=\"short version for the impatient\"></a>short version for the impatient</h2><p>download <a href=\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs\" target=\"_blank\" rel=\"external\">downloadmod.py</a> and <a href=\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE\" target=\"_blank\" rel=\"external\">mod2mp3.py</a> into /usr/local/bin/</p>\n   92: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install xmp adplay unrar lame</span><br><span class=\"line\">mkdir ~/modules/</span><br><span class=\"line\">downloadmod.py ~/modules/ &quot;Purple Motion&quot;</span><br><span class=\"line\">mod2mp3.py ~/modules/</span><br></pre></td></tr></table></figure>\n   93  <h3 id=\"First-get-those-modules\"><a href=\"#First-get-those-modules\" class=\"headerlink\" title=\"First, get those modules\"></a>First, get those modules</h3><p>The first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)</p>\n   94  <p>Afaik the most complete module resource is <a href=\"ftp://ftp.modland.com\" target=\"_blank\" rel=\"external\">modland</a>. The crux is that it&rsquo;s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.</p>\n\n/home/philipp/blogs/howto/.deploy_git/2007/02/18/set-timeout-for-a-shell-command-in-python/index.html:\n   88        <p>I wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href=\"http://adplug.sourceforge.net/\" target=\"_blank\" rel=\"external\">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href=\"http://www.python.net/crew/hooft/\" target=\"_blank\" rel=\"external\">the “task” module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br></p>\n   89  <a id=\"more\"></a>\n   90: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def timeout_command(command, timeout):</span><br><span class=\"line\">  &quot;&quot;&quot;call shell-command and either return its output or kill it</span><br><span class=\"line\">  if it doesn&apos;t normally exit within timeout seconds and return None&quot;&quot;&quot;</span><br><span class=\"line\">  import subprocess, datetime, os, time, signal</span><br><span class=\"line\">  start = datetime.datetime.now()</span><br><span class=\"line\">  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class=\"line\">  while process.poll() is None:</span><br><span class=\"line\">    time.sleep(0.1)</span><br><span class=\"line\">    now = datetime.datetime.now()</span><br><span class=\"line\">    if (now - start).seconds&amp;gt; timeout:</span><br><span class=\"line\">      os.kill(process.pid, signal.SIGKILL)</span><br><span class=\"line\">      os.waitpid(-1, os.WNOHANG)</span><br><span class=\"line\">      return None</span><br><span class=\"line\">  return process.stdout.read()</span><br></pre></td></tr></table></figure>\n   91  <p>Note especially lines 6, 11 and 12.<br>Usage:</p>\n   92: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;10&quot;], 2)</span><br><span class=\"line\">None</span><br><span class=\"line\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;1&quot;], 2)</span><br></pre></td></tr></table></figure>\n   93  <p>The process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen’ed process’ printed is caught and returned if it doesn’t timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn’t passed to a shell and furthermore you can just call one command with options, nothing more.</p>\n   94  \n\n/home/philipp/blogs/howto/.deploy_git/2017/11/29/How-to-mass-convert-mp3-files-to-aac-m3a/index.html:\n   97  <p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p>\n   98  <h1 id=\"No-words-I-just-want-to-copy-paste\"><a href=\"#No-words-I-just-want-to-copy-paste\" class=\"headerlink\" title=\"No words! I just want to copy-paste\"></a>No words! I just want to copy-paste</h1><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p>\n   99: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">detox *.mp3</span><br><span class=\"line\">fmpeg -i *.mp3([1]) artwork.jpg</span><br><span class=\"line\">for i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 $&#123;i/mp3/m4a&#125;; done</span><br><span class=\"line\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done</span><br><span class=\"line\">rm artwork.jpg &amp;&amp; rm *.mp3</span><br></pre></td></tr></table></figure>\n  100  <a id=\"more\"></a>\n  101  <h1 id=\"Line-1-Asciify-your-filenames-with-detox\"><a href=\"#Line-1-Asciify-your-filenames-with-detox\" class=\"headerlink\" title=\"Line 1: Asciify your filenames with detox\"></a>Line 1: Asciify your filenames with detox</h1><p>Everything is easier on the shell if instead of having <code>my süpér s&#39;öñg.mp3</code> having a file called <code>my_super_song.mp3</code>. Detox converts all characters which you need to somehow escape on the shell to ascii characters.</p>\n\n/home/philipp/blogs/howto/.deploy_git/2017/12/02/How-to-streamline-cd-ripping-without-tagging-track-data/index.html:\n  118  </ul>\n  119  <p>Btw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.</p>\n  120: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">set -e</span><br><span class=\"line\">tmp_dir=$(mktemp -d)</span><br><span class=\"line\">cd $tmp_dir</span><br><span class=\"line\">cdparanoia -BY</span><br><span class=\"line\">eject</span><br><span class=\"line\">for i in *.wav; do ffmpeg -i $i -c:a libfdk_aac -b:a 96k $&#123;i/cdda.wav/m4a&#125;; done</span><br><span class=\"line\">total=$(ls *.m4a | wc -l); for i in *.m4a; do number=$(echo $i | sed &apos;s/^track\\([0-9]\\+\\).*/\\1/&apos;); AtomicParsley $i --tracknum &quot;$number/$total&quot; --title &quot;Track $number&quot; --genre &quot;Kinder Geschichten&quot; --overWrite; done</span><br><span class=\"line\">echo -n &quot;Album name&gt;&quot; &amp;&amp; read album</span><br><span class=\"line\">echo -n &quot;Artist name&gt;&quot; &amp;&amp; read artist</span><br><span class=\"line\">search_term=&quot;$(perl -MURI::Escape -e &apos;print uri_escape($ARGV[0]);&apos; &quot;$album $artist cd&quot;)&quot;</span><br><span class=\"line\">chrome &quot;https://www.google.ch/search?&amp;q=$search_term&amp;tbm=isch&quot; &gt;/dev/null 2&gt;/dev/null &amp;</span><br><span class=\"line\">echo -n &quot;Artwork url&gt;&quot; &amp;&amp; read artwork_url</span><br><span class=\"line\">wget -q &quot;$artwork_url&quot; -O artwork.orig</span><br><span class=\"line\">convert artwork.orig -resize &quot;250x&quot; artwork.jpg</span><br><span class=\"line\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --artist &quot;$artist&quot; --album &quot;$album&quot; --overWrite; done</span><br><span class=\"line\">dir_name=$(echo &quot;$&#123;artist// /_&#125;_$&#123;album// /_&#125;&quot; | sed &apos;s/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g&apos; | tr &apos;[:upper:]&apos; &apos;[:lower:]&apos;)</span><br><span class=\"line\">mkdir $dir_name</span><br><span class=\"line\">mv *.m4a $dir_name</span><br><span class=\"line\">scp -rp $dir_name root@wdmycloud:/DataVolume/shares/Public/Shared\\\\\\ Music/kinder</span><br><span class=\"line\">python3 -c &quot;import soco; soco.music_library.MusicLibrary().start_library_update()&quot;</span><br><span class=\"line\">cd -</span><br><span class=\"line\">rm -rf $tmp_dir</span><br></pre></td></tr></table></figure>\n  121  \n  122      \n\n/home/philipp/blogs/howto/.deploy_git/2018/01/20/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi/index.html:\n  107  <a id=\"more\"></a>\n  108  <h1 id=\"Enable-ssh-and-wlan-on-the-image\"><a href=\"#Enable-ssh-and-wlan-on-the-image\" class=\"headerlink\" title=\"Enable ssh and wlan on the image\"></a>Enable ssh and wlan on the image</h1><p>Etcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using <code>sudo fdisk -l</code>. In my case I found:</p>\n  109: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Disk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectors</span><br><span class=\"line\">Units: sectors of 1 * 512 = 512 bytes</span><br><span class=\"line\">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class=\"line\">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class=\"line\">Disklabel type: dos</span><br><span class=\"line\">Disk identifier: 0x37665771</span><br><span class=\"line\">Device         Boot Start     End Sectors  Size Id Type</span><br><span class=\"line\">/dev/mmcblk0p1       8192   93236   85045 41.5M  c W95 FAT32 (LBA)</span><br><span class=\"line\">/dev/mmcblk0p2      94208 3629055 3534848  1.7G 83 Linux</span><br></pre></td></tr></table></figure>\n  110  <p>The relevant lines are 8 (boot partition) and 9 (data partition).</p>\n  111  <h2 id=\"Enable-ssh\"><a href=\"#Enable-ssh\" class=\"headerlink\" title=\"Enable ssh\"></a>Enable ssh</h2><ul>\n  ...\n  129  </ul>\n  130  <p>And, of course add your public key to authorized_keys:</p>\n  131: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat &gt;&gt;  ~/.ssh/authorized_keys&quot;</span><br></pre></td></tr></table></figure>\n  132      \n  133    </div>\n\n/home/philipp/blogs/howto/.deploy_git/css/site.css:\n 6398    margin-bottom: 0;\n 6399  }\n 6400: .hljs table > tbody > tr > td.gutter {\n 6401    width: 1%;\n 6402  }\n\n/home/philipp/blogs/howto/node_modules/ajv/dist/regenerator.min.js:\n    <binary>\n\n/home/philipp/blogs/howto/node_modules/babel-code-frame/lib/index.js:\n   36      var number = start + 1 + index;\n   37      var paddedNumber = (\" \" + number).slice(-numberMaxWidth);\n   38:     var gutter = \" \" + paddedNumber + \" | \";\n   39      if (number === lineNumber) {\n   40        var markerLine = \"\";\n   41        if (colNumber) {\n   42          var markerSpacing = line.slice(0, colNumber - 1).replace(/[^\\t]/g, \" \");\n   43:         markerLine = [\"\\n \", maybeHighlight(defs.gutter, gutter.replace(/\\d/g, \" \")), markerSpacing, maybeHighlight(defs.marker, \"^\")].join(\"\");\n   44        }\n   45:       return [maybeHighlight(defs.marker, \">\"), maybeHighlight(defs.gutter, gutter), line, markerLine].join(\"\");\n   46      } else {\n   47:       return \" \" + maybeHighlight(defs.gutter, gutter) + line;\n   48      }\n   49    }).join(\"\\n\");\n   ..\n   82      comment: chalk.grey,\n   83      invalid: chalk.white.bgRed.bold,\n   84:     gutter: chalk.grey,\n   85      marker: chalk.red.bold\n   86    };\n\n/home/philipp/blogs/howto/node_modules/hexo/lib/plugins/filter/before_post_render/backtick_code_block.js:\n   21      var options = {\n   22        autoDetect: config.auto_detect,\n   23:       gutter: config.line_number,\n   24        tab: config.tab_replace\n   25      };\n   26  \n   27:     if (options.gutter) {\n   28        config.first_line_number = config.first_line_number || 'always1';\n   29        if (config.first_line_number === 'inline') {\n   ..\n   31          //setup line number by inline\n   32          arguments[3] = arguments[3].replace('=+', '=');\n   33:         options.gutter = arguments[3].includes('=');\n   34  \n   35          // setup fiestLineNumber;\n   36:         options.firstLine = options.gutter ? arguments[3].split('=')[1] || 1 : 0;\n   37        }\n   38      }\n\n/home/philipp/blogs/howto/node_modules/hexo/lib/plugins/tag/code.js:\n  115        firstLine: first_line,\n  116        caption: caption,\n  117:       gutter: line_number,\n  118        mark: mark,\n  119        tab: config.tab_replace,\n\n/home/philipp/blogs/howto/node_modules/hexo/lib/plugins/tag/include_code.js:\n   70          lang: lang,\n   71          caption: caption,\n   72:         gutter: config.line_number,\n   73          tab: config.tab_replace\n   74        });\n\n/home/philipp/blogs/howto/node_modules/hexo/node_modules/hexo-cli/assets/themes/landscape/source/css/_variables.styl:\n   52  // Grids\n   53  column-width = 80px\n   54: gutter-width = 20px\n   55  columns = main-column + _sidebar-column\n   56  \n\n/home/philipp/blogs/howto/node_modules/hexo/node_modules/hexo-cli/assets/themes/landscape/source/css/style.styl:\n   33  .outer\n   34    clearfix()\n   35:   max-width: (column-width + gutter-width) * columns + gutter-width\n   36    margin: 0 auto\n   37:   padding: 0 gutter-width\n   38  \n   39  .inner\n\n/home/philipp/blogs/howto/node_modules/hexo/node_modules/hexo-cli/assets/themes/landscape/source/css/_partial/highlight.styl:\n   61        a\n   62          float: right\n   63:     .gutter pre\n   64        @extend $line-numbers\n   65        text-align: right\n\n/home/philipp/blogs/howto/node_modules/hexo/node_modules/hexo-cli/assets/themes/landscape/source/css/_util/grid.styl:\n    4  \n    5  // Utility function — you should never need to modify this\n    6: // _gridsystem-width = (column-width + gutter-width) * columns\n    7  gridsystem-width(_columns = columns)\n    8:   (column-width + gutter-width) * _columns\n    9  \n   10  // Set @total-width to 100% for a fluid layout\n   ..\n   23    clearfix()\n   24    display: block\n   25:   width: total-width * ((gutter-width + gridsystem-width(_columns)) / gridsystem-width(_columns))\n   26:   margin: 0 total-width * (((gutter-width * .5) / gridsystem-width(_columns)) * -1)\n   27  \n   28  column(x, _columns = columns)\n   29    display: inline\n   30    float: left\n   31:   width: total-width * ((((gutter-width + column-width) * x) - gutter-width) / gridsystem-width(_columns))\n   32:   margin: 0 total-width * ((gutter-width * .5) / gridsystem-width(_columns))\n   33  \n   34  push(offset = 1)\n   35:   margin-left: total-width * (((gutter-width + column-width) * offset) / gridsystem-width(columns))\n   36  \n   37  pull(offset = 1)\n   38:   margin-right: total-width * (((gutter-width + column-width) * offset) / gridsystem-width(columns))\n\n/home/philipp/blogs/howto/node_modules/hexo-renderer-marked/lib/renderer.js:\n   89      return highlight(stripIndent(code), {\n   90        lang: lang,\n   91:       gutter: false,\n   92        wrap: false\n   93      });\n\n/home/philipp/blogs/howto/node_modules/hexo-util/README.md:\n   87  Option | Description | Default\n   88  --- | --- | ---\n   89: `gutter` | Whether to show line numbers | true\n   90  `wrap` | Whether to wrap the code block | true\n   91  `firstLine` | First line number | 1\n\n/home/philipp/blogs/howto/node_modules/hexo-util/lib/highlight.js:\n   14    options = options || {};\n   15  \n   16:   var gutter = options.hasOwnProperty('gutter') ? options.gutter : true;\n   17    var wrap = options.hasOwnProperty('wrap') ? options.wrap : true;\n   18    var firstLine = options.hasOwnProperty('firstLine') ? +options.firstLine : 1;\n   ..\n   47    result += '<table><tr>';\n   48  \n   49:   if (gutter) {\n   50:     result += '<td class=\"gutter\"><pre>' + numbers + '</pre></td>';\n   51    }\n   52  \n\n/home/philipp/blogs/howto/node_modules/less/node_modules/ajv/dist/regenerator.min.js:\n    <binary>\n\n/home/philipp/blogs/howto/node_modules/less/test/less/comments2.less:\n   12  @base                       :   1;\n   13  @column-width               :   @base * 6em;                //      Width of column             */\n   14: @gutter-width               :   2em;                        //      Width of column spacing     */\n   15  @columns                    :   12;                         //      Number of Columns           */\n   16  @gridsystem-width           :   (@column-width *            //      For calculating the total   */\n   17                                      @columns) + (               //      width of the content area.  */\n   18:                                     @gutter-width *             //      We strongly recommend you   */\n   19                                      @columns);                  //      do not change this formula. */\n   20  @total-width                :   @gridsystem-width;          //      set to 100% for fluid grid  */\n\n/home/philipp/blogs/howto/node_modules/less/test/less-bom/comments2.less:\n   12  @base                       :   1;\n   13  @column-width               :   @base * 6em;                //      Width of column             */\n   14: @gutter-width               :   2em;                        //      Width of column spacing     */\n   15  @columns                    :   12;                         //      Number of Columns           */\n   16  @gridsystem-width           :   (@column-width *            //      For calculating the total   */\n   17                                      @columns) + (               //      width of the content area.  */\n   18:                                     @gutter-width *             //      We strongly recommend you   */\n   19                                      @columns);                  //      do not change this formula. */\n   20  @total-width                :   @gridsystem-width;          //      set to 100% for fluid grid  */\n\n/home/philipp/blogs/howto/public/index.html:\n  198  <p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p>\n  199  <h1 id=\"No-words-I-just-want-to-copy-paste\"><a href=\"#No-words-I-just-want-to-copy-paste\" class=\"headerlink\" title=\"No words! I just want to copy-paste\"></a>No words! I just want to copy-paste</h1><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p>\n  200: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">detox *.mp3</span><br><span class=\"line\">fmpeg -i *.mp3([1]) artwork.jpg</span><br><span class=\"line\">for i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 $&#123;i/mp3/m4a&#125;; done</span><br><span class=\"line\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done</span><br><span class=\"line\">rm artwork.jpg &amp;&amp; rm *.mp3</span><br></pre></td></tr></table></figure>\n  201      \n  202    </div>\n\n/home/philipp/blogs/howto/public/2007/02/10/Turn-demoscene-modules-into-mp3s/index.html:\n   90  <a id=\"more\"></a>\n   91  <h2 id=\"short-version-for-the-impatient\"><a href=\"#short-version-for-the-impatient\" class=\"headerlink\" title=\"short version for the impatient\"></a>short version for the impatient</h2><p>download <a href=\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHucXNKdUVlUGsyaGs\" target=\"_blank\" rel=\"external\">downloadmod.py</a> and <a href=\"https://docs.google.com/uc?export=download&amp;id=0B0uw1JCogWHubk9CdDFCdnJXNkE\" target=\"_blank\" rel=\"external\">mod2mp3.py</a> into /usr/local/bin/</p>\n   92: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install xmp adplay unrar lame</span><br><span class=\"line\">mkdir ~/modules/</span><br><span class=\"line\">downloadmod.py ~/modules/ &quot;Purple Motion&quot;</span><br><span class=\"line\">mod2mp3.py ~/modules/</span><br></pre></td></tr></table></figure>\n   93  <h3 id=\"First-get-those-modules\"><a href=\"#First-get-those-modules\" class=\"headerlink\" title=\"First, get those modules\"></a>First, get those modules</h3><p>The first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)</p>\n   94  <p>Afaik the most complete module resource is <a href=\"ftp://ftp.modland.com\" target=\"_blank\" rel=\"external\">modland</a>. The crux is that it&rsquo;s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.</p>\n\n/home/philipp/blogs/howto/public/2007/02/18/set-timeout-for-a-shell-command-in-python/index.html:\n   88        <p>I wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href=\"http://adplug.sourceforge.net/\" target=\"_blank\" rel=\"external\">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href=\"http://www.python.net/crew/hooft/\" target=\"_blank\" rel=\"external\">the “task” module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br></p>\n   89  <a id=\"more\"></a>\n   90: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def timeout_command(command, timeout):</span><br><span class=\"line\">  &quot;&quot;&quot;call shell-command and either return its output or kill it</span><br><span class=\"line\">  if it doesn&apos;t normally exit within timeout seconds and return None&quot;&quot;&quot;</span><br><span class=\"line\">  import subprocess, datetime, os, time, signal</span><br><span class=\"line\">  start = datetime.datetime.now()</span><br><span class=\"line\">  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class=\"line\">  while process.poll() is None:</span><br><span class=\"line\">    time.sleep(0.1)</span><br><span class=\"line\">    now = datetime.datetime.now()</span><br><span class=\"line\">    if (now - start).seconds&amp;gt; timeout:</span><br><span class=\"line\">      os.kill(process.pid, signal.SIGKILL)</span><br><span class=\"line\">      os.waitpid(-1, os.WNOHANG)</span><br><span class=\"line\">      return None</span><br><span class=\"line\">  return process.stdout.read()</span><br></pre></td></tr></table></figure>\n   91  <p>Note especially lines 6, 11 and 12.<br>Usage:</p>\n   92: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;10&quot;], 2)</span><br><span class=\"line\">None</span><br><span class=\"line\">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;1&quot;], 2)</span><br></pre></td></tr></table></figure>\n   93  <p>The process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen’ed process’ printed is caught and returned if it doesn’t timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn’t passed to a shell and furthermore you can just call one command with options, nothing more.</p>\n   94  \n\n/home/philipp/blogs/howto/public/2017/11/29/How-to-mass-convert-mp3-files-to-aac-m3a/index.html:\n   97  <p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p>\n   98  <h1 id=\"No-words-I-just-want-to-copy-paste\"><a href=\"#No-words-I-just-want-to-copy-paste\" class=\"headerlink\" title=\"No words! I just want to copy-paste\"></a>No words! I just want to copy-paste</h1><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p>\n   99: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">detox *.mp3</span><br><span class=\"line\">fmpeg -i *.mp3([1]) artwork.jpg</span><br><span class=\"line\">for i in *.mp3; do ~/bin/ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 $&#123;i/mp3/m4a&#125;; done</span><br><span class=\"line\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done</span><br><span class=\"line\">rm artwork.jpg &amp;&amp; rm *.mp3</span><br></pre></td></tr></table></figure>\n  100  <a id=\"more\"></a>\n  101  <h1 id=\"Line-1-Asciify-your-filenames-with-detox\"><a href=\"#Line-1-Asciify-your-filenames-with-detox\" class=\"headerlink\" title=\"Line 1: Asciify your filenames with detox\"></a>Line 1: Asciify your filenames with detox</h1><p>Everything is easier on the shell if instead of having <code>my süpér s&#39;öñg.mp3</code> having a file called <code>my_super_song.mp3</code>. Detox converts all characters which you need to somehow escape on the shell to ascii characters.</p>\n\n/home/philipp/blogs/howto/public/2017/12/02/How-to-streamline-cd-ripping-without-tagging-track-data/index.html:\n  118  </ul>\n  119  <p>Btw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.</p>\n  120: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">set -e</span><br><span class=\"line\">tmp_dir=$(mktemp -d)</span><br><span class=\"line\">cd $tmp_dir</span><br><span class=\"line\">cdparanoia -BY</span><br><span class=\"line\">eject</span><br><span class=\"line\">for i in *.wav; do ffmpeg -i $i -c:a libfdk_aac -b:a 96k $&#123;i/cdda.wav/m4a&#125;; done</span><br><span class=\"line\">total=$(ls *.m4a | wc -l); for i in *.m4a; do number=$(echo $i | sed &apos;s/^track\\([0-9]\\+\\).*/\\1/&apos;); AtomicParsley $i --tracknum &quot;$number/$total&quot; --title &quot;Track $number&quot; --genre &quot;Kinder Geschichten&quot; --overWrite; done</span><br><span class=\"line\">echo -n &quot;Album name&gt;&quot; &amp;&amp; read album</span><br><span class=\"line\">echo -n &quot;Artist name&gt;&quot; &amp;&amp; read artist</span><br><span class=\"line\">search_term=&quot;$(perl -MURI::Escape -e &apos;print uri_escape($ARGV[0]);&apos; &quot;$album $artist cd&quot;)&quot;</span><br><span class=\"line\">chrome &quot;https://www.google.ch/search?&amp;q=$search_term&amp;tbm=isch&quot; &gt;/dev/null 2&gt;/dev/null &amp;</span><br><span class=\"line\">echo -n &quot;Artwork url&gt;&quot; &amp;&amp; read artwork_url</span><br><span class=\"line\">wget -q &quot;$artwork_url&quot; -O artwork.orig</span><br><span class=\"line\">convert artwork.orig -resize &quot;250x&quot; artwork.jpg</span><br><span class=\"line\">for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --artist &quot;$artist&quot; --album &quot;$album&quot; --overWrite; done</span><br><span class=\"line\">dir_name=$(echo &quot;$&#123;artist// /_&#125;_$&#123;album// /_&#125;&quot; | sed &apos;s/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g&apos; | tr &apos;[:upper:]&apos; &apos;[:lower:]&apos;)</span><br><span class=\"line\">mkdir $dir_name</span><br><span class=\"line\">mv *.m4a $dir_name</span><br><span class=\"line\">scp -rp $dir_name root@wdmycloud:/DataVolume/shares/Public/Shared\\\\\\ Music/kinder</span><br><span class=\"line\">python3 -c &quot;import soco; soco.music_library.MusicLibrary().start_library_update()&quot;</span><br><span class=\"line\">cd -</span><br><span class=\"line\">rm -rf $tmp_dir</span><br></pre></td></tr></table></figure>\n  121  \n  122      \n\n/home/philipp/blogs/howto/public/2018/01/20/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi/index.html:\n  107  <a id=\"more\"></a>\n  108  <h1 id=\"Enable-ssh-and-wlan-on-the-image\"><a href=\"#Enable-ssh-and-wlan-on-the-image\" class=\"headerlink\" title=\"Enable ssh and wlan on the image\"></a>Enable ssh and wlan on the image</h1><p>Etcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using <code>sudo fdisk -l</code>. In my case I found:</p>\n  109: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Disk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectors</span><br><span class=\"line\">Units: sectors of 1 * 512 = 512 bytes</span><br><span class=\"line\">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class=\"line\">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class=\"line\">Disklabel type: dos</span><br><span class=\"line\">Disk identifier: 0x37665771</span><br><span class=\"line\">Device         Boot Start     End Sectors  Size Id Type</span><br><span class=\"line\">/dev/mmcblk0p1       8192   93236   85045 41.5M  c W95 FAT32 (LBA)</span><br><span class=\"line\">/dev/mmcblk0p2      94208 3629055 3534848  1.7G 83 Linux</span><br></pre></td></tr></table></figure>\n  110  <p>The relevant lines are 8 (boot partition) and 9 (data partition).</p>\n  111  <h2 id=\"Enable-ssh\"><a href=\"#Enable-ssh\" class=\"headerlink\" title=\"Enable ssh\"></a>Enable ssh</h2><ul>\n  ...\n  129  </ul>\n  130  <p>And, of course add your public key to authorized_keys:</p>\n  131: <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat &gt;&gt;  ~/.ssh/authorized_keys&quot;</span><br></pre></td></tr></table></figure>\n  132      \n  133    </div>\n\n/home/philipp/blogs/howto/public/css/site.css:\n 6398    margin-bottom: 0;\n 6399  }\n 6400: .hljs table > tbody > tr > td.gutter {\n 6401    width: 1%;\n 6402  }\n\n/home/philipp/blogs/howto/themes/ewal/source/css/_variables.less:\n  228  @grid-columns:              12;\n  229  // Padding, to be divided by two and applied to the left and right of all columns\n  230: @grid-gutter-width:         40px;\n  231  // Point at which the navbar stops collapsing\n  232  @grid-float-breakpoint:     @screen-tablet;\n  ...\n  243  @navbar-default-border:            darken(@navbar-default-bg, 6.5%);\n  244  @navbar-border-radius:             @border-radius-base;\n  245: @navbar-padding-horizontal:        floor(@grid-gutter-width / 2);\n  246  @navbar-padding-vertical:          ((@navbar-height - @line-height-computed) / 2);\n  247  \n  ...\n  612  \n  613  // Small screen / tablet\n  614: @container-tablet:            ((720px + @grid-gutter-width));\n  615  \n  616  // Medium screen / desktop\n  617: @container-desktop:           ((940px + @grid-gutter-width));\n  618  \n  619  // Large screen / wide desktop\n  620: @container-lg-desktop:        ((940px + @grid-gutter-width));\n  621  \n\n/home/philipp/blogs/howto/themes/ewal/source/css/site.less:\n   25    table {\n   26      margin-bottom: 0;\n   27:     > tbody > tr > td.gutter {\n   28        width: 1%;\n   29      }\n\n/home/philipp/blogs/howto/themes/ewal/source/css/_bootstrap/grid.less:\n   66    // Prevent columns from collapsing when empty\n   67    min-height: 1px;\n   68:   // Inner gutter via padding\n   69:   padding-left:  (@grid-gutter-width / 2);\n   70:   padding-right: (@grid-gutter-width / 2);\n   71  }\n   72  \n\n/home/philipp/blogs/howto/themes/ewal/source/css/_bootstrap/mixins.less:\n  188  \n  189  // CSS3 Content Columns\n  190: .content-columns(@column-count; @column-gap: @grid-gutter-width) {\n  191    -webkit-column-count: @column-count;\n  192       -moz-column-count: @column-count;\n  ...\n  525    margin-right: auto;\n  526    margin-left: auto;\n  527:   padding-left:  (@grid-gutter-width / 2);\n  528:   padding-right: (@grid-gutter-width / 2);\n  529    .clearfix();\n  530  }\n  531  \n  532  // Creates a wrapper for a series of columns\n  533: .make-row(@gutter: @grid-gutter-width) {\n  534:   margin-left:  (@gutter / -2);\n  535:   margin-right: (@gutter / -2);\n  536    .clearfix();\n  537  }\n  538  \n  539  // Generate the extra small columns\n  540: .make-xs-column(@columns; @gutter: @grid-gutter-width) {\n  541    position: relative;\n  542    float: left;\n  ...\n  544    // Prevent columns from collapsing when empty\n  545    min-height: 1px;\n  546:   // Inner gutter via padding\n  547:   padding-left:  (@gutter / 2);\n  548:   padding-right: (@gutter / 2);\n  549  }\n  550  \n  551  // Generate the small columns\n  552: .make-sm-column(@columns; @gutter: @grid-gutter-width) {\n  553    position: relative;\n  554    // Prevent columns from collapsing when empty\n  555    min-height: 1px;\n  556:   // Inner gutter via padding\n  557:   padding-left:  (@gutter / 2);\n  558:   padding-right: (@gutter / 2);\n  559  \n  560    // Calculate width based on number of columns available\n  ...\n  583  \n  584  // Generate the medium columns\n  585: .make-md-column(@columns; @gutter: @grid-gutter-width) {\n  586    position: relative;\n  587    // Prevent columns from collapsing when empty\n  588    min-height: 1px;\n  589:   // Inner gutter via padding\n  590:   padding-left:  (@gutter / 2);\n  591:   padding-right: (@gutter / 2);\n  592  \n  593    // Calculate width based on number of columns available\n  ...\n  616  \n  617  // Generate the large columns\n  618: .make-lg-column(@columns; @gutter: @grid-gutter-width) {\n  619    position: relative;\n  620    // Prevent columns from collapsing when empty\n  621    min-height: 1px;\n  622:   // Inner gutter via padding\n  623:   padding-left:  (@gutter / 2);\n  624:   padding-right: (@gutter / 2);\n  625  \n  626    // Calculate width based on number of columns available\n\n/home/philipp/blogs/howto/themes/ewal/source/css/_bootstrap/variables.less:\n  228  @grid-columns:              12;\n  229  // Padding, to be divided by two and applied to the left and right of all columns\n  230: @grid-gutter-width:         30px;\n  231  // Point at which the navbar stops collapsing\n  232  @grid-float-breakpoint:     @screen-tablet;\n  ...\n  243  @navbar-default-border:            darken(@navbar-default-bg, 6.5%);\n  244  @navbar-border-radius:             @border-radius-base;\n  245: @navbar-padding-horizontal:        floor(@grid-gutter-width / 2);\n  246  @navbar-padding-vertical:          ((@navbar-height - @line-height-computed) / 2);\n  247  \n  ...\n  612  \n  613  // Small screen / tablet\n  614: @container-tablet:            ((720px + @grid-gutter-width));\n  615  \n  616  // Medium screen / desktop\n  617: @container-desktop:           ((940px + @grid-gutter-width));\n  618  \n  619  // Large screen / wide desktop\n  620: @container-lg-desktop:        ((1140px + @grid-gutter-width));\n  621  \n\n/home/philipp/blogs/howto/themes/landscape/source/css/_variables.styl:\n   52  // Grids\n   53  column-width = 80px\n   54: gutter-width = 20px\n   55  columns = main-column + _sidebar-column\n   56  \n\n/home/philipp/blogs/howto/themes/landscape/source/css/style.styl:\n   33  .outer\n   34    clearfix()\n   35:   max-width: (column-width + gutter-width) * columns + gutter-width\n   36    margin: 0 auto\n   37:   padding: 0 gutter-width\n   38  \n   39  .inner\n\n/home/philipp/blogs/howto/themes/landscape/source/css/_partial/highlight.styl:\n   61        a\n   62          float: right\n   63:     .gutter pre\n   64        @extend $line-numbers\n   65        text-align: right\n\n/home/philipp/blogs/howto/themes/landscape/source/css/_util/grid.styl:\n    4  \n    5  // Utility function — you should never need to modify this\n    6: // _gridsystem-width = (column-width + gutter-width) * columns\n    7  gridsystem-width(_columns = columns)\n    8:   (column-width + gutter-width) * _columns\n    9  \n   10  // Set @total-width to 100% for a fluid layout\n   ..\n   23    clearfix()\n   24    display: block\n   25:   width: total-width * ((gutter-width + gridsystem-width(_columns)) / gridsystem-width(_columns))\n   26:   margin: 0 total-width * (((gutter-width * .5) / gridsystem-width(_columns)) * -1)\n   27  \n   28  column(x, _columns = columns)\n   29    display: inline\n   30    float: left\n   31:   width: total-width * ((((gutter-width + column-width) * x) - gutter-width) / gridsystem-width(_columns))\n   32:   margin: 0 total-width * ((gutter-width * .5) / gridsystem-width(_columns))\n   33  \n   34  push(offset = 1)\n   35:   margin-left: total-width * (((gutter-width + column-width) * offset) / gridsystem-width(columns))\n   36  \n   37  pull(offset = 1)\n   38:   margin-right: total-width * (((gutter-width + column-width) * offset) / gridsystem-width(columns))\n\n162 matches across 39 files\n",
			"settings":
			{
				"buffer_size": 651765,
				"line_ending": "Unix",
				"name": "Find Results",
				"scratch": true
			}
		},
		{
			"file": "themes/ewal/source/css/_variables.less",
			"settings":
			{
				"buffer_size": 18728,
				"line_ending": "Unix"
			}
		},
		{
			"file": "db.json",
			"settings":
			{
				"buffer_size": 609190,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "themes/landscape/source/css/_util/grid.styl",
			"settings":
			{
				"buffer_size": 1203,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 124.0,
		"last_filter": "project",
		"selected_items":
		[
			[
				"project",
				"Project: Save As"
			],
			[
				"json",
				"Pretty JSON: Minify (compress) JSON"
			],
			[
				"install",
				"Package Control: Install Package"
			],
			[
				"base64",
				"Base Encoding: Base64 Encode Selection(s)"
			],
			[
				"insta",
				"Package Control: Install Package"
			],
			[
				"kre",
				"Reg Replace: Kreditkarte neu2"
			],
			[
				"markdown",
				"Set Syntax: Markdown Extended"
			],
			[
				"ec",
				"Reg Replace: EC"
			],
			[
				"krei",
				"Reg Replace: Kreditkarte neu2"
			],
			[
				"regreplace",
				"RegReplace: Settings"
			],
			[
				"kred",
				"Reg Replace: Kreditkarte"
			],
			[
				"reg replace",
				"RegReplace: User Rules"
			],
			[
				"reg replac",
				"RegReplace: Settings"
			],
			[
				"regex",
				"RegReplace: Edit Regular Expression Rule"
			],
			[
				"table",
				"Table Editor: Set table syntax 'Pandoc' for current view"
			],
			[
				"table pand",
				"Table Editor: Set table syntax 'Pandoc' for current view"
			],
			[
				"tasks new",
				"Tasks: New"
			],
			[
				"wrap",
				"Word Wrap: Toggle"
			]
		],
		"width": 461.0
	},
	"console":
	{
		"height": 130.0,
		"history":
		[
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/home/philipp/blogs/howto",
		"/home/philipp/blogs/howto/source",
		"/home/philipp/blogs/howto/source/_posts",
		"/home/philipp/blogs/howto/themes",
		"/home/philipp/blogs/howto/themes/ewal",
		"/home/philipp/blogs/howto/themes/ewal/layout",
		"/home/philipp/blogs/howto/themes/ewal/source",
		"/home/philipp/blogs/howto/themes/ewal/source/css"
	],
	"file_history":
	[
		"/home/philipp/blogs/howto/source/_posts/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF.md",
		"/home/philipp/oss/serverless-sms-gateway/handler.py",
		"/home/philipp/oss/ocr/ocr.py",
		"/home/philipp/oss/ocr/handler.py",
		"/home/philipp/oss/ocr/README.md",
		"/home/philipp/oss/ocr/context.json",
		"/home/philipp/oss/ocr/event.js",
		"/home/philipp/install-scanner-pi3.md",
		"/home/philipp/.aws/pi_scanner.csv",
		"/home/philipp/Downloads/polly/scripts.js",
		"/home/philipp/.s3cfg",
		"/home/philipp/.aws/credentials",
		"/home/philipp/Downloads/hellocloudgurus.py",
		"/home/philipp/Downloads/lambda/index.html",
		"/home/philipp/Downloads/index.html",
		"/home/philipp/Downloads/error.html",
		"/home/philipp/oss/playground/a.py",
		"/home/philipp/Downloads/cc_2018-01-11.csv",
		"/home/philipp/win/Google Drive/Documents/acg_dev_nodes.md",
		"/home/philipp/.config/sublime-text-3/Packages/User/Default.sublime-commands",
		"/home/philipp/oss/serverless-sms-gateway/sonos.py",
		"/home/philipp/Downloads/Konto_20180101184332.csv",
		"/home/philipp/.config/sublime-text-3/Packages/User/reg_replace_rules.sublime-settings",
		"/home/philipp/Downloads/Raiffeisen_1512832760470.csv",
		"/home/philipp/Downloads/Konto_20171231190435.csv",
		"/home/philipp/Downloads/Konto_20171231190627.csv",
		"/home/philipp/Downloads/Raiffeisen_1514744265287.csv",
		"/home/philipp/Downloads/cc-new.csv",
		"/home/philipp/oss/serverless-sms-gateway/requirements.txt",
		"/home/philipp/.config/sublime-text-3/Packages/Package Control/Package Control.sublime-settings",
		"/home/philipp/.config/sublime-text-3/Packages/User/Package Control.sublime-settings",
		"/home/philipp/oss/serverless-sms-gateway/get_people_credentials.py",
		"/home/philipp/oss/serverless-sms-gateway/post.md",
		"/home/philipp/oss/serverless-sms-gateway/get-google-people-credentials.py",
		"/home/philipp/oss/serverless-sms-gateway/quickstart.py",
		"/home/philipp/oss/serverless-sms-gateway/client_secret.json",
		"/home/philipp/oss/serverless-sms-gateway/serverless.yml",
		"/home/philipp/oss/serverless-sms-gateway/secrets-example.yml",
		"/home/philipp/oss/playground/asc_desc.py",
		"/home/philipp/oss/playground/multi_process_with_return.py",
		"/home/philipp/oss/playground/b.py",
		"/var/tmp/ex48/ex48/parser.py",
		"/var/tmp/ex48/tests/parser_tests.py",
		"/home/philipp/oss/serverless-sms-gateway/secrets.yml",
		"/home/philipp/oss/serverless-sms-gateway/README.md",
		"/home/philipp/oss/serverless-sms-gateway/contacts.py",
		"/home/philipp/Downloads/geschenke.md",
		"/home/philipp/oss/playground/parse.py",
		"/home/philipp/.config/sublime-text-3/Packages/User/reg_replace.sublime-settings",
		"/home/philipp/.config/sublime-text-3/Packages/RegReplace/reg_replace.sublime-settings",
		"/home/philipp/.config/sublime-text-3/Packages/RegReplace/Default.sublime-commands",
		"/home/philipp/Downloads/Konto_20171209132314.csv",
		"/home/philipp/oss/playground/test.py",
		"/media/win/Users/lcl40026/Google Drive/Familie/Philipp/CV/cv.css",
		"/media/win/Users/lcl40026/Google Drive/Familie/Philipp/CV/CV-de.md",
		"/home/philipp/.config/sublime-text-3/Packages/PlainTasks/Default (Linux).sublime-keymap",
		"/home/philipp/Downloads/Konto_20171118161141.csv",
		"/home/philipp/Downloads/cc-2017-11-18.csv",
		"/home/philipp/Downloads/Konto_20171127162055.csv",
		"/home/philipp/Downloads/cc-2017-11-27.csv",
		"/home/philipp/Google Drive/local.ch/Localsearch.todo",
		"/home/philipp/.config/sublime-text-3/Packages/User/Default (Linux).sublime-keymap",
		"/home/philipp/blogs/howto/source/_posts/Turn-demoscene-modules-into-mp3s.md",
		"/home/philipp/blogs/howto/source/_posts/Django-Serve-big-files-via-fcgid.md",
		"/home/philipp/blogs/howto/source/_posts/Tagsystems-performance-tests.md",
		"/home/philipp/blogs/howto/source/_posts/Tags-with-MySQL-fulltext.md",
		"/home/philipp/blogs/howto/_config.yml",
		"/home/philipp/blogs/howto/source/_posts/Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet.md",
		"/home/philipp/blogs/howto/source/_posts/set-timeout-for-a-shell-command-in-python.md",
		"/home/philipp/blogs/howto/source/_posts/Python-Find-out-cpu-time-of-a-certain-process.md",
		"/home/philipp/blogs/howto/source/_posts/Send-javascript-errors-by-mail.md",
		"/home/philipp/blogs/howto/source/_posts/How-to-reset-Jambox-when-bluetooth-completely-stopped-working.md",
		"/home/philipp/blogs/howto/source/_posts/how-to-fix-jambox-static-noise.md",
		"/home/philipp/blogs/howto/source/_posts/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments.md",
		"/home/philipp/blogs/howto/source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL.md",
		"/home/philipp/blogs/howto/source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5.md",
		"/home/philipp/blogs/howto/source/_posts/Automated-tag-clustering.md",
		"/home/philipp/blogs/howto/source/_posts/How-to-attach-a-file-to-google-spreadsheet.md",
		"/home/philipp/blogs/howto/source/_posts/Tag-history-and-gartners-hype-cycles.md",
		"/home/philipp/blogs/howto/source/_posts/Tags-Database-schemas.md",
		"/home/philipp/blogs/howto/feature-phone-with-tethering-nokia-asha-302",
		"/home/philipp/blogs/howto/themes/ewal/source/css/_post.less",
		"/home/philipp/blogs/philippkeller/_config.yml",
		"/home/philipp/blogs/howto/themes/ewal/_config.yml",
		"/home/philipp/blogs/philippkeller/.deploy_git/pages/chesterton-orthodoxie.html",
		"/home/philipp/Downloads/cc1022.csv",
		"/home/philipp/Downloads/cc1028.csv",
		"/home/philipp/Downloads/Konto_20171029075201.csv",
		"/home/philipp/.config/i3/config",
		"/home/philipp/Google Drive/Documents/geburri-maria.md",
		"/home/philipp/Downloads/ready_player_one.md"
	],
	"find":
	{
		"height": 43.0
	},
	"find_in_files":
	{
		"height": 119.0,
		"where_history":
		[
			""
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"gutter"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": true,
		"replace_history":
		[
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 3,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "source/_posts/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF.md",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 12966,
						"regions":
						{
						},
						"selection":
						[
							[
								2529,
								2529
							]
						],
						"settings":
						{
							"syntax": "Packages/Markdown Extended/Syntaxes/Markdown Extended.sublime-syntax",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 1364.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 1,
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 651765,
						"regions":
						{
							"match":
							{
								"flags": 112,
								"regions":
								[
									[
										86697,
										86703
									],
									[
										92574,
										92580
									],
									[
										116228,
										116234
									],
									[
										121472,
										121478
									],
									[
										133856,
										133862
									],
									[
										137059,
										137065
									],
									[
										139358,
										139364
									],
									[
										142561,
										142567
									],
									[
										191956,
										191962
									],
									[
										192960,
										192966
									],
									[
										193397,
										193403
									],
									[
										194193,
										194199
									],
									[
										194848,
										194854
									],
									[
										195345,
										195351
									],
									[
										197691,
										197697
									],
									[
										198741,
										198747
									],
									[
										199158,
										199164
									],
									[
										200444,
										200450
									],
									[
										202159,
										202165
									],
									[
										204545,
										204551
									],
									[
										206956,
										206962
									],
									[
										209827,
										209833
									],
									[
										214336,
										214342
									],
									[
										215340,
										215346
									],
									[
										215777,
										215783
									],
									[
										216573,
										216579
									],
									[
										217228,
										217234
									],
									[
										217725,
										217731
									],
									[
										220071,
										220077
									],
									[
										221121,
										221127
									],
									[
										221538,
										221544
									],
									[
										222824,
										222830
									],
									[
										224539,
										224545
									],
									[
										226925,
										226931
									],
									[
										229336,
										229342
									],
									[
										232207,
										232213
									],
									[
										294919,
										294925
									],
									[
										301063,
										301069
									],
									[
										398440,
										398446
									],
									[
										400171,
										400177
									],
									[
										401701,
										401707
									],
									[
										403432,
										403438
									],
									[
										609896,
										609902
									],
									[
										611256,
										611262
									],
									[
										613265,
										613271
									],
									[
										614946,
										614952
									],
									[
										616492,
										616498
									],
									[
										618011,
										618017
									],
									[
										621600,
										621606
									],
									[
										622995,
										623001
									],
									[
										623436,
										623442
									],
									[
										623754,
										623760
									],
									[
										624039,
										624045
									],
									[
										624047,
										624053
									],
									[
										624225,
										624231
									],
									[
										624233,
										624239
									],
									[
										624336,
										624342
									],
									[
										624344,
										624350
									],
									[
										624490,
										624496
									],
									[
										624748,
										624754
									],
									[
										624858,
										624864
									],
									[
										625142,
										625148
									],
									[
										625271,
										625277
									],
									[
										625495,
										625501
									],
									[
										625732,
										625738
									],
									[
										625985,
										625991
									],
									[
										626244,
										626250
									],
									[
										626270,
										626276
									],
									[
										626327,
										626333
									],
									[
										626544,
										626550
									],
									[
										626860,
										626866
									],
									[
										626953,
										626959
									],
									[
										627122,
										627128
									],
									[
										627231,
										627237
									],
									[
										627411,
										627417
									],
									[
										627447,
										627453
									],
									[
										627526,
										627532
									],
									[
										627646,
										627652
									],
									[
										627786,
										627792
									],
									[
										628019,
										628025
									],
									[
										628204,
										628210
									],
									[
										628470,
										628476
									],
									[
										628503,
										628509
									],
									[
										628522,
										628528
									],
									[
										628759,
										628765
									],
									[
										628802,
										628808
									],
									[
										629190,
										629196
									],
									[
										629654,
										629660
									],
									[
										630167,
										630173
									],
									[
										630631,
										630637
									],
									[
										631527,
										631533
									],
									[
										632882,
										632888
									],
									[
										634886,
										634892
									],
									[
										636567,
										636573
									],
									[
										638108,
										638114
									],
									[
										639622,
										639628
									],
									[
										643206,
										643212
									],
									[
										644601,
										644607
									],
									[
										645037,
										645043
									],
									[
										645283,
										645289
									],
									[
										645614,
										645620
									],
									[
										645830,
										645836
									],
									[
										645941,
										645947
									],
									[
										646056,
										646062
									],
									[
										646216,
										646222
									],
									[
										646433,
										646439
									],
									[
										646483,
										646489
									],
									[
										646533,
										646539
									],
									[
										646740,
										646746
									],
									[
										646942,
										646948
									],
									[
										646992,
										646998
									],
									[
										647120,
										647126
									],
									[
										647134,
										647140
									],
									[
										647175,
										647181
									],
									[
										647214,
										647220
									],
									[
										647344,
										647350
									],
									[
										647358,
										647364
									],
									[
										647530,
										647536
									],
									[
										647575,
										647581
									],
									[
										647614,
										647620
									],
									[
										647715,
										647721
									],
									[
										647729,
										647735
									],
									[
										647873,
										647879
									],
									[
										647918,
										647924
									],
									[
										647957,
										647963
									],
									[
										648129,
										648135
									],
									[
										648143,
										648149
									],
									[
										648287,
										648293
									],
									[
										648332,
										648338
									],
									[
										648371,
										648377
									],
									[
										648542,
										648548
									],
									[
										648556,
										648562
									],
									[
										648700,
										648706
									],
									[
										648745,
										648751
									],
									[
										648784,
										648790
									],
									[
										649088,
										649094
									],
									[
										649419,
										649425
									],
									[
										649635,
										649641
									],
									[
										649746,
										649752
									],
									[
										649862,
										649868
									],
									[
										650008,
										650014
									],
									[
										650220,
										650226
									],
									[
										650246,
										650252
									],
									[
										650303,
										650309
									],
									[
										650473,
										650479
									],
									[
										650742,
										650748
									],
									[
										650835,
										650841
									],
									[
										651004,
										651010
									],
									[
										651113,
										651119
									],
									[
										651293,
										651299
									],
									[
										651329,
										651335
									],
									[
										651408,
										651414
									],
									[
										651528,
										651534
									],
									[
										651668,
										651674
									]
								],
								"scope": ""
							}
						},
						"selection":
						[
							[
								645286,
								645286
							]
						],
						"settings":
						{
							"detect_indentation": false,
							"line_numbers": false,
							"output_tag": 1,
							"result_base_dir": "",
							"result_file_regex": "^([^ \t].*):$",
							"result_line_regex": "^ +([0-9]+):",
							"scroll_past_end": true,
							"syntax": "Packages/Default/Find Results.hidden-tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 194214.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "themes/ewal/source/css/_variables.less",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 18728,
						"regions":
						{
						},
						"selection":
						[
							[
								6201,
								6201
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 4388.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "db.json",
					"semi_transient": true,
					"settings":
					{
						"buffer_size": 609190,
						"regions":
						{
						},
						"selection":
						[
							[
								609190,
								609190
							]
						],
						"settings":
						{
							"syntax": "Packages/JavaScript/JSON.sublime-syntax"
						},
						"translation.x": 6698993.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "themes/landscape/source/css/_util/grid.styl",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 1203,
						"regions":
						{
						},
						"selection":
						[
							[
								263,
								263
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 30.0
	},
	"input":
	{
		"height": 42.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.find_results":
	{
		"height": 0.0
	},
	"output.reg_replace":
	{
		"height": 594.0
	},
	"pinned_build_system": "",
	"project": "howto.sublime-project",
	"replace":
	{
		"height": 56.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"read",
				"README.md"
			],
			[
				"en.yml",
				"themes/ewal/languages/en.yml"
			],
			[
				"headless",
				"source/_posts/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi.md"
			],
			[
				"a.py",
				"a.py"
			],
			[
				"sonos",
				"sonos.py"
			],
			[
				"serv",
				"serverless.yml"
			],
			[
				"sono",
				"sonos.py"
			],
			[
				"ex",
				"secrets-example.yml"
			],
			[
				"se",
				"secrets.yml"
			],
			[
				"sec",
				"secrets.yml"
			],
			[
				"req",
				"requirements.txt"
			],
			[
				"han",
				"handler.py"
			],
			[
				"cont",
				"contacts.py"
			],
			[
				"quick",
				"~/oss/serverless-sms-gateway/quickstart.py"
			],
			[
				"get",
				"get_people_credentials.py"
			],
			[
				"sms",
				"sms.py"
			],
			[
				"credenti",
				"get_people_credentials.py"
			],
			[
				"conta",
				"contacts.py"
			],
			[
				"cc.py",
				"cc.py"
			],
			[
				"",
				"README.md"
			],
			[
				"yml",
				"serverless.yml"
			],
			[
				"css",
				"cv.css"
			],
			[
				"cv-en",
				"CV-en.md"
			],
			[
				"tags-da",
				"source/_posts/Tags-Database-schemas.md"
			],
			[
				"how-to-fix",
				"source/_posts/how-to-fix-jambox-static-noise.md"
			],
			[
				"completely",
				"source/_posts/How-to-reset-Jambox-when-bluetooth-completely-stopped-working.md"
			],
			[
				"adaptions",
				"source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5.md"
			],
			[
				"how-to-mig",
				"source/_posts/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments.md"
			],
			[
				"tutorial",
				"source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL.md"
			],
			[
				"gartner",
				"source/_posts/Tag-history-and-gartners-hype-cycles.md"
			],
			[
				"automated-",
				"source/_posts/Automated-tag-clustering.md"
			],
			[
				"performance-test",
				"source/_posts/Tagsystems-performance-tests.md"
			],
			[
				"tags-with",
				"source/_posts/Tags-with-MySQL-fulltext.md"
			],
			[
				"database-sch",
				"source/_posts/Tags-Database-schemas.md"
			],
			[
				"attach-",
				"source/_posts/How-to-attach-a-file-to-google-spreadsheet.md"
			],
			[
				"django-on",
				"source/_posts/Tutorial-Django-on-Appengine-using-Google-Cloud-SQL-Adaptations-for-Python-2-5.md"
			],
			[
				"migrate",
				"source/_posts/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments.md"
			],
			[
				"jambox-st",
				"source/_posts/how-to-fix-jambox-static-noise.md"
			],
			[
				"reset-jam",
				"source/_posts/How-to-reset-Jambox-when-bluetooth-completely-stopped-working.md"
			],
			[
				"javascript-er",
				"source/_posts/Send-javascript-errors-by-mail.md"
			],
			[
				"big-files",
				"source/_posts/Django-Serve-big-files-via-fcgid.md"
			],
			[
				"find-out",
				"source/_posts/Python-Find-out-cpu-time-of-a-certain-process.md"
			],
			[
				"timeout",
				"source/_posts/set-timeout-for-a-shell-command-in-python.md"
			],
			[
				"demosc",
				"source/_posts/Turn-demoscene-modules-into-mp3s.md"
			],
			[
				"feature",
				"source/_posts/Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet.md"
			],
			[
				"set-tim",
				"source/_posts/set-timeout-for-a-shell-command-in-python.md"
			],
			[
				"_config",
				"themes/ewal/_config.yml"
			],
			[
				"chest",
				"source/pages/chesterton-orthodoxie.html"
			],
			[
				"review",
				"source/_posts/2014-12-26-Review-der-Guten-Nachricht-Bibel.md"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 220.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
