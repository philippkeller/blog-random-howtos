<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Random Howtos</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://howto.philippkeller.com/"/>
  <updated>2018-03-11T16:16:18.321Z</updated>
  <id>http://howto.philippkeller.com/</id>
  
  <author>
    <name>Philipp Keller</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>How to remove browser shortcuts interferring with cloud9</title>
    <link href="http://howto.philippkeller.com/2018/03/11/How-to-remove-browser-shortcuts-interferring-with-cloud9/"/>
    <id>http://howto.philippkeller.com/2018/03/11/How-to-remove-browser-shortcuts-interferring-with-cloud9/</id>
    <published>2018-03-11T15:31:19.000Z</published>
    <updated>2018-03-11T16:16:18.321Z</updated>
    
    <content type="html"><![CDATA[<p><img src="images/cloud9.png" alt="cloud9"></p><p>I just started playing around with cloud9, particularly because it looks like the ideal IDE to develop lambda functions.</p><p>One thing which bothered me from the start: Emacs keybindings such as <code>ctrl-n</code> for next line won’t work because this makes the browser (in my case firefox) open a new window. I’d like to have <em>all</em> shortcuts available for cloud9, so ideally cloud9 would run in some minimalistic browser window.</p><p>Because Firefox and also Chrome don’t support <em>removing</em> shortcuts I found <a href="https://stackoverflow.com/a/25995884/119861" target="_blank" rel="external">this nice solution</a>:</p><a id="more"></a><p>First, install nw.js (requires node.js)</p><pre><code>sudo npm install nw -g</code></pre><p>then install package.json into e.g. ~/bin/:</p><pre><code>mkdir ~/bin/cloud9vim ~/bin/cloud9/package.json</code></pre><p>and put this into package.json:</p><pre><code class="json">{    &quot;name&quot; : &quot;cloud9 launcher&quot;,    &quot;window&quot; : {        &quot;fullscreen&quot; : true,        &quot;toolbar&quot; : false    },    &quot;main&quot; : &quot;https://console.aws.amazon.com/cloud9/home&quot;}</code></pre><p>You can directly launch that with <code>nw ~/bin/cloud9/</code>. To also have a desktop entry for Ubuntu: First install the icon of cloud9:</p><pre><code>cd /usr/share/pixmaps/wget http://howto.philippkeller.com/images/cloud9.png -O cloud9.png</code></pre><p>Then put this into <code>~/.local/share/applications/Cloud9.desktop</code>:</p><pre><code class="txt">[Desktop Entry]Type=ApplicationName=Cloud9Exec=nw bin/cloud9Icon=cloud9Categories=Development;IDEComment=Start Cloud9 in kiosk modeTerminal=false</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;images/cloud9.png&quot; alt=&quot;cloud9&quot;&gt;&lt;/p&gt;
&lt;p&gt;I just started playing around with cloud9, particularly because it looks like the ideal IDE to develop lambda functions.&lt;/p&gt;
&lt;p&gt;One thing which bothered me from the start: Emacs keybindings such as &lt;code&gt;ctrl-n&lt;/code&gt; for next line won’t work because this makes the browser (in my case firefox) open a new window. I’d like to have &lt;em&gt;all&lt;/em&gt; shortcuts available for cloud9, so ideally cloud9 would run in some minimalistic browser window.&lt;/p&gt;
&lt;p&gt;Because Firefox and also Chrome don’t support &lt;em&gt;removing&lt;/em&gt; shortcuts I found &lt;a href=&quot;https://stackoverflow.com/a/25995884/119861&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;this nice solution&lt;/a&gt;:&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Scan with raspberry pi, convert with aws lambda to searchable PDF</title>
    <link href="http://howto.philippkeller.com/2018/02/08/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF/"/>
    <id>http://howto.philippkeller.com/2018/02/08/Scan-with-raspberry-pi-convert-with-aws-to-searchable-PDF/</id>
    <published>2018-02-08T21:15:00.000Z</published>
    <updated>2018-02-10T08:12:34.858Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/scan_flow.png" alt="What we're building today :)" class="caption"></p><p>I have long dreamed for a setup which lets me just press the scan button on my scanner and — without any further input — uploads it as a searchable PDF onto some cloud drive. Thanks to the good support of scanners by SANE and the ease of use of AWS lambda it’s actually <em>quite</em> easy (judging to the length of this post it looks like quite a task, but in the end it is straightforwards and is — surprisingly — quite free of hacks).</p><p>In this solution you:</p><ul><li>set up <strong>SANE</strong> on your raspberry pi 3 so it scans your document</li><li>set up <strong>scanbd</strong> to detect the scan button</li><li>set up a S3 bucket for uploading</li><li>set up a <strong>lambda</strong> function which uses <strong>tesseract</strong> to create a searchable PDF</li><li>(optionally) set up <strong>google api</strong> to store the PDF to google drive</li></ul><p>What you need:</p><ul><li>Raspberry Pi 3 (I guess the other models serve equally well)</li><li>Paper scanner with a “scan” button which is <a href="http://www.sane-project.org/sane-mfgs.html" target="_blank" rel="external">supported by saned</a></li><li>an AWS account</li></ul><p>Personally I’m using Raspbian Stretch Lite as OS on my Raspberry and a Fujitsu S1300i.</p><p>Before you start: you might just want to wipe your pi and start fresh. Takes you about 15 minutes extra, you can <a href="http://localhost:4000/2018/01/20/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi/" target="_blank" rel="external">follow my howto</a> so you can do that headless (without attaching monitor/keyboard to the pi).</p><a id="more"></a><h2 id="Set-up-SANE"><a href="#Set-up-SANE" class="headerlink" title="Set up SANE"></a>Set up SANE</h2><p>First I tried to compile SANE from source, believing that this is the only way to get my scanner to work. After hours of trying and simplifying this howto (And after I wiped the pi3 two times to start over!) I figured out that <code>apt install</code> works just fine! So bear in mind that this howto was done with sweat and after hours of painful try-and-error :)</p><p>Just install:</p><pre><code class="bash">sudo apt install sane-utils -y</code></pre><p>No need to install the whole <code>sane</code> package which comes with 162 packages needing 430MB of space (sic!). <code>sane-utils</code> is enough. Now, when you plug your scanner to your pi and do..</p><pre><code class="bash">sudo sane-find-scanner -q</code></pre><p>.. you should see something like this:</p><pre><code class="shell">found USB scanner (vendor=0x04c6 [FUJITSU], product=0x128d [ScanSnap S1300i]) at libusb:001:011found USB scanner (vendor=0x0424, product=0xec00) at libusb:001:003</code></pre><p>That is, your scanner is already detected by sane. Now, throughout this howto, I’ll use user <code>pi</code> to run the processes. You can choose to go for another user, but please don’t use <code>root</code> for it. </p><p>To give your user <code>pi</code> the permission to scan you’d do:</p><pre><code class="bash">sudo usermod -a -G scanner pi</code></pre><p>This works because the group <code>scanner</code> is configured in <code>/etc/udev/rules.d/*.conf</code> to access the scanner. If this step does not work then <a href="https://wiki.archlinux.org/index.php/SANE#Permission_problem" target="_blank" rel="external">this section</a> might help you to troubleshoot.</p><p>You still cannot scan though, because you need to install the firmware file for your scanner. First, find out where the firmware needs to sit: Grep for your model (in my case scansnap 1300i):</p><pre><code class="bash">grep 1300i /etc/sane.d/*.conf</code></pre><p>Shows you something like:</p><pre><code class="shell">/etc/sane.d/epjitsu.conf:# Fujitsu S1300i/etc/sane.d/epjitsu.conf:firmware /usr/share/sane/epjitsu/1300i_0D12.nal</code></pre><p>So all you’d need to do is get this <code>1300i_0D12.nal</code> file. Get it from installation files (i.e. that old CD rom), or just google for your firmware file and hope that there’s no security concerns.. In my case I found it on github and installed it with:</p><pre><code>sudo mkdir /usr/share/sane/epjitsu/sudo wget https://github.com/ckunte/sfware/raw/master/1300i_0D12.nal -O /usr/share/sane/epjitsu/1300i_0D12.nal</code></pre><p>Now you should be able to insert a document into the scanner and ..</p><pre><code>scanimage &gt;/tmp/out.pnm</code></pre><p>.. should produce a nice <a href="https://en.wikipedia.org/wiki/Image_file_formats#PPM,_PGM,_PBM,_and_PNM" target="_blank" rel="external">PNM file</a> ready to be further processed.</p><h2 id="Set-up-scanbd"><a href="#Set-up-scanbd" class="headerlink" title="Set up scanbd"></a>Set up scanbd</h2><p><img src="/images/bacon.jpg" alt="Random button image to keep you motivated throughout this guide. And we're not even at half.. sheesh" class="caption"></p><p>Scanbd is <a href="https://sourceforge.net/projects/scanbd/reviews/#reviews-n-ratings" target="_blank" rel="external">very badly documented</a>. This is sad, because once you get it working, it’s doing its job very well. Plus: there’s really no alternative to scanbd.</p><p>Scanbd is just a daemon which regularly polls the scanner to see if a button was pressed. If it was, it just starts a shell script which itself then uses sane to scan. I found <a href="https://superuser.com/a/1044684/33963" target="_blank" rel="external">this stackoverflow answer</a> a good explanation how scanbd works.</p><p>There are a few howtos on the web which are overly complicated (i.e. copying all files of sane to scanbd), after 2-3 fresh installs I found out a quite forward way to get it working.</p><p>Fist, install it via</p><pre><code class="bash">sudo apt install scanbd -y</code></pre><p>then, edit <code>/etc/scanbd/scanbd.conf</code> and set <small>(if your scanbd.conf is missing — as it was missing for me on the first try — take <a href="/files/scanbd.conf">this conf file as a start</a>)</small>:</p><ul><li><code>debug-level = 7</code>: to see errors more easily while setting up</li><li><code>user = pi</code>: to run script and the scanning process as user <code>pi</code></li></ul><p>Start scanbd with </p><pre><code class="bash">sudo scanbd -f</code></pre><p>and you’d see that scanbd is polling. When you hit the scan button, then you should see output lines of scanbd trying to run <code>/etc/scanbd/scripts/test.script</code> which doesn’t exist. So far, so good!</p><p>Next, put your own script into place: Edit <code>/etc/scanbd/scanbd.conf</code> and set:</p><ul><li><code>script_dir=/etc/scanbd/scripts</code></li><li>in <code>action scan</code>:<ul><li><code>desc = &quot;Scan to file and upload to s3&quot;</code></li><li><code>script = &quot;scan.sh&quot;</code></li></ul></li></ul><p>Then put this sample script into <code>/tmp/foo.pnm</code>:</p><pre><code class="bash">sudo mkdir /etc/scanbd/scripts/echo -e &#39;#!/bin/sh\nscanimage &gt; /tmp/foo.pnm&#39; | sudo tee /etc/scanbd/scripts/scan.shsudo chmod a+x /etc/scanbd/scripts/scan.sh</code></pre><p>Replug your scanner and test it with:</p><pre><code class="bash">sudo scanbd -f</code></pre><p><img src="/images/segfault.jpg" alt="C++ developers aiding a comrade facing SEGFAULT, 1890 - Frederic Remington" class="caption"></p><p>Hitting the scanner button should scan. Buuut: if you now power off the scanner (close the lid on my model) or unplug it or whatever, and then replug it, then scanbd crashes spectacularly with a segmentation fault. There is <a href="https://bugs.launchpad.net/ubuntu/+source/scanbd/+bug/1500095" target="_blank" rel="external">this reported bug</a> which is solved with version 1.5.1, but instead of compiling from source it’s easier to start it over systemd and tell it to restart the service after crash:</p><p>First, edit <code>/lib/systemd/system/scanbd.service</code> and in the <code>[Service]</code> section add the line <code>Restart=on-failure</code>.</p><p>Then, reload systemd and tell it to start the service on boot time:</p><pre><code>sudo systemctl daemon-reloadsudo service scanbd startsudo update-rc.d scanbd enable</code></pre><p>Now, hitting the scanner button should work out of the box. Also try restarting the pi and replugging your scanner. You also may want to have a look at syslog, where all scanbds messages end up: <code>tail -f /var/log/syslog</code></p><p><small>If, for any reasons your service would just not start, then examine <code>/lib/systemd/system/scanbd.service</code> and check if ExecStart references your scanbd (use <code>which scanbd</code>) and your scanbd.conf, and also that <code>SANE_CONFIG_DIR</code> is set correctly.</small></p><h2 id="Upload-to-S3"><a href="#Upload-to-S3" class="headerlink" title="Upload to S3"></a>Upload to S3</h2><p>The idea is to offload as much computing as possible into the cloud. In theory you could also just run tesseract on your pi and then store it somewhere, but first I wanted to free up the pi as fast as possible for the next scan and second I was just searching for another excuse to try out lambda..</p><p>So in the next step we’ll alter the script so it uploads to s3. But before we can do that we’ll need to create a user on AWS which has just enough rights to do that.</p><h3 id="AWS-add-bucket-and-user"><a href="#AWS-add-bucket-and-user" class="headerlink" title="AWS: add bucket and user"></a>AWS: add bucket and user</h3><p><img src="/images/locked.jpg" alt=""></p><ul><li><strong>S3</strong>: Create a temporary upload bucket e.g. <code>temporary-upload</code> (be sure to choose a region close to you. Upload speed is a lot faster for closer regions). Note the ARN of the bucket.</li><li><strong>IAM</strong>: create a policy <code>ReadWriteOCR</code>, switch into JSON editor and paste this (replace the arns):</li></ul><pre><code class="json">{  &quot;Version&quot;: &quot;2012-10-17&quot;,  &quot;Statement&quot;: [    {      &quot;Effect&quot;: &quot;Allow&quot;,      &quot;Action&quot;: [&quot;s3:ListBucket&quot;],      &quot;Resource&quot;: [&quot;arn:aws:s3:::&lt;temporary-upload-bucket&gt;&quot;]    },    {      &quot;Effect&quot;: &quot;Allow&quot;,      &quot;Action&quot;: [        &quot;s3:GetObject&quot;,        &quot;s3:PutObject&quot;,        &quot;s3:DeleteObject&quot;      ],      &quot;Resource&quot;: [&quot;arn:aws:s3:::&lt;temporary-upload-bucket&gt;/*&quot;]    },    {      &quot;Effect&quot;: &quot;Allow&quot;,      &quot;Action&quot;: [        &quot;logs:CreateLogGroup&quot;,        &quot;logs:CreateLogStream&quot;,        &quot;logs:PutLogEvents&quot;      ],      &quot;Resource&quot;: &quot;arn:aws:logs:*:*:*&quot;    }  ]}</code></pre><ul><li><strong>IAM</strong>: Create a user with programmatic access only and attach the <code>ReadWriteOCR</code> policy. Download the csv which contains the key and secret of this user</li></ul><p>Now, this policy has a little too much right for just uploading the files from your pi, but that way we can reuse the policy for the lambda function later and we don’t need to create two policies.</p><p>Back on Raspberry, first install and configure aws cli (use the key and secret from the downloaded csv):</p><pre><code class="bash">sudo apt install python-pip -ysudo pip install awscliaws configure</code></pre><p>It’s important that you start <code>aws configure</code> as the user with which you run your script (i.e. user <code>pi</code>). </p><p>Now, test that s3 access works: </p><pre><code class="bash">aws s3 ls s3://&lt;temporary-upload-bucket&gt;/s3 cp some_file.txt s3://&lt;temporary-upload-bucket&gt;/</code></pre><h2 id="Write-the-scanner-script"><a href="#Write-the-scanner-script" class="headerlink" title="Write the scanner script"></a>Write the scanner script</h2><p>Now – finally – all the things are in place to finish the scanner script.</p><p>The below script..</p><ul><li>scans in batch mode: creates multiple files until the feeder is empty</li><li>does a duplex scan (there’s no detection if both sides contain content. It means that if it’s a one sided paper the second page is just empty)</li><li>scan with <code>resolution 300</code>: this is the default. It is a pretty fast scan and the quality is just what OCR (tesseract) recommends</li><li>does a <code>.tar.gz</code> archive. I did some speed tests and in my case it was quicker to first gzip the file before uploading. But that greatly depends on your upload speed</li><li>does the compression and uploading in the background so the scanner is ready to do the next scan</li></ul><p>Take the script and save it in <code>/etc/scanbd/scripts/scan.sh</code>, the only thing you’d need to adapt is the s3 bucket name. You may also comment out the <code>rm -rf</code> in the second last line until you’re sure your lambda function doesn’t eat up your files)</p><pre><code class="bash">#!/bin/shset -eexport TMP_DIR=`mktemp -d`echo &#39;scanning..&#39;scanimage --resolution 300 --batch=&quot;$TMP_DIR/scan_%03d.pnm&quot; --format=pnm --mode Gray --source &quot;ADF Duplex&quot;echo &#39;packaging and uploading in subshell&#39;(tarname=scan_$(date &quot;+%Y-%m-%d_%H%M%S&quot;).tar.gzcd $TMP_DIRtar -czf $tarname *.pnmecho &#39;uploading..&#39;aws s3 cp $TMP_DIR/$tarname s3://&lt;temporary-upload-bucket&gt;/rm -rf $TMP_DIRecho &#39;done&#39;) &amp;</code></pre><p>Now, pressing the button on your scanner should upload the file to s3.. whohoo!</p><p>If everything works then you can set <code>debug-level=3</code> in <code>/etc/scandb/scanbd.conf</code> so it does less verbose logging into syslog.</p><h2 id="Set-up-AWS-lambda"><a href="#Set-up-AWS-lambda" class="headerlink" title="Set up AWS lambda"></a>Set up AWS lambda</h2><p><img src="/images/magic_card.jpg" alt="Another random motivational picutre" class="caption"></p><p>Now to the second part – the one I was looking forward the most: create a lambda function which triggers automatically once the raw scan files are uploaded on s3. Once the trigger fires, it will </p><ol><li>start a lambda instance</li><li>download and unpack the <code>tar.gz</code> file from the temp bucket</li><li>run tesseract with pdf output, remove empty pages</li><li>upload the OCRed pdf to S3 or google drive</li><li>delete the tar.gz file from the temp bucket</li></ol><p>To cut this howto a little short I created a ready made zip file which contains the lambda function. You can <a href="https://github.com/philippkeller/lambda-scanner-ocr/blob/master/ocr.py" target="_blank" rel="external">have a look at it</a> but it’s not particularly beautiful. It’s mainly just a wrapper around calling the tesseract binaries. The tesseract binaries are built on an EC2 host which is <a href="https://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html" target="_blank" rel="external">the same execution environment as is used for AWS lambda</a>.</p><p>You could go ahead and fork that git repo and adapt it. In this guide we’ll just use it as-is:</p><ul><li>Download <code>ocr-lambda.zip</code> from <a href="https://github.com/philippkeller/lambda-scanner-ocr/releases" target="_blank" rel="external">the release page</a></li><li>Upload the zip file into an s3 bucket of your choice (the bucket needs to be in the same region you want your lambda function to run in)</li></ul><p>Now, set up a lambda function with:</p><ul><li><code>Name</code>: e.g. <code>scan-ocr</code></li><li><code>Runtime</code>: <code>Python 3.6</code></li><li><code>Role</code>: <code>Choose an existing role</code></li><li><code>Existing role</code>: the role you created earlier: <code>ReadWriteOCR</code></li></ul><p>Then, in the lambda function set</p><ul><li>Function code: <code>Handler</code> = <code>handler.handler</code></li><li>Environment variables: <ul><li><code>S3_DEST_BUCKET=&lt;ocr-document-bucket&gt;</code> Destination bucket name where lambda will upload the OCRed pdf</li><li><code>EMPTY_PAGE_THRESHOLD=200</code> if tesseract finds less than 200 characters on a page it’s — from experience — likely to be empty and will be removed (assumes you’re using a duplex scanner). If you want to disable empty page removal, just put this to 0</li><li><code>UPLOAD_TYPE</code>: <code>discard</code>: just to get going for now, the OCRed file will be discarded. Later on you’ll configure this lambda function to upload to S3 or Google Drive.</li></ul></li><li>Basic settings:<ul><li>Description: e.g. <code>take tar.gz and turn it into OCRed PDF</code></li><li><code>Timeout</code>: <code>5:00</code> minutes: This is the max value which lambda allows. For 6 page scans my lambda needed about 12s, so with 5 minutes you should be fine handling ~150 pages :)</li><li><code>Memory</code>: I chose 2048MB. The more memory you take, the faster the execution time (see also <a href="https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html" target="_blank" rel="external">the official doc</a>). 128MB is not enough. It will lead to out of memory exceptions.</li></ul></li></ul><p>Now, load in the zip file you just uploaded to s3:</p><ul><li>Function code:<ul><li><code>Code entry type</code>: <code>upload from s3</code></li><li><code>S3 link URL</code>: the zip file location in the form <code>https://s3.&lt;region&gt;.amazonaws.com/&lt;bucket&gt;/ocr-lambda.zip</code></li></ul></li></ul><h2 id="Test-it"><a href="#Test-it" class="headerlink" title="Test it"></a>Test it</h2><p><img src="/images/first_try.jpg" alt=""></p><p>In theory this all would work out of the box of course. But let’s try it out. Upload a tar.gz from a test scan to your temporary s3 bucket. Then, hit <code>configure test event</code> from the dropdown at the top of your lambda function. Now, put this json into the editor:</p><pre><code class="json">{  &quot;Records&quot;: [    {      &quot;s3&quot;: {        &quot;bucket&quot;: {          &quot;name&quot;: &quot;&lt;temporary-upload-bucket&gt;&quot;        },        &quot;object&quot;: {          &quot;key&quot;: &quot;&lt;uploaded-file&gt;.tar.gz&quot;        }      }    }  ]}</code></pre><p>After saving the test you can run it and you’ll see all the text output of the lambda function, and hopefully the line <code>all fine, discarding file, but not deleting source file</code>.</p><h2 id="Upload-to-S3-Google-Drive"><a href="#Upload-to-S3-Google-Drive" class="headerlink" title="Upload to S3 / Google Drive"></a>Upload to S3 / Google Drive</h2><p>Originally I just had the lambda function upload the file to S3 and hoped to find a nice frontend above S3 (but failed. Apparently there’s nothing really decent), but then I realized that I’d need some text search anyway. Otherwise, half the fun of OCR (apart from copy-pasting lines from invoices into my ebanking, which is my main use case) is gone anyway, I decided to go for Google Drive support.</p><div class="alert alert-warning" role="alert" style="font-size: 85%"><br><span class="glyphicon glyphicon-info-sign" aria-hidden="true"></span> If you don’t need Google Drive and just want uploads to another S3 bucket, then you could skip this section and instead put the env vars <code>UPLOAD_TYPE</code> = <code>s3</code>, and set <code>S3_BUCKET</code> to your destination bucket name add this json to your policy and you’ll be fine:<br><pre style="font-size: 85%"><br>{<br>  “Effect”: “Allow”,<br>  “Action”: [<br>    “s3:PutObject”<br>  ],<br>  “Resource”: [“arn:aws:s3:::&lt;dest-bucket&gt;/*”]<br>}<br></pre><br>Then, proceed to the last section to add the lambda trigger.<br></div><p><img src="/images/hoops.jpg" alt="Yay, the final hoops to jump through.." class="caption"></p><p>First, follow through steps a-h in <a href="https://developers.google.com/drive/v3/web/quickstart/python#step_1_turn_on_the_api_name" target="_blank" rel="external">this documentation</a>. This makes you enable gdrive on your google api account. In the end you’ll end up with a <code>client_secret.json</code> file.</p><p>Now, git clone the ocr-scanner repo you already used for downloading the zip release file and trigger the oauth flow:</p><pre><code>git clone https://github.com/philippkeller/lambda-scanner-ocr.gitcd lambda-scanner-ocrpip install oauth2clientpython scripts/get_drive_credentials.py</code></pre><p>Your browser should open and asks if you’d like to authenticate your lambda function to go over your google api account and created files in your google drive and access the files it created (which it won’t need). See <a href="https://developers.google.com/drive/v2/web/about-auth" target="_blank" rel="external">here</a> for more details about the right you’re granting.</p><p>Once you grant the right, you’ll see a bunch of environment variables you need to copy-paste over to your lambda function.</p><p>Optionally, if you wish your PDFs to be stored in a specific folder, go to that folder in your google drive, copy the part in the url after <code>/folders/</code> and put that into an additional environment variabled named <code>GDRIVE_FOLDER</code></p><h2 id="Add-trigger"><a href="#Add-trigger" class="headerlink" title="Add trigger"></a>Add trigger</h2><p>Now, to the very very last thing: Your lambda function should auto-trigger once your raspberry pi3 uploads a file into your temporary s3 bucket. First, reload the page of your lambda function, then, from the <code>Add triggers</code> menu of your lambda function (top left) choose <code>S3</code>, then in <code>Configure trigger</code> dialogue:</p><ul><li><code>Bucket</code>: the bucket where the lambda function should listen to</li><li><code>Event tpye</code>: <code>Object Created (All)</code></li><li><code>Prefix</code> and <code>Suffix</code> you can leave empty</li></ul><p>That’s it! Now, pressing your button on your scanner should make the whole chain reaction start and you should see your OCRed file in Google Drive (or S3, if you chose so). If it does not, you should be able to go to the <code>Monitoring</code> “tab” top of your lambda function and see if it triggered at all and head over to its log file.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/scan_flow.png&quot; alt=&quot;What we&#39;re building today :)&quot; class=&quot;caption&quot;&gt;&lt;/p&gt;
&lt;p&gt;I have long dreamed for a setup which lets me just press the scan button on my scanner and — without any further input — uploads it as a searchable PDF onto some cloud drive. Thanks to the good support of scanners by SANE and the ease of use of AWS lambda it’s actually &lt;em&gt;quite&lt;/em&gt; easy (judging to the length of this post it looks like quite a task, but in the end it is straightforwards and is — surprisingly — quite free of hacks).&lt;/p&gt;
&lt;p&gt;In this solution you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set up &lt;strong&gt;SANE&lt;/strong&gt; on your raspberry pi 3 so it scans your document&lt;/li&gt;
&lt;li&gt;set up &lt;strong&gt;scanbd&lt;/strong&gt; to detect the scan button&lt;/li&gt;
&lt;li&gt;set up a S3 bucket for uploading&lt;/li&gt;
&lt;li&gt;set up a &lt;strong&gt;lambda&lt;/strong&gt; function which uses &lt;strong&gt;tesseract&lt;/strong&gt; to create a searchable PDF&lt;/li&gt;
&lt;li&gt;(optionally) set up &lt;strong&gt;google api&lt;/strong&gt; to store the PDF to google drive&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What you need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Raspberry Pi 3 (I guess the other models serve equally well)&lt;/li&gt;
&lt;li&gt;Paper scanner with a “scan” button which is &lt;a href=&quot;http://www.sane-project.org/sane-mfgs.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;supported by saned&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;an AWS account&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Personally I’m using Raspbian Stretch Lite as OS on my Raspberry and a Fujitsu S1300i.&lt;/p&gt;
&lt;p&gt;Before you start: you might just want to wipe your pi and start fresh. Takes you about 15 minutes extra, you can &lt;a href=&quot;http://localhost:4000/2018/01/20/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;follow my howto&lt;/a&gt; so you can do that headless (without attaching monitor/keyboard to the pi).&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>How to check for broken links in markdown files</title>
    <link href="http://howto.philippkeller.com/2018/01/26/How-to-check-for-broken-links-in-markdown-files/"/>
    <id>http://howto.philippkeller.com/2018/01/26/How-to-check-for-broken-links-in-markdown-files/</id>
    <published>2018-01-26T22:49:45.000Z</published>
    <updated>2018-01-26T23:07:21.704Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/dead.jpg" alt="dead link"></p><p>Having blog articles up &gt;10 years needs some kind of tool to check for dead links.</p><p>Having googled a bit I didn’t find anything convincing. So I just created a very dirty solution which did the job for me.</p><p>You start it with </p><p><code>python3 link_checker.py path/to/md/files/ http://mysite.com</code></p><p>and it iterates over all <code>.md</code> files in <code>path/to/md/files</code> for links and images in your articles, sends a <code>HTTP HEAD</code> request and prints everything which does not look right</p><a id="more"></a><h3 id="Some-words-of-caution"><a href="#Some-words-of-caution" class="headerlink" title="Some words of caution:"></a>Some words of caution:</h3><p>This is just a 80% solution. It will give you some false negatives:</p><ul><li>it does regex to find the links. It finds both markdown styled links and <code>a href=</code> styled links</li><li>it sends a basic user-agent, but some sites such as google don’t allow crawling so you’ll see <code>405 Method not allowed</code></li></ul><h3 id="Screw-that-I-want-to-use-it-anyway"><a href="#Screw-that-I-want-to-use-it-anyway" class="headerlink" title="Screw that, I want to use it anyway"></a>Screw that, I want to use it anyway</h3><p><a href="/files/link_checker.py">Here’s the script to download</a>. And here’s how it looks (it even put the <span style="color: green">✔</span> in green and the <span style="color: red">x</span> in red) (if you use Hexo you can exactly call the script like that):</p><pre><code class="sh">$ ./link_checker.py source http://localhost:4000How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi.md ‎✔Tagsystems-performance-tests.md x-------------------------------http://pastie.org/5480706 Got exception timed outhttp://pastie.org/5480722 Got exception timed outhttp://www.webmasterworld.com/forum23/3557.htm Got exception HTTP Error 403: ForbiddenHow-to-attach-a-file-to-google-spreadsheet.md ‎✔Django-Serve-big-files-via-fcgid.md ‎✔Python-Print-list-of-dicts-as-ascii-table.md ‎✔Tags-Database-schemas.md ‎✔Tags-with-MySQL-fulltext.md ‎✔How-to-reset-Jambox-when-bluetooth-completely-stopped-working.md ‎✔</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/dead.jpg&quot; alt=&quot;dead link&quot;&gt;&lt;/p&gt;
&lt;p&gt;Having blog articles up &amp;gt;10 years needs some kind of tool to check for dead links.&lt;/p&gt;
&lt;p&gt;Having googled a bit I didn’t find anything convincing. So I just created a very dirty solution which did the job for me.&lt;/p&gt;
&lt;p&gt;You start it with &lt;/p&gt;
&lt;p&gt;&lt;code&gt;python3 link_checker.py path/to/md/files/ http://mysite.com&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and it iterates over all &lt;code&gt;.md&lt;/code&gt; files in &lt;code&gt;path/to/md/files&lt;/code&gt; for links and images in your articles, sends a &lt;code&gt;HTTP HEAD&lt;/code&gt; request and prints everything which does not look right&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>How to set up raspberry pi headless with ssh and wifi</title>
    <link href="http://howto.philippkeller.com/2018/01/20/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi/"/>
    <id>http://howto.philippkeller.com/2018/01/20/How-to-set-up-raspberry-pi-headless-with-ssh-and-wifi/</id>
    <published>2018-01-20T08:32:44.000Z</published>
    <updated>2018-01-26T14:00:07.943Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/pi.jpg" alt="raspberry pi 3"></p><p>Setting up raspberry pi is a bit tedious when doing it over attached monitor, keyboard and mouse (I usually don’t have those around anyway, being laptop only at the moment), so here’s a good and easy way to get an installation directly from your laptop, making the pi automatically join your wifi and enable ssh:</p><h2 id="Flash"><a href="#Flash" class="headerlink" title="Flash"></a>Flash</h2><p><img src="/images/etcher.png" alt="etcher"></p><p>I found that etcher.io is a very easy way to flash, in order to do so:</p><ul><li><strong>Install <a href="https://etcher.io/" target="_blank" rel="external">etcher</a></strong> (available for linux/osx/windows)</li><li><strong>Download image:</strong> I chose the raspbian lite version from <a href="https://www.raspberrypi.org/downloads/raspbian/" target="_blank" rel="external">official</a></li><li><strong>Open etcher</strong> etcher (on linux just unzip the etcher.zip and open the executable therein)</li><li><strong>Insert sd card</strong> (don’t mount it yet!), watch that etcher now detects that new card in the middle</li><li><strong>Select image</strong> e.g. <code>~/Downloads/2017-11-29-raspbian-stretch-lite.zip</code> and <strong>flash</strong> <small>(for linux i3 users: you’ll get a polkit error. You’ll need to start a polkit agent, e.g. <code>/usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1</code> before flashing)</small></li></ul><a id="more"></a><h2 id="Enable-ssh-and-wlan-on-the-image"><a href="#Enable-ssh-and-wlan-on-the-image" class="headerlink" title="Enable ssh and wlan on the image"></a>Enable ssh and wlan on the image</h2><p>Etcher just created two partitions: a boot partition and a data partition. First, find out the device files of the two partitions using <code>sudo fdisk -l</code>. In my case I found:</p><pre><code class="shell">Disk /dev/mmcblk0: 14.9 GiB, 15931539456 bytes, 31116288 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0x37665771Device               Boot   Start     End Sectors Size Id Type/dev/mmcblk0p1       8192   93236   85045 41.5M         c W95 FAT32 (LBA)/dev/mmcblk0p2      94208 3629055 3534848  1.7G        83 Linux</code></pre><p>The relevant lines are the last two lines whereas <code>mmcblk0p1</code> is the boot partition and <code>mmcblk0p2</code> the data partition</p><h2 id="Enable-ssh"><a href="#Enable-ssh" class="headerlink" title="Enable ssh"></a>Enable ssh</h2><p>Create the mount point and mount it i.e. in my case this was</p><pre><code class="bash">mkdir /var/tmp/sdcardsudo mount -t vfat /dev/mmcblk0p1 /var/tmp/sdcard</code></pre><p>whereas <code>-t vfar</code> is the file system (corresponds to W95 FAT32) and <code>/dev/mmcblk0p1</code> is the device from above (be sure to take the first one, that with the lower start number). Now enable ssh and unmount again:</p><pre><code class="bash">sudo touch /var/tmp/sdcard/sshsudo umount /var/tmp/sdcard</code></pre><h2 id="Enable-wireless"><a href="#Enable-wireless" class="headerlink" title="Enable wireless"></a>Enable wireless</h2><p>Mount the data partition (take the second <code>/dev/...</code> from the <code>fdisk</code> call)</p><pre><code class="bash">sudo mount -t ext4 /dev/mmcblk0p2 /var/tmp/sdcard</code></pre><p>Then run </p><pre><code class="bash">wpa_passphrase &lt;ssid&gt; &lt;password&gt;</code></pre><p>to create the wireless config which you need to put into <code>/var/tmp/sdcard/etc/wpa_supplicant/wpa_supplicant.conf</code>. Be sure to delete the plain text psk line. Finally, unmount with:</p><pre><code class="bash">sudo umount /var/tmp/sdcard</code></pre><h2 id="Profit"><a href="#Profit" class="headerlink" title="Profit!"></a>Profit!</h2><p>Boot your pi, check your router for the ip address and ssh in with <code>ssh pi@192.168.x.x</code> using <code>raspberry</code> as password.</p><p>A good first step is to <code>sudo raspi-config</code> and use it to:</p><ul><li>change password</li><li>generate the locale (get rid of the <code>warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)</code>)</li><li>set the correct timezone</li></ul><p>And, of course add your public key to authorized_keys:</p><pre><code class="bash">cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &quot;mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh &amp;&amp; cat &gt;&gt;  ~/.ssh/authorized_keys&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/pi.jpg&quot; alt=&quot;raspberry pi 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;Setting up raspberry pi is a bit tedious when doing it over attached monitor, keyboard and mouse (I usually don’t have those around anyway, being laptop only at the moment), so here’s a good and easy way to get an installation directly from your laptop, making the pi automatically join your wifi and enable ssh:&lt;/p&gt;
&lt;h2 id=&quot;Flash&quot;&gt;&lt;a href=&quot;#Flash&quot; class=&quot;headerlink&quot; title=&quot;Flash&quot;&gt;&lt;/a&gt;Flash&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/etcher.png&quot; alt=&quot;etcher&quot;&gt;&lt;/p&gt;
&lt;p&gt;I found that etcher.io is a very easy way to flash, in order to do so:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Install &lt;a href=&quot;https://etcher.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;etcher&lt;/a&gt;&lt;/strong&gt; (available for linux/osx/windows)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Download image:&lt;/strong&gt; I chose the raspbian lite version from &lt;a href=&quot;https://www.raspberrypi.org/downloads/raspbian/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;official&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open etcher&lt;/strong&gt; etcher (on linux just unzip the etcher.zip and open the executable therein)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Insert sd card&lt;/strong&gt; (don’t mount it yet!), watch that etcher now detects that new card in the middle&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Select image&lt;/strong&gt; e.g. &lt;code&gt;~/Downloads/2017-11-29-raspbian-stretch-lite.zip&lt;/code&gt; and &lt;strong&gt;flash&lt;/strong&gt; &lt;small&gt;(for linux i3 users: you’ll get a polkit error. You’ll need to start a polkit agent, e.g. &lt;code&gt;/usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1&lt;/code&gt; before flashing)&lt;/small&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>How to streamline cd ripping without tagging track data</title>
    <link href="http://howto.philippkeller.com/2017/12/02/How-to-streamline-cd-ripping-without-tagging-track-data/"/>
    <id>http://howto.philippkeller.com/2017/12/02/How-to-streamline-cd-ripping-without-tagging-track-data/</id>
    <published>2017-12-02T15:23:53.000Z</published>
    <updated>2018-01-24T20:10:35.999Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/automate.jpg" alt="CD tower to rip"></p><p>Since we recently stopped using Spotify (mainly because I think having everything at your fingertips influences brain in a negative way) we switched to borrowing CDs from the local library (which, in our case is only 200m away from our house).</p><p>Now, because the kids get CDs at least once a week, I needed a way to quickly import those CDs into our Sonos system without too much hassle. Since the kids only borrow children stories (spoken audio) which often are not on MusicBrainz, I needed an easy way to tag them myself. Because I don’t care about tagging every single track (because you usually listen to a story start to end anyway), I wanted to have a streamlined process. The following script does:</p><ul><li>Rip the CD and convert it to m4a (AAC encoding, slightly better compression than mp3)</li><li>Eject the CD</li><li>Ask me for the album and artist name</li><li>Opens chrome so I can choose an artwork</li><li>Convert the artwork to JPG in a reasonable size</li><li>Copies the music to the directory on my NAS</li><li>Triggers Sonos to update the music library</li></ul><a id="more"></a><p>You may take it as a starting point, you’d want to adapt:</p><ul><li>the paranoia level. <code>-Y</code> is only basic checking which is enough for me. You can remove the <code>-Y</code> to increase the error handle</li><li>the bitrate (line 7). 96k is enough for me</li><li>the genre (line 8)</li><li>the handling of special characters for the album directory name (line 15)</li><li>the hostname/directory of your NAS</li><li>the updating of the music library (line 23. For Sonos there’s <a href="https://github.com/SoCo/SoCo" target="_blank" rel="external">soco</a>, an awesome python library. If you want to use that you’d need to <code>pip install soco</code> first)</li></ul><p>Btw: the script can be run in parallel, i.e. when the first cd is finished ripping and the aac encoding runs you can insert the next disc and start the script again.</p><pre><code class="bash">#!/bin/bashset -etmp_dir=$(mktemp -d)cd $tmp_dircdparanoia -BYejectfor i in *.wav; do     ffmpeg -i $i -c:a libfdk_aac -b:a 96k ${i/cdda.wav/m4a}donetotal=$(ls *.m4a | wc -l)for i in *.m4a; do     number=$(echo $i | sed &#39;s/^track\([0-9]\+\).*/\1/&#39;)    AtomicParsley $i --tracknum &quot;$number/$total&quot; --title &quot;Track $number&quot; --genre &quot;&lt;my genre&gt;&quot; --overWritedoneecho -n &quot;Album name&gt;&quot; &amp;&amp; read albumecho -n &quot;Artist name&gt;&quot; &amp;&amp; read artistsearch_term=&quot;$(perl -MURI::Escape -e &#39;print uri_escape($ARGV[0]);&#39; &quot;$album $artist cd&quot;)&quot;chrome &quot;https://www.google.ch/search?&amp;q=$search_term&amp;tbm=isch&quot; &gt;/dev/null 2&gt;/dev/null &amp;echo -n &quot;Artwork url&gt;&quot; &amp;&amp; read artwork_urlwget -q &quot;$artwork_url&quot; -O artwork.origconvert artwork.orig -resize &quot;250x&quot; artwork.jpgfor i in *.m4a; do     AtomicParsley $i --artwork artwork.jpg --artist &quot;$artist&quot; --album &quot;$album&quot; --overWritedonedir_name=$(echo &quot;${artist// /_}_${album// /_}&quot; | sed &#39;s/Ö/oe/g; s/Ä/ae/g; s/Ü/ue/g; s/ä/ae/g; s/ö/oe/g; s/ü/ue/g&#39; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;)mkdir $dir_namemv *.m4a $dir_namescp -rp $dir_name user@nas:/directory/of/my/musicpython3 -c &quot;import soco; soco.music_library.MusicLibrary().start_library_update()&quot;cd -rm -rf $tmp_dir</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/automate.jpg&quot; alt=&quot;CD tower to rip&quot;&gt;&lt;/p&gt;
&lt;p&gt;Since we recently stopped using Spotify (mainly because I think having everything at your fingertips influences brain in a negative way) we switched to borrowing CDs from the local library (which, in our case is only 200m away from our house).&lt;/p&gt;
&lt;p&gt;Now, because the kids get CDs at least once a week, I needed a way to quickly import those CDs into our Sonos system without too much hassle. Since the kids only borrow children stories (spoken audio) which often are not on MusicBrainz, I needed an easy way to tag them myself. Because I don’t care about tagging every single track (because you usually listen to a story start to end anyway), I wanted to have a streamlined process. The following script does:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rip the CD and convert it to m4a (AAC encoding, slightly better compression than mp3)&lt;/li&gt;
&lt;li&gt;Eject the CD&lt;/li&gt;
&lt;li&gt;Ask me for the album and artist name&lt;/li&gt;
&lt;li&gt;Opens chrome so I can choose an artwork&lt;/li&gt;
&lt;li&gt;Convert the artwork to JPG in a reasonable size&lt;/li&gt;
&lt;li&gt;Copies the music to the directory on my NAS&lt;/li&gt;
&lt;li&gt;Triggers Sonos to update the music library&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ripping" scheme="http://howto.philippkeller.com/tags/ripping/"/>
    
      <category term="music" scheme="http://howto.philippkeller.com/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>How to mass convert mp3 files to aac (m3a)</title>
    <link href="http://howto.philippkeller.com/2017/11/29/How-to-mass-convert-mp3-files-to-aac-m3a/"/>
    <id>http://howto.philippkeller.com/2017/11/29/How-to-mass-convert-mp3-files-to-aac-m3a/</id>
    <published>2017-11-29T15:22:14.000Z</published>
    <updated>2018-02-11T12:56:34.531Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/tape.jpg"></p><p>Since aac has a slightly better compression rate than mp3 (and, geez, mp3 was standardized 1992, there must be better standards nowaday), I decided to mass convert my music library from mp3 to aac</p><h3 id="Won’t-the-quality-be-just-awful"><a href="#Won’t-the-quality-be-just-awful" class="headerlink" title="Won’t the quality be just awful?"></a>Won’t the quality be just awful?</h3><p>Of course, re-encoding sounds like a terrible idea. You’re converting from one lossfull format to another, similar when mass-converting gifs to jpegs. But on the other hand, for my setting it was just good enough. The library I converted we listen to at home over Sonos or in the car. So in both settings there are only half-decent speakers. Also, many of the tracks I converted from audio cassettes, so they were in a bad quality already. You can certainly play with the bitrate, but if you have invested into an expensive stereo you’d be better off converting from a lossless source.</p><h3 id="Declutter"><a href="#Declutter" class="headerlink" title="Declutter"></a>Declutter</h3><p>First things first: Almost everything in life is easier if you first reduce it to the absolute necessity. I recently spoke with a colleague who told me she has converted her whole CD stack into mp3 without first trashing the CDs she never listens to. That’s insane.</p><p>First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.</p><h3 id="No-words-I-just-want-to-copy-paste"><a href="#No-words-I-just-want-to-copy-paste" class="headerlink" title="No words! I just want to copy-paste"></a>No words! I just want to copy-paste</h3><p>Here you go: Once, you haved <code>cd</code>ed into the directory with the mp3 files you want to convert, do this:</p><pre><code class="bash">detox *.mp3ffmpeg -i *.mp3([1]) artwork.jpgfor i in *.mp3; do ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 ${i/mp3/m4a} donefor i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; donerm artwork.jpg &amp;&amp; rm *.mp3</code></pre><a id="more"></a><h3 id="Line-1-Ascify-your-filenames-with-detox"><a href="#Line-1-Ascify-your-filenames-with-detox" class="headerlink" title="Line 1: Ascify your filenames with detox"></a>Line 1: Ascify your filenames with detox</h3><p>Everything is easier on the shell if instead of having <code>my süpér s&#39;öñg.mp3</code> having a file called <code>my_super_song.mp3</code>. Detox converts all characters which you need to somehow escape on the shell to ascii characters.</p><h3 id="Line-2-Extract-artwork"><a href="#Line-2-Extract-artwork" class="headerlink" title="Line 2: Extract artwork"></a>Line 2: Extract artwork</h3><p>We’ll use ffmpeg to convert from mp3 to aac. Sadly the convert command does not transport your artworks, so you need to first extract the artwork. Use the correct ending (otherwise you’ll have a problem in line 4). This command takes the first mp3 and extracts the artwork into artwork.jpg.</p><h3 id="Lines-3-Convert"><a href="#Lines-3-Convert" class="headerlink" title="Lines 3: Convert"></a>Lines 3: Convert</h3><p>Now, in my version of Ubuntu (Xenial, 16.04) ffmpeg does not come with the compiled in converter from mp3 to aac, so I needed to first <a href="http://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu" target="_blank" rel="external">compile ffmpeg from source</a>. This was quite straightforward for me except that it kept saying I had x265 not installed even after doing <code>sudo apt install libx265-dev</code>. I needed to follow <a href="https://bitbucket.org/multicoreware/x265/issues/125/x265-not-found-using-pkg-config#comment-17635086" target="_blank" rel="external">these steps</a> to have this resolved. </p><p>If you don’t want to compile from source then <a href="https://superuser.com/a/370637" target="_blank" rel="external">here</a> is a good overview on all the options you have for doing this step. Just be sure to use the right path, <code>~/bin/ffmpeg</code> is referring to my compiled ffmpeg binary.</p><h4 id="Playing-with-the-options"><a href="#Playing-with-the-options" class="headerlink" title="Playing with the options"></a>Playing with the options</h4><ul><li><code>-b:a 128k</code>: this sets a fixed bitrate. If you’d wish a variable bitrate (having more details for more “dynamic” sections of the track) then you can use <code>-vbr 4</code> instead, or lower it for lower quality/higher compression.</li><li>the <code>-vf scale=1280:-2</code> bit is needed to circumvent the <code>height not divisible by 2</code> error. Taken from <a href="https://stackoverflow.com/a/20848224/119861" target="_blank" rel="external">here</a></li></ul><h3 id="Line-4-Set-artwork"><a href="#Line-4-Set-artwork" class="headerlink" title="Line 4: Set artwork"></a>Line 4: Set artwork</h3><p>This just sets back the artwork you extracted in line 2. This was taken from <a href="https://superuser.com/a/524120" target="_blank" rel="external">here</a>.</p><h3 id="Line-5-Cleanup"><a href="#Line-5-Cleanup" class="headerlink" title="Line 5: Cleanup"></a>Line 5: Cleanup</h3><p>Yeah, finally delete all the old file and enjoy the smaller filesize :)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/tape.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Since aac has a slightly better compression rate than mp3 (and, geez, mp3 was standardized 1992, there must be better standards nowaday), I decided to mass convert my music library from mp3 to aac&lt;/p&gt;
&lt;h3 id=&quot;Won’t-the-quality-be-just-awful&quot;&gt;&lt;a href=&quot;#Won’t-the-quality-be-just-awful&quot; class=&quot;headerlink&quot; title=&quot;Won’t the quality be just awful?&quot;&gt;&lt;/a&gt;Won’t the quality be just awful?&lt;/h3&gt;&lt;p&gt;Of course, re-encoding sounds like a terrible idea. You’re converting from one lossfull format to another, similar when mass-converting gifs to jpegs. But on the other hand, for my setting it was just good enough. The library I converted we listen to at home over Sonos or in the car. So in both settings there are only half-decent speakers. Also, many of the tracks I converted from audio cassettes, so they were in a bad quality already. You can certainly play with the bitrate, but if you have invested into an expensive stereo you’d be better off converting from a lossless source.&lt;/p&gt;
&lt;h3 id=&quot;Declutter&quot;&gt;&lt;a href=&quot;#Declutter&quot; class=&quot;headerlink&quot; title=&quot;Declutter&quot;&gt;&lt;/a&gt;Declutter&lt;/h3&gt;&lt;p&gt;First things first: Almost everything in life is easier if you first reduce it to the absolute necessity. I recently spoke with a colleague who told me she has converted her whole CD stack into mp3 without first trashing the CDs she never listens to. That’s insane.&lt;/p&gt;
&lt;p&gt;First, reduce your collection to, say the albums you listened in the past 12 months. Make it 24. But anything beyond is just an overly burden you don’t need to carry.&lt;/p&gt;
&lt;h3 id=&quot;No-words-I-just-want-to-copy-paste&quot;&gt;&lt;a href=&quot;#No-words-I-just-want-to-copy-paste&quot; class=&quot;headerlink&quot; title=&quot;No words! I just want to copy-paste&quot;&gt;&lt;/a&gt;No words! I just want to copy-paste&lt;/h3&gt;&lt;p&gt;Here you go: Once, you haved &lt;code&gt;cd&lt;/code&gt;ed into the directory with the mp3 files you want to convert, do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;detox *.mp3
ffmpeg -i *.mp3([1]) artwork.jpg
for i in *.mp3; do ffmpeg -i $i -c:a libfdk_aac -b:a 128k -vf scale=1280:-2 ${i/mp3/m4a} done
for i in *.m4a; do AtomicParsley $i --artwork artwork.jpg --overWrite; done
rm artwork.jpg &amp;amp;&amp;amp; rm *.mp3
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="ffmpeg" scheme="http://howto.philippkeller.com/tags/ffmpeg/"/>
    
      <category term="mp3" scheme="http://howto.philippkeller.com/tags/mp3/"/>
    
      <category term="aac" scheme="http://howto.philippkeller.com/tags/aac/"/>
    
  </entry>
  
  <entry>
    <title>Feature phone with tethering (Nokia Asha 302) - tune out of Internet</title>
    <link href="http://howto.philippkeller.com/2016/05/15/Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet/"/>
    <id>http://howto.philippkeller.com/2016/05/15/Feature-phone-with-tethering-Nokia-Asha-302-tune-out-of-Internet/</id>
    <published>2016-05-15T18:25:41.000Z</published>
    <updated>2018-01-24T20:12:11.001Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/asha-302.jpg"></p><p>Since the days of the iPhone finding the right way to handle the mobile phone is challenging to me. Working in web programming and being a father and husband at the same time is means that I need to be able to connect to my colleagues at work when not at my desk while being able to “tune out” while being with my family.</p><p>My latest try at the problem was to buy a “feature phone” which was good enough to support the bare minimum (apart phone calls and SMS this is WhatsApp and internet tethering for my tablet/laptop) but was dumb enough that it would not tempt me away to check any news/mails while being with my family. I came across the “Nokia Asha 302” which is no longer produced but IMO was selling bad enough that there are some in stock in the most countries (at least that was in case here in Switzerland).</p><p>I’m on this “feature phone” now since a few days and must say that I’m quite happy with it. When I am at work I just take my android tablet (nvidia shield k1) with me, if I want to tune out I can leave the house with my mobile only. As it is an outdated phone there are some tweaks you need to do which I documented below:</p><a id="more"></a><h2 id="Tips-and-Tricks"><a href="#Tips-and-Tricks" class="headerlink" title="Tips and Tricks"></a>Tips and Tricks</h2><h3 id="Install-WhatsApp"><a href="#Install-WhatsApp" class="headerlink" title="Install WhatsApp"></a>Install WhatsApp</h3><p>When trying to access the nokia store the first time I got</p><blockquote><p>certificate not valid according to phone’s date</p></blockquote><p>What solved the issue for me was to set the date a few years back (I think I tried 2013). After the store was updated I needed to set the date back to the current date in order to download WhatsApp (otherwise it triggers another certificate exception)</p><h3 id="Install-Google-Maps"><a href="#Install-Google-Maps" class="headerlink" title="Install Google Maps"></a>Install Google Maps</h3><p>Go to <a href="http://www.getjar.com" target="_blank" rel="external">getjar.com</a> with your mobile and search for “map” -&gt; lets you install google maps on your s40 based phone even though google maps is no longer officially supported for this series.</p><h3 id="Tethering"><a href="#Tethering" class="headerlink" title="Tethering"></a>Tethering</h3><p>Just enable bluetooth on your mobile, pair device and connect to network.</p><h3 id="Phone-doesn’t-turn-on"><a href="#Phone-doesn’t-turn-on" class="headerlink" title="Phone doesn’t turn on"></a>Phone doesn’t turn on</h3><p>I had this when trying to charge with a wrong adapter. Asha 302 said it was charging but in fact it was not, just change to a different adapter</p><h3 id="Headphones"><a href="#Headphones" class="headerlink" title="Headphones"></a>Headphones</h3><p>All headphones with three rings do not work (e.g. iphone headphones), but the “normal” headphones without mic with just two rings do work.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/asha-302.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Since the days of the iPhone finding the right way to handle the mobile phone is challenging to me. Working in web programming and being a father and husband at the same time is means that I need to be able to connect to my colleagues at work when not at my desk while being able to “tune out” while being with my family.&lt;/p&gt;
&lt;p&gt;My latest try at the problem was to buy a “feature phone” which was good enough to support the bare minimum (apart phone calls and SMS this is WhatsApp and internet tethering for my tablet/laptop) but was dumb enough that it would not tempt me away to check any news/mails while being with my family. I came across the “Nokia Asha 302” which is no longer produced but IMO was selling bad enough that there are some in stock in the most countries (at least that was in case here in Switzerland).&lt;/p&gt;
&lt;p&gt;I’m on this “feature phone” now since a few days and must say that I’m quite happy with it. When I am at work I just take my android tablet (nvidia shield k1) with me, if I want to tune out I can leave the house with my mobile only. As it is an outdated phone there are some tweaks you need to do which I documented below:&lt;/p&gt;
    
    </summary>
    
    
      <category term="nokia asha 302" scheme="http://howto.philippkeller.com/tags/nokia-asha-302/"/>
    
      <category term="nvidia shield" scheme="http://howto.philippkeller.com/tags/nvidia-shield/"/>
    
      <category term="tethering" scheme="http://howto.philippkeller.com/tags/tethering/"/>
    
  </entry>
  
  <entry>
    <title>How to attach a file to google spreadsheet</title>
    <link href="http://howto.philippkeller.com/2014/01/20/How-to-attach-a-file-to-google-spreadsheet/"/>
    <id>http://howto.philippkeller.com/2014/01/20/How-to-attach-a-file-to-google-spreadsheet/</id>
    <published>2014-01-20T15:06:00.000Z</published>
    <updated>2018-01-26T14:24:51.005Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/attach.png" alt="attach file"></p><p>The following setup lets you</p><ul><li>choose a file from your computer to upload</li><li>upload it to a defined folder on google drive</li><li>inserts the link to the current cell</li></ul><a id="more"></a><p>To get it working:</p><ol><li>find out the id of the google drive folder you want your attachments be saved (in the example below this is <code>0B0uw1JCogWHuc29FWFJMWmc3Z1k</code>)</li><li>in the spreadsheet where you want to upload the file: do Tools→Script Editor.. and paste the script below. Be sure to replace the id with your folders id</li></ol><p><strong>Update 2014</strong>: Made it working with <a href="http://googleblog.blogspot.ch/2013/12/new-google-sheets-faster-more-powerful.html" target="_blank" rel="external">the new sheets</a><br><strong>Update 2016-05</strong> Fixed the script thanks to the comments by Fede and Dov (DocsList.getFolderId was not working any more)</p><pre><code class="javascript">// upload document into google spreadsheet// and put link to it into current cellfunction onOpen(e) {  var ss = SpreadsheetApp.getActiveSpreadsheet()  var menuEntries = [];  menuEntries.push({name: &quot;File...&quot;, functionName: &quot;doGet&quot;});  ss.addMenu(&quot;Attach ...&quot;, menuEntries);}function doGet(e) {  var app = UiApp.createApplication().setTitle(&quot;upload attachment into Google Drive&quot;);  SpreadsheetApp.getActiveSpreadsheet().show(app);  var form = app.createFormPanel().setId(&#39;frm&#39;).setEncoding(&#39;multipart/form-data&#39;);  var formContent = app.createVerticalPanel();  form.add(formContent);    formContent.add(app.createFileUpload().setName(&#39;thefile&#39;));  // these parameters need to be passed by form  // in doPost() these cannot be found out anymore  formContent.add(app.createHidden(&quot;activeCell&quot;, SpreadsheetApp.getActiveRange().getA1Notation()));  formContent.add(app.createHidden(&quot;activeSheet&quot;, SpreadsheetApp.getActiveSheet().getName()));  formContent.add(app.createHidden(&quot;activeSpreadsheet&quot;, SpreadsheetApp.getActiveSpreadsheet().getId()));  formContent.add(app.createSubmitButton(&#39;Submit&#39;));  app.add(form);  SpreadsheetApp.getActiveSpreadsheet().show(app);  return app;}function doPost(e) {  var app = UiApp.getActiveApplication();  app.createLabel(&#39;saving...&#39;);  var fileBlob = e.parameter.thefile;  var doc = DriveApp.getFolderById(&#39;0B0uw1JCogWHuc29FWFJMWmc3Z1k&#39;).createFile(fileBlob);  var label = app.createLabel(&#39;file uploaded successfully&#39;);  // write value into current cell  var value = &#39;hyperlink(&quot;&#39; + doc.getUrl() + &#39;&quot;;&quot;&#39; + doc.getName() + &#39;&quot;)&#39;  var activeSpreadsheet = e.parameter.activeSpreadsheet;  var activeSheet = e.parameter.activeSheet;  var activeCell = e.parameter.activeCell;  var label = app.createLabel(&#39;file uploaded successfully&#39;);  app.add(label);  SpreadsheetApp.openById(activeSpreadsheet).getSheetByName(activeSheet).getRange(activeCell).setFormula(value);  app.close();  return app;}</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/attach.png&quot; alt=&quot;attach file&quot;&gt;&lt;/p&gt;
&lt;p&gt;The following setup lets you&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;choose a file from your computer to upload&lt;/li&gt;
&lt;li&gt;upload it to a defined folder on google drive&lt;/li&gt;
&lt;li&gt;inserts the link to the current cell&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="google-spreadsheet" scheme="http://howto.philippkeller.com/tags/google-spreadsheet/"/>
    
      <category term="google-apps-scripts" scheme="http://howto.philippkeller.com/tags/google-apps-scripts/"/>
    
      <category term="attachments" scheme="http://howto.philippkeller.com/tags/attachments/"/>
    
  </entry>
  
  <entry>
    <title>How to migrate your wordpress to tumblr. Including images and comments.</title>
    <link href="http://howto.philippkeller.com/2012/12/14/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments/"/>
    <id>http://howto.philippkeller.com/2012/12/14/How-to-migrate-your-wordpress-to-tumblr-Including-images-and-comments/</id>
    <published>2012-12-14T10:37:00.000Z</published>
    <updated>2018-01-26T22:46:38.106Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/wordpresstumblr.jpg" alt=""></p><p>So I’ve decided to move my wordpress blogs to tumblr. Although apparently TechCrunch <a href="http://techcrunch.com/2010/09/18/stuff-white-person-doesnt-like/" target="_blank" rel="external">thinks that’s a bad idea</a>. And although <a href="https://twitter.com/moritzadler" target="_blank" rel="external">Moritz Adler</a> would kill me for that. (Although: He doesn’t have a personal blog and hence has no licence to kill me). Anyway. With tumblr I don’t need to host a blog software myself. And I don’t end up having my blog hacked and then seeing my blog being displayed as a malware site in Chrome/Firefox (happened to me twice). And then with tumblr I create new blogs with subdomains within minutes. Cool stuff. Hail to the cloud, baby!</p><p>So here you go: A complete guide how to fully migrate your wordpress blog to tumblr. Including comments and pictures. And still supporting your old url scheme.</p><p><strong>Update:</strong> I ran into a tool that claims to do a lot for you: <a href="http://www.import2.com/tumblr" target="_blank" rel="external">import2.com/tumblr</a>. It doesn’t migrate images and 302 redirects. Not sure about comments migration. And it costs 24$. Still, if you can leave out some of the steps below that’d be worth the money. <a href="http://www.quora.com/Mark-Kofman/answers/Tumblr" target="_blank" rel="external">Comments of the author on quora</a></p><a id="more"></a><h2 id="Before-you-start"><a href="#Before-you-start" class="headerlink" title="Before you start"></a>Before you start</h2><p>Before you start to actually move your blog, you need to consider a few things:</p><h3 id="Where-do-you-move-your-DNS-to"><a href="#Where-do-you-move-your-DNS-to" class="headerlink" title="Where do you move your DNS to?"></a>Where do you move your <strong>DNS</strong> to?</h3><p>If you have a wordpress webhost, then this webhost most probably also does DNS for you. You need to replace that by a third party solution. I think these are good services:</p><ul><li><a href="https://dns.he.net/" target="_blank" rel="external">he.net</a>. Free service. No strings attached. The one I’ve chosen. The interface is nice and very easy to add new CNAMES, MX records, etc. The uptime was <a href="http://www.lowendtalk.com/discussion/262/which-dns-site-to-use-for-domains#Comment_3800" target="_blank" rel="external">reported to be not so good</a>, but I don’t really care about uptime of my blogs. To host your tumblr blog on your domain, you add a <code>CNAME</code> to <code>domains.tumblr.com</code> and then configure your tumblr blog to listen to that domain. Very simple.</li><li><a href="http://aws.amazon.com/route53/" target="_blank" rel="external">Amazon Route 53</a>: They charge you $0.50 per hosted zone per month. That’s a fair price and probably has a better uptime then he.net</li></ul><h3 id="What-do-you-want-to-do-with-your-images"><a href="#What-do-you-want-to-do-with-your-images" class="headerlink" title="What do you want to do with your images?"></a>What do you want to do with your <strong>images</strong>?</h3><p>At default they’re all located under <code>www.yourolddomain.com/wp-content/img1.jpg</code>. To completely get rid of your old web host you need to move those to a different image hoster. I don’t advice you to upload it to tumblr because if in future you want to move away from tumblr you run into the same problem again.</p><h3 id="Would-you-like-to-keep-your-comments"><a href="#Would-you-like-to-keep-your-comments" class="headerlink" title="Would you like to keep your comments?"></a>Would you like to keep your <strong>comments</strong>?</h3><p>Do you have comments at all? Tumblr doesn’t support comments by itself. Most themes have disqus support. Moving comments to disqus is no big deal, but still it’s some work, so you may decide to just not migrate comments.</p><h3 id="Are-you-keen-to-not-break-your-old-blog-urls"><a href="#Are-you-keen-to-not-break-your-old-blog-urls" class="headerlink" title="Are you keen to not break your old blog urls?"></a>Are you keen to not break your <strong>old blog urls</strong>?</h3><p>Wordpress’ url scheme generally is e.g. <code>code.pui.ch/2007/01/05/print-hello-world/</code>.<br>That same post ends up at this tumblr url: <code>howto.pui.ch/post/37471154429/print-hello-world</code>. Note that the last part of the url is optional, i.e. <code>howto.pui.ch/post/37471154429</code> works as well.<br>If you care about incoming links to your blog not to break and if you care about your google ranking (I guess 302 redirects inherit the google ranking), there are two possibilities:</p><ol><li>Stay on the same domain, handle the redirects in tumblr (tumblr supports that with the pages’ type “redirect”)</li><li>Move to a different domain and put up e.g. <code>redirect permanent</code> in a .htaccess file on your web server</li></ol><h2 id="A-rough-outline-of-what-you’re-up-to"><a href="#A-rough-outline-of-what-you’re-up-to" class="headerlink" title="A rough outline of what you’re up to"></a>A rough outline of what you’re up to</h2><p>At a glance, that what you’ll do:</p><ol><li>Upload your images to a different hoster (if you want to get rid of your old webhost)</li><li>Extract all blog posts+comment from wordpress</li><li>Fix the export.xml: Replace images, more-tags and fix some additional stuff</li><li>Migrate your wordpress blog to blogger</li><li>Migrate your blogger blog to tumblr</li><li>Install http redirects (on old webhost or on tumblr)</li><li>Migrate your comments to disqus</li><li>Clean up blog posts (might be a biggie if you’re a perfectionist)</li></ol><p>Alright, let’s specify those 8 steps.</p><h2 id="Step-1-Upload-your-images-to-a-different-hoster"><a href="#Step-1-Upload-your-images-to-a-different-hoster" class="headerlink" title="Step 1: Upload your images to a different hoster"></a>Step 1: Upload your images to a different hoster</h2><p>If you’re ok with keeping your old webhost you can skip this point. Easiest thing to do would be to copy your wp-content directory one to one to a different hoster so <code>www.yourolddomain.com/wp-content/img1.jpg</code> turns into <code>http://www.imagehoster.com/my_user_name/img1.jpg</code>.</p><p>I don’t have experience with image hosting providers so I just uploaded my images to picasa, but that meant I needed to update every single image in all my blog posts to the new image url of picasa. That was quite a pain. I couldn’t find a image hoster yet who meets the criterias above. Photobucket doesn’t, Dropbox doesn’t, Google Drive doesn’t. Maybe Amazon S3</p><h2 id="Step-2-Extract-your-blog-posts-comment-from-wordpress"><a href="#Step-2-Extract-your-blog-posts-comment-from-wordpress" class="headerlink" title="Step 2: Extract your blog posts+comment from wordpress"></a>Step 2: Extract your blog posts+comment from wordpress</h2><ol><li>In your wordpress admin go to Tools → Export. On my blog that was <code>code.pui.ch/wp-admin/export.php</code>.</li><li>Choose <code>All content</code>, <code>Download Export File</code>.</li></ol><h2 id="Step-3-Fix-the-export-xml"><a href="#Step-3-Fix-the-export-xml" class="headerlink" title="Step 3: Fix the export.xml"></a>Step 3: Fix the export.xml</h2><p>You have just downloaded an xml file, in my case the name was <code>coderandom.wordpress.2012-12-13.xml</code>. Open that file with your favourite text editor. Now you need to do a few things before you can go on:</p><ol><li>Replace all &lt;!&ndash;more&ndash;&gt; by <span>[[</span>MORE<span>]]</span>. The uppercase actually matters. <span>[[</span>MORE<span>]]</span> is the divider that tumblr actually understands as the place where you want your excerpt to stop in the blog overview view.</li><li>Replace all images by the new urls you got by uploading the images to the image hoster in step 1. It’s much easier to do this at this stage than to replace the images once you’ve migrated your blog to tumblr.</li><li>You may have more wordpress plugins you used in your posts. I used <code>[python]...[/python]</code> to syntax highlight my python markup. I’ve moved to <a href="https://github.com/google/code-prettify" target="_blank" rel="external">google code prettify</a> which needs <code>&amp;lt;pre class=&quot;prettyprint&quot;&amp;gt;...&amp;lt;/pre&amp;gt;</code> as a syntax. So I needed to replace all occurrences by the new markup. Obviously, regex is your friend at this stage.</li></ol><h2 id="Step-4-Migrate-your-wordpress-blog-to-blogger"><a href="#Step-4-Migrate-your-wordpress-blog-to-blogger" class="headerlink" title="Step 4: Migrate your wordpress blog to blogger"></a>Step 4: Migrate your wordpress blog to blogger</h2><p>Unfortunately there’s no direct way to directly import this xml file into tumblr. Instead, that’s what you need to do:</p><ol><li><p><strong>Convert</strong> your xml file <a href="http://www.wordpress-to-blogger-converter.appspot.com/" target="_blank" rel="external">on this website</a> to a file fit for importing into blogger.</p><p>  This doesn’t work for files bigger than 1MB. If that’s the case then you can either convert the file on your own machine using <a href="http://code.google.com/p/google-blog-converters-appengine/" target="_blank" rel="external">this sourcecode on google code</a>.</p></li><li><strong>Create a new blog</strong> on <a href="http://www.blogger.com" target="_blank" rel="external">blogger.com</a>.</li><li>In blogger navigate to your new blog and do settings → other settings → <strong>import blog</strong></li><li><strong>Publish</strong> all blog posts: Posts → All → Select all → Publish</li></ol><p>If you have difficulties in this step you might try a different solution (didn’t try any of these):</p><ul><li><a href="https://github.com/ideashower/Export-Wordpress-posts-to-Tumblr" target="_blank" rel="external">ideashowers PHP script on github</a></li><li><a href="http://www.daveexmachina.com/wordpress/?p=5974" target="_blank" rel="external">Dave Lartigues php script (plus explanations)</a></li><li><a href="http://snipplr.com/view/14609/migrate-wordpress-to-tumblr/" target="_blank" rel="external">shakefons php script</a></li></ul><h2 id="Step-5-Migrate-your-blogger-blog-to-tumblr"><a href="#Step-5-Migrate-your-blogger-blog-to-tumblr" class="headerlink" title="Step 5: Migrate your blogger blog to tumblr"></a>Step 5: Migrate your blogger blog to tumblr</h2><ol><li>Go to <a href="http://www.bloggertotumblr.com/" target="_blank" rel="external">bloggertotumblr.com</a> and enter your url for your newly created blogger and tumblr blogs. The conversion is very straight forward.</li><li>Delete your blogger blog</li><li>Enjoy. Your blog posts are now on tumblr. Still missing: Support of the old url scheme and comments</li></ol><h2 id="Step-6-Install-http-redirects-on-old-webhost-or-on-tumblr"><a href="#Step-6-Install-http-redirects-on-old-webhost-or-on-tumblr" class="headerlink" title="Step 6: Install http redirects (on old webhost or on tumblr)"></a>Step 6: Install http redirects (on old webhost or on tumblr)</h2><p>In the section <a href="#beforeyoustart">before you start</a> I asked you to decide if you’re ok to break your old urls. If you don’t care, then skip this step. Although: if you care about keeping your comments then you still might to do this step, as it makes migrating comments to disqus a lot easier</p><p>If you do care, then:</p><ul><li>If you keep the domain of your blog: You need to install tumblr redirect pages. See below.</li><li>If you changed the domain of your blog: You need to install redirects on your former wordpress webhost. I describe how this is done via .htaccess config below</li></ul><h3 id="Install-tumblr-redirect-pages"><a href="#Install-tumblr-redirect-pages" class="headerlink" title="Install tumblr redirect pages"></a>Install tumblr redirect pages</h3><ol><li>go to your new tumblr blog</li><li>click customize top right</li><li>add a page (left column)</li><li>instead of “Standard Layout” choose “Redirect” and add a posts’ old url on top, and the new url on bottom. Repeat this for every blog posts (yeah, lots of work here)</li></ol><h3 id="Install-htaccess-on-your-old-webhost"><a href="#Install-htaccess-on-your-old-webhost" class="headerlink" title="Install .htaccess on your old webhost"></a>Install .htaccess on your old webhost</h3><p>IMO that’s a bit simpler than installing a tumblr redirect for every blog post. Still it’s a lot of work since you need to come up with a map of old_url → new_url for every blog post. If your webhost supports .htaccess then go for this method. Most probably you have such a file already for your wordpress installation.</p><p>An example of a .htaccess file:</p><pre><code class="apache">RewriteEngine OnRedirect permanent /page/2/ http://howto.pui.ch/page/2Redirect permanent /feed/ http://howto.pui.ch/rssRewriteRule ^$ http://howto.pui.ch/ [R=301,L]Redirect permanent /2007/02/25/add-bandwidth-to-a-file-download-in-python/ http://howto.pui.ch/post/37471156141/add-bandwidth-to-a-file-download-in-pythonRedirect permanent /2007/06/08/python-find-out-cpu-time-of-a-certain-process/ http://howto.pui.ch/post/37471156554/python-find-out-cpu-time-of-a-certain-processRedirect permanent /2007/07/23/python-sort-a-list-of-dicts-by-dict-key/ http://howto.pui.ch/post/37471157116/python-sort-a-list-of-dicts-by-dict-keyRedirect permanent /2009/12/30/dealing-with-mysql-backend-does-not-support-timezone-aware-datetimes/ http://howto.pui.ch/post/37471158729/dealing-with-mysql-backend-does-not-supportRedirect permanent /2011/01/19/python-easy-way-to-show-progress/ http://howto.pui.ch/post/37471159741/python-easy-way-to-show-progressRedirect permanent /2012/07/17/how-to-detect-a-files-character-encoding/ http://howto.pui.ch/post/37471161169/how-to-detect-a-files-character-encodingRedirect permanent /2010/04/04/python-display-refreshing-status-like-top/ http://howto.pui.ch/post/37471159398/python-display-refreshing-status-like-topRedirect permanent /2011/11/03/how-to-switch-gnu-screen-windows-in-iterm2-via-keyboard-shortcuts/ http://howto.pui.ch/404Redirect permanent /2007/01/19/sched-20-pizza-is-ready/ http://howto.pui.ch/post/37471155110/sched-20-pizza-is-ready</code></pre><p>Note the first 3 lines, you will need the same for your redirects. Note the special syntax of line 3. That is important to not redirect a non existing url to the new domain.</p><h4 id="Wait-I-just-moved-my-blog-away-from-my-old-webhost-and-now-I-need-to-keep-it-to-have-http-redirects-in-place"><a href="#Wait-I-just-moved-my-blog-away-from-my-old-webhost-and-now-I-need-to-keep-it-to-have-http-redirects-in-place" class="headerlink" title="Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?"></a>Wait! I just moved my blog away from my old webhost, and now I need to keep it to have http redirects in place?</h4><p>Uh, yes. Alternatively, you can move to a free hoster like google apps engine and e.g. <a href="http://blog.dantup.com/2010/01/generic-redirection-script-for-google-app-engine" target="_blank" rel="external">use this</a> to redirect. Or you just wait a few months and wait until all search engines have digested your redirects and kill your old webhost only then (that’s what I’m probably gonna do).</p><h2 id="Step-7-Migrate-your-comments-to-disqus"><a href="#Step-7-Migrate-your-comments-to-disqus" class="headerlink" title="Step 7: Migrate your comments to disqus"></a>Step 7: Migrate your comments to disqus</h2><p>Because tumblr doesn’t offer comments by itself you need to migrate your comments to disqus:</p><ol><li><a href="http://disqus.com/admin/register/" target="_blank" rel="external">Register</a> your new tumblr blog url at disqus</li><li>On disqus go to <code>Admin</code> → <code>Tools</code> → <code>Import/Export</code> → <code>Upload WXR</code>. Choose the XML file you downloaded from your wordpress installation (not that got converted for blogger). Upload that</li><li>On the same page go to <code>Migrate Threads</code>. Choose “Redirect crawler” if you installed the redirects in step 6. Otherwise you need to use the “Upload a URL map” option</li></ol><p>Voilà! After a few minutes your comments should appear in your new tumblr blog.</p><h2 id="Step-8-Clean-up-your-tumblr-posts"><a href="#Step-8-Clean-up-your-tumblr-posts" class="headerlink" title="Step 8: Clean up your tumblr posts"></a>Step 8: Clean up your tumblr posts</h2><p>Might be that the html markup of my wordpress posts were so bad, but I needed to fix a lot of spacing between paragraphs. I also had some CSS tweaks to right align the images which I needed to fix.</p><p>Lastly, blogger adds these paragraphs to the end of every blog post:</p><pre><code class="html">&lt;div class=&quot;blogger-post-footer&quot;&gt;  &lt;img alt=&quot;&quot; height=&quot;1&quot; src=&quot;https://blogger.googleusercontent.com/tracker/290349385069691835-5946149615494229188?l=coderandomm.blogspot.com&quot; width=&quot;1&quot;&gt;&lt;/div&gt;</code></pre><p>If you are a perfectionist you may want to remove this markup from every blog post.</p><p>A word of caution: You can spend a lot of time at this step if you overdo it.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/wordpresstumblr.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;So I’ve decided to move my wordpress blogs to tumblr. Although apparently TechCrunch &lt;a href=&quot;http://techcrunch.com/2010/09/18/stuff-white-person-doesnt-like/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;thinks that’s a bad idea&lt;/a&gt;. And although &lt;a href=&quot;https://twitter.com/moritzadler&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Moritz Adler&lt;/a&gt; would kill me for that. (Although: He doesn’t have a personal blog and hence has no licence to kill me). Anyway. With tumblr I don’t need to host a blog software myself. And I don’t end up having my blog hacked and then seeing my blog being displayed as a malware site in Chrome/Firefox (happened to me twice). And then with tumblr I create new blogs with subdomains within minutes. Cool stuff. Hail to the cloud, baby!&lt;/p&gt;
&lt;p&gt;So here you go: A complete guide how to fully migrate your wordpress blog to tumblr. Including comments and pictures. And still supporting your old url scheme.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; I ran into a tool that claims to do a lot for you: &lt;a href=&quot;http://www.import2.com/tumblr&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;import2.com/tumblr&lt;/a&gt;. It doesn’t migrate images and 302 redirects. Not sure about comments migration. And it costs 24$. Still, if you can leave out some of the steps below that’d be worth the money. &lt;a href=&quot;http://www.quora.com/Mark-Kofman/answers/Tumblr&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Comments of the author on quora&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="wordpress-to-tumblr" scheme="http://howto.philippkeller.com/tags/wordpress-to-tumblr/"/>
    
      <category term="wordpress" scheme="http://howto.philippkeller.com/tags/wordpress/"/>
    
      <category term="tumblr" scheme="http://howto.philippkeller.com/tags/tumblr/"/>
    
      <category term="migration" scheme="http://howto.philippkeller.com/tags/migration/"/>
    
  </entry>
  
  <entry>
    <title>How to fix Jambox’ “static noise and no bluetooth sound” problem(includes soldering)</title>
    <link href="http://howto.philippkeller.com/2012/07/21/how-to-fix-jambox-static-noise/"/>
    <id>http://howto.philippkeller.com/2012/07/21/how-to-fix-jambox-static-noise/</id>
    <published>2012-07-21T13:07:00.000Z</published>
    <updated>2018-01-26T22:32:21.620Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/soldered.png" alt="fixed"></p><p>Jambox is a pretty cool device: The sound quality is very good, it is small, it has a battery. I liked it. Until it broke. It just didn’t play music over bluetooth any more but instead uttered static noise. This seems to be a quite severe production problem as after some internet research I found that many people have devices with the exact same problem. So going down the “Jambox please replace my device” way didn’t sound promising to me. The possibility that the replacement device is broken as well is just too high.</p><p>The problem lies in the aux in port. The device thinks there’s an aux cable plugged in and outputs the signal from the aux input when in fact it should play the bluetooth sound.</p><a id="more"></a><p>In my <a href="http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/">last post</a> I described the different easy-to-do solutions to this problem, but today I needed to implement the soldering solution because nothing else worked. Implementing this solution means tricking the Jambox to think there’s no aux cable plugged in.</p><p><strong>Update</strong>: My initial soldering was working, but after the first recharge the fix stopped working. Might be that the soldering melted and if you are a solder pro this might work for you. Anyway. I personally ended up putting a <a href="http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/">screw into the aux port</a></p><h2 id="What-do-you-need"><a href="#What-do-you-need" class="headerlink" title="What do you need?"></a>What do you need?</h2><ul><li>a star shaped screw driver (aka torx)</li><li>Soldering equipment</li><li>being ok that the aux cable will never work again</li><li>desparation to get this machine working again (I’m not sure how safe this is, being not used to that kind of stuff)</li><li>and of course it will void your warranty</li></ul><p>I personally hate soldering, I’m not good at it, but still I managed to get my Jambox working agagin so I thought I’d share with the world:</p><h3 id="How-to-disassemble"><a href="#How-to-disassemble" class="headerlink" title="How to disassemble"></a>How to disassemble</h3><p>There’s <a href="http://www.youtube.com/watch?v=X5APtwqtEps" target="_blank" rel="external">a good video describing how it should be done</a> (I did it just with the screwdriver. No gloves and no other equipment.)<br><br>  You need to follow the video until 5:00</p><h3 id="What-to-solder"><a href="#What-to-solder" class="headerlink" title="What to solder?"></a>What to solder?</h3><p><img class="caption" alt="The two contacts you need to bridge" src="/images/aux_port.jpg"></p><p><strong>Update</strong>: David Choi <a href="http://www.youtube.com/watch?v=nd5nF2hSFHw&amp;feature=youtu.be" target="_blank" rel="external">has made a video</a> that shows very well which two contacts to solder. He claims that with good soldering skills you can achieve that both bluetooth and aux will still work.</p><p>It’s pretty simple: Follow the aux port and where the end of the aux jack would be there are 2 metal contacts which need to be soldered together. Turn on the jambox and try to push the upper metal contact so the two metal pieces touch and you’ll hear the bluetooth sound. Hearing the music should give you enough motivation now to go on. Now:</p><ul><li>Turn off the Jambox</li><li>Try to solder (it is tricky because the spot is hard to reach)</li><li>Try if it has worked. If it worked, wait some time. Shake the bluetooth device to really go sure the soldering joint is good (first time I was so happy that it worked, I assembled the device again and then it didn’t work because the soldering joint was flaky)</li></ul><h3 id="How-to-assemble"><a href="#How-to-assemble" class="headerlink" title="How to assemble"></a>How to assemble</h3><p><img class="caption" src="/images/bend.jpg" alt="I needed to bend the two metal pieces at the end of the grid to be able to assemble it"></p><p>Again <a href="http://www.youtube.com/watch?v=X5APtwqtEps&amp;t=10m40s" target="_blank" rel="external">follow the video starting from 10:40</a></p><p>I found the assembling the hardest part. In the end I needed to bend the small metal pieces of the grid to be able to put it back together (although I didn’t follow the video so you might be more successful).</p><h3 id="Happy-listening"><a href="#Happy-listening" class="headerlink" title="Happy listening"></a>Happy listening</h3><p>My Jambox is now up and running again since 24h. I’m very very happy that this little thing did the trick.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/soldered.png&quot; alt=&quot;fixed&quot;&gt;&lt;/p&gt;
&lt;p&gt;Jambox is a pretty cool device: The sound quality is very good, it is small, it has a battery. I liked it. Until it broke. It just didn’t play music over bluetooth any more but instead uttered static noise. This seems to be a quite severe production problem as after some internet research I found that many people have devices with the exact same problem. So going down the “Jambox please replace my device” way didn’t sound promising to me. The possibility that the replacement device is broken as well is just too high.&lt;/p&gt;
&lt;p&gt;The problem lies in the aux in port. The device thinks there’s an aux cable plugged in and outputs the signal from the aux input when in fact it should play the bluetooth sound.&lt;/p&gt;
    
    </summary>
    
    
      <category term="jambox" scheme="http://howto.philippkeller.com/tags/jambox/"/>
    
  </entry>
  
  <entry>
    <title>How to reset Jambox when bluetooth completely stopped working</title>
    <link href="http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/"/>
    <id>http://howto.philippkeller.com/2012/07/14/How-to-reset-Jambox-when-bluetooth-completely-stopped-working/</id>
    <published>2012-07-14T17:26:00.000Z</published>
    <updated>2018-01-26T22:43:27.832Z</updated>
    
    <content type="html"><![CDATA[<p>I bought a Jambox about half a year ago. Sound wise it is great, but apparently it is not very stable, especially after recharging it falls into some state where it only utters static noise. In this state it still plays music over the aux cable, but not any more over bluetooth.<a id="more"></a></p><p>Apparently the issue is the aux port which has two contacts that should touch each other when there is no aux cable inserted. But, because of manufacture problems these two contacts don’t touch on some device, even though there is no aux cable inserted. So: The jambox thinks there is an aux cable, but there is none. That’s why it utters static noise</p><p>So, because I have a device with such problems I needed to hard reset my jambox half a dozen. That’s why I thought I finally write it down.</p><p><img alt="Jambox, screwed" src="/images/jambox_screwed.jpg" class="caption"></p><ul><li><strong>Soft reset</strong>: Holding down the circle button (talk button) and plugging it into the charger and then releasing. You will see the red flash</li><li>Unpair / Pair again; being deleting it from every device, restarting all of them and pairing once more</li><li><strong>Hard reset</strong>: Turn off bluetooth on all devices in reach, then turn on the jambox and press the circle button six times, when you see the light flash red, press the circle once more and hold it and it will go into pairing mode</li><li>Update the software to &gt;=2.1 using <a href="http://mytalk.jawbone.com" target="_blank" rel="external">mytalk.jawbone.com</a></li><li>Insert an <strong>aux cable</strong> and removing it again (worked a few times for me)</li><li>Insert a small <strong>screw driver</strong>. This connects the two metal contacts which should touch each other to make the Jambox believe there is no AUX cable inserted</li><li>If the screw driver thing is working for you, you might consider putting a screw into the aux port (see photo)</li><li>If nothing of the above works, you can <a href="/2012/07/21/how-to-fix-jambox-static-noise/">solder a bypass of the aux port</a> (which is what I finally did)</li></ul><p>I don’t recommend buying a Jambox to anyone, I completely agree with <a href="http://www.amazon.com/review/R3GYH7DT8H8EKR/ref=cm_cr_pr_cmt?ie=UTF8&amp;ASIN=B004E10KGU" target="_blank" rel="external">this review on Amazon</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I bought a Jambox about half a year ago. Sound wise it is great, but apparently it is not very stable, especially after recharging it falls into some state where it only utters static noise. In this state it still plays music over the aux cable, but not any more over bluetooth.
    
    </summary>
    
    
      <category term="gadgets" scheme="http://howto.philippkeller.com/tags/gadgets/"/>
    
  </entry>
  
  <entry>
    <title>Python: Print list of dicts as ascii table</title>
    <link href="http://howto.philippkeller.com/2010/02/27/Python-Print-list-of-dicts-as-ascii-table/"/>
    <id>http://howto.philippkeller.com/2010/02/27/Python-Print-list-of-dicts-as-ascii-table/</id>
    <published>2010-02-27T11:55:00.000Z</published>
    <updated>2018-01-24T20:24:51.501Z</updated>
    
    <content type="html"><![CDATA[<p>Sometimes I want to print list of dicts as an ascii table, like this:</p><pre><code>| Programming Language | Language Type | Years of Experience |+----------------------+---------------+---------------------+| python               | script        |                   4 || php                  | script        |                   5 || java                 | compiled      |                  11 || assember             | compiled      |                  15 |</code></pre><p>I searched on Google - but without luck.<a id="more"></a></p><p> That’s what I came up with - it’s not particularly nice but it does the job:</p><pre><code class="python">def table_print(data, title_row):    &quot;&quot;&quot;    data: list of dicts,    title_row: e.g. [(&#39;name&#39;, &#39;Programming Language&#39;), (&#39;type&#39;, &#39;Language Type&#39;)]    &quot;&quot;&quot;    max_widths = {}    data_copy = [dict(title_row)] + list(data)    for col in data_copy[0].keys():      max_widths[col] = max([len(str(row[col])) for row in data_copy])    cols_order = [tup[0] for tup in title_row]    def custom_just(col, value):      if type(value) == int:        return str(value).rjust(max_widths[col])      else:        return value.ljust(max_widths[col])    for row in data_copy:      row_str = &quot; | &quot;.join([custom_just(col, row[col]) for col in cols_order])      print &quot;| %s |&quot; % row_str      if data_copy.index(row) == 0:        underline = &quot;-+-&quot;.join([&#39;-&#39; * max_widths[col] for col in cols_order])        print &#39;+-%s-+&#39; % underline</code></pre><p>Use it like this:</p><pre><code class="python">data = [dict(name=&#39;python&#39;, type=&#39;script&#39;, years_experience=4),    dict(name=&#39;php&#39;, type=&#39;script&#39;, years_experience=5),    dict(name=&#39;java&#39;, type=&#39;compiled&#39;, years_experience=11),    dict(name=&#39;assember&#39;, type=&#39;compiled&#39;, years_experience=15)    ]  titles = [(&#39;name&#39;, &#39;Programming Language&#39;),    (&#39;type&#39;, &#39;Language Type&#39;),    (&#39;years_experience&#39;, &#39;Years of Experience&#39;)]  table_print(data, titles)</code></pre><p>It will produce the table printed above. It’s not fancy - the only &lsquo;smart’ thing it does is <strong>right-adjusting integers, strings are left-adjusted</strong>.</p><p> P.S. no, I don’t have 15 years of experience of Assembler - I just know it since 15 years - it’s one of the first programming languages I learned - and I even wrote a text editor with it - then I learned that’s probably not the best language to write an editor :-)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Sometimes I want to print list of dicts as an ascii table, like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;| Programming Language | Language Type | Years of Experience |
+----------------------+---------------+---------------------+
| python               | script        |                   4 |
| php                  | script        |                   5 |
| java                 | compiled      |                  11 |
| assember             | compiled      |                  15 |
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I searched on Google - but without luck.
    
    </summary>
    
    
      <category term="python" scheme="http://howto.philippkeller.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Send javascript errors by mail</title>
    <link href="http://howto.philippkeller.com/2007/10/06/Send-javascript-errors-by-mail/"/>
    <id>http://howto.philippkeller.com/2007/10/06/Send-javascript-errors-by-mail/</id>
    <published>2007-10-06T13:33:00.000Z</published>
    <updated>2018-01-24T20:25:18.393Z</updated>
    
    <content type="html"><![CDATA[<p>I’m running <a href="http://extranet.icoc.ch" target="_blank" rel="external">a Django-powered site for a closed user group</a> and added a bit of JavaScript magic here and there (mainly <a href="http://www.prototypejs.org/" target="_blank" rel="external">Prototype</a> and <a href="http://codylindley.com/Javascript/219/finding-a-javascript-tool-tip-script" target="_blank" rel="external">Tooltip</a>).</p><a id="more"></a><p>Now Django sends me a mail whenever a 404 or 500 error occurs. But when one of my users encounters a JavaScript-Error, I’m not informed. I thought anyone in the web has solved this problem but didn’t find anything, so here’s my take: Just send any error using Ajax (here: using <a href="http://www.prototypejs.org/learn/introduction-to-ajax" target="_blank" rel="external">Prototypes Ajax abstraction</a>) to the server</p><pre><code class="javascript">onerror = Extranet.mailError;function mailError(msg, url, line) {   var postBody = &#39;url=&#39; + url + &#39;&amp;amp;line=&#39; + line + &#39;&amp;amp;message=&#39; + escape(msg)   + &#39;&amp;amp;useragent=&#39; + escape(navigator.userAgent) + &#39;&amp;amp;user=&#39; + escape(user_name);   var myAjax = new Ajax.Request(&#39;/api/jserror/&#39;, {method: &#39;post&#39;, postBody: postBody});}</code></pre><p>  <code>user_name</code> is a JavaScript variable holding the Django username (so I know whom I can inform when the error is fixed).</p><p>  On the server side, I just send me mails containing the JavaScript error message, the username and the user agent:</p><pre><code class="python">def jserror(request):   from django.core.mail import mail_admins   omit_messages = [&#39;pointerobj is not defined&#39;,      &#39;tipobj is not defined&#39;,      &#39;ns6 is not defined&#39;, &#39;enabletip is not defined&#39;]    if request.POST.get(&#39;message&#39;, &#39;&#39;) not in omit_messages:    message = &quot;&quot;&quot;url: %s (%s) %s    user-agent: %s    username: %s&quot;&quot;&quot; % (request.POST.get(&#39;url&#39;, &#39;&#39;),         request.POST.get(&#39;line&#39;, &#39;&#39;),        request.POST.get(&#39;message&#39;, &#39;&#39;),        request.POST.get(&#39;useragent&#39;, &#39;&#39;),        request.POST.get(&#39;user&#39;, &#39;&#39;))    mail_admins(&quot;javascript error&quot;, urldecode(message))    return HttpResponse()</code></pre><p>Yeah, that’s all very trivial but I wonder what other solutions exist for this problem…</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’m running &lt;a href=&quot;http://extranet.icoc.ch&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;a Django-powered site for a closed user group&lt;/a&gt; and added a bit of JavaScript magic here and there (mainly &lt;a href=&quot;http://www.prototypejs.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Prototype&lt;/a&gt; and &lt;a href=&quot;http://codylindley.com/Javascript/219/finding-a-javascript-tool-tip-script&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Tooltip&lt;/a&gt;).&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://howto.philippkeller.com/tags/python/"/>
    
      <category term="django" scheme="http://howto.philippkeller.com/tags/django/"/>
    
      <category term="javascript" scheme="http://howto.philippkeller.com/tags/javascript/"/>
    
  </entry>
  
  <entry>
    <title>Django: Serve big files via fcgid</title>
    <link href="http://howto.philippkeller.com/2007/10/03/Django-Serve-big-files-via-fcgid/"/>
    <id>http://howto.philippkeller.com/2007/10/03/Django-Serve-big-files-via-fcgid/</id>
    <published>2007-10-03T08:14:00.000Z</published>
    <updated>2018-01-26T21:06:47.769Z</updated>
    
    <content type="html"><![CDATA[<p>I’ve got a <a href="http://extranet.icoc.ch" target="_blank" rel="external">django project</a> running which requires you to login to access files.</p><p>That means that I have to serve the files via python, like this:</p><pre><code class="python">@login_requireddef download(request, filename):  # ... some code specific to my site ...  response = HttpResponse(mimetype=postUpload.mimetype)  response[&#39;Content-Disposition&#39;] = &quot;attachment; filename=&quot; + original_filename  response[&#39;Content-Length&#39;] = os.path.getsize(filename_path)  response.write(open(filename_path).read())  return response</code></pre><a id="more"></a><p>The problem: If the download of a file exceeded 5 minutes (big files and/or low<br>bandwidth) the download was canceled on the server side by a timeout. This Apache<br>configuration for mod_fcgid solved the problem (Note that this has been renamed into <code>FcgidBusyTimeout</code>, <a href="https://httpd.apache.org/mod_fcgid/en/mod/mod_fcgid.html#fcgidbusytimeout" target="_blank" rel="external">documentation here</a>)</p><pre><code class="apache">&lt;IfModule mod_fcgid.c&gt; BusyTimeout 1200&lt;/IfModule&gt;</code></pre><p>The problem was that the apache module scanned every minute for processes that run for<br>more than BusyTimeout seconds. These processes are potentially in bad health (infinite<br>loop et al.) and have to be killed. Not so with my processes (since I know what I’m<br>doing..). The setting of the busy timeout to 1200 seconds now lets my processes run for<br>a maximum of one hour.</p><p>As this setting can’t by overwritten in a htaccess file by default I needed to bug<br><a href="http://www.citrin.ch/" target="_blank" rel="external">my web hosting provider</a> with the request, which was<br>handled in 24 hours, so thanks for that one!</p><p>PS: If you know of another way how to serve protected static files via a single sign on<br>(no HTTP basic auth), please let me know.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ve got a &lt;a href=&quot;http://extranet.icoc.ch&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;django project&lt;/a&gt; running which requires you to login to access files.&lt;/p&gt;
&lt;p&gt;That means that I have to serve the files via python, like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;@login_required
def download(request, filename):
  # ... some code specific to my site ...
  response = HttpResponse(mimetype=postUpload.mimetype)
  response[&amp;#39;Content-Disposition&amp;#39;] = &amp;quot;attachment; filename=&amp;quot; + original_filename
  response[&amp;#39;Content-Length&amp;#39;] = os.path.getsize(filename_path)
  response.write(open(filename_path).read())
  return response
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://howto.philippkeller.com/tags/python/"/>
    
      <category term="django" scheme="http://howto.philippkeller.com/tags/django/"/>
    
  </entry>
  
  <entry>
    <title>Python: Find out cpu time of a certain process</title>
    <link href="http://howto.philippkeller.com/2007/06/08/Python-Find-out-cpu-time-of-a-certain-process/"/>
    <id>http://howto.philippkeller.com/2007/06/08/Python-Find-out-cpu-time-of-a-certain-process/</id>
    <published>2007-06-08T04:52:00.000Z</published>
    <updated>2018-01-24T20:27:19.423Z</updated>
    
    <content type="html"><![CDATA[<p>To find out how many percentage a certain process uses the cpu:</p><a id="more"></a><pre><code class="python">import os, time# find out the pid by username.# &quot;-o pid h&quot; omits the header and just prints the pidpid = os.popen(&#39;ps -U my_user_name -o pid h&#39;).read().strip()# 14th column is utime, 15th column is stime:# The time the process has been scheduled in user/kernel mode# The time value is in jiffies. One jiffie is appox 1/100 second# see man proc for more infostat = os.popen(&#39;cat /proc/%s/stat&#39; % pid).read().strip()cpu_time1=int(stat.split()[14]) + int(stat.split()[15])time1=time.time()time.sleep(1)stat = os.popen(&#39;cat /proc/%s/stat&#39; % pid).read().strip()cpu_time2=int(stat.split()[14]) + int(stat.split()[15])time2=time.time()print str(float(cpu_time2 - cpu_time1) / (time2 - time1)) + &quot;%&quot;</code></pre><p>I don’t know though if the number is accurate :)</p><p>What is “cpu time” anyway? It’s the time the process is running (using the cpu for 100%) divided by the time the process is laid asleep by the scheduler. Then, <a href="http://www.ecos.sourceware.org/ml/systemtap/2005-q4/msg00185.html" target="_blank" rel="external">jiffies seem to be not a safe number</a> for time measurements.</p><p>But for relative measurements it should do the trick.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;To find out how many percentage a certain process uses the cpu:&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://howto.philippkeller.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Tag history and gartners hype cycles</title>
    <link href="http://howto.philippkeller.com/2007/05/12/Tag-history-and-gartners-hype-cycles/"/>
    <id>http://howto.philippkeller.com/2007/05/12/Tag-history-and-gartners-hype-cycles/</id>
    <published>2007-05-12T14:21:00.000Z</published>
    <updated>2018-01-26T22:44:31.853Z</updated>
    
    <content type="html"><![CDATA[<p>For last Webtuesday I gathered a few historic data of the «tag movement» (that got very quiet in the last two years).</p><p><img src="/images/tagging_history_900.gif" alt=""></p><p><strong>Update September, 2007</strong>: <a href="http://vanderwal.net/random/entrysel.php?blog=1945" target="_blank" rel="external">Thomas Vander Wal wrote a very good roundup on the tag history</a></p><a id="more"></a><h3 id="Gartners-hype-cycles-applied-to-tag-history"><a href="#Gartners-hype-cycles-applied-to-tag-history" class="headerlink" title="Gartners hype cycles applied to tag history"></a>Gartners hype cycles applied to tag history</h3><p>I think <a href="http://en.wikipedia.org/wiki/Hype_cycle" target="_blank" rel="external">gartners hype cycles</a> prove to be right when applied to the tag history (hype cycle descriptions taken from <a href="http://www.floor.nl/ebiz/gartnershypecycle.htm" target="_blank" rel="external">Floor eTrends</a>):</p><p><strong>Technology trigger</strong></p><blockquote><p>A breakthrough, public demonstration, product launch or other event that generates significant press and industry interest.</p></blockquote><p>The technology trigger most likely was <a href="http://del.icio.us" target="_blank" rel="external">del.icio.us</a> and subsequently flickr adding tagging to their service.</p><h4 id="Peak-of-inflated-expectations"><a href="#Peak-of-inflated-expectations" class="headerlink" title="Peak of inflated expectations"></a>Peak of inflated expectations</h4><blockquote><p>A phase of overenthusiasm and unrealistic projections during which a flurry of publicized activity by technology leaders results in some successes but more failures as the technology is pushed to its limits. The only enterprises making money at this stage are conference organizers and magazine publishers.</p></blockquote><p>In this phase there were indeed many blog posts talking about this subject, as <a href="http://louisrosenfeld.com/home/bloug_archive/000330.html" target="_blank" rel="external">Louis Rosenfeld</a><br>put it:</p><blockquote><p>Lately, you can’t surf information architecture blogs for five minutes without stumbling on a discussion of folksonomies</p></blockquote><p>I guess in this phase many people said things they now feel embarassed about.</p><p><strong>Trough of disillusionment</strong></p><blockquote><p>The point at which the technology becomes unfashionable and the press abandons the topic, because the technology did not live up to its overinflated expectations.</p></blockquote><p>This is the phase we’re in now. There are no blog posts any more. Tagging is not really</p><p>unfashionable but the topic is “done” à la «if that’s all what’s tagging adds to the web experience, I’m not interested in this technology any more». There isn’t much thinking and innovation going on.</p><h4 id="Slope-of-enlightenment"><a href="#Slope-of-enlightenment" class="headerlink" title="Slope of enlightenment"></a>Slope of enlightenment</h4><blockquote><p>Focused experimentation and solid hard work by an increasingly diverse range of organizations lead to a true understanding of the technology’s applicability, risks and benefits. Commercial off-the-shelf methodologies and tools become available to ease the development process.</p></blockquote><p>Let’s hope gartner is right about the future of folksonomies!</p><h4 id="Plateau-of-productivity"><a href="#Plateau-of-productivity" class="headerlink" title="Plateau of productivity"></a>Plateau of productivity</h4><blockquote><p>The real-world benefits of the technology are demonstrated and accepted. Tools and methodologies are increasingly stable as they enter their second and third generation. The final height of the plateau varies according to whether the technology is broadly applicable or only benefits a niche market.</p></blockquote><p>It has yet to show if folksonomies such as in del.icio.us or flickr prove themselves for the masses.</p><p><strong>Update (September, 2007): Do folksonomies apply to hype cycles at all?</strong></p><p>Joe Lamantia raised the question if tagging should be applied at all to Gartners Hype Cycles:</p><blockquote><p>Tagging in fact shows few characteristics of the enterprise technologies that Gartner’s Hype Cycle is built around</p></blockquote><p>Joe argues rightly, that tagging has not yet reached the broad economy, it’s not that Gartner would care to apply folksonomies to their Hype Cycles.</p><p>Although: Gartner apply the hype cycle to technologies such as <a href="http://www.gartner.com/DisplayDocument?doc_cd=140881&amp;ref=g_SiteLink" target="_blank" rel="external">“corporate blogging” or wikis</a>. It seems it does not lie in the nature of tagging that it won’t ever apply to hype cycles, the only fact that hinders Gartner to apply tagging to their hype cycles is that there is no money earned with it. I’m not into business analysis at all so I am grateful for Joes insights which he concludes with:</p><blockquote><p>If it doesn’t cost money, the perceived risks of the technology are lower, and the big analysis firms pay less attention, because their customers see less need to pay for analysis</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;For last Webtuesday I gathered a few historic data of the «tag movement» (that got very quiet in the last two years).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/tagging_history_900.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update September, 2007&lt;/strong&gt;: &lt;a href=&quot;http://vanderwal.net/random/entrysel.php?blog=1945&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Thomas Vander Wal wrote a very good roundup on the tag history&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="History" scheme="http://howto.philippkeller.com/tags/History/"/>
    
      <category term="Tagging" scheme="http://howto.philippkeller.com/tags/Tagging/"/>
    
  </entry>
  
  <entry>
    <title>Set timeout for a shell command in python</title>
    <link href="http://howto.philippkeller.com/2007/02/18/set-timeout-for-a-shell-command-in-python/"/>
    <id>http://howto.philippkeller.com/2007/02/18/set-timeout-for-a-shell-command-in-python/</id>
    <published>2007-02-18T17:04:00.000Z</published>
    <updated>2018-01-24T20:28:29.827Z</updated>
    
    <content type="html"><![CDATA[<p>I wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (<a href="http://adplug.sourceforge.net/" target="_blank" rel="external">adplay</a> that was, sometimes it simply hangs).<br><br><strong>Update:</strong> <a href="http://www.python.net/crew/hooft/" target="_blank" rel="external">the “task” module of Rob Hooft</a> seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.<br><br></p><a id="more"></a><pre><code class="python">def timeout_command(command, timeout):  &quot;&quot;&quot;call shell-command and either return its output or kill it  if it doesn&#39;t normally exit within timeout seconds and return None&quot;&quot;&quot;  import subprocess, datetime, os, time, signal  start = datetime.datetime.now()  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)  while process.poll() is None:    time.sleep(0.1)    now = datetime.datetime.now()    if (now - start).seconds&amp;gt; timeout:      os.kill(process.pid, signal.SIGKILL)      os.waitpid(-1, os.WNOHANG)      return None  return process.stdout.read()</code></pre><p>Usage:</p><pre><code class="python">&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;10&quot;], 2)None&gt;&gt;&gt; output = timeout_command([&quot;sleep&quot;, &quot;1&quot;], 2)</code></pre><p>The process can be killed when it has run for too long (the <code>os.waitpid</code> waits for the kill to end and avoids defunct-processes) and furthermore the Popen’ed process’ printed is caught and returned if it doesn’t timeout. However, <code>subprocess.Popen</code> is called with a list as argument. That means, that the command isn’t passed to a shell and furthermore you can just call one command with options, nothing more.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I wanted to run a shell command in python without knowing if the shell command is going to exit within reasonable time (&lt;a href=&quot;http://adplug.sourceforge.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;adplay&lt;/a&gt; that was, sometimes it simply hangs).&lt;br&gt;&lt;br&gt;&lt;strong&gt;Update:&lt;/strong&gt; &lt;a href=&quot;http://www.python.net/crew/hooft/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;the “task” module of Rob Hooft&lt;/a&gt; seems to solve this exact problem. At the time I wrote this, the python.net website was down. I leave my solution here just for archive purpose.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://howto.philippkeller.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Turn demoscene modules into mp3s</title>
    <link href="http://howto.philippkeller.com/2007/02/10/Turn-demoscene-modules-into-mp3s/"/>
    <id>http://howto.philippkeller.com/2007/02/10/Turn-demoscene-modules-into-mp3s/</id>
    <published>2007-02-10T18:39:00.000Z</published>
    <updated>2018-01-26T22:25:29.827Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Update 2018</strong> (11 years later): I fixed the python scripts below, so they should still work! If not, then please add a comment below. Btw: Isn’t it <strong>amazing</strong> that modland is still up and running after all these years?</p><p><img src="/images/purple_motion.png" alt="iTunes screenshot of purple motions tracks"></p><p>If you were part of the demoscene in your former life, if you were and still are fond of modules (those sound files with the mod, xm, s3m, it, &hellip; ending), if you are a linux user and if you still want to listen to this music on your computer without doing all the tweaks of installing (or even compiling) music player plugins for itunes or amarok or if you simply want to listen to Purple Motions tunes on your mp3 player then this little tutorial is for you. If not, then you won’t have read that far anyway..</p><a id="more"></a><h2 id="short-version-for-the-impatient"><a href="#short-version-for-the-impatient" class="headerlink" title="short version for the impatient"></a>short version for the impatient</h2><p>Download <a href="/files/downloadmod.py">downloadmod.py</a> and <a href="/files/mod2mp3.py">mod2mp3.py</a> and start then with python2 (the command may be just <code>python</code> on your machine).</p><pre><code class="bash">sudo apt-get install xmp adplay unrar lamemkdir ~/modules/python2 downloadmod.py ~/modules/ &quot;Purple Motion&quot;python2 mod2mp3.py ~/modules/</code></pre><h3 id="First-get-those-modules"><a href="#First-get-those-modules" class="headerlink" title="First, get those modules"></a>First, get those modules</h3><p>The first task is to get those modules onto your computer (as you most certainly deleted them - either per accident or when you were in needed of some space on your hard drive back when hard drives where small and expensive)</p><p>Afaik the most complete module resource is <a href="ftp://ftp.modland.com" target="_blank" rel="external">modland</a>. The crux is that it’s just an ftp site with deep directory structure and without a search facility. All it has got is a complete list of all the modules in a RAR file (which is kept up to date by a cron job) that holds a text file with all the available modules and their path.</p><p>To download all modules of a certain artist, I wrote a little <a href="/files/downloadmod.py">python script</a> that downloads the module list, unrars it, caches it for further search requests, searches for the artist and downloads all modules of that particular artist.</p><p><code>downloadmod.py ~/modules/ &quot;Michael Land&quot;</code> downloads all Adlib songs of Michael Land and places them into ~/modules/Michael Land/ and writes some artist/album meta information into those newly created directories.</p><h3 id="Then-convert-those-modules-into-mp3-files"><a href="#Then-convert-those-modules-into-mp3-files" class="headerlink" title="Then, convert those modules into mp3 files"></a>Then, convert those modules into mp3 files</h3><p>To convert the modules into mp3 files you usually take a module player and call with some special parameters in order to “play” the module into a wav-File and convert that wav into an mp3 file.</p><p>On linux, I’d suggest to install this module players (both exist as debian packages and work without hassle on my ubuntu installation)</p><ul><li><a href="http://xmp.sourceforge.net/" target="_blank" rel="external">xmp</a> is *nix “native”</li><li><a href="http://adplug.sourceforge.net/" target="_blank" rel="external">adplay</a> supports many adlib formats</li></ul><p>I wrote a <a href="/files/mod2mp3.py">python script</a> that converts the downloaded modules into mp3s using the just mentioned module players. You need at least xmp or adplay. If you install both, you’d be able to play about 90% of all modules.</p><p>Just call <code>mod2mp3.py</code> with your root module directory as argument and the script creates a mp3 file for each module that is convertible and isn’t already converted. If you downloaded the modules with my download script, this script will use the meta information of the first script to write the id3 tags of the mp3s.</p><p>If everything worked, you now should have mp3 files with correct id3 tags that can be imported into your amarok/itunes library.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Update 2018&lt;/strong&gt; (11 years later): I fixed the python scripts below, so they should still work! If not, then please add a comment below. Btw: Isn’t it &lt;strong&gt;amazing&lt;/strong&gt; that modland is still up and running after all these years?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/purple_motion.png&quot; alt=&quot;iTunes screenshot of purple motions tracks&quot;&gt;&lt;/p&gt;
&lt;p&gt;If you were part of the demoscene in your former life, if you were and still are fond of modules (those sound files with the mod, xm, s3m, it, &amp;hellip; ending), if you are a linux user and if you still want to listen to this music on your computer without doing all the tweaks of installing (or even compiling) music player plugins for itunes or amarok or if you simply want to listen to Purple Motions tunes on your mp3 player then this little tutorial is for you. If not, then you won’t have read that far anyway..&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://howto.philippkeller.com/tags/python/"/>
    
      <category term="music" scheme="http://howto.philippkeller.com/tags/music/"/>
    
      <category term="demoscene" scheme="http://howto.philippkeller.com/tags/demoscene/"/>
    
      <category term="modules" scheme="http://howto.philippkeller.com/tags/modules/"/>
    
  </entry>
  
  <entry>
    <title>Tagsystems: performance tests</title>
    <link href="http://howto.philippkeller.com/2005/06/19/Tagsystems-performance-tests/"/>
    <id>http://howto.philippkeller.com/2005/06/19/Tagsystems-performance-tests/</id>
    <published>2005-06-19T15:09:00.000Z</published>
    <updated>2018-01-26T22:16:47.905Z</updated>
    
    <content type="html"><![CDATA[<p>In my <a href="/2005/04/24/Tags-Database-schemas/">previous article named “Tags: database schemas”</a> we analysed different database schemas on how they could meet the needs of tag systems. In this article, the focus is on performance (speed). That is: if you want to build a tagsystem that performs good with about 1 million items (bookmarks for instance), then you may want to have a look at the following result of my performance tests.<br>In this article I tested tagging of bookmarks, but as you can tag pretty much anything, this goes for tagging systems in general.<a id="more"></a></p><p>I tested the following schemas (I keep the naming from the previous article):</p><ul><li><strong>mysqlicious</strong>: One table. Tags are space separated in column “tags”; <a href="/2005/04/24/Tags-Database-schemas#mysqlicious">as introduced</a></li><li><strong>mysqlicious fulltext</strong>: Same schema but with <a href="http://dev.mysql.com/doc/mysql/en/fulltext-search.html" target="_blank" rel="external">mysql fulltext</a> on the tag column; <a href="/2005/05/05/Tags-with-MySQL-fulltext/">as introduced</a></li><li><strong>scuttle</strong>: Two tables: One for bookmarks, one for tags. Tag-table has foreign key to bookmark table; <a href="/2005/04/24/Tags-Database-schemas#scuttle">as introduced</a></li><li><strong>toxi</strong>: Three tables: One for bookmarks, one for tags, one for junction; <a href="/2005/04/24/Tags-Database-schemas#toxi">as introduced</a></li></ul><p>You may want to have a close watch at the details of the schemas when having a look at the <a href="http://pastie.org/5480706" target="_blank" rel="external">sql-create-table-queries</a>.</p><p>But let’s go directly to the results. The x-axis depicts the number of bookmarks in the corresponding database, on the y-axis you see how much time each query took to execute.<!-- more --></p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a><a name="#results" id="#results"></a>Results</h3><h4 id="Intersection-250-tag-set"><a href="#Intersection-250-tag-set" class="headerlink" title="Intersection: 250 tag set"></a>Intersection: 250 tag set</h4><p><img src="/images/intersection_250_3_i300.png" alt="Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset" title="Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset"></p><p>The first two tests are done with 250 tags in the small dataset. I think the queries in the “1 million bookmarks database” are the only size we should pay attention to. I mean if you have a small number of bookmarks, performance isn’t really a thing to bother..</p><p>We run intersection queries, like</p><blockquote><div>I want to search for bookmarks tagged with “design” and “html”</div></blockquote><p>You see that, not surprisingly, mysqlicious with its <code>WHERE tag LIKE &quot;% tag %&quot;</code> is very slow. That is, MySQL has to go through the whole dataset and test each bookmark against the query.<br>What actually <strong>is</strong> surprising me, is that the fulltext search of mysql is not that high-performance. In fact it is not faster then the <code>LIKE</code>-query in the MySQLicious DB. This really disappointed me. I tried to do any quirks possible to make this faster as <a href="/2005/05/05/Tags-with-MySQL-fulltext/">I think, a tag-database-system with mysql fulltext would be very easy and like the only thing you should head to..</a>.<br>What is surprising me too, is that the queries on the 3 table schema are about double as fast the the ones on the two-table ones(<a href="http://pastie.org/5480722" target="_blank" rel="external">take a look at the queries</a> if you think you could give me a hint on this). Noticeable is, that in the scuttle and toxi-variant, the more queries were run, the faster they were. I didn’t do any tests with queries and inserts mixed so this may be coming from just plain good caching and this effect possible doesn’t show up on live bookmark management systems.</p><h4 id="Intersection-999-tag-set"><a href="#Intersection-999-tag-set" class="headerlink" title="Intersection: 999 tag set"></a>Intersection: 999 tag set</h4><p><img src="/images/intersection_999_3_300.png" alt="Intersection test with 300 queries, up to three tags in query, 250 tags in small dataset"><br>Now have a look to what happens if we broaden our small tag set: MySQLicious with fulltext suddenly gets the performance leader. That means, if you have a bookmark management system with diverse tags (this most probably comes from the fact that there are many users), the fulltext solution is possibly the way to go.<br>So now, as you see, choosing the right schema is all about tag distribution. In my previous post about guessing the overall tag distribution on <a href="http://del.icio.us" target="_blank" rel="external">del.icio.us</a>, I came to the conclusion, that delicious’ most popular tag “design” is showing up in 3.2% of all bookmarks on <a href="http://del.icio.us" target="_blank" rel="external">del.icio.us</a>. So then, what is the mean tag distribution?</p><ul><li>If we say 1% (a tag shows up in 1/100 of all bookmarks on an average) that makes our small tag set 250 tags big</li><li>If we say 0.25%, the small tag set grows to a size of 1000</li><li>If we say 0.1%, the small set will contain 2500 tags</li></ul><p>So I’d suggest that if your average distribution is 1%, take “toxi”, if the distribution is broader, take “MySQLicious fulltext”.</p><p>If you take a closer look, you can see that the fulltext schema stayed as fast as when queried in the 250 tag set. That means, if you want to go sure your tag system responds ok in every situation, you should go with the “mysql fulltext” schema.</p><h4 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h4><p><img src="/images/union_full_250_3.png" alt="Union test with 250 tags in small dataset"><br>When doing a union query we say</p><blockquote><p>I want to search for all the bookmarks that are tagged either with “delicious” or “del.icio.us”</p></blockquote><p>This queries, you guessed, are handled the fastest by “MySQLicious schema” with its <code>LIKE</code>-queries: MySQL seeks through the bookmarks, harvesting all bookmarks with one of the given tags and says “I’m finished!” when it was at bookmark number #968, because it found 50 bookmarks. Whereas in the other schemas, MySQL has to join the tags with the bookmarks first and only then could search though it..</p><h4 id="Insert"><a href="#Insert" class="headerlink" title="Insert"></a>Insert</h4><p><img src="/images/setup_250.png" alt="Setup database schemas with the data: 250 tags in small dataset"><br>When comparing the different schemas on the time of the insert-“statements” of one bookmark, the result isn’t very surprising (notice that I’ve changed the scale of the y-axis).<br>Mysqlicious with it’s 1 table is very fast indeed, its variation with fulltext had to create the fulltext index and therefore is a bit slower. Scuttle, with its 2 tables and toxi with its 3 tables are at least two respectively three times as slow. I have to remark, that I used quite a bit of caching for the toxi schema, as I didn’t want hours to have the data ready..</p><p>I guess it doesn’t really make sense to base your decision, which schema to take on the time for an insert: Bookmark inserts are about 100 times as fast as the intersection queries..</p><h4 id="«What-That-slow-»"><a href="#«What-That-slow-»" class="headerlink" title="«What? That slow??»"></a>«What? That slow??»</h4><p>You said it. You don’t want your intersection queries take 0.2 seconds each. That would bring your system to its knees.</p><p>There are some recipes to avoid that:</p><h5 id="Caching"><a href="#Caching" class="headerlink" title="Caching"></a>Caching</h5><p>I think, you don’t come around good old caching. I think that you could cache results to a query like “mysql+tagging” for about an hour or so. If a user queries his own items, I would lower the cache time (as up-to-dateness is more important with his own items).<br>Then, I expect if you for instance cache items per tag and intersection them with a decent algorithm, that could be faster..</p><h5 id="The-Best-Of-Both-Worlds"><a href="#The-Best-Of-Both-Worlds" class="headerlink" title="The Best Of Both Worlds"></a>The Best Of Both Worlds</h5><p>I think you could have “mysqlicous fulltext” and “toxi” running at the same time. That means you have to update/insert in both schemas but when you have to query, you could take the one you think is faster: For simple union the mysqlicious without fulltext search, for intersection queries with common tags the toxi, and for those with uncommon tags the mysqlicious fulltext variant.</p><h5 id="Slicing-and-dicing"><a href="#Slicing-and-dicing" class="headerlink" title="Slicing and dicing"></a>Slicing and dicing</h5><p>You could “slice and dice” data, that is: you slice your user/tag/item-room and build fact tables. You “prebuild” your results in a way. This way, inserts take long but queries themself should be much faster. In our examples, you would for instance first query the tag-intersections on “toxi” and then get the facts about each bookmark out of the “mysqlicious”-fact-table. But you really should read Nitins posts, as they give a lot of insight.</p><h5 id="Using-a-non-RDBMS-system"><a href="#Using-a-non-RDBMS-system" class="headerlink" title="Using a non RDBMS system"></a>Using a non RDBMS system</h5><p><strong>Update:</strong> It’s been about a year since I wrote that article, and during that year I came to the conclusion that <a href="http://en.wikipedia.org/wiki/RDBMS" target="_blank" rel="external">RDBMS</a> systems don’t scale good in systems that have more than 1 million items. Yes, this is a warning: If you are planning to build a large scale system then look for alternatives to <a href="http://en.wikipedia.org/wiki/RDBMS" target="_blank" rel="external">RDBMS</a> systems. To quote Joshua Schachter, founder of <a href="http://del.icio.us" target="_blank" rel="external">delicious</a>:<br>«tags doesn’t map to sql at all. so use partial indexing.»[<a href="http://www.redmonk.com/jgovernor/2006/02/08/things-weve-learned-josh-schachter-quotes-of-the-day/" target="_blank" rel="external">Joshua Schachter at Carson Summit</a>]<br>I didn’t try any of the non-RDBMS system but it looks like <a href="http://lucene.apache.org/java/docs/" target="_blank" rel="external">Apache Lucene</a> and <a href="http://lucene.apache.org/hadoop/" target="_blank" rel="external">Hadoop</a>.</p><h3 id="Performance-Tests-Setup"><a href="#Performance-Tests-Setup" class="headerlink" title="Performance Tests Setup"></a><a id="setup" name="setup"></a>Performance Tests Setup</h3><p>Now, if you have read that far, you probably want to know some background information: As you noticed, for each schema, I set up 4 databases, one database holding 1000 bookmarks, the next 10’000, then 100’000 and the fourth 1 million bookmarks. The inserted tags (as well as urls) are random English words taken from two sets of tags:</p><ul><li>the large set containing about 44’000 tags (that are simple English words)</li><li>the small set is varying in size (the results shown here are taken from 250 and 999 tag sets)</li></ul><p>Every bookmark gets one to ten tags attached. Every odd tag is from the large set, alternately taken from small and large set. Every schema got exactly the same bookmarks and tag data.</p><p>Then every schema got queried with an alternately 1-3 tag query. So the first query is for instance just “blog”, the second “design+css”, the third “webdesign+music+software”, the fourth again with just one tag an so forth..<br>All the tags for the queries are taken from the small set so that the queries don’t all end in empty results..<br>All the queries are tested and work. The outcome of each query on the three schemas is exactly the same.</p><h4 id="Mysql-Setup"><a href="#Mysql-Setup" class="headerlink" title="Mysql Setup"></a>Mysql Setup</h4><p>I used mysql 4.0.21.<br>An excerpt from <code>/etc/my.cnf</code> (I think these are the relevant settings to this performance test)</p><pre>key_buffer=300Mquery_cache_size=30Mquery_cache_limit=30Mtable_cache = 64ft_min_word_len = 2ft_stopword_file = ''</pre><h4 id="System"><a href="#System" class="headerlink" title="System"></a>System</h4><blockquote><div>CPU: 3GHz Dual Xeon<br>Cache: 1MB<br>Harddisk: SCSI Ultra 320 Atlas 10K, no RAID<br>RAM: 3GB</div></blockquote><h4 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h4><ul><li>Queries select just the id of a bookmark. I assume that you have to do a second query to get all the wished data to display. I know that this is not fair towards the mysqlicious schema.</li><li>I left out user data, as I assume, user data columns wouldn’t change the outcome of this tests. I wanted to keep the schemas as simple as possible.</li><li>Each query is done with <code>LIMIT 50</code> as I assume that a normal application doesn’t want to get all bookmarks. I assume nobody wants to <code>order</code> bookmarks by any dimension, because this would be <strong>very</strong> expensive (ever wondered why you cannot sort bookmarks on <a href="http://del.icio.us" target="_blank" rel="external">del.icio.us</a> by date or similar? You get it..)</li></ul><h3 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h3><p>Thanks to <a href="http://www.citrin.ch" target="_blank" rel="external">Citrin</a>, the company I work, to let me use our new server to run the queries. The server didn’t have much anything else to do so the results should be accurate.<br>The graphs are done using <a href="http://jpgraph.net/" target="_blank" rel="external">JpGraph</a>. Very easy to use and produces beautiful images.</p><h3 id="Further-reading"><a href="#Further-reading" class="headerlink" title="Further reading"></a>Further reading</h3><ul><li><a href="http://www.webmasterworld.com/forum23/3557.htm" target="_blank" rel="external">WebmasterWorld forum: mysql fulltext performance issues</a></li><li><a href="http://jeremy.zawodny.com/mysql/mysql-optimization.html" target="_blank" rel="external">Powerpoint article of jeremy zawodny</a>on Mysql optimisation</li><li><a href="http://www.petefreitag.com/item/389.cfm" target="_blank" rel="external">Pete Freitag did a sort of review of this article</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In my &lt;a href=&quot;/2005/04/24/Tags-Database-schemas/&quot;&gt;previous article named “Tags: database schemas”&lt;/a&gt; we analysed different database schemas on how they could meet the needs of tag systems. In this article, the focus is on performance (speed). That is: if you want to build a tagsystem that performs good with about 1 million items (bookmarks for instance), then you may want to have a look at the following result of my performance tests.&lt;br&gt;In this article I tested tagging of bookmarks, but as you can tag pretty much anything, this goes for tagging systems in general.
    
    </summary>
    
    
      <category term="Tagging" scheme="http://howto.philippkeller.com/tags/Tagging/"/>
    
      <category term="Del.icio.us" scheme="http://howto.philippkeller.com/tags/Del-icio-us/"/>
    
      <category term="MySQL" scheme="http://howto.philippkeller.com/tags/MySQL/"/>
    
      <category term="Performance" scheme="http://howto.philippkeller.com/tags/Performance/"/>
    
  </entry>
  
  <entry>
    <title>Tags with MySQL fulltext</title>
    <link href="http://howto.philippkeller.com/2005/05/05/Tags-with-MySQL-fulltext/"/>
    <id>http://howto.philippkeller.com/2005/05/05/Tags-with-MySQL-fulltext/</id>
    <published>2005-05-05T17:09:00.000Z</published>
    <updated>2018-01-26T10:32:06.255Z</updated>
    
    <content type="html"><![CDATA[<p>While setting up the promised performance test in my <a href="http://tagging.pui.ch/post/37027745720/tags-database-schemas" target="_blank" rel="external">last post</a>, I did some tests with the <a href="http://dev.mysql.com/doc/mysql/en/fulltext-search.html" target="_blank" rel="external">MySQL fulltext features</a> and it seems that they are built for tagging systems. Take a look at the queries (if it is not clear for you what is done here, please read <a href="http://tagging.pui.ch/post/37027745720/tags-database-schemas" target="_blank" rel="external">my previous post</a>).<a id="more"></a></p><p>I took the <a href="http://nanovivid.com/projects/mysqlicious/" target="_blank" rel="external">MySQLicious</a> schema and added <code>ALTER TABLE</code>delicious<code>ADD FULLTEXT (</code>tags<code>)</code>.<br>The full schema:</p><blockquote><div><br><div><code>CREATE TABLE</code>delicious<code>(</code>id<code>int(11) NOT NULL auto_increment,</code>url<code>text,</code>description<code>text,</code>extended<code>text,</code>tags<code>text,</code>date<code>datetime default NULL,</code>hash<code>varchar(255) default NULL, PRIMARY KEY (</code>id<code>), KEY</code>date<code>(</code>date<code>), FULLTEXT KEY</code>tags<code>(</code>tags<code>)) ENGINE=MyISAM</code></div><br></div></blockquote><h2 id="Queries"><a href="#Queries" class="headerlink" title="Queries"></a>Queries</h2><h3 id="Intersection"><a href="#Intersection" class="headerlink" title="Intersection"></a>Intersection</h3><p>Intersections can be done using <a href="http://dev.mysql.com/doc/mysql/en/fulltext-boolean.html" target="_blank" rel="external">boolean fulltext search</a> (since MySQL 4.01):<br>Query for semweb+search:</p><p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+semweb +search&#39; IN BOOLEAN MODE)</code></p><p>Now this was easy. And, you guess it, Minus is very similar:</p><h3 id="Minus"><a href="#Minus" class="headerlink" title="Minus"></a>Minus</h3><p><span>Query for search+webservice-search:</span></p><p><span></span><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+search +webservice -search&#39; IN BOOLEAN MODE)</code></p><h3 id="Brackets"><a href="#Brackets" class="headerlink" title="Brackets"></a>Brackets</h3><p><span>Even brackets are possible:</span><br>Query for (del.icio.us|delicious)+(webservice|project):</p><p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;+(del.icio.us delicious) +(webservice project)&#39; IN BOOLEAN MODE)</code></p><h3 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h3><p><img src="https://lh5.googleusercontent.com/-KI8lkatasrA/UL0A4ABDj4I/AAAAAAAALEY/X2i8ehJDAiE/s508/union_result.png" alt="union DB result"></p><p><span>For union you could use the already mentioned boolean mode, but if you want to have the results ordered so that the bookmark with the most “hits” is the first entry of the result try this sort of query:</span></p><p><code>SELECT * FROM delicious WHERE MATCH (tags) AGAINST (&#39;delicious clone project webservice&#39;)</code></p><p>If you take a look at the screenshot of the first 7 results of the query run on my DB, you can see that the first hit has got all four tags we searched for, the second has got two and the rest has got just one of them. Like this you can do a “find similar entries” very easily.</p><h2 id="Downsides-and-problems"><a href="#Downsides-and-problems" class="headerlink" title="Downsides and problems"></a>Downsides and problems</h2><p><span>There are two points where difficulties can accur: When MySQL builds its index out of the tags and when searching for specific tags. I stumbled on three problems:</span></p><h3 id="Stopcharacters"><a href="#Stopcharacters" class="headerlink" title="Stopcharacters"></a>Stopcharacters</h3><p><span>If you insert tags with characters like “-“ (as in “my-comment”), then MySQL will make two index entries: One for “my” and one for “comment”. Vice versa if you search for “my-comment” you’ll find bookmarks with tag “my” and those with tag “comment”. It seems that this problem can be eliminated by </span><a href="http://dev.mysql.com/doc/mysql/en/fulltext-search.html" target="_blank" rel="external">setting the character set of the column “tags” to <code>latin1_bin</code></a><span> but this feature is not available before MySQL 4.1.</span><br>But nontheless this shouldn’t be a showstopper. You could replace “-“ with a string, say “<em>minus</em>“. This is ugly but should do it..</p><h3 id="Stopwords"><a href="#Stopwords" class="headerlink" title="Stopwords"></a>Stopwords</h3><p>When searching for or indexing tags like “against” or “brief” (<a href="http://www.databasejournal.com/features/mysql/article.php/1578331" target="_blank" rel="external">full list of stopwords</a>), these tags will not be regarded.<br>Since MySQL 4.0.10 you can <a href="http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html" target="_blank" rel="external">customize your stopwordlist</a>.</p><h3 id="Minimum-length-of-a-tag"><a href="#Minimum-length-of-a-tag" class="headerlink" title="Minimum length of a tag"></a>Minimum length of a tag</h3><p>Per default, the minimal length of a word indexed by MySQL fulltext is 4 characters. You should therefor <a href="http://dev.mysql.com/doc/mysql/en/fulltext-fine-tuning.html" target="_blank" rel="external">edit <code>my.cnf</code></a> in order to set the minimal tag length to 1.</p><h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2><p>This solution scales ok. I did tests with tables from 1000 to 1 million bookmarks.<br>The time for inserting a bookmark is the same for small as for big tables. The time for an intersection query was 0.001 (finding 0.7 urls averaged) in the 1000-table and 0.1 seconds in the 1 million-table(finding 70 bookmarks averaged). There are some <a href="http://dev.mysql.com/doc/mysql/en/fulltext-search.html" target="_blank" rel="external">discussions about if MySQLs fulltext search is fast or not (have a look at the user comments)</a>. Quick performance tests showed that it is about 10 times as fast as the LIKE-queries mentioned in <a href="http://tagging.pui.ch/post/37027745720/tags-database-schemas" target="_blank" rel="external">my previous post</a>. But I guess it is not fast enough for webservices like <a href="http://del.icio.us" target="_blank" rel="external">del.icio.us</a>, I guess this services have to run more than 10 queries a second and then this solution is too slow..<br>Update: <a href="http://tagging.pui.ch/post/37027746608/tagsystems-performance-tests" target="_blank" rel="external">I tested the performance of this setup</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;While setting up the promised performance test in my &lt;a href=&quot;http://tagging.pui.ch/post/37027745720/tags-database-schemas&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;last post&lt;/a&gt;, I did some tests with the &lt;a href=&quot;http://dev.mysql.com/doc/mysql/en/fulltext-search.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MySQL fulltext features&lt;/a&gt; and it seems that they are built for tagging systems. Take a look at the queries (if it is not clear for you what is done here, please read &lt;a href=&quot;http://tagging.pui.ch/post/37027745720/tags-database-schemas&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;my previous post&lt;/a&gt;).
    
    </summary>
    
    
      <category term="Tagging" scheme="http://howto.philippkeller.com/tags/Tagging/"/>
    
      <category term="MySQL" scheme="http://howto.philippkeller.com/tags/MySQL/"/>
    
  </entry>
  
</feed>
